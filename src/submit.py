import os
import torch
import pandas as pd
import numpy as np
import argparse
from pathlib import Path
import sys
import ast

# --- ç¡®ä¿è„šæœ¬å¯ä»¥æ‰¾åˆ°æ‚¨çš„è‡ªå®šä¹‰æ¨¡å— ---
SRC_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SRC_DIR.parent
if str(SRC_DIR) not in sys.path:
    sys.path.insert(0, str(SRC_DIR))

# --- ä»æ‚¨çš„é¡¹ç›®æ¨¡å—ä¸­å¯¼å…¥ ---
try:
    from models.align_hetero import AlignHeteroMLP
    from data_loader import get_data_and_scalers
    import config  # <-- å¯¼å…¥ config æ–‡ä»¶
except ImportError as e:
    print(f"é”™è¯¯: æ— æ³•å¯¼å…¥å¿…è¦çš„æ¨¡å—ã€‚è¯·ç¡®ä¿æ­¤è„šæœ¬ä½äº 'src' ç›®å½•ä¸­ã€‚")
    print(f"è¯¦ç»†ä¿¡æ¯: {e}")
    sys.exit(1)


def run_inference(opamp_type, model_path, test_file_path, output_file_path, hidden_dims, dropout_rate, device):
    """
    æ‰§è¡Œå®Œæ•´çš„æ¨ç†æµç¨‹ï¼šåŠ è½½æ¨¡å‹ã€åŠ è½½æ•°æ®ã€é¢„å¤„ç†ã€é¢„æµ‹ã€åå¤„ç†ã€ä¿å­˜ã€‚
    """
    print(f"--- [submit.py] å¼€å§‹ä¸º {opamp_type} ç”Ÿæˆæäº¤æ–‡ä»¶ ---")

    # --- 1. æ£€æŸ¥è·¯å¾„ ---
    if not model_path.exists():
        print(f"âŒ [submit.py] é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
        print(f"   è¯·å…ˆè¿è¡Œ train.py ç”Ÿæˆ {model_path.name} æ–‡ä»¶ã€‚")
        return
    if not test_file_path.exists():
        print(f"âŒ [submit.py] é”™è¯¯: æ‰¾ä¸åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶: {test_file_path}")
        return

    # --- 2. åŠ è½½ Scalers ---
    print("--- [submit.py] æ­£åœ¨åŠ è½½ Scalers... ---")
    data_payload = get_data_and_scalers(opamp_type=opamp_type)
    x_scaler = data_payload['x_scaler']
    y_scaler = data_payload['y_scaler']
    train_x_cols = data_payload['raw_source'][0].columns.tolist()
    train_y_cols = data_payload['raw_source'][1].columns.tolist()

    # --- 3. åŠ è½½æ¨¡å‹ ---
    print(f"--- [submit.py] æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path.name} ---")
    model = AlignHeteroMLP(
        input_dim=x_scaler.n_features_in_,
        output_dim=y_scaler.n_features_in_,
        hidden_dims=hidden_dims,
        dropout_rate=dropout_rate
    ).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()

    # --- 4. åŠ è½½å¹¶é¢„å¤„ç†æµ‹è¯•æ•°æ® ---
    print(f"--- [submit.py] æ­£åœ¨è¯»å–å’Œé¢„å¤„ç†æµ‹è¯•æ•°æ®... ---")
    X_test_df = pd.read_csv(test_file_path)
    X_test_df_reordered = X_test_df[train_x_cols]
    X_test_scaled = x_scaler.transform(X_test_df_reordered)
    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)

    # --- 5. æ‰§è¡Œæ¨¡å‹æ¨ç† ---
    print(f"--- [submit.py] æ­£åœ¨æ‰§è¡Œæ¨¡å‹æ¨ç†... ---")
    with torch.no_grad():
        mu_scaled, _, _ = model(X_test_tensor)
        mu_scaled_np = mu_scaled.cpu().numpy()

    # --- 6. åå¤„ç† (åæ ‡å‡†åŒ–) ---
    print("--- [submit.py] æ­£åœ¨åæ ‡å‡†åŒ–å’Œåå¤„ç†... ---")
    y_pred_unscaled = y_scaler.inverse_transform(mu_scaled_np)
    y_pred_physical = y_pred_unscaled.copy()
    log_cols = config.LOG_TRANSFORMED_COLS

    for i, col_name in enumerate(train_y_cols):
        if col_name in log_cols:
            y_pred_physical[:, i] = np.expm1(y_pred_unscaled[:, i])  # è¿˜åŸlogå˜æ¢

    # --- 7. ä¿å­˜ä¸ºæŒ‡å®šæ ¼å¼ ---
    print(f"--- [submit.py] æ­£åœ¨ä¿å­˜ç»“æœ (é€—å·åˆ†éš”) è‡³: {output_file_path.name} ---")
    np.savetxt(
        output_file_path,
        y_pred_physical,
        fmt='%.10g',  # ä½¿ç”¨é€šç”¨æµ®ç‚¹æ•°æ ¼å¼
        delimiter=','   # ä½¿ç”¨é€—å·åˆ†éš”
    )
    print(f"âœ… [submit.py] æˆåŠŸç”Ÿæˆæäº¤æ–‡ä»¶: {output_file_path.name}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="æ¨¡å‹æ¨ç†è„šæœ¬ (ä»config.pyè¯»å–é»˜è®¤å€¼)")

    # --- æ‰€æœ‰å‚æ•°ç°åœ¨éƒ½æ˜¯å¯é€‰çš„ ---
    parser.add_argument("--opamp", type=str, default=None,
                        help=f"è¿æ”¾ç±»å‹ (é»˜è®¤: ä» config.py è¯»å– '{config.OPAMP_TYPE}')")
    parser.add_argument("--model-path", type=str, default=None,
                        help="æŒ‡å‘ .pth æ¨¡å‹æ–‡ä»¶çš„è·¯å¾„ (é»˜è®¤: è‡ªåŠ¨æ¨æ–­)")
    parser.add_argument("--test-file", type=str, default=None,
                        help="è¾“å…¥çš„æµ‹è¯•æ•°æ® .csv è·¯å¾„ (é»˜è®¤: è‡ªåŠ¨æ¨æ–­)")
    parser.add_argument("--output-file", type=str, default=None,
                        help="è¾“å‡ºçš„æäº¤æ–‡ä»¶çš„è·¯å¾„ (é»˜è®¤: è‡ªåŠ¨æ¨æ–­)")
    parser.add_argument("--hidden-dims", type=str, default=None,
                        help=f"æ¨¡å‹ç»“æ„ (é»˜è®¤: ä» config.py è¯»å– '{config.HIDDEN_DIMS}')")
    parser.add_argument("--dropout-rate", type=float, default=None,
                        help=f"Dropout (é»˜è®¤: ä» config.py è¯»å– '{config.DROPOUT_RATE}')")
    parser.add_argument("--device", type=str, default=None,
                        help=f"è®¾å¤‡ (é»˜è®¤: ä» config.py è¯»å– '{config.DEVICE}')")

    args = parser.parse_args()

    print("="*60)
    print("ğŸš€ å¼€å§‹ç”Ÿæˆæäº¤æ–‡ä»¶...")

    # --- æ ¸å¿ƒé€»è¾‘ï¼šä½¿ç”¨ config.py ä½œä¸ºé»˜è®¤å€¼ ---

    # 1. è®¾ç½®åŸºç¡€å‚æ•°
    opamp_type = args.opamp if args.opamp else config.OPAMP_TYPE
    device = torch.device(args.device if args.device else config.DEVICE)

    if args.hidden_dims:
        hidden_dims_list = ast.literal_eval(args.hidden_dims)
    else:
        hidden_dims_list = config.HIDDEN_DIMS

    dropout_rate = args.dropout_rate if args.dropout_rate is not None else config.DROPOUT_RATE

    # 2. æ ¹æ® opamp_type è‡ªåŠ¨æ¨æ–­æ–‡ä»¶è·¯å¾„
    if opamp_type == '5t_opamp':
        default_test_file = PROJECT_ROOT / \
            "data/02_public_test_set/features/features_A.csv"
        default_output_file = PROJECT_ROOT / "predA"
    elif opamp_type == 'two_stage_opamp':  # å¢åŠ äº†å¯¹Bæ–‡ä»¶çš„æ”¯æŒ
        default_test_file = PROJECT_ROOT / \
            "data/02_public_test_set/features/features_B.csv"
        default_output_file = PROJECT_ROOT / "predB"
    else:
        print(f"âŒ é”™è¯¯: æœªçŸ¥çš„ opamp_type '{opamp_type}'")
        sys.exit(1)

    # é»˜è®¤æ¨¡å‹è·¯å¾„ (å‡è®¾ 'results' ç›®å½•åœ¨é¡¹ç›®æ ¹ç›®å½•)
    default_model_path = PROJECT_ROOT / \
        "results" / f"{opamp_type}_finetuned.pth"

    # 3. å†³å®šæœ€ç»ˆä½¿ç”¨çš„è·¯å¾„ (å‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆ)
    model_path = Path(
        args.model_path) if args.model_path else default_model_path
    test_file_path = Path(
        args.test_file) if args.test_file else default_test_file
    output_file_path = Path(
        args.output_file) if args.output_file else default_output_file

    print(f"--- æœ€ç»ˆé…ç½® ---")
    print(f"  - Opamp ç±»å‹: {opamp_type}")
    print(f"  - æ¨¡å‹æ–‡ä»¶:   {model_path}")
    print(f"  - æµ‹è¯•æ–‡ä»¶:   {test_file_path}")
    print(f"  - è¾“å‡ºæ–‡ä»¶:   {output_file_path}")
    print(f"  - è®¾å¤‡:       {device}")
    print(f"  - ç»“æ„:       {hidden_dims_list}")
    print("="*60)

    # 4. æ‰§è¡Œæ¨ç†
    run_inference(
        opamp_type=opamp_type,
        model_path=model_path,
        test_file_path=test_file_path,
        output_file_path=output_file_path,
        hidden_dims=hidden_dims_list,
        dropout_rate=dropout_rate,
        device=device
    )

# src/run_experiments.py (æœ€ç»ˆå½¢æ€ - å…¨è‡ªåŠ¨æµæ°´çº¿)
import subprocess
import os
import pandas as pd
import time
import json
import shutil
import logging
import sys
from pathlib import Path

# --- ä»é¡¹ç›®æ¨¡å—ä¸­å¯¼å…¥ ---
from find_lr_utils import find_pretrain_lr, find_finetune_lr
from models.align_hetero import AlignHeteroMLP
from data_loader import get_data_and_scalers
import config

# ==============================================================================
# --- 0. è·¯å¾„å’Œå®éªŒæ§åˆ¶ ---
# ==============================================================================
SRC_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SRC_DIR.parent

# ==============================================================================
# --- 1. å®šä¹‰ä½ çš„å®éªŒæœç´¢ç©ºé—´ ---
# ==============================================================================
# hidden_dims (å¿…éœ€): æ¨¡å‹ç»“æ„
# dropout_rate (å¯é€‰): è¦†ç›–é»˜è®¤çš„ config.DROPOUT_RATE
# lr_finetune (å¯é€‰): è¦†ç›–è‡ªåŠ¨æŸ¥æ‰¾çš„ lr_finetune (è®¾ä¸º "auto" æˆ–çœç•¥åˆ™è‡ªåŠ¨æŸ¥æ‰¾)
BASE_EXPERIMENT_GRID = [
    {
        "name": "1",
        "hidden_dims": [256, 256, 256, 256],
        "dropout_rate": 0.1
    },
    {
        "name": "2",
        "hidden_dims": [256, 256, 256, 256],
        "dropout_rate": 0.15
    },
    {
        "name": "3",
        "hidden_dims": [256, 256, 256, 256],
        "dropout_rate": 0.2
    },
    {
        "name": "4",
        "hidden_dims": [256, 256, 256, 256],
        "dropout_rate": 0.25
    },
    {
        "name": "5",
        "hidden_dims": [256, 256, 256, 256],
        "dropout_rate": 0.3
    },
    {
        "name": "6",
        "hidden_dims": [256, 256, 256, 256],
        "dropout_rate": 0.35
    },
    {
        "name": "7",
        "hidden_dims": [256, 256, 256, 256],
        "dropout_rate": 0.4
    },
    {
        "name": "8",
        "hidden_dims": [256, 256, 256, 256],
        "dropout_rate": 0.45
    },
    {
        "name": "1",
        "hidden_dims": [128, 256, 512],
        "dropout_rate": 0.05
    },
    {
        "name": "2",
        "hidden_dims": [128, 256, 512],
        "dropout_rate": 0.1
    },
    {
        "name": "3",
        "hidden_dims": [128, 256, 512],
        "dropout_rate": 0.15
    },
    {
        "name": "4",
        "hidden_dims": [128, 256, 512],
        "dropout_rate": 0.2
    },
    {
        "name": "5",
        "hidden_dims": [128, 256, 512],
        "dropout_rate": 0.25
    },
    {
        "name": "6",
        "hidden_dims": [128, 256, 512],
        "dropout_rate": 0.3
    },
    {
        "name": "7",
        "hidden_dims": [128, 256, 512],
        "dropout_rate": 0.35
    },
]

# --- å®éªŒæ§åˆ¶è®¾ç½® ---
NUM_REPETITIONS = 1  # å»ºè®®å…ˆè®¾ä¸º1ï¼Œè·‘é€šåå†æ”¹ä¸º3
OPAMP_TYPE = '5t_opamp'
BASE_RESULTS_DIR = PROJECT_ROOT / "results_experiments_full_auto"

# --- æäº¤æ–‡ä»¶è®¾ç½® ---
TEST_FILE_PATH = PROJECT_ROOT / "data/02_public_test_set/features/features_A.csv"
SUBMISSION_FILE_PREFIX = "predA"  # å°†ç”Ÿæˆ predA_1, predA_2 ...

# ==============================================================================
# --- 2. è®¾ç½®æ—¥å¿—ç³»ç»Ÿ ---
# ==============================================================================
BASE_RESULTS_DIR.mkdir(parents=True, exist_ok=True)
log_file_path = BASE_RESULTS_DIR / "experiment_log.txt"

# é…ç½®æ—¥å¿—è®°å½•å™¨
logging.basicConfig(
    level=logging.INFO,
    format="%(message)s",  # åªè®°å½•åŸå§‹æ¶ˆæ¯
    handlers=[
        logging.FileHandler(log_file_path, mode='w', encoding='utf-8'),  # å†™å…¥æ–‡ä»¶
        logging.StreamHandler(sys.stdout)  # åŒæ—¶ä¹Ÿæ‰“å°åˆ°æ§åˆ¶å°
    ]
)
logger = logging.getLogger()

# ==============================================================================
# --- 3. åŠ¨æ€ç”Ÿæˆå®Œæ•´çš„å®éªŒåˆ—è¡¨ ---
# ==============================================================================
EXPERIMENT_GRID = []
for exp_params in BASE_EXPERIMENT_GRID:
    for run_num in range(1, NUM_REPETITIONS + 1):
        new_params = exp_params.copy()
        new_params['name'] = f"{exp_params['name']}_run{run_num}"
        new_params['base_name'] = exp_params['name']
        EXPERIMENT_GRID.append(new_params)

# ==============================================================================
# --- 4. å®éªŒæ‰§è¡Œä¸ç»“æœæ•è· ---
# ==============================================================================
RESULTS_DF = []
start_time = time.time()

logger.info(f"--- å®éªŒå¼€å§‹ï¼šå…± {len(EXPERIMENT_GRID)} æ¬¡è¿è¡Œ ---")
logger.info(f"--- ç»“æœå°†ä¿å­˜åœ¨: {BASE_RESULTS_DIR} ---")

# --- é¢„å…ˆåŠ è½½ä¸€æ¬¡æ•°æ® ---
logger.info("æ­£åœ¨é¢„åŠ è½½æ•°æ®...")
data = get_data_and_scalers(opamp_type=OPAMP_TYPE)
input_dim = data['source'][0].shape[1]
output_dim = data['source'][1].shape[1]
logger.info("æ•°æ®åŠ è½½å®Œæˆã€‚")


def run_command(command, log_prefix=""):
    """è¾…åŠ©å‡½æ•°ï¼šæ‰§è¡Œå­è¿›ç¨‹å¹¶å®æ—¶æ‰“å°è¾“å‡º"""
    logger.info(f"--- [CMD] {log_prefix} æ­£åœ¨æ‰§è¡Œ: {' '.join(command)} ---")
    process = subprocess.Popen(
        command, cwd=SRC_DIR, stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT, text=True, encoding='utf-8'
    )
    output_lines = []
    for line in iter(process.stdout.readline, ''):
        line = line.strip()
        if line:
            logger.info(f"[{log_prefix}] {line}")
            output_lines.append(line)
    process.wait()
    logger.info(f"--- [CMD] {log_prefix} æ‰§è¡Œå®Œæ¯• ---")
    return process.returncode == 0, output_lines


for i, params in enumerate(EXPERIMENT_GRID):
    exp_name = f"{i+1:02d}_{params['name']}"
    logger.info(f"\n{'='*80}")
    logger.info(f"ğŸš€ å¼€å§‹å®éªŒ {i+1}/{len(EXPERIMENT_GRID)}: {exp_name}")
    logger.info(f"{'='*80}")

    exp_results_path = BASE_RESULTS_DIR / exp_name
    exp_results_path.mkdir(parents=True, exist_ok=True)

    # --- å‡†å¤‡æ¨¡å‹å‚æ•° ---
    model_params = {
        'input_dim': input_dim, 'output_dim': output_dim,
        'hidden_dims': params['hidden_dims'],
        # å¦‚æœæœªåœ¨GRIDä¸­æŒ‡å®šï¼Œåˆ™ä»configåŠ è½½é»˜è®¤å€¼
        'dropout_rate': params.get('dropout_rate', config.DROPOUT_RATE)
    }

    # --- æ­¥éª¤ A: å¯»æ‰¾ lr_pretrain ---
    logger.info("--- æ­¥éª¤ A: æ­£åœ¨å¯»æ‰¾ lr_pretrain... ---")
    lr_plot_path_pre = exp_results_path / f"lr_finder_pretrain_{i+1}.png"
    optimal_lr_pretrain = find_pretrain_lr(
        AlignHeteroMLP, model_params, data,
        num_iter=1000, save_plot_path=str(lr_plot_path_pre)
    )
    logger.info(f"   -> æ‰¾åˆ°çš„æœ€ä¼˜ lr_pretrain: {optimal_lr_pretrain:.2e}")

    # --- æ­¥éª¤ B: è¿è¡Œ Pretrain-Only æ¥ç”ŸæˆåŒ¹é…çš„ .pth ---
    logger.info("--- æ­¥éª¤ B: æ­£åœ¨ç”ŸæˆåŒ¹é…çš„é¢„è®­ç»ƒæ¨¡å‹... ---")
    temp_pretrained_path = exp_results_path / f"{OPAMP_TYPE}_pretrained.pth"
    pretrain_cmd = [
        "python", "train.py", "--opamp", OPAMP_TYPE,
        "--hidden_dims", str(model_params['hidden_dims']),
        "--dropout_rate", str(model_params['dropout_rate']),
        "--lr_pretrain", str(optimal_lr_pretrain),
        "--save_path", str(exp_results_path),
        "--pretrain-only"  # <-- ä½¿ç”¨æ–°æ ‡å¿—
    ]
    success, _ = run_command(pretrain_cmd, f"{exp_name}_Pretrain")
    if not success:
        logger.error(f"âŒ å®éªŒ {exp_name} åœ¨æ­¥éª¤Bï¼ˆé¢„è®­ç»ƒï¼‰å¤±è´¥ã€‚è·³è¿‡æ­¤å®éªŒã€‚")
        continue

    # --- æ­¥éª¤ C: å¯»æ‰¾ lr_finetune ---
    logger.info("--- æ­¥éª¤ C: æ­£åœ¨å¯»æ‰¾ lr_finetune... ---")
    if "lr_finetune" in params and params["lr_finetune"] != "auto":
        optimal_lr_finetune = params["lr_finetune"]
        logger.info(f"   -> ä½¿ç”¨äº†å®éªŒç½‘æ ¼ä¸­æŒ‡å®šçš„ lr_finetune: {optimal_lr_finetune}")
    else:
        lr_plot_path_fine = exp_results_path / f"lr_finder_finetune_{i+1}.png"
        optimal_lr_finetune = find_finetune_lr(
            AlignHeteroMLP, model_params, data,
            pretrained_weights_path=str(temp_pretrained_path),
            num_iter=1000, save_plot_path=str(lr_plot_path_fine)
        )
        logger.info(
            f"   -> æ‰¾åˆ°çš„æœ€ä¼˜ lr_finetune (MinLoss/2): {optimal_lr_finetune:.2e}")

    # --- æ­¥éª¤ D: è¿è¡Œå®Œæ•´çš„è®­ç»ƒå’Œè¯„ä¼° ---
    logger.info("--- æ­¥éª¤ D: æ­£åœ¨è¿è¡Œå®Œæ•´è®­ç»ƒå’Œè¯„ä¼°... ---")
    final_metrics_file = exp_results_path / "final_metrics.json"
    full_train_cmd = [
        "python", "train.py", "--opamp", OPAMP_TYPE,
        "--hidden_dims", str(model_params['hidden_dims']),
        "--dropout_rate", str(model_params['dropout_rate']),
        "--lr_pretrain", str(optimal_lr_pretrain),
        "--lr_finetune", str(optimal_lr_finetune),
        "--save_path", str(exp_results_path),
        "--restart", "--evaluate",  # <-- å¼ºåˆ¶é‡æ–°è®­ç»ƒå¹¶è¯„ä¼°
        "--results_file", str(final_metrics_file)
    ]

    # --- å…³é”®ï¼šæ•è·è¯„ä¼°æ—¥å¿— ---
    success, output_lines = run_command(
        full_train_cmd, f"{exp_name}_FullTrain")
    if not success:
        logger.error(f"âŒ å®éªŒ {exp_name} åœ¨æ­¥éª¤Dï¼ˆå®Œæ•´è®­ç»ƒï¼‰å¤±è´¥ã€‚è·³è¿‡æ­¤å®éªŒã€‚")
        continue

    # å°†è¯„ä¼°ç»“æœå†™å…¥ä¸»æ—¥å¿—
    eval_log_started = False
    logger.info(f"\n=== å®éªŒ {i+1} ({exp_name})ï¼šç›®æ ‡åŸŸéªŒè¯é›†æŒ‡æ ‡ï¼ˆç‰©ç†å•ä½ï¼‰===")
    for line in output_lines:
        if "=== ç›®æ ‡åŸŸéªŒè¯é›†æŒ‡æ ‡ï¼ˆç‰©ç†å•ä½ï¼‰ ===" in line:
            eval_log_started = True
            continue
        if eval_log_started and line.strip():
            logger.info(line)
        if eval_log_started and not line.strip():  # é‡åˆ°ç©ºè¡Œåœæ­¢
            eval_log_started = False
    logger.info("========================================\n")

    # --- æ­¥éª¤ E: ç”Ÿæˆæäº¤æ–‡ä»¶ ---
    logger.info(f"--- æ­¥éª¤ E: æ­£åœ¨ä¸ºå®éªŒ {i+1} ç”Ÿæˆæäº¤æ–‡ä»¶... ---")
    final_model_path = exp_results_path / f"{OPAMP_TYPE}_finetuned.pth"
    submission_path = BASE_RESULTS_DIR / f"{SUBMISSION_FILE_PREFIX}_{i+1}"

    if not final_model_path.exists():
        logger.error(f"âŒ å®éªŒ {exp_name} æœªèƒ½ç”Ÿæˆ {final_model_path.name}ã€‚æ— æ³•æäº¤ã€‚")
        continue

    submit_cmd = [
        "python", "submit.py",
        "--opamp", OPAMP_TYPE,
        "--model-path", str(final_model_path),
        "--output-file", str(submission_path),
        "--test-file", str(TEST_FILE_PATH),
        "--hidden-dims", str(model_params['hidden_dims']),
        "--dropout-rate", str(model_params['dropout_rate'])
    ]
    success, _ = run_command(submit_cmd, f"{exp_name}_Submit")
    if success:
        logger.info(f"âœ… æˆåŠŸç”Ÿæˆæäº¤æ–‡ä»¶: {submission_path.name}")

    # --- æ­¥éª¤ F: è®°å½•æœ€ç»ˆç»“æœ (ä» JSON æ–‡ä»¶) ---
    if final_metrics_file.exists():
        with open(final_metrics_file, 'r', encoding='utf-8') as f:
            # è¯»å–æ–‡ä»¶å†…å®¹ï¼Œä½†æ³¨æ„æˆ‘ä»¬æ˜¯è¿½åŠ æ¨¡å¼ï¼Œå¯èƒ½åŒ…å«å¤šä¸ªJSONå¯¹è±¡
            # æˆ‘ä»¬åªå–æœ€åä¸€ä¸ª
            all_results = [json.loads(obj)
                           for obj in f.read().strip().split('\n') if obj]
            final_metrics = all_results[-1]

        final_nll = final_metrics.get('best_finetune_val_nll')
        avg_mse = final_metrics.get('evaluation_metrics', {}).get('avg_mse')

        RESULTS_DF.append({
            'å®éªŒåç§°': exp_name, 'åŸºç¡€æ¨¡å‹': params['base_name'],
            'hidden_dims': str(params['hidden_dims']),
            'dropout_rate': model_params['dropout_rate'],
            'lr_pretrain': f"{optimal_lr_pretrain:.2e}",
            'lr_finetune': f"{optimal_lr_finetune:.2e}",
            'final_val_nll': final_nll, 'avg_mse': avg_mse
        })
    else:
        logger.error(f"âŒ å®éªŒ {exp_name} æœªèƒ½ç”Ÿæˆ {final_metrics_file.name}ã€‚")

# ==============================================================================
# --- 5. æ±‡æ€»å¹¶å±•ç¤ºæœ€ç»ˆç»“æœ ---
# ==============================================================================
end_time = time.time()
total_duration = end_time - start_time
logger.info(f"\n\n{'='*80}")
logger.info(f"ğŸ‰ æ‰€æœ‰å®éªŒå·²å®Œæˆï¼æ€»è€—æ—¶: {total_duration / 60:.2f} åˆ†é’Ÿ")
logger.info(f"ä¸»æ—¥å¿—æ–‡ä»¶: {log_file_path}")
logger.info("="*80)

if RESULTS_DF:
    results_df = pd.DataFrame(RESULTS_DF)
    logger.info("\nğŸ“Š æ‰€æœ‰è¿è¡Œçš„è¯¦ç»†ç»“æœ (ä»ä¼˜åˆ°åŠ£æ’åº):")
    detailed_results = results_df.sort_values(
        by='final_val_nll', ascending=True)
    logger.info(detailed_results.to_string(index=False))
    summary_path = BASE_RESULTS_DIR / "experiment_summary_detailed.csv"
    detailed_results.to_csv(summary_path, index=False, encoding='utf-8-sig')
    logger.info(f"\nğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜è‡³: {summary_path}")

    logger.info("\n\n" + "="*80)
    logger.info("ğŸ“ˆ æŒ‰åŸºç¡€æ¨¡å‹èšåˆçš„ç»Ÿè®¡ç»“æœ:")
    aggregated_df = results_df.groupby('åŸºç¡€æ¨¡å‹')['final_val_nll'].agg(
        ['mean', 'std', 'min', 'max', 'count']).sort_values(by='mean', ascending=True)
    aggregated_df.rename(columns={'mean': 'å¹³å‡NLL', 'std': 'NLLæ ‡å‡†å·®',
                         'min': 'æœ€ä½³NLL', 'max': 'æœ€å·®NLL', 'count': 'è¿è¡Œæ¬¡æ•°'}, inplace=True)
    logger.info(aggregated_df)
    agg_summary_path = BASE_RESULTS_DIR / "experiment_summary_aggregated.csv"
    aggregated_df.to_csv(agg_summary_path, encoding='utf-8-sig')
    logger.info(f"\nğŸ“„ èšåˆç»Ÿè®¡ç»“æœå·²ä¿å­˜è‡³: {agg_summary_path}")

    best_model_name = aggregated_df.index[0]
    best_model_stats = aggregated_df.iloc[0]
    logger.info("\n\nğŸ† ç»¼åˆè¡¨ç°æœ€ä½³çš„æ¨¡å‹ç»“æ„ (åŸºäºå¹³å‡NLL):")
    logger.info(f"   - åç§°: {best_model_name}")
    logger.info(f"   - å¹³å‡éªŒè¯é›†NLL: {best_model_stats['å¹³å‡NLL']:.6f}")
    logger.info(f"   - ç¨³å®šæ€§ (æ ‡å‡†å·®): {best_model_stats['NLLæ ‡å‡†å·®']:.6f}")

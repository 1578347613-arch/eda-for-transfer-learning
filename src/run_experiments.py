# src/run_experiments.py (å·²æ›´æ–°ï¼šè®°å½•è¯„ä¼°æ—¥å¿— + è‡ªåŠ¨æäº¤)
import subprocess
import os
import time
import json
import shutil
from pathlib import Path
import logging  # <-- å¯¼å…¥æ—¥å¿—æ¨¡å—
import sys
import re  # <-- å¯¼å…¥æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—

# --- ä»é¡¹ç›®æ¨¡å—ä¸­å¯¼å…¥ ---
from find_lr_utils import find_pretrain_lr
from models.align_hetero import AlignHeteroMLP
from data_loader import get_data_and_scalers
from find_lr_utils import find_pretrain_lr, find_finetune_lr
import config  # <-- å¯¼å…¥ config ä»¥è·å–é»˜è®¤å€¼

# ==============================================================================
# --- 0. è·¯å¾„å’Œå®éªŒæ§åˆ¶ ---
# ==============================================================================
SRC_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SRC_DIR.parent

# --- æ ¸å¿ƒä¿®æ”¹ï¼šä¸å†è‡ªåŠ¨æ¸…ç†ï¼Œå› ä¸º submit.py éœ€è¦ .pth æ–‡ä»¶ ---
CLEANUP_AFTER_RUN = False
SILENT_TRAINING = True

# ==============================================================================
# --- 1. å®šä¹‰ä½ çš„å®éªŒæœç´¢ç©ºé—´ ---
# ==============================================================================
BASE_EXPERIMENT_GRID = [
    {"name": "0.2_ratio3", "hidden_dims": [
        128, 256, 256, 512], "dropout_rate": 0.2, "backbone_lr_ratio": 3.0},
    {"name": "0.2_ratio4", "hidden_dims": [
        128, 256, 256, 512], "dropout_rate": 0.2, "backbone_lr_ratio": 4.0},
    {"name": "0.2_ratio5", "hidden_dims": [
        128, 256, 256, 512], "dropout_rate": 0.2, "backbone_lr_ratio": 5.0},
    {"name": "0.2_ratio6", "hidden_dims": [
        128, 256, 256, 512], "dropout_rate": 0.2, "backbone_lr_ratio": 6.0},
    {"name": "0.2_ratio7", "hidden_dims": [
        128, 256, 256, 512], "dropout_rate": 0.2, "backbone_lr_ratio": 7.0},
    {"name": "0.2_ratio8", "hidden_dims": [
        128, 256, 256, 512], "dropout_rate": 0.2, "backbone_lr_ratio": 8.0},
    {"name": "0.2_ratio9", "hidden_dims": [
        128, 256, 256, 512], "dropout_rate": 0.2, "backbone_lr_ratio": 9.0},
    {"name": "0.2_ratio10", "hidden_dims": [
        128, 256, 256, 512], "dropout_rate": 0.2, "backbone_lr_ratio": 10.0},
    {"name": "0.2_ratio11", "hidden_dims": [
        128, 256, 256, 512], "dropout_rate": 0.2, "backbone_lr_ratio": 11.0},
    {"name": "0.2_ratio12", "hidden_dims": [
        128, 256, 256, 512], "dropout_rate": 0.2, "backbone_lr_ratio": 12.0},
    {"name": "0.2_ratio13", "hidden_dims": [
        128, 256, 256, 512], "dropout_rate": 0.2, "backbone_lr_ratio": 13.0},
    {"name": "0.2_ratio14", "hidden_dims": [
        128, 256, 256, 512], "dropout_rate": 0.2, "backbone_lr_ratio": 14.0},
    {"name": "0.2_ratio15", "hidden_dims": [
        128, 256, 256, 512], "dropout_rate": 0.2, "backbone_lr_ratio": 15.0},
]

# --- å®éªŒæ§åˆ¶è®¾ç½® ---
NUM_REPETITIONS = 1
OPAMP_TYPE = '5t_opamp'
BASE_RESULTS_DIR = PROJECT_ROOT / "results_experiments_auto_lr"

# --- æäº¤æ–‡ä»¶è®¾ç½® ---
TEST_FILE_PATH = PROJECT_ROOT / "data/02_public_test_set/features/features_A.csv"
SUBMISSION_FILE_PREFIX = "predA"  # å°†ç”Ÿæˆ predA_1, predA_2 ...

# ==============================================================================
# --- 2. è®¾ç½®æ—¥å¿—ç³»ç»Ÿ ---
# ==============================================================================
BASE_RESULTS_DIR.mkdir(parents=True, exist_ok=True)
EVALUATION_LOG_FILE = BASE_RESULTS_DIR / "experiment_evaluation_log.txt"

# åˆ›å»ºä¸€ä¸ªåªå†™å…¥æ–‡ä»¶çš„ logger
file_logger = logging.getLogger('ExperimentLogger')
file_logger.setLevel(logging.INFO)
file_logger.propagate = False  # é˜²æ­¢æ—¥å¿—å‘ä¸Šä¼ æ’­
# ç§»é™¤æ‰€æœ‰ç°æœ‰çš„ handlers (å¦‚æœåœ¨ notebook ä¸­é‡è·‘)
if file_logger.hasHandlers():
    file_logger.handlers.clear()
# åˆ›å»ºæ–‡ä»¶ handler
file_handler = logging.FileHandler(
    EVALUATION_LOG_FILE, mode='w', encoding='utf-8')
file_handler.setFormatter(logging.Formatter('%(message)s'))
file_logger.addHandler(file_handler)

# ==============================================================================
# --- 3. åŠ¨æ€ç”Ÿæˆå®Œæ•´çš„å®éªŒåˆ—è¡¨ ---
# ==============================================================================
# ... (è¿™éƒ¨åˆ†é€»è¾‘ä¸å˜) ...
EXPERIMENT_GRID = []
for exp_params in BASE_EXPERIMENT_GRID:
    for run_num in range(1, NUM_REPETITIONS + 1):
        new_params = exp_params.copy()
        new_params['name'] = f"{exp_params['name']}_run{run_num}"
        new_params['base_name'] = exp_params['name']
        EXPERIMENT_GRID.append(new_params)

# ==============================================================================
# --- 4. è¾…åŠ©å‡½æ•° ---
# ==============================================================================


def run_command(command, log_prefix=""):
    """
    è¾…åŠ©å‡½æ•°ï¼šæ‰§è¡Œå­è¿›ç¨‹å¹¶æ•è·æ‰€æœ‰è¾“å‡ºã€‚
    è¿”å›: (bool: success, list: stdout_lines, str: stderr_output)
    """
    print(f"--- [CMD] {log_prefix} æ­£åœ¨æ‰§è¡Œ: {' '.join(command)} ---")
    process = subprocess.Popen(
        command, cwd=SRC_DIR, stdout=subprocess.PIPE,
        stderr=subprocess.PIPE, text=True, encoding='utf-8'
    )
    stdout_lines = []

    # å®æ—¶æ‰“å°åˆ°æ§åˆ¶å° (å¦‚æœéé™é»˜)
    if not SILENT_TRAINING:
        for line in iter(process.stdout.readline, ''):
            line = line.strip()
            if line:
                print(f"[{log_prefix}] {line}")
            stdout_lines.append(line)
        process.wait()
        stderr_output = process.stderr.read()
    else:
        # é™é»˜æ¨¡å¼ï¼šåªæ•è·ï¼Œä¸æ‰“å°
        stdout_data, stderr_output = process.communicate()
        stdout_lines = stdout_data.splitlines()

    if process.returncode != 0:
        print(f"âš ï¸ {log_prefix} æ‰§è¡Œå¤±è´¥ã€‚")
        if SILENT_TRAINING:  # ä»…åœ¨é™é»˜æ¨¡å¼ä¸‹å¤±è´¥æ—¶æ‰“å°é”™è¯¯
            print("--- é”™è¯¯æ—¥å¿—å¼€å§‹ ---")
            print(stderr_output)
            print("--- é”™è¯¯æ—¥å¿—ç»“æŸ ---")
        return False, stdout_lines, stderr_output

    print(f"--- [CMD] {log_prefix} æ‰§è¡Œå®Œæ¯• ---")
    return True, stdout_lines, stderr_output


def parse_evaluation_log(stdout_lines, exp_name, exp_num):
    """
    ä» train.py çš„ stdout ä¸­æå–è¯„ä¼°æ—¥å¿—å—ã€‚
    """
    eval_block = []
    capturing = False

    # åŒ¹é…è¯„ä¼°å—çš„å¼€å§‹
    start_marker = re.compile(r"===\s*ç›®æ ‡åŸŸéªŒè¯é›†æŒ‡æ ‡ï¼ˆç‰©ç†å•ä½ï¼‰\s*===")

    for line in stdout_lines:
        if start_marker.search(line):
            capturing = True
            eval_block.append(
                f"=== å®éªŒ {exp_num} ({exp_name})ï¼šç›®æ ‡åŸŸéªŒè¯é›†æŒ‡æ ‡ï¼ˆç‰©ç†å•ä½ï¼‰===")
            continue

        if capturing and line.strip():  # æ•è·æ‰€æœ‰éç©ºè¡Œ
            eval_block.append(line)

        if capturing and not line.strip():  # é‡åˆ°ç©ºè¡Œåœæ­¢
            capturing = False
            break  # è¯„ä¼°å—ç»“æŸ

    return "\n".join(eval_block)


# ==============================================================================
# --- 5. å®éªŒæ‰§è¡Œä¸ç»“æœæ•è· ---
# ==============================================================================
start_time = time.time()
print(f"--- å®éªŒå¼€å§‹ï¼šå…± {len(EXPERIMENT_GRID)} æ¬¡è¿è¡Œ ---")
print(f"--- è¯„ä¼°æ—¥å¿—å°†ä¿å­˜åˆ°: {EVALUATION_LOG_FILE} ---")

print("æ­£åœ¨é¢„åŠ è½½æ•°æ®...")
data = get_data_and_scalers(opamp_type=OPAMP_TYPE)
input_dim = data['source'][0].shape[1]
output_dim = data['source'][1].shape[1]
print("æ•°æ®åŠ è½½å®Œæˆã€‚")

for i, params in enumerate(EXPERIMENT_GRID):
    exp_name = f"{i+1:02d}_{params['name']}"
    print(f"\n{'='*80}")
    print(f"ğŸš€ å¼€å§‹å®éªŒ {i+1}/{len(EXPERIMENT_GRID)}: {exp_name}")

    exp_results_path = BASE_RESULTS_DIR / exp_name
    exp_results_path.mkdir(parents=True, exist_ok=True)

    # å®šä¹‰æ¨¡å‹å‚æ•°å’Œè·¯å¾„
    model_params = {
        'input_dim': input_dim, 'output_dim': output_dim,
        'hidden_dims': params['hidden_dims'], 'dropout_rate': params['dropout_rate']
    }
    pretrained_model_path = exp_results_path / f"{OPAMP_TYPE}_pretrained.pth"
    final_model_path = exp_results_path / f"{OPAMP_TYPE}_finetuned.pth"
    final_results_file = exp_results_path / "final_metrics.json"

    # --------------------------------------------------------------------------
    # --- æ­¥éª¤ A: å¯»æ‰¾æœ€ä¼˜é¢„è®­ç»ƒå­¦ä¹ ç‡ ---
    # --------------------------------------------------------------------------
    print("\n--- æ­¥éª¤ A: æ­£åœ¨å¯»æ‰¾æœ€ä¼˜é¢„è®­ç»ƒå­¦ä¹ ç‡... ---")
    optimal_lr_pretrain = find_pretrain_lr(
        AlignHeteroMLP, model_params, data,
        save_plot_path=str(exp_results_path / "lr_finder_pretrain.png")
    )
    print(f"   - æ‰¾åˆ°çš„æœ€ä¼˜é¢„è®­ç»ƒå­¦ä¹ ç‡ (lr_pretrain): {optimal_lr_pretrain:.2e}")

    # --------------------------------------------------------------------------
    # --- æ­¥éª¤ B: è¿è¡Œ Pretrain-Only ---
    # --------------------------------------------------------------------------
    print("\n--- æ­¥éª¤ B: æ­£åœ¨æ‰§è¡Œ Pretrain-Only... ---")
    pretrain_command = [
        "python", "train.py", "--opamp", OPAMP_TYPE,
        "--hidden_dims", str(params['hidden_dims']),
        "--dropout_rate", str(params['dropout_rate']),
        "--lr_pretrain", str(optimal_lr_pretrain),
        "--save_path", str(exp_results_path),
        "--restart",  # ç¡®ä¿é‡æ–°è¿è¡Œé¢„è®­ç»ƒ
        "--pretrain"  # <-- å…³é”®ï¼šåªè¿è¡Œé¢„è®­ç»ƒ
    ]
    success, _, _ = run_command(pretrain_command, f"{exp_name}_Pretrain")

    if not success or not pretrained_model_path.exists():
        print(f"âŒ å®éªŒ {exp_name} åœ¨é¢„è®­ç»ƒé˜¶æ®µå¤±è´¥ã€‚è·³è¿‡æ­¤å®éªŒã€‚")
        continue
    print(f"   - é¢„è®­ç»ƒæ¨¡å‹å·²ä¿å­˜è‡³: {pretrained_model_path.name}")

    # --------------------------------------------------------------------------
    # --- æ­¥éª¤ C: å¯»æ‰¾æœ€ä¼˜å¾®è°ƒå­¦ä¹ ç‡ ---
    # --------------------------------------------------------------------------
    print("\n--- æ­¥éª¤ C: æ­£åœ¨å¯»æ‰¾æœ€ä¼˜å¾®è°ƒå­¦ä¹ ç‡... ---")
    current_ratio = params['backbone_lr_ratio']
    optimal_lr_finetune = find_finetune_lr(
        AlignHeteroMLP, model_params, data,
        pretrained_weights_path=str(pretrained_model_path),
        backbone_lr_ratio=current_ratio,  # <-- ä¼ å…¥å½“å‰å®éªŒçš„ ratio
        save_plot_path=str(exp_results_path / "lr_finder_finetune.png")
    )
    print(f"   - æ‰¾åˆ°çš„æœ€ä¼˜å¾®è°ƒå­¦ä¹ ç‡ (lr_finetune_head): {optimal_lr_finetune:.2e}")

    # --------------------------------------------------------------------------
    # --- æ­¥éª¤ D: è¿è¡Œ Finetune + Evaluate ---
    # --------------------------------------------------------------------------
    print(
        f"\n--- æ­¥éª¤ D: æ­£åœ¨æ‰§è¡Œ Finetune + Evaluate (Ratio={current_ratio})... ---")
    finetune_command = [
        "python", "train.py", "--opamp", OPAMP_TYPE,
        "--hidden_dims", str(params['hidden_dims']),
        "--dropout_rate", str(params['dropout_rate']),

        # ä¼ å…¥è‡ªåŠ¨æ‰¾åˆ°çš„å¾®è°ƒLR å’Œ ç½‘æ ¼ä¸­çš„Ratio
        "--lr_finetune", str(optimal_lr_finetune),
        "--backbone_lr_ratio", str(current_ratio),

        "--save_path", str(exp_results_path),
        "--results_file", str(final_results_file),

        "--finetune",   # <-- å…³é”®ï¼šè·³è¿‡é¢„è®­ç»ƒï¼Œåªå¾®è°ƒ
        "--evaluate"    # <-- å…³é”®ï¼šå¾®è°ƒåç«‹å³è¯„ä¼°
    ]

    success, stdout_lines, _ = run_command(
        finetune_command, f"{exp_name}_FinetuneEval")

    if not success:
        print(f"âŒ å®éªŒ {exp_name} åœ¨å¾®è°ƒ/è¯„ä¼°é˜¶æ®µå¤±è´¥ã€‚è·³è¿‡æ­¤å®éªŒã€‚")
        continue

    # --------------------------------------------------------------------------
    # --- æ­¥éª¤ E: æå–æ—¥å¿—å¹¶ä¿å­˜ ---
    # --------------------------------------------------------------------------
    print(f"\n--- æ­¥éª¤ E: æå–æ—¥å¿—å¹¶ä¿å­˜... ---")
    evaluation_text = parse_evaluation_log(stdout_lines, exp_name, i+1)
    if evaluation_text:
        file_logger.info(evaluation_text + "\n")
        print(f"âœ… è¯„ä¼°æ—¥å¿—å·²ä¿å­˜åˆ° {EVALUATION_LOG_FILE.name}")
    else:
        print(f"âš ï¸ è­¦å‘Š: æœªèƒ½ä» {exp_name} çš„è®­ç»ƒè¾“å‡ºä¸­æ•è·åˆ°è¯„ä¼°æ—¥å¿—ã€‚")

    # --------------------------------------------------------------------------
    # --- æ­¥éª¤ F: ç”Ÿæˆæäº¤æ–‡ä»¶ ---
    # --------------------------------------------------------------------------
    print(f"\n--- æ­¥éª¤ F: æ­£åœ¨ä¸ºå®éªŒ {i+1} ç”Ÿæˆæäº¤æ–‡ä»¶... ---")
    submission_path = BASE_RESULTS_DIR / f"{SUBMISSION_FILE_PREFIX}_{i+1}"

    if not final_model_path.exists():
        print(f"âŒ å®éªŒ {exp_name} æœªèƒ½ç”Ÿæˆ {final_model_path.name}ã€‚æ— æ³•æäº¤ã€‚")
        continue

    submit_cmd = [
        "python", "submit.py",
        "--opamp", OPAMP_TYPE,
        "--model-path", str(final_model_path),
        "--output-file", str(submission_path),
        "--test-file", str(TEST_FILE_PATH),
        "--hidden-dims", str(model_params['hidden_dims']),
        "--dropout-rate", str(model_params['dropout_rate']),
        "--device", config.DEVICE
    ]
    success, _, _ = run_command(submit_cmd, f"{exp_name}_Submit")
    if success:
        print(f"âœ… æˆåŠŸç”Ÿæˆæäº¤æ–‡ä»¶: {submission_path.name}")
    else:
        print(f"âŒ ç”Ÿæˆæäº¤æ–‡ä»¶å¤±è´¥: {submission_path.name}")

    # --------------------------------------------------------------------------
    # --- æ­¥éª¤ G: æ¸…ç† (å¦‚æœå¯ç”¨) ---
    # --------------------------------------------------------------------------
    if CLEANUP_AFTER_RUN:
        try:
            shutil.rmtree(exp_results_path)
            print(f"æ¸…ç†å®Œæ¯•: å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤¹ {exp_results_path}")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†å¤±è´¥: åˆ é™¤æ–‡ä»¶å¤¹ {exp_results_path} æ—¶å‡ºé”™ - {e}")
# ==============================================================================
# --- 5. æ±‡æ€»å¹¶å±•ç¤ºæœ€ç»ˆç»“æœ ---
# ==============================================================================
end_time = time.time()
total_duration = end_time - start_time
final_message = f"\n\n{'='*80}\nğŸ‰ æ‰€æœ‰å®éªŒå·²å®Œæˆï¼æ€»è€—æ—¶: {total_duration / 60:.2f} åˆ†é’Ÿ\n{'='*80}\n"
final_message += f"è¯„ä¼°æ—¥å¿—å·²å…¨éƒ¨ä¿å­˜åˆ°: {EVALUATION_LOG_FILE}\n"
final_message += f"æäº¤æ–‡ä»¶å·²ç”Ÿæˆåœ¨: {BASE_RESULTS_DIR}\n"
print(final_message)
file_logger.info(final_message)  # ä¹Ÿåœ¨æ—¥å¿—æ–‡ä»¶æœ«å°¾å†™å…¥æ€»ç»“

--- 开始为 two_stage_opamp 加载数据 ---
已对列 ['ugf', 'cmrr', 'dc_gain', 'slewrate_pos'] 进行 log1p 变换。
StandardScaler 已在工艺 A(Source) 上完成 fit。
A/B 全部数据已完成标准化（基于 A 域的 scaler）。
工艺 A 数据已划分为 80% 训练集 / 20% 验证集。
工艺 B 数据已划分为 80% 训练集 / 20% 验证集。
=============================================
== SWEEP_B on two_stage_opamp
== hidden_dims: [128, 256, 512]
== num_layers : [2, 3, 4]
== 其它参数全部来自 config；策略：对齐(align) 两阶段，不训练 target_only
=============================================


===== [HD128_L2] 训练开始 =====

--- [阶段一] Backbone 预训练 (source_train / source_val, HuberLoss) ---
Pretrain [1/1000]  train=0.266647  val=0.239674
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [2/1000]  train=0.215441  val=0.187629
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [3/1000]  train=0.185032  val=0.167983
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [4/1000]  train=0.171018  val=0.154342
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [5/1000]  train=0.160172  val=0.143792
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [6/1000]  train=0.152028  val=0.139644
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [7/1000]  train=0.148105  val=0.133886
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [8/1000]  train=0.143184  val=0.126966
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [9/1000]  train=0.139023  val=0.121484
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [10/1000]  train=0.133364  val=0.119469
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [11/1000]  train=0.128568  val=0.116360
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [12/1000]  train=0.128424  val=0.115233
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [13/1000]  train=0.126050  val=0.116449
Pretrain [14/1000]  train=0.123737  val=0.111777
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [15/1000]  train=0.121000  val=0.109166
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [16/1000]  train=0.121456  val=0.111338
Pretrain [17/1000]  train=0.119475  val=0.109075
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [18/1000]  train=0.115798  val=0.110230
Pretrain [19/1000]  train=0.115426  val=0.104785
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [20/1000]  train=0.115880  val=0.104494
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [21/1000]  train=0.112964  val=0.110393
Pretrain [22/1000]  train=0.112114  val=0.105349
Pretrain [23/1000]  train=0.112500  val=0.100833
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [24/1000]  train=0.112088  val=0.102412
Pretrain [25/1000]  train=0.109960  val=0.099538
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [26/1000]  train=0.109420  val=0.100125
Pretrain [27/1000]  train=0.110013  val=0.099175
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [28/1000]  train=0.109041  val=0.098188
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [29/1000]  train=0.107188  val=0.100143
Pretrain [30/1000]  train=0.107993  val=0.097905
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [31/1000]  train=0.107255  val=0.098378
Pretrain [32/1000]  train=0.105566  val=0.097947
Pretrain [33/1000]  train=0.105918  val=0.097947
Pretrain [34/1000]  train=0.106011  val=0.096949
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [35/1000]  train=0.103560  val=0.096832
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [36/1000]  train=0.106068  val=0.096886
Pretrain [37/1000]  train=0.103953  val=0.095066
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [38/1000]  train=0.104490  val=0.096206
Pretrain [39/1000]  train=0.103344  val=0.095456
Pretrain [40/1000]  train=0.103269  val=0.096057
Pretrain [41/1000]  train=0.102202  val=0.095371
Pretrain [42/1000]  train=0.102163  val=0.095618
Pretrain [43/1000]  train=0.100407  val=0.094420
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [44/1000]  train=0.102897  val=0.095307
Pretrain [45/1000]  train=0.100140  val=0.094697
Pretrain [46/1000]  train=0.099111  val=0.095621
Pretrain [47/1000]  train=0.101744  val=0.098270
Pretrain [48/1000]  train=0.100242  val=0.093148
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [49/1000]  train=0.101296  val=0.097302
Pretrain [50/1000]  train=0.099362  val=0.094783
Pretrain [51/1000]  train=0.099459  val=0.094293
Pretrain [52/1000]  train=0.099153  val=0.093942
Pretrain [53/1000]  train=0.098687  val=0.094932
Pretrain [54/1000]  train=0.099637  val=0.093660
Pretrain [55/1000]  train=0.097840  val=0.095690
Pretrain [56/1000]  train=0.097250  val=0.093324
Pretrain [57/1000]  train=0.098474  val=0.091472
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [58/1000]  train=0.096912  val=0.096012
Pretrain [59/1000]  train=0.096112  val=0.091174
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [60/1000]  train=0.096977  val=0.091835
Pretrain [61/1000]  train=0.097319  val=0.092141
Pretrain [62/1000]  train=0.097411  val=0.091765
Pretrain [63/1000]  train=0.097265  val=0.093601
Pretrain [64/1000]  train=0.096668  val=0.090837
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [65/1000]  train=0.094611  val=0.091443
Pretrain [66/1000]  train=0.097378  val=0.094675
Pretrain [67/1000]  train=0.096106  val=0.091572
Pretrain [68/1000]  train=0.095692  val=0.093564
Pretrain [69/1000]  train=0.094895  val=0.092506
Pretrain [70/1000]  train=0.095483  val=0.089646
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [71/1000]  train=0.093709  val=0.092932
Pretrain [72/1000]  train=0.095137  val=0.091108
Pretrain [73/1000]  train=0.091885  val=0.089005
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [74/1000]  train=0.094214  val=0.091683
Pretrain [75/1000]  train=0.094027  val=0.089740
Pretrain [76/1000]  train=0.094137  val=0.090623
Pretrain [77/1000]  train=0.092894  val=0.093212
Pretrain [78/1000]  train=0.093219  val=0.089889
Pretrain [79/1000]  train=0.093264  val=0.091618
Pretrain [80/1000]  train=0.092414  val=0.092742
Pretrain [81/1000]  train=0.092073  val=0.091533
Pretrain [82/1000]  train=0.092268  val=0.091858
Pretrain [83/1000]  train=0.092622  val=0.091815
Pretrain [84/1000]  train=0.091396  val=0.090769
Pretrain [85/1000]  train=0.093349  val=0.091584
Pretrain [86/1000]  train=0.089862  val=0.091076
Pretrain [87/1000]  train=0.090991  val=0.089249
Pretrain [88/1000]  train=0.088872  val=0.090424
Pretrain [89/1000]  train=0.092421  val=0.091745
Pretrain [90/1000]  train=0.091575  val=0.090712
Pretrain [91/1000]  train=0.090686  val=0.089282
Pretrain [92/1000]  train=0.090238  val=0.091330
Pretrain [93/1000]  train=0.090365  val=0.090955
Pretrain [94/1000]  train=0.090136  val=0.090648
Pretrain [95/1000]  train=0.089258  val=0.090763
Pretrain [96/1000]  train=0.089289  val=0.088871
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [97/1000]  train=0.089458  val=0.087976
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [98/1000]  train=0.088434  val=0.091207
Pretrain [99/1000]  train=0.088096  val=0.088865
Pretrain [100/1000]  train=0.090859  val=0.089283
Pretrain [101/1000]  train=0.086287  val=0.089462
Pretrain [102/1000]  train=0.086895  val=0.089175
Pretrain [103/1000]  train=0.089608  val=0.090505
Pretrain [104/1000]  train=0.089742  val=0.089072
Pretrain [105/1000]  train=0.088530  val=0.092286
Pretrain [106/1000]  train=0.086430  val=0.089913
Pretrain [107/1000]  train=0.087742  val=0.089972
Pretrain [108/1000]  train=0.088036  val=0.088542
Pretrain [109/1000]  train=0.086790  val=0.088557
Pretrain [110/1000]  train=0.087013  val=0.086859
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [111/1000]  train=0.086912  val=0.088656
Pretrain [112/1000]  train=0.087126  val=0.088774
Pretrain [113/1000]  train=0.086702  val=0.087314
Pretrain [114/1000]  train=0.085463  val=0.089187
Pretrain [115/1000]  train=0.085255  val=0.089804
Pretrain [116/1000]  train=0.086279  val=0.089855
Pretrain [117/1000]  train=0.085547  val=0.088306
Pretrain [118/1000]  train=0.084090  val=0.087877
Pretrain [119/1000]  train=0.086195  val=0.088017
Pretrain [120/1000]  train=0.083790  val=0.088361
Pretrain [121/1000]  train=0.083354  val=0.087738
Pretrain [122/1000]  train=0.085210  val=0.088914
Pretrain [123/1000]  train=0.084659  val=0.087912
Pretrain [124/1000]  train=0.083374  val=0.087867
Pretrain [125/1000]  train=0.084772  val=0.087582
Pretrain [126/1000]  train=0.084586  val=0.087070
Pretrain [127/1000]  train=0.086044  val=0.088431
Pretrain [128/1000]  train=0.083769  val=0.087090
Pretrain [129/1000]  train=0.085941  val=0.087716
Pretrain [130/1000]  train=0.083697  val=0.088716
Pretrain [131/1000]  train=0.083698  val=0.087537
Pretrain [132/1000]  train=0.082843  val=0.088160
Pretrain [133/1000]  train=0.084517  val=0.087108
Pretrain [134/1000]  train=0.082564  val=0.086857
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [135/1000]  train=0.082659  val=0.088231
Pretrain [136/1000]  train=0.083849  val=0.087964
Pretrain [137/1000]  train=0.081108  val=0.089410
Pretrain [138/1000]  train=0.082183  val=0.085969
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [139/1000]  train=0.080808  val=0.086367
Pretrain [140/1000]  train=0.081401  val=0.085872
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/pretrained.pth
Pretrain [141/1000]  train=0.082468  val=0.086681
Pretrain [142/1000]  train=0.082562  val=0.086740
Pretrain [143/1000]  train=0.081850  val=0.087117
Pretrain [144/1000]  train=0.081168  val=0.088061
Pretrain [145/1000]  train=0.080374  val=0.088843
Pretrain [146/1000]  train=0.081528  val=0.086995
Pretrain [147/1000]  train=0.081661  val=0.088626
Pretrain [148/1000]  train=0.081185  val=0.087262
Pretrain [149/1000]  train=0.082617  val=0.087173
Pretrain [150/1000]  train=0.081149  val=0.087464
Pretrain [151/1000]  train=0.080454  val=0.087290
Pretrain [152/1000]  train=0.080286  val=0.086895
Pretrain [153/1000]  train=0.082086  val=0.087116
Pretrain [154/1000]  train=0.079370  val=0.088216
Pretrain [155/1000]  train=0.081761  val=0.086784
Pretrain [156/1000]  train=0.080617  val=0.087220
Pretrain [157/1000]  train=0.081727  val=0.087859
Pretrain [158/1000]  train=0.079728  val=0.086490
Pretrain [159/1000]  train=0.080397  val=0.086454
Pretrain [160/1000]  train=0.080535  val=0.087024
Pretrain [161/1000]  train=0.079032  val=0.086550
Pretrain [162/1000]  train=0.079833  val=0.087080
Pretrain [163/1000]  train=0.078249  val=0.086767
Pretrain [164/1000]  train=0.080175  val=0.087374
Pretrain [165/1000]  train=0.081044  val=0.086892
Pretrain [166/1000]  train=0.079441  val=0.087183
Pretrain [167/1000]  train=0.078707  val=0.086737
Pretrain [168/1000]  train=0.078787  val=0.087102
Pretrain [169/1000]  train=0.079528  val=0.087209
Pretrain [170/1000]  train=0.077906  val=0.087376
Pretrain [171/1000]  train=0.078885  val=0.087141
Pretrain [172/1000]  train=0.079775  val=0.087329
Pretrain [173/1000]  train=0.079479  val=0.087123
Pretrain [174/1000]  train=0.078964  val=0.087075
Pretrain [175/1000]  train=0.080295  val=0.086916
Pretrain [176/1000]  train=0.080674  val=0.087119
Pretrain [177/1000]  train=0.079576  val=0.086868
Pretrain [178/1000]  train=0.077601  val=0.086659
Pretrain [179/1000]  train=0.078183  val=0.086427
Pretrain [180/1000]  train=0.082304  val=0.086744
Pretrain [181/1000]  train=0.079326  val=0.086896
Pretrain [182/1000]  train=0.077949  val=0.086505
Pretrain [183/1000]  train=0.078954  val=0.086727
Pretrain [184/1000]  train=0.079274  val=0.086794
Pretrain [185/1000]  train=0.078925  val=0.086611
Pretrain [186/1000]  train=0.078601  val=0.086437
Pretrain [187/1000]  train=0.079207  val=0.086710
Pretrain [188/1000]  train=0.078699  val=0.086600
Pretrain [189/1000]  train=0.078331  val=0.086696
Pretrain [190/1000]  train=0.078602  val=0.086593
Pretrain [191/1000]  train=0.080121  val=0.086565
Pretrain [192/1000]  train=0.079773  val=0.086468
Pretrain [193/1000]  train=0.078135  val=0.086486
Pretrain [194/1000]  train=0.078342  val=0.086445
Pretrain [195/1000]  train=0.078047  val=0.086491
Pretrain [196/1000]  train=0.078243  val=0.086496
Pretrain [197/1000]  train=0.078416  val=0.086507
Pretrain [198/1000]  train=0.079076  val=0.086506
Pretrain [199/1000]  train=0.080237  val=0.086507
Pretrain [200/1000]  train=0.078481  val=0.086512
Pretrain [201/1000]  train=0.089449  val=0.095219
Pretrain [202/1000]  train=0.092552  val=0.092532
Pretrain [203/1000]  train=0.093680  val=0.093664
Pretrain [204/1000]  train=0.093256  val=0.091822
Pretrain [205/1000]  train=0.091093  val=0.094717
Pretrain [206/1000]  train=0.090401  val=0.094481
Pretrain [207/1000]  train=0.093498  val=0.092143
Pretrain [208/1000]  train=0.092134  val=0.093706
Pretrain [209/1000]  train=0.089433  val=0.098444
Pretrain [210/1000]  train=0.090733  val=0.092969
Pretrain [211/1000]  train=0.091008  val=0.093893
Pretrain [212/1000]  train=0.092065  val=0.094007
Pretrain [213/1000]  train=0.092153  val=0.091036
Pretrain [214/1000]  train=0.091866  val=0.093554
Pretrain [215/1000]  train=0.090157  val=0.093126
Pretrain [216/1000]  train=0.090316  val=0.091605
Pretrain [217/1000]  train=0.089641  val=0.094160
Pretrain [218/1000]  train=0.087941  val=0.090656
Pretrain [219/1000]  train=0.090853  val=0.093737
Pretrain [220/1000]  train=0.089600  val=0.092411
Pretrain [221/1000]  train=0.088983  val=0.090630
Pretrain [222/1000]  train=0.088695  val=0.095175
Pretrain [223/1000]  train=0.089569  val=0.092877
Pretrain [224/1000]  train=0.089568  val=0.093028
Pretrain [225/1000]  train=0.091138  val=0.090767
Pretrain [226/1000]  train=0.089675  val=0.091148
Pretrain [227/1000]  train=0.089176  val=0.092513
Pretrain [228/1000]  train=0.087867  val=0.089264
Pretrain [229/1000]  train=0.091471  val=0.087986
Pretrain [230/1000]  train=0.087563  val=0.092205
Pretrain [231/1000]  train=0.087334  val=0.093875
Pretrain [232/1000]  train=0.089625  val=0.091343
Pretrain [233/1000]  train=0.089460  val=0.090579
Pretrain [234/1000]  train=0.087166  val=0.089330
Pretrain [235/1000]  train=0.089160  val=0.089592
Pretrain [236/1000]  train=0.087914  val=0.089410
Pretrain [237/1000]  train=0.087552  val=0.092492
Pretrain [238/1000]  train=0.086818  val=0.095817
Pretrain [239/1000]  train=0.086380  val=0.095296
Pretrain [240/1000]  train=0.088795  val=0.091801
Pretrain [241/1000]  train=0.086518  val=0.089867
Pretrain [242/1000]  train=0.088529  val=0.088824
Pretrain [243/1000]  train=0.089980  val=0.094311
Pretrain [244/1000]  train=0.085760  val=0.089780
Pretrain [245/1000]  train=0.085910  val=0.089782
Pretrain [246/1000]  train=0.086257  val=0.091382
Pretrain [247/1000]  train=0.085969  val=0.091843
Pretrain [248/1000]  train=0.088543  val=0.093486
Pretrain [249/1000]  train=0.085227  val=0.090971
Pretrain [250/1000]  train=0.085294  val=0.093625
Pretrain [251/1000]  train=0.085962  val=0.094744
Pretrain [252/1000]  train=0.086501  val=0.091720
Pretrain [253/1000]  train=0.088404  val=0.095648
Pretrain [254/1000]  train=0.085079  val=0.092173
Pretrain [255/1000]  train=0.086457  val=0.092395
Pretrain [256/1000]  train=0.085729  val=0.092619
Pretrain [257/1000]  train=0.083591  val=0.091370
Pretrain [258/1000]  train=0.085202  val=0.091527
Pretrain [259/1000]  train=0.083960  val=0.090970
Pretrain [260/1000]  train=0.087414  val=0.090045
Pretrain [261/1000]  train=0.082518  val=0.092427
Pretrain [262/1000]  train=0.083716  val=0.091997
Pretrain [263/1000]  train=0.086057  val=0.090637
Pretrain [264/1000]  train=0.083426  val=0.092800
Pretrain [265/1000]  train=0.084861  val=0.093896
Pretrain [266/1000]  train=0.085852  val=0.088679
Pretrain [267/1000]  train=0.082542  val=0.089580
Pretrain [268/1000]  train=0.086577  val=0.090137
Pretrain [269/1000]  train=0.085983  val=0.092550
Pretrain [270/1000]  train=0.084239  val=0.090654
Pretrain [271/1000]  train=0.083685  val=0.094313
Pretrain [272/1000]  train=0.083055  val=0.092797
Pretrain [273/1000]  train=0.085846  val=0.089820
Pretrain [274/1000]  train=0.083155  val=0.091537
Pretrain [275/1000]  train=0.083147  val=0.088596
Pretrain [276/1000]  train=0.085326  val=0.092245
Pretrain [277/1000]  train=0.084646  val=0.090924
Pretrain [278/1000]  train=0.082869  val=0.090927
Pretrain [279/1000]  train=0.082267  val=0.092122
Pretrain [280/1000]  train=0.082510  val=0.090978
Pretrain [281/1000]  train=0.084497  val=0.090221
Pretrain [282/1000]  train=0.078975  val=0.090269
Pretrain [283/1000]  train=0.083975  val=0.091179
Pretrain [284/1000]  train=0.082547  val=0.091932
Pretrain [285/1000]  train=0.081197  val=0.089969
Pretrain [286/1000]  train=0.082008  val=0.089492
Pretrain [287/1000]  train=0.081220  val=0.091320
Pretrain [288/1000]  train=0.080720  val=0.090791
Pretrain [289/1000]  train=0.080044  val=0.089921
Pretrain [290/1000]  train=0.079924  val=0.092766
Pretrain [291/1000]  train=0.080904  val=0.089126
Pretrain [292/1000]  train=0.080742  val=0.087978
Pretrain [293/1000]  train=0.080501  val=0.091778
Pretrain [294/1000]  train=0.081588  val=0.087438
Pretrain [295/1000]  train=0.079310  val=0.088599
Pretrain [296/1000]  train=0.080115  val=0.088755
Pretrain [297/1000]  train=0.079617  val=0.091626
Pretrain [298/1000]  train=0.081182  val=0.092772
Pretrain [299/1000]  train=0.079713  val=0.090946
Pretrain [300/1000]  train=0.078446  val=0.093438
Pretrain [301/1000]  train=0.077939  val=0.089045
Pretrain [302/1000]  train=0.078394  val=0.091151
Pretrain [303/1000]  train=0.078725  val=0.090705
Pretrain [304/1000]  train=0.078345  val=0.090699
Pretrain [305/1000]  train=0.079309  val=0.089743
Pretrain [306/1000]  train=0.078377  val=0.088860
Pretrain [307/1000]  train=0.075707  val=0.088828
Pretrain [308/1000]  train=0.077903  val=0.089251
Pretrain [309/1000]  train=0.077417  val=0.089464
Pretrain [310/1000]  train=0.077885  val=0.090108
Pretrain [311/1000]  train=0.076591  val=0.090657
Pretrain [312/1000]  train=0.077470  val=0.091095
Pretrain [313/1000]  train=0.076557  val=0.091272
Pretrain [314/1000]  train=0.076684  val=0.090022
Pretrain [315/1000]  train=0.076685  val=0.090499
Pretrain [316/1000]  train=0.076855  val=0.088131
Pretrain [317/1000]  train=0.077042  val=0.090120
Pretrain [318/1000]  train=0.078508  val=0.089649
Pretrain [319/1000]  train=0.077842  val=0.090519
Pretrain [320/1000]  train=0.077338  val=0.089744
Pretrain [321/1000]  train=0.077464  val=0.088841
Pretrain [322/1000]  train=0.077118  val=0.091236
Pretrain [323/1000]  train=0.077092  val=0.089802
Pretrain [324/1000]  train=0.075862  val=0.090638
Pretrain [325/1000]  train=0.076029  val=0.090244
Pretrain [326/1000]  train=0.075871  val=0.089882
Pretrain [327/1000]  train=0.077503  val=0.090130
Pretrain [328/1000]  train=0.076887  val=0.090415
Pretrain [329/1000]  train=0.077486  val=0.089237
Pretrain [330/1000]  train=0.075281  val=0.090013
Pretrain [331/1000]  train=0.076284  val=0.089805
Pretrain [332/1000]  train=0.074556  val=0.090727
Pretrain [333/1000]  train=0.075678  val=0.089764
Pretrain [334/1000]  train=0.074243  val=0.089691
Pretrain [335/1000]  train=0.077695  val=0.092123
Pretrain [336/1000]  train=0.074512  val=0.090406
Pretrain [337/1000]  train=0.074250  val=0.089618
Pretrain [338/1000]  train=0.075241  val=0.089943
Pretrain [339/1000]  train=0.075329  val=0.089413
Pretrain [340/1000]  train=0.076519  val=0.089698
  -> 验证未改进 200 次，早停。
[PRETRAIN] 最佳 val=0.085872 已保存。

--- [阶段二] 对齐微调 (NLL + α·(1−R2) + λ·CORAL) ---
Fine-tune [1/100000]  val_loss=0.458861
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [2/100000]  val_loss=0.273778
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [3/100000]  val_loss=0.113249
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [4/100000]  val_loss=-0.019750
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [5/100000]  val_loss=-0.112217
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [6/100000]  val_loss=-0.193171
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [7/100000]  val_loss=-0.265658
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [8/100000]  val_loss=-0.328109
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [9/100000]  val_loss=-0.370530
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [10/100000]  val_loss=-0.407432
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [11/100000]  val_loss=-0.438275
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [12/100000]  val_loss=-0.466098
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [13/100000]  val_loss=-0.486855
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [14/100000]  val_loss=-0.515702
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [15/100000]  val_loss=-0.540139
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [16/100000]  val_loss=-0.553045
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [17/100000]  val_loss=-0.576159
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [18/100000]  val_loss=-0.576387
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [19/100000]  val_loss=-0.593555
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [20/100000]  val_loss=-0.613147
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [21/100000]  val_loss=-0.618504
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [22/100000]  val_loss=-0.627880
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [23/100000]  val_loss=-0.630825
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [24/100000]  val_loss=-0.646888
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [25/100000]  val_loss=-0.655115
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [26/100000]  val_loss=-0.668219
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [27/100000]  val_loss=-0.666796
Fine-tune [28/100000]  val_loss=-0.670719
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [29/100000]  val_loss=-0.673483
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [30/100000]  val_loss=-0.686853
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [31/100000]  val_loss=-0.701957
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [32/100000]  val_loss=-0.703799
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [33/100000]  val_loss=-0.717054
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [34/100000]  val_loss=-0.712118
Fine-tune [35/100000]  val_loss=-0.721080
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [36/100000]  val_loss=-0.724981
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [37/100000]  val_loss=-0.724936
Fine-tune [38/100000]  val_loss=-0.738199
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [39/100000]  val_loss=-0.734864
Fine-tune [40/100000]  val_loss=-0.737427
Fine-tune [41/100000]  val_loss=-0.738019
Fine-tune [42/100000]  val_loss=-0.746899
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [43/100000]  val_loss=-0.758831
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [44/100000]  val_loss=-0.766827
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [45/100000]  val_loss=-0.760493
Fine-tune [46/100000]  val_loss=-0.776973
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [47/100000]  val_loss=-0.776752
Fine-tune [48/100000]  val_loss=-0.782755
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [49/100000]  val_loss=-0.782949
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [50/100000]  val_loss=-0.787658
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [51/100000]  val_loss=-0.792822
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [52/100000]  val_loss=-0.781151
Fine-tune [53/100000]  val_loss=-0.801241
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [54/100000]  val_loss=-0.797470
Fine-tune [55/100000]  val_loss=-0.787356
Fine-tune [56/100000]  val_loss=-0.801818
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [57/100000]  val_loss=-0.805921
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [58/100000]  val_loss=-0.801460
Fine-tune [59/100000]  val_loss=-0.808866
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [60/100000]  val_loss=-0.832355
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [61/100000]  val_loss=-0.811449
Fine-tune [62/100000]  val_loss=-0.824167
Fine-tune [63/100000]  val_loss=-0.825527
Fine-tune [64/100000]  val_loss=-0.831164
Fine-tune [65/100000]  val_loss=-0.831327
Fine-tune [66/100000]  val_loss=-0.837288
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [67/100000]  val_loss=-0.839503
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [68/100000]  val_loss=-0.837365
Fine-tune [69/100000]  val_loss=-0.836720
Fine-tune [70/100000]  val_loss=-0.847801
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [71/100000]  val_loss=-0.838658
Fine-tune [72/100000]  val_loss=-0.841916
Fine-tune [73/100000]  val_loss=-0.845489
Fine-tune [74/100000]  val_loss=-0.840552
Fine-tune [75/100000]  val_loss=-0.857340
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [76/100000]  val_loss=-0.852730
Fine-tune [77/100000]  val_loss=-0.852205
Fine-tune [78/100000]  val_loss=-0.851805
Fine-tune [79/100000]  val_loss=-0.864557
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [80/100000]  val_loss=-0.852810
Fine-tune [81/100000]  val_loss=-0.853238
Fine-tune [82/100000]  val_loss=-0.864371
Fine-tune [83/100000]  val_loss=-0.869619
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [84/100000]  val_loss=-0.861177
Fine-tune [85/100000]  val_loss=-0.875347
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [86/100000]  val_loss=-0.887166
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [87/100000]  val_loss=-0.883177
Fine-tune [88/100000]  val_loss=-0.882250
Fine-tune [89/100000]  val_loss=-0.893377
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [90/100000]  val_loss=-0.888753
Fine-tune [91/100000]  val_loss=-0.887549
Fine-tune [92/100000]  val_loss=-0.885937
Fine-tune [93/100000]  val_loss=-0.885349
Fine-tune [94/100000]  val_loss=-0.891915
Fine-tune [95/100000]  val_loss=-0.884621
Fine-tune [96/100000]  val_loss=-0.887903
Fine-tune [97/100000]  val_loss=-0.884806
Fine-tune [98/100000]  val_loss=-0.888554
Fine-tune [99/100000]  val_loss=-0.906683
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [100/100000]  val_loss=-0.900902
Fine-tune [101/100000]  val_loss=-0.891607
Fine-tune [102/100000]  val_loss=-0.899215
Fine-tune [103/100000]  val_loss=-0.907321
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [104/100000]  val_loss=-0.909895
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [105/100000]  val_loss=-0.903281
Fine-tune [106/100000]  val_loss=-0.903364
Fine-tune [107/100000]  val_loss=-0.895402
Fine-tune [108/100000]  val_loss=-0.904759
Fine-tune [109/100000]  val_loss=-0.891909
Fine-tune [110/100000]  val_loss=-0.916476
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [111/100000]  val_loss=-0.911046
Fine-tune [112/100000]  val_loss=-0.896119
Fine-tune [113/100000]  val_loss=-0.896579
Fine-tune [114/100000]  val_loss=-0.908446
Fine-tune [115/100000]  val_loss=-0.909565
Fine-tune [116/100000]  val_loss=-0.920889
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [117/100000]  val_loss=-0.913289
Fine-tune [118/100000]  val_loss=-0.918811
Fine-tune [119/100000]  val_loss=-0.909953
Fine-tune [120/100000]  val_loss=-0.899184
Fine-tune [121/100000]  val_loss=-0.911781
Fine-tune [122/100000]  val_loss=-0.915730
Fine-tune [123/100000]  val_loss=-0.920954
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [124/100000]  val_loss=-0.923514
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [125/100000]  val_loss=-0.925567
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [126/100000]  val_loss=-0.929772
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [127/100000]  val_loss=-0.915195
Fine-tune [128/100000]  val_loss=-0.922016
Fine-tune [129/100000]  val_loss=-0.930960
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [130/100000]  val_loss=-0.926822
Fine-tune [131/100000]  val_loss=-0.936296
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [132/100000]  val_loss=-0.923874
Fine-tune [133/100000]  val_loss=-0.928563
Fine-tune [134/100000]  val_loss=-0.939638
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [135/100000]  val_loss=-0.920507
Fine-tune [136/100000]  val_loss=-0.916116
Fine-tune [137/100000]  val_loss=-0.929841
Fine-tune [138/100000]  val_loss=-0.933137
Fine-tune [139/100000]  val_loss=-0.931256
Fine-tune [140/100000]  val_loss=-0.939218
Fine-tune [141/100000]  val_loss=-0.930627
Fine-tune [142/100000]  val_loss=-0.925013
Fine-tune [143/100000]  val_loss=-0.918775
Fine-tune [144/100000]  val_loss=-0.939503
Fine-tune [145/100000]  val_loss=-0.939893
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [146/100000]  val_loss=-0.947909
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [147/100000]  val_loss=-0.933362
Fine-tune [148/100000]  val_loss=-0.936407
Fine-tune [149/100000]  val_loss=-0.937215
Fine-tune [150/100000]  val_loss=-0.934777
Fine-tune [151/100000]  val_loss=-0.938360
Fine-tune [152/100000]  val_loss=-0.937515
Fine-tune [153/100000]  val_loss=-0.946366
Fine-tune [154/100000]  val_loss=-0.935103
Fine-tune [155/100000]  val_loss=-0.941801
Fine-tune [156/100000]  val_loss=-0.939939
Fine-tune [157/100000]  val_loss=-0.938738
Fine-tune [158/100000]  val_loss=-0.930352
Fine-tune [159/100000]  val_loss=-0.923537
Fine-tune [160/100000]  val_loss=-0.938590
Fine-tune [161/100000]  val_loss=-0.944145
Fine-tune [162/100000]  val_loss=-0.932683
Fine-tune [163/100000]  val_loss=-0.936550
Fine-tune [164/100000]  val_loss=-0.934016
Fine-tune [165/100000]  val_loss=-0.923956
Fine-tune [166/100000]  val_loss=-0.924688
Fine-tune [167/100000]  val_loss=-0.914992
Fine-tune [168/100000]  val_loss=-0.924042
Fine-tune [169/100000]  val_loss=-0.930894
Fine-tune [170/100000]  val_loss=-0.932998
Fine-tune [171/100000]  val_loss=-0.928944
Fine-tune [172/100000]  val_loss=-0.923193
Fine-tune [173/100000]  val_loss=-0.924496
Fine-tune [174/100000]  val_loss=-0.932018
Fine-tune [175/100000]  val_loss=-0.932257
Fine-tune [176/100000]  val_loss=-0.944637
Fine-tune [177/100000]  val_loss=-0.951371
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [178/100000]  val_loss=-0.937302
Fine-tune [179/100000]  val_loss=-0.935588
Fine-tune [180/100000]  val_loss=-0.939993
Fine-tune [181/100000]  val_loss=-0.953746
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [182/100000]  val_loss=-0.949961
Fine-tune [183/100000]  val_loss=-0.948603
Fine-tune [184/100000]  val_loss=-0.937990
Fine-tune [185/100000]  val_loss=-0.937385
Fine-tune [186/100000]  val_loss=-0.937411
Fine-tune [187/100000]  val_loss=-0.951338
Fine-tune [188/100000]  val_loss=-0.956926
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [189/100000]  val_loss=-0.956955
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [190/100000]  val_loss=-0.959350
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [191/100000]  val_loss=-0.950546
Fine-tune [192/100000]  val_loss=-0.944204
Fine-tune [193/100000]  val_loss=-0.952167
Fine-tune [194/100000]  val_loss=-0.941341
Fine-tune [195/100000]  val_loss=-0.940199
Fine-tune [196/100000]  val_loss=-0.935026
Fine-tune [197/100000]  val_loss=-0.938400
Fine-tune [198/100000]  val_loss=-0.939198
Fine-tune [199/100000]  val_loss=-0.942189
Fine-tune [200/100000]  val_loss=-0.945298
Fine-tune [201/100000]  val_loss=-0.944789
Fine-tune [202/100000]  val_loss=-0.932397
Fine-tune [203/100000]  val_loss=-0.940768
Fine-tune [204/100000]  val_loss=-0.950879
Fine-tune [205/100000]  val_loss=-0.948081
Fine-tune [206/100000]  val_loss=-0.948521
Fine-tune [207/100000]  val_loss=-0.951660
Fine-tune [208/100000]  val_loss=-0.956028
Fine-tune [209/100000]  val_loss=-0.963292
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [210/100000]  val_loss=-0.956490
Fine-tune [211/100000]  val_loss=-0.948843
Fine-tune [212/100000]  val_loss=-0.952638
Fine-tune [213/100000]  val_loss=-0.960193
Fine-tune [214/100000]  val_loss=-0.960289
Fine-tune [215/100000]  val_loss=-0.957406
Fine-tune [216/100000]  val_loss=-0.946800
Fine-tune [217/100000]  val_loss=-0.944210
Fine-tune [218/100000]  val_loss=-0.946477
Fine-tune [219/100000]  val_loss=-0.958035
Fine-tune [220/100000]  val_loss=-0.962157
Fine-tune [221/100000]  val_loss=-0.957373
Fine-tune [222/100000]  val_loss=-0.961054
Fine-tune [223/100000]  val_loss=-0.954192
Fine-tune [224/100000]  val_loss=-0.940266
Fine-tune [225/100000]  val_loss=-0.939994
Fine-tune [226/100000]  val_loss=-0.949823
Fine-tune [227/100000]  val_loss=-0.956001
Fine-tune [228/100000]  val_loss=-0.945060
Fine-tune [229/100000]  val_loss=-0.955938
Fine-tune [230/100000]  val_loss=-0.964545
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [231/100000]  val_loss=-0.960018
Fine-tune [232/100000]  val_loss=-0.952827
Fine-tune [233/100000]  val_loss=-0.959853
Fine-tune [234/100000]  val_loss=-0.955730
Fine-tune [235/100000]  val_loss=-0.955569
Fine-tune [236/100000]  val_loss=-0.952535
Fine-tune [237/100000]  val_loss=-0.945859
Fine-tune [238/100000]  val_loss=-0.942800
Fine-tune [239/100000]  val_loss=-0.941709
Fine-tune [240/100000]  val_loss=-0.957986
Fine-tune [241/100000]  val_loss=-0.962881
Fine-tune [242/100000]  val_loss=-0.959664
Fine-tune [243/100000]  val_loss=-0.954290
Fine-tune [244/100000]  val_loss=-0.949097
Fine-tune [245/100000]  val_loss=-0.954746
Fine-tune [246/100000]  val_loss=-0.948277
Fine-tune [247/100000]  val_loss=-0.942303
Fine-tune [248/100000]  val_loss=-0.950280
Fine-tune [249/100000]  val_loss=-0.964273
Fine-tune [250/100000]  val_loss=-0.969265
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [251/100000]  val_loss=-0.962897
Fine-tune [252/100000]  val_loss=-0.953797
Fine-tune [253/100000]  val_loss=-0.949402
Fine-tune [254/100000]  val_loss=-0.956441
Fine-tune [255/100000]  val_loss=-0.960053
Fine-tune [256/100000]  val_loss=-0.962450
Fine-tune [257/100000]  val_loss=-0.957809
Fine-tune [258/100000]  val_loss=-0.968846
Fine-tune [259/100000]  val_loss=-0.965249
Fine-tune [260/100000]  val_loss=-0.957387
Fine-tune [261/100000]  val_loss=-0.954807
Fine-tune [262/100000]  val_loss=-0.957326
Fine-tune [263/100000]  val_loss=-0.967869
Fine-tune [264/100000]  val_loss=-0.962203
Fine-tune [265/100000]  val_loss=-0.960694
Fine-tune [266/100000]  val_loss=-0.961834
Fine-tune [267/100000]  val_loss=-0.958262
Fine-tune [268/100000]  val_loss=-0.960752
Fine-tune [269/100000]  val_loss=-0.969735
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [270/100000]  val_loss=-0.959060
Fine-tune [271/100000]  val_loss=-0.953825
Fine-tune [272/100000]  val_loss=-0.958822
Fine-tune [273/100000]  val_loss=-0.950722
Fine-tune [274/100000]  val_loss=-0.959398
Fine-tune [275/100000]  val_loss=-0.955918
Fine-tune [276/100000]  val_loss=-0.959976
Fine-tune [277/100000]  val_loss=-0.955313
Fine-tune [278/100000]  val_loss=-0.955753
Fine-tune [279/100000]  val_loss=-0.957382
Fine-tune [280/100000]  val_loss=-0.964119
Fine-tune [281/100000]  val_loss=-0.956626
Fine-tune [282/100000]  val_loss=-0.954150
Fine-tune [283/100000]  val_loss=-0.965852
Fine-tune [284/100000]  val_loss=-0.962196
Fine-tune [285/100000]  val_loss=-0.951517
Fine-tune [286/100000]  val_loss=-0.944381
Fine-tune [287/100000]  val_loss=-0.947886
Fine-tune [288/100000]  val_loss=-0.955216
Fine-tune [289/100000]  val_loss=-0.960685
Fine-tune [290/100000]  val_loss=-0.953519
Fine-tune [291/100000]  val_loss=-0.966970
Fine-tune [292/100000]  val_loss=-0.962408
Fine-tune [293/100000]  val_loss=-0.960188
Fine-tune [294/100000]  val_loss=-0.957127
Fine-tune [295/100000]  val_loss=-0.964578
Fine-tune [296/100000]  val_loss=-0.971993
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [297/100000]  val_loss=-0.971185
Fine-tune [298/100000]  val_loss=-0.968007
Fine-tune [299/100000]  val_loss=-0.978096
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [300/100000]  val_loss=-0.977867
Fine-tune [301/100000]  val_loss=-0.971215
Fine-tune [302/100000]  val_loss=-0.973148
Fine-tune [303/100000]  val_loss=-0.957817
Fine-tune [304/100000]  val_loss=-0.963013
Fine-tune [305/100000]  val_loss=-0.956807
Fine-tune [306/100000]  val_loss=-0.966847
Fine-tune [307/100000]  val_loss=-0.971985
Fine-tune [308/100000]  val_loss=-0.952951
Fine-tune [309/100000]  val_loss=-0.953725
Fine-tune [310/100000]  val_loss=-0.962951
Fine-tune [311/100000]  val_loss=-0.962652
Fine-tune [312/100000]  val_loss=-0.960854
Fine-tune [313/100000]  val_loss=-0.966607
Fine-tune [314/100000]  val_loss=-0.967818
Fine-tune [315/100000]  val_loss=-0.962353
Fine-tune [316/100000]  val_loss=-0.956480
Fine-tune [317/100000]  val_loss=-0.950199
Fine-tune [318/100000]  val_loss=-0.954165
Fine-tune [319/100000]  val_loss=-0.960289
Fine-tune [320/100000]  val_loss=-0.944072
Fine-tune [321/100000]  val_loss=-0.955692
Fine-tune [322/100000]  val_loss=-0.964674
Fine-tune [323/100000]  val_loss=-0.963741
Fine-tune [324/100000]  val_loss=-0.957655
Fine-tune [325/100000]  val_loss=-0.961291
Fine-tune [326/100000]  val_loss=-0.972175
Fine-tune [327/100000]  val_loss=-0.981491
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [328/100000]  val_loss=-0.982114
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [329/100000]  val_loss=-0.968432
Fine-tune [330/100000]  val_loss=-0.952080
Fine-tune [331/100000]  val_loss=-0.962610
Fine-tune [332/100000]  val_loss=-0.972631
Fine-tune [333/100000]  val_loss=-0.971859
Fine-tune [334/100000]  val_loss=-0.972573
Fine-tune [335/100000]  val_loss=-0.968000
Fine-tune [336/100000]  val_loss=-0.965883
Fine-tune [337/100000]  val_loss=-0.968516
Fine-tune [338/100000]  val_loss=-0.983449
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [339/100000]  val_loss=-0.982046
Fine-tune [340/100000]  val_loss=-0.972204
Fine-tune [341/100000]  val_loss=-0.965926
Fine-tune [342/100000]  val_loss=-0.974499
Fine-tune [343/100000]  val_loss=-0.978593
Fine-tune [344/100000]  val_loss=-0.973929
Fine-tune [345/100000]  val_loss=-0.977864
Fine-tune [346/100000]  val_loss=-0.974667
Fine-tune [347/100000]  val_loss=-0.980065
Fine-tune [348/100000]  val_loss=-0.978893
Fine-tune [349/100000]  val_loss=-0.976356
Fine-tune [350/100000]  val_loss=-0.972710
Fine-tune [351/100000]  val_loss=-0.972180
Fine-tune [352/100000]  val_loss=-0.981483
Fine-tune [353/100000]  val_loss=-0.980983
Fine-tune [354/100000]  val_loss=-0.977652
Fine-tune [355/100000]  val_loss=-0.986429
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [356/100000]  val_loss=-0.986132
Fine-tune [357/100000]  val_loss=-0.974155
Fine-tune [358/100000]  val_loss=-0.973395
Fine-tune [359/100000]  val_loss=-0.961080
Fine-tune [360/100000]  val_loss=-0.954598
Fine-tune [361/100000]  val_loss=-0.969164
Fine-tune [362/100000]  val_loss=-0.970459
Fine-tune [363/100000]  val_loss=-0.960960
Fine-tune [364/100000]  val_loss=-0.944453
Fine-tune [365/100000]  val_loss=-0.951784
Fine-tune [366/100000]  val_loss=-0.963948
Fine-tune [367/100000]  val_loss=-0.962776
Fine-tune [368/100000]  val_loss=-0.961207
Fine-tune [369/100000]  val_loss=-0.958110
Fine-tune [370/100000]  val_loss=-0.971658
Fine-tune [371/100000]  val_loss=-0.975284
Fine-tune [372/100000]  val_loss=-0.958746
Fine-tune [373/100000]  val_loss=-0.970652
Fine-tune [374/100000]  val_loss=-0.978925
Fine-tune [375/100000]  val_loss=-0.978308
Fine-tune [376/100000]  val_loss=-0.981279
Fine-tune [377/100000]  val_loss=-0.971740
Fine-tune [378/100000]  val_loss=-0.976809
Fine-tune [379/100000]  val_loss=-0.966797
Fine-tune [380/100000]  val_loss=-0.956282
Fine-tune [381/100000]  val_loss=-0.956860
Fine-tune [382/100000]  val_loss=-0.959092
Fine-tune [383/100000]  val_loss=-0.965282
Fine-tune [384/100000]  val_loss=-0.975908
Fine-tune [385/100000]  val_loss=-0.983455
Fine-tune [386/100000]  val_loss=-0.981792
Fine-tune [387/100000]  val_loss=-0.981657
Fine-tune [388/100000]  val_loss=-0.965145
Fine-tune [389/100000]  val_loss=-0.964725
Fine-tune [390/100000]  val_loss=-0.962289
Fine-tune [391/100000]  val_loss=-0.969127
Fine-tune [392/100000]  val_loss=-0.973961
Fine-tune [393/100000]  val_loss=-0.981371
Fine-tune [394/100000]  val_loss=-0.985442
Fine-tune [395/100000]  val_loss=-0.978438
Fine-tune [396/100000]  val_loss=-0.972084
Fine-tune [397/100000]  val_loss=-0.983010
Fine-tune [398/100000]  val_loss=-0.973892
Fine-tune [399/100000]  val_loss=-0.972626
Fine-tune [400/100000]  val_loss=-0.967004
Fine-tune [401/100000]  val_loss=-0.971981
Fine-tune [402/100000]  val_loss=-0.972941
Fine-tune [403/100000]  val_loss=-0.976654
Fine-tune [404/100000]  val_loss=-0.960690
Fine-tune [405/100000]  val_loss=-0.970001
Fine-tune [406/100000]  val_loss=-0.974791
Fine-tune [407/100000]  val_loss=-0.969855
Fine-tune [408/100000]  val_loss=-0.972868
Fine-tune [409/100000]  val_loss=-0.967350
Fine-tune [410/100000]  val_loss=-0.962729
Fine-tune [411/100000]  val_loss=-0.965056
Fine-tune [412/100000]  val_loss=-0.967940
Fine-tune [413/100000]  val_loss=-0.969866
Fine-tune [414/100000]  val_loss=-0.978653
Fine-tune [415/100000]  val_loss=-0.972216
Fine-tune [416/100000]  val_loss=-0.971324
Fine-tune [417/100000]  val_loss=-0.979938
Fine-tune [418/100000]  val_loss=-0.988232
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [419/100000]  val_loss=-0.987560
Fine-tune [420/100000]  val_loss=-0.988707
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [421/100000]  val_loss=-0.989911
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [422/100000]  val_loss=-0.992223
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [423/100000]  val_loss=-0.983706
Fine-tune [424/100000]  val_loss=-0.979120
Fine-tune [425/100000]  val_loss=-0.978373
Fine-tune [426/100000]  val_loss=-0.990493
Fine-tune [427/100000]  val_loss=-0.993134
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [428/100000]  val_loss=-0.990877
Fine-tune [429/100000]  val_loss=-0.974601
Fine-tune [430/100000]  val_loss=-0.976686
Fine-tune [431/100000]  val_loss=-0.986295
Fine-tune [432/100000]  val_loss=-0.989328
Fine-tune [433/100000]  val_loss=-0.976928
Fine-tune [434/100000]  val_loss=-0.975506
Fine-tune [435/100000]  val_loss=-0.980214
Fine-tune [436/100000]  val_loss=-0.969095
Fine-tune [437/100000]  val_loss=-0.961775
Fine-tune [438/100000]  val_loss=-0.971668
Fine-tune [439/100000]  val_loss=-0.966809
Fine-tune [440/100000]  val_loss=-0.974679
Fine-tune [441/100000]  val_loss=-0.985225
Fine-tune [442/100000]  val_loss=-0.971368
Fine-tune [443/100000]  val_loss=-0.974288
Fine-tune [444/100000]  val_loss=-0.972278
Fine-tune [445/100000]  val_loss=-0.969266
Fine-tune [446/100000]  val_loss=-0.966038
Fine-tune [447/100000]  val_loss=-0.955170
Fine-tune [448/100000]  val_loss=-0.964487
Fine-tune [449/100000]  val_loss=-0.979192
Fine-tune [450/100000]  val_loss=-0.980667
Fine-tune [451/100000]  val_loss=-0.986971
Fine-tune [452/100000]  val_loss=-0.978249
Fine-tune [453/100000]  val_loss=-0.969816
Fine-tune [454/100000]  val_loss=-0.974357
Fine-tune [455/100000]  val_loss=-0.967347
Fine-tune [456/100000]  val_loss=-0.960182
Fine-tune [457/100000]  val_loss=-0.968428
Fine-tune [458/100000]  val_loss=-0.975841
Fine-tune [459/100000]  val_loss=-0.984582
Fine-tune [460/100000]  val_loss=-0.965675
Fine-tune [461/100000]  val_loss=-0.975215
Fine-tune [462/100000]  val_loss=-0.990297
Fine-tune [463/100000]  val_loss=-0.984332
Fine-tune [464/100000]  val_loss=-0.979387
Fine-tune [465/100000]  val_loss=-0.984920
Fine-tune [466/100000]  val_loss=-1.001245
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [467/100000]  val_loss=-0.985619
Fine-tune [468/100000]  val_loss=-0.980179
Fine-tune [469/100000]  val_loss=-0.986415
Fine-tune [470/100000]  val_loss=-0.989593
Fine-tune [471/100000]  val_loss=-0.975115
Fine-tune [472/100000]  val_loss=-0.970467
Fine-tune [473/100000]  val_loss=-0.969570
Fine-tune [474/100000]  val_loss=-0.976798
Fine-tune [475/100000]  val_loss=-0.989017
Fine-tune [476/100000]  val_loss=-0.986680
Fine-tune [477/100000]  val_loss=-0.996314
Fine-tune [478/100000]  val_loss=-0.983719
Fine-tune [479/100000]  val_loss=-0.982417
Fine-tune [480/100000]  val_loss=-0.984415
Fine-tune [481/100000]  val_loss=-0.974129
Fine-tune [482/100000]  val_loss=-0.975428
Fine-tune [483/100000]  val_loss=-0.977438
Fine-tune [484/100000]  val_loss=-0.979330
Fine-tune [485/100000]  val_loss=-0.978179
Fine-tune [486/100000]  val_loss=-0.983850
Fine-tune [487/100000]  val_loss=-0.981423
Fine-tune [488/100000]  val_loss=-0.970691
Fine-tune [489/100000]  val_loss=-0.965636
Fine-tune [490/100000]  val_loss=-0.967951
Fine-tune [491/100000]  val_loss=-0.966492
Fine-tune [492/100000]  val_loss=-0.967614
Fine-tune [493/100000]  val_loss=-0.977160
Fine-tune [494/100000]  val_loss=-0.986329
Fine-tune [495/100000]  val_loss=-0.987244
Fine-tune [496/100000]  val_loss=-0.990659
Fine-tune [497/100000]  val_loss=-1.001819
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L2/finetuned.pth
Fine-tune [498/100000]  val_loss=-0.997117
Fine-tune [499/100000]  val_loss=-0.990992
Fine-tune [500/100000]  val_loss=-0.982666
Fine-tune [501/100000]  val_loss=-0.976939
Fine-tune [502/100000]  val_loss=-0.974474
Fine-tune [503/100000]  val_loss=-0.968052
Fine-tune [504/100000]  val_loss=-0.962671
Fine-tune [505/100000]  val_loss=-0.964514
Fine-tune [506/100000]  val_loss=-0.960267
Fine-tune [507/100000]  val_loss=-0.966818
Fine-tune [508/100000]  val_loss=-0.982977
Fine-tune [509/100000]  val_loss=-0.979212
Fine-tune [510/100000]  val_loss=-0.977771
Fine-tune [511/100000]  val_loss=-0.975908
Fine-tune [512/100000]  val_loss=-0.972623
Fine-tune [513/100000]  val_loss=-0.979859
Fine-tune [514/100000]  val_loss=-0.978725
Fine-tune [515/100000]  val_loss=-0.975032
Fine-tune [516/100000]  val_loss=-0.967431
Fine-tune [517/100000]  val_loss=-0.973274
Fine-tune [518/100000]  val_loss=-0.970799
Fine-tune [519/100000]  val_loss=-0.986460
Fine-tune [520/100000]  val_loss=-0.985483
Fine-tune [521/100000]  val_loss=-0.984473
Fine-tune [522/100000]  val_loss=-0.984005
Fine-tune [523/100000]  val_loss=-0.998352
Fine-tune [524/100000]  val_loss=-0.990119
Fine-tune [525/100000]  val_loss=-0.990698
Fine-tune [526/100000]  val_loss=-0.992934
Fine-tune [527/100000]  val_loss=-0.994827
Fine-tune [528/100000]  val_loss=-0.996411
Fine-tune [529/100000]  val_loss=-0.990903
Fine-tune [530/100000]  val_loss=-0.993396
Fine-tune [531/100000]  val_loss=-0.992332
Fine-tune [532/100000]  val_loss=-0.992047
Fine-tune [533/100000]  val_loss=-0.984756
Fine-tune [534/100000]  val_loss=-0.979907
Fine-tune [535/100000]  val_loss=-0.977778
Fine-tune [536/100000]  val_loss=-0.977363
Fine-tune [537/100000]  val_loss=-0.981455
Fine-tune [538/100000]  val_loss=-0.982106
Fine-tune [539/100000]  val_loss=-0.981391
Fine-tune [540/100000]  val_loss=-0.974926
Fine-tune [541/100000]  val_loss=-0.975762
Fine-tune [542/100000]  val_loss=-0.973174
Fine-tune [543/100000]  val_loss=-0.961507
Fine-tune [544/100000]  val_loss=-0.972757
Fine-tune [545/100000]  val_loss=-0.970650
Fine-tune [546/100000]  val_loss=-0.970630
Fine-tune [547/100000]  val_loss=-0.979941
Fine-tune [548/100000]  val_loss=-0.980925
Fine-tune [549/100000]  val_loss=-0.979838
Fine-tune [550/100000]  val_loss=-0.970363
Fine-tune [551/100000]  val_loss=-0.967815
Fine-tune [552/100000]  val_loss=-0.971070
Fine-tune [553/100000]  val_loss=-0.970796
Fine-tune [554/100000]  val_loss=-0.962530
Fine-tune [555/100000]  val_loss=-0.970735
Fine-tune [556/100000]  val_loss=-0.978805
Fine-tune [557/100000]  val_loss=-0.964161
Fine-tune [558/100000]  val_loss=-0.962079
Fine-tune [559/100000]  val_loss=-0.960474
Fine-tune [560/100000]  val_loss=-0.962441
Fine-tune [561/100000]  val_loss=-0.962247
Fine-tune [562/100000]  val_loss=-0.957551
Fine-tune [563/100000]  val_loss=-0.967208
Fine-tune [564/100000]  val_loss=-0.973440
Fine-tune [565/100000]  val_loss=-0.976019
Fine-tune [566/100000]  val_loss=-0.974120
Fine-tune [567/100000]  val_loss=-0.983049
Fine-tune [568/100000]  val_loss=-0.970636
Fine-tune [569/100000]  val_loss=-0.963623
Fine-tune [570/100000]  val_loss=-0.970374
Fine-tune [571/100000]  val_loss=-0.979112
Fine-tune [572/100000]  val_loss=-0.969812
Fine-tune [573/100000]  val_loss=-0.984571
Fine-tune [574/100000]  val_loss=-0.990843
Fine-tune [575/100000]  val_loss=-0.975666
Fine-tune [576/100000]  val_loss=-0.983840
Fine-tune [577/100000]  val_loss=-0.986083
Fine-tune [578/100000]  val_loss=-0.975200
Fine-tune [579/100000]  val_loss=-0.968293
Fine-tune [580/100000]  val_loss=-0.978602
Fine-tune [581/100000]  val_loss=-0.981039
Fine-tune [582/100000]  val_loss=-0.984898
Fine-tune [583/100000]  val_loss=-0.972757
Fine-tune [584/100000]  val_loss=-0.965233
Fine-tune [585/100000]  val_loss=-0.960880
Fine-tune [586/100000]  val_loss=-0.949920
Fine-tune [587/100000]  val_loss=-0.949499
Fine-tune [588/100000]  val_loss=-0.953567
Fine-tune [589/100000]  val_loss=-0.955855
Fine-tune [590/100000]  val_loss=-0.949689
Fine-tune [591/100000]  val_loss=-0.953086
Fine-tune [592/100000]  val_loss=-0.956605
Fine-tune [593/100000]  val_loss=-0.967250
Fine-tune [594/100000]  val_loss=-0.963817
Fine-tune [595/100000]  val_loss=-0.960713
Fine-tune [596/100000]  val_loss=-0.964378
Fine-tune [597/100000]  val_loss=-0.954431
Fine-tune [598/100000]  val_loss=-0.954012
Fine-tune [599/100000]  val_loss=-0.948851
Fine-tune [600/100000]  val_loss=-0.961203
Fine-tune [601/100000]  val_loss=-0.962838
Fine-tune [602/100000]  val_loss=-0.963864
Fine-tune [603/100000]  val_loss=-0.970508
Fine-tune [604/100000]  val_loss=-0.968252
Fine-tune [605/100000]  val_loss=-0.973221
Fine-tune [606/100000]  val_loss=-0.969959
Fine-tune [607/100000]  val_loss=-0.960367
Fine-tune [608/100000]  val_loss=-0.960567
Fine-tune [609/100000]  val_loss=-0.965972
Fine-tune [610/100000]  val_loss=-0.972057
Fine-tune [611/100000]  val_loss=-0.964382
Fine-tune [612/100000]  val_loss=-0.959272
Fine-tune [613/100000]  val_loss=-0.961321
Fine-tune [614/100000]  val_loss=-0.960589
Fine-tune [615/100000]  val_loss=-0.952442
Fine-tune [616/100000]  val_loss=-0.966702
Fine-tune [617/100000]  val_loss=-0.961811
Fine-tune [618/100000]  val_loss=-0.959870
Fine-tune [619/100000]  val_loss=-0.956241
Fine-tune [620/100000]  val_loss=-0.958191
Fine-tune [621/100000]  val_loss=-0.957121
Fine-tune [622/100000]  val_loss=-0.965372
Fine-tune [623/100000]  val_loss=-0.967010
Fine-tune [624/100000]  val_loss=-0.974554
Fine-tune [625/100000]  val_loss=-0.967697
Fine-tune [626/100000]  val_loss=-0.972549
Fine-tune [627/100000]  val_loss=-0.975412
Fine-tune [628/100000]  val_loss=-0.964066
Fine-tune [629/100000]  val_loss=-0.962357
Fine-tune [630/100000]  val_loss=-0.962234
Fine-tune [631/100000]  val_loss=-0.959371
Fine-tune [632/100000]  val_loss=-0.958924
Fine-tune [633/100000]  val_loss=-0.957764
Fine-tune [634/100000]  val_loss=-0.961300
Fine-tune [635/100000]  val_loss=-0.959823
Fine-tune [636/100000]  val_loss=-0.939694
Fine-tune [637/100000]  val_loss=-0.937402
Fine-tune [638/100000]  val_loss=-0.946830
Fine-tune [639/100000]  val_loss=-0.950100
Fine-tune [640/100000]  val_loss=-0.954446
Fine-tune [641/100000]  val_loss=-0.970039
Fine-tune [642/100000]  val_loss=-0.968679
Fine-tune [643/100000]  val_loss=-0.956969
Fine-tune [644/100000]  val_loss=-0.957921
Fine-tune [645/100000]  val_loss=-0.956400
Fine-tune [646/100000]  val_loss=-0.969675
Fine-tune [647/100000]  val_loss=-0.963321
Fine-tune [648/100000]  val_loss=-0.951308
Fine-tune [649/100000]  val_loss=-0.961192
Fine-tune [650/100000]  val_loss=-0.959095
Fine-tune [651/100000]  val_loss=-0.964540
Fine-tune [652/100000]  val_loss=-0.952159
Fine-tune [653/100000]  val_loss=-0.943182
Fine-tune [654/100000]  val_loss=-0.960753
Fine-tune [655/100000]  val_loss=-0.956291
Fine-tune [656/100000]  val_loss=-0.963981
Fine-tune [657/100000]  val_loss=-0.963518
Fine-tune [658/100000]  val_loss=-0.963696
Fine-tune [659/100000]  val_loss=-0.959916
Fine-tune [660/100000]  val_loss=-0.959748
Fine-tune [661/100000]  val_loss=-0.964796
Fine-tune [662/100000]  val_loss=-0.961199
Fine-tune [663/100000]  val_loss=-0.966569
Fine-tune [664/100000]  val_loss=-0.967234
Fine-tune [665/100000]  val_loss=-0.966595
Fine-tune [666/100000]  val_loss=-0.968565
Fine-tune [667/100000]  val_loss=-0.971846
Fine-tune [668/100000]  val_loss=-0.953614
Fine-tune [669/100000]  val_loss=-0.964962
Fine-tune [670/100000]  val_loss=-0.980526
Fine-tune [671/100000]  val_loss=-0.969147
Fine-tune [672/100000]  val_loss=-0.965833
Fine-tune [673/100000]  val_loss=-0.955098
Fine-tune [674/100000]  val_loss=-0.956077
Fine-tune [675/100000]  val_loss=-0.973549
Fine-tune [676/100000]  val_loss=-0.969587
Fine-tune [677/100000]  val_loss=-0.973958
Fine-tune [678/100000]  val_loss=-0.978171
Fine-tune [679/100000]  val_loss=-0.962210
Fine-tune [680/100000]  val_loss=-0.968640
Fine-tune [681/100000]  val_loss=-0.971690
Fine-tune [682/100000]  val_loss=-0.961801
Fine-tune [683/100000]  val_loss=-0.961443
Fine-tune [684/100000]  val_loss=-0.971662
Fine-tune [685/100000]  val_loss=-0.973899
Fine-tune [686/100000]  val_loss=-0.971599
Fine-tune [687/100000]  val_loss=-0.975382
Fine-tune [688/100000]  val_loss=-0.960063
Fine-tune [689/100000]  val_loss=-0.968090
Fine-tune [690/100000]  val_loss=-0.970253
Fine-tune [691/100000]  val_loss=-0.970520
Fine-tune [692/100000]  val_loss=-0.974061
Fine-tune [693/100000]  val_loss=-0.983588
Fine-tune [694/100000]  val_loss=-0.978005
Fine-tune [695/100000]  val_loss=-0.978854
Fine-tune [696/100000]  val_loss=-0.987040
Fine-tune [697/100000]  val_loss=-0.961664
Fine-tune [698/100000]  val_loss=-0.952653
Fine-tune [699/100000]  val_loss=-0.962669
Fine-tune [700/100000]  val_loss=-0.966969
Fine-tune [701/100000]  val_loss=-0.963227
Fine-tune [702/100000]  val_loss=-0.965892
Fine-tune [703/100000]  val_loss=-0.967541
Fine-tune [704/100000]  val_loss=-0.963974
Fine-tune [705/100000]  val_loss=-0.973291
Fine-tune [706/100000]  val_loss=-0.980329
Fine-tune [707/100000]  val_loss=-0.973311
Fine-tune [708/100000]  val_loss=-0.968493
Fine-tune [709/100000]  val_loss=-0.969545
Fine-tune [710/100000]  val_loss=-0.960882
Fine-tune [711/100000]  val_loss=-0.946491
Fine-tune [712/100000]  val_loss=-0.954034
Fine-tune [713/100000]  val_loss=-0.969997
Fine-tune [714/100000]  val_loss=-0.966341
Fine-tune [715/100000]  val_loss=-0.956284
Fine-tune [716/100000]  val_loss=-0.952751
Fine-tune [717/100000]  val_loss=-0.950742
Fine-tune [718/100000]  val_loss=-0.955595
Fine-tune [719/100000]  val_loss=-0.955756
Fine-tune [720/100000]  val_loss=-0.957670
Fine-tune [721/100000]  val_loss=-0.959924
Fine-tune [722/100000]  val_loss=-0.963865
Fine-tune [723/100000]  val_loss=-0.963802
Fine-tune [724/100000]  val_loss=-0.961017
Fine-tune [725/100000]  val_loss=-0.960660
Fine-tune [726/100000]  val_loss=-0.956430
Fine-tune [727/100000]  val_loss=-0.966149
Fine-tune [728/100000]  val_loss=-0.976391
Fine-tune [729/100000]  val_loss=-0.960316
Fine-tune [730/100000]  val_loss=-0.957338
Fine-tune [731/100000]  val_loss=-0.945319
Fine-tune [732/100000]  val_loss=-0.948971
Fine-tune [733/100000]  val_loss=-0.961713
Fine-tune [734/100000]  val_loss=-0.972389
Fine-tune [735/100000]  val_loss=-0.969585
Fine-tune [736/100000]  val_loss=-0.948206
Fine-tune [737/100000]  val_loss=-0.936707
Fine-tune [738/100000]  val_loss=-0.948799
Fine-tune [739/100000]  val_loss=-0.963422
Fine-tune [740/100000]  val_loss=-0.960690
Fine-tune [741/100000]  val_loss=-0.949665
Fine-tune [742/100000]  val_loss=-0.943978
Fine-tune [743/100000]  val_loss=-0.932830
Fine-tune [744/100000]  val_loss=-0.939400
Fine-tune [745/100000]  val_loss=-0.948485
Fine-tune [746/100000]  val_loss=-0.942416
Fine-tune [747/100000]  val_loss=-0.937026
Fine-tune [748/100000]  val_loss=-0.929418
Fine-tune [749/100000]  val_loss=-0.942856
Fine-tune [750/100000]  val_loss=-0.929681
Fine-tune [751/100000]  val_loss=-0.931806
Fine-tune [752/100000]  val_loss=-0.940516
Fine-tune [753/100000]  val_loss=-0.950483
Fine-tune [754/100000]  val_loss=-0.956854
Fine-tune [755/100000]  val_loss=-0.948396
Fine-tune [756/100000]  val_loss=-0.931127
Fine-tune [757/100000]  val_loss=-0.952597
Fine-tune [758/100000]  val_loss=-0.954732
Fine-tune [759/100000]  val_loss=-0.947263
Fine-tune [760/100000]  val_loss=-0.960511
Fine-tune [761/100000]  val_loss=-0.966100
Fine-tune [762/100000]  val_loss=-0.958570
Fine-tune [763/100000]  val_loss=-0.938375
Fine-tune [764/100000]  val_loss=-0.939975
Fine-tune [765/100000]  val_loss=-0.941746
Fine-tune [766/100000]  val_loss=-0.953764
Fine-tune [767/100000]  val_loss=-0.942043
Fine-tune [768/100000]  val_loss=-0.930222
Fine-tune [769/100000]  val_loss=-0.924653
Fine-tune [770/100000]  val_loss=-0.933912
Fine-tune [771/100000]  val_loss=-0.942828
Fine-tune [772/100000]  val_loss=-0.957191
Fine-tune [773/100000]  val_loss=-0.952908
Fine-tune [774/100000]  val_loss=-0.942964
Fine-tune [775/100000]  val_loss=-0.934189
Fine-tune [776/100000]  val_loss=-0.932411
Fine-tune [777/100000]  val_loss=-0.935180
Fine-tune [778/100000]  val_loss=-0.948462
Fine-tune [779/100000]  val_loss=-0.943982
Fine-tune [780/100000]  val_loss=-0.946639
Fine-tune [781/100000]  val_loss=-0.951199
Fine-tune [782/100000]  val_loss=-0.944140
Fine-tune [783/100000]  val_loss=-0.942918
Fine-tune [784/100000]  val_loss=-0.946291
Fine-tune [785/100000]  val_loss=-0.939361
Fine-tune [786/100000]  val_loss=-0.935558
Fine-tune [787/100000]  val_loss=-0.942810
Fine-tune [788/100000]  val_loss=-0.938704
Fine-tune [789/100000]  val_loss=-0.931475
Fine-tune [790/100000]  val_loss=-0.934082
Fine-tune [791/100000]  val_loss=-0.936350
Fine-tune [792/100000]  val_loss=-0.940097
Fine-tune [793/100000]  val_loss=-0.943182
Fine-tune [794/100000]  val_loss=-0.949524
Fine-tune [795/100000]  val_loss=-0.939749
Fine-tune [796/100000]  val_loss=-0.930888
Fine-tune [797/100000]  val_loss=-0.930874
Fine-tune [798/100000]  val_loss=-0.937309
Fine-tune [799/100000]  val_loss=-0.933007
Fine-tune [800/100000]  val_loss=-0.940749
Fine-tune [801/100000]  val_loss=-0.934268
Fine-tune [802/100000]  val_loss=-0.934686
Fine-tune [803/100000]  val_loss=-0.935707
Fine-tune [804/100000]  val_loss=-0.923293
Fine-tune [805/100000]  val_loss=-0.915817
Fine-tune [806/100000]  val_loss=-0.935178
Fine-tune [807/100000]  val_loss=-0.940565
Fine-tune [808/100000]  val_loss=-0.926348
Fine-tune [809/100000]  val_loss=-0.926464
Fine-tune [810/100000]  val_loss=-0.930947
Fine-tune [811/100000]  val_loss=-0.943646
Fine-tune [812/100000]  val_loss=-0.940129
Fine-tune [813/100000]  val_loss=-0.929305
Fine-tune [814/100000]  val_loss=-0.933710
Fine-tune [815/100000]  val_loss=-0.926006
Fine-tune [816/100000]  val_loss=-0.937479
Fine-tune [817/100000]  val_loss=-0.939863
Fine-tune [818/100000]  val_loss=-0.931029
Fine-tune [819/100000]  val_loss=-0.941892
Fine-tune [820/100000]  val_loss=-0.935170
Fine-tune [821/100000]  val_loss=-0.925872
Fine-tune [822/100000]  val_loss=-0.929019
Fine-tune [823/100000]  val_loss=-0.920236
Fine-tune [824/100000]  val_loss=-0.928225
Fine-tune [825/100000]  val_loss=-0.943511
Fine-tune [826/100000]  val_loss=-0.941456
Fine-tune [827/100000]  val_loss=-0.951514
Fine-tune [828/100000]  val_loss=-0.945195
Fine-tune [829/100000]  val_loss=-0.946002
Fine-tune [830/100000]  val_loss=-0.945718
Fine-tune [831/100000]  val_loss=-0.935153
Fine-tune [832/100000]  val_loss=-0.949049
Fine-tune [833/100000]  val_loss=-0.953259
Fine-tune [834/100000]  val_loss=-0.930970
Fine-tune [835/100000]  val_loss=-0.934848
Fine-tune [836/100000]  val_loss=-0.940740
Fine-tune [837/100000]  val_loss=-0.945473
Fine-tune [838/100000]  val_loss=-0.944122
Fine-tune [839/100000]  val_loss=-0.926088
Fine-tune [840/100000]  val_loss=-0.924584
Fine-tune [841/100000]  val_loss=-0.934129
Fine-tune [842/100000]  val_loss=-0.933418
Fine-tune [843/100000]  val_loss=-0.934788
Fine-tune [844/100000]  val_loss=-0.943218
Fine-tune [845/100000]  val_loss=-0.929561
Fine-tune [846/100000]  val_loss=-0.946519
Fine-tune [847/100000]  val_loss=-0.932023
Fine-tune [848/100000]  val_loss=-0.921828
Fine-tune [849/100000]  val_loss=-0.916368
Fine-tune [850/100000]  val_loss=-0.918700
Fine-tune [851/100000]  val_loss=-0.922613
Fine-tune [852/100000]  val_loss=-0.932780
Fine-tune [853/100000]  val_loss=-0.916151
Fine-tune [854/100000]  val_loss=-0.910979
Fine-tune [855/100000]  val_loss=-0.908144
Fine-tune [856/100000]  val_loss=-0.915734
Fine-tune [857/100000]  val_loss=-0.918939
Fine-tune [858/100000]  val_loss=-0.926816
Fine-tune [859/100000]  val_loss=-0.923359
Fine-tune [860/100000]  val_loss=-0.919406
Fine-tune [861/100000]  val_loss=-0.909683
Fine-tune [862/100000]  val_loss=-0.924414
Fine-tune [863/100000]  val_loss=-0.942018
Fine-tune [864/100000]  val_loss=-0.934058
Fine-tune [865/100000]  val_loss=-0.929245
Fine-tune [866/100000]  val_loss=-0.914334
Fine-tune [867/100000]  val_loss=-0.924254
Fine-tune [868/100000]  val_loss=-0.918810
Fine-tune [869/100000]  val_loss=-0.923037
Fine-tune [870/100000]  val_loss=-0.920380
Fine-tune [871/100000]  val_loss=-0.918950
Fine-tune [872/100000]  val_loss=-0.935384
Fine-tune [873/100000]  val_loss=-0.934020
Fine-tune [874/100000]  val_loss=-0.922698
Fine-tune [875/100000]  val_loss=-0.915619
Fine-tune [876/100000]  val_loss=-0.910407
Fine-tune [877/100000]  val_loss=-0.915380
Fine-tune [878/100000]  val_loss=-0.924040
Fine-tune [879/100000]  val_loss=-0.925208
Fine-tune [880/100000]  val_loss=-0.918002
Fine-tune [881/100000]  val_loss=-0.916005
Fine-tune [882/100000]  val_loss=-0.921624
Fine-tune [883/100000]  val_loss=-0.934505
Fine-tune [884/100000]  val_loss=-0.935024
Fine-tune [885/100000]  val_loss=-0.932165
Fine-tune [886/100000]  val_loss=-0.929284
Fine-tune [887/100000]  val_loss=-0.927576
Fine-tune [888/100000]  val_loss=-0.907440
Fine-tune [889/100000]  val_loss=-0.916794
Fine-tune [890/100000]  val_loss=-0.920107
Fine-tune [891/100000]  val_loss=-0.921677
Fine-tune [892/100000]  val_loss=-0.917115
Fine-tune [893/100000]  val_loss=-0.925363
Fine-tune [894/100000]  val_loss=-0.939344
Fine-tune [895/100000]  val_loss=-0.936605
Fine-tune [896/100000]  val_loss=-0.928249
Fine-tune [897/100000]  val_loss=-0.926016
Fine-tune [898/100000]  val_loss=-0.930556
Fine-tune [899/100000]  val_loss=-0.928574
Fine-tune [900/100000]  val_loss=-0.937322
Fine-tune [901/100000]  val_loss=-0.930822
Fine-tune [902/100000]  val_loss=-0.938228
Fine-tune [903/100000]  val_loss=-0.937129
Fine-tune [904/100000]  val_loss=-0.923812
Fine-tune [905/100000]  val_loss=-0.922787
Fine-tune [906/100000]  val_loss=-0.916064
Fine-tune [907/100000]  val_loss=-0.931757
Fine-tune [908/100000]  val_loss=-0.941759
Fine-tune [909/100000]  val_loss=-0.932235
Fine-tune [910/100000]  val_loss=-0.927218
Fine-tune [911/100000]  val_loss=-0.939431
Fine-tune [912/100000]  val_loss=-0.949606
Fine-tune [913/100000]  val_loss=-0.936482
Fine-tune [914/100000]  val_loss=-0.922669
Fine-tune [915/100000]  val_loss=-0.913816
Fine-tune [916/100000]  val_loss=-0.920388
Fine-tune [917/100000]  val_loss=-0.916272
Fine-tune [918/100000]  val_loss=-0.916045
Fine-tune [919/100000]  val_loss=-0.922258
Fine-tune [920/100000]  val_loss=-0.928437
Fine-tune [921/100000]  val_loss=-0.910633
Fine-tune [922/100000]  val_loss=-0.919381
Fine-tune [923/100000]  val_loss=-0.909200
Fine-tune [924/100000]  val_loss=-0.913851
Fine-tune [925/100000]  val_loss=-0.918213
Fine-tune [926/100000]  val_loss=-0.911660
Fine-tune [927/100000]  val_loss=-0.910957
Fine-tune [928/100000]  val_loss=-0.912565
Fine-tune [929/100000]  val_loss=-0.904735
Fine-tune [930/100000]  val_loss=-0.909940
Fine-tune [931/100000]  val_loss=-0.903932
Fine-tune [932/100000]  val_loss=-0.917764
Fine-tune [933/100000]  val_loss=-0.919185
Fine-tune [934/100000]  val_loss=-0.923450
Fine-tune [935/100000]  val_loss=-0.923782
Fine-tune [936/100000]  val_loss=-0.916942
Fine-tune [937/100000]  val_loss=-0.925410
Fine-tune [938/100000]  val_loss=-0.924738
Fine-tune [939/100000]  val_loss=-0.923534
Fine-tune [940/100000]  val_loss=-0.900481
Fine-tune [941/100000]  val_loss=-0.913083
Fine-tune [942/100000]  val_loss=-0.902382
Fine-tune [943/100000]  val_loss=-0.907331
Fine-tune [944/100000]  val_loss=-0.927016
Fine-tune [945/100000]  val_loss=-0.923710
Fine-tune [946/100000]  val_loss=-0.925324
Fine-tune [947/100000]  val_loss=-0.916457
Fine-tune [948/100000]  val_loss=-0.925455
Fine-tune [949/100000]  val_loss=-0.922776
Fine-tune [950/100000]  val_loss=-0.917709
Fine-tune [951/100000]  val_loss=-0.918511
Fine-tune [952/100000]  val_loss=-0.915155
Fine-tune [953/100000]  val_loss=-0.923691
Fine-tune [954/100000]  val_loss=-0.933113
Fine-tune [955/100000]  val_loss=-0.930254
Fine-tune [956/100000]  val_loss=-0.931321
Fine-tune [957/100000]  val_loss=-0.933823
Fine-tune [958/100000]  val_loss=-0.941871
Fine-tune [959/100000]  val_loss=-0.933190
Fine-tune [960/100000]  val_loss=-0.939209
Fine-tune [961/100000]  val_loss=-0.934644
Fine-tune [962/100000]  val_loss=-0.913783
Fine-tune [963/100000]  val_loss=-0.903149
Fine-tune [964/100000]  val_loss=-0.911199
Fine-tune [965/100000]  val_loss=-0.918966
Fine-tune [966/100000]  val_loss=-0.908422
Fine-tune [967/100000]  val_loss=-0.903346
Fine-tune [968/100000]  val_loss=-0.907471
Fine-tune [969/100000]  val_loss=-0.907056
Fine-tune [970/100000]  val_loss=-0.917134
Fine-tune [971/100000]  val_loss=-0.914518
Fine-tune [972/100000]  val_loss=-0.883138
Fine-tune [973/100000]  val_loss=-0.910535
Fine-tune [974/100000]  val_loss=-0.919685
Fine-tune [975/100000]  val_loss=-0.918039
Fine-tune [976/100000]  val_loss=-0.911863
Fine-tune [977/100000]  val_loss=-0.925148
Fine-tune [978/100000]  val_loss=-0.923699
Fine-tune [979/100000]  val_loss=-0.923912
Fine-tune [980/100000]  val_loss=-0.932628
Fine-tune [981/100000]  val_loss=-0.917429
Fine-tune [982/100000]  val_loss=-0.918711
Fine-tune [983/100000]  val_loss=-0.914563
Fine-tune [984/100000]  val_loss=-0.907598
Fine-tune [985/100000]  val_loss=-0.913951
Fine-tune [986/100000]  val_loss=-0.922076
Fine-tune [987/100000]  val_loss=-0.916499
Fine-tune [988/100000]  val_loss=-0.928664
Fine-tune [989/100000]  val_loss=-0.934695
Fine-tune [990/100000]  val_loss=-0.905245
Fine-tune [991/100000]  val_loss=-0.914180
Fine-tune [992/100000]  val_loss=-0.931525
Fine-tune [993/100000]  val_loss=-0.934351
Fine-tune [994/100000]  val_loss=-0.922616
Fine-tune [995/100000]  val_loss=-0.913193
Fine-tune [996/100000]  val_loss=-0.898312
Fine-tune [997/100000]  val_loss=-0.913004
Fine-tune [998/100000]  val_loss=-0.915388
Fine-tune [999/100000]  val_loss=-0.894036
Fine-tune [1000/100000]  val_loss=-0.881690
Fine-tune [1001/100000]  val_loss=-0.875957
Fine-tune [1002/100000]  val_loss=-0.900146
Fine-tune [1003/100000]  val_loss=-0.911137
Fine-tune [1004/100000]  val_loss=-0.901999
Fine-tune [1005/100000]  val_loss=-0.913067
Fine-tune [1006/100000]  val_loss=-0.907607
Fine-tune [1007/100000]  val_loss=-0.916263
Fine-tune [1008/100000]  val_loss=-0.902319
Fine-tune [1009/100000]  val_loss=-0.898421
Fine-tune [1010/100000]  val_loss=-0.892313
Fine-tune [1011/100000]  val_loss=-0.893737
Fine-tune [1012/100000]  val_loss=-0.896472
Fine-tune [1013/100000]  val_loss=-0.889485
Fine-tune [1014/100000]  val_loss=-0.904046
Fine-tune [1015/100000]  val_loss=-0.919400
Fine-tune [1016/100000]  val_loss=-0.929286
Fine-tune [1017/100000]  val_loss=-0.925248
Fine-tune [1018/100000]  val_loss=-0.925435
Fine-tune [1019/100000]  val_loss=-0.909891
Fine-tune [1020/100000]  val_loss=-0.909590
Fine-tune [1021/100000]  val_loss=-0.907178
Fine-tune [1022/100000]  val_loss=-0.914173
Fine-tune [1023/100000]  val_loss=-0.900724
Fine-tune [1024/100000]  val_loss=-0.902829
Fine-tune [1025/100000]  val_loss=-0.920887
Fine-tune [1026/100000]  val_loss=-0.908071
Fine-tune [1027/100000]  val_loss=-0.892231
Fine-tune [1028/100000]  val_loss=-0.897414
Fine-tune [1029/100000]  val_loss=-0.909890
Fine-tune [1030/100000]  val_loss=-0.921489
Fine-tune [1031/100000]  val_loss=-0.929989
Fine-tune [1032/100000]  val_loss=-0.926790
Fine-tune [1033/100000]  val_loss=-0.904343
Fine-tune [1034/100000]  val_loss=-0.904372
Fine-tune [1035/100000]  val_loss=-0.910826
Fine-tune [1036/100000]  val_loss=-0.909620
Fine-tune [1037/100000]  val_loss=-0.915526
Fine-tune [1038/100000]  val_loss=-0.918495
Fine-tune [1039/100000]  val_loss=-0.918645
Fine-tune [1040/100000]  val_loss=-0.924479
Fine-tune [1041/100000]  val_loss=-0.930093
Fine-tune [1042/100000]  val_loss=-0.918780
Fine-tune [1043/100000]  val_loss=-0.940511
Fine-tune [1044/100000]  val_loss=-0.923079
Fine-tune [1045/100000]  val_loss=-0.911770
Fine-tune [1046/100000]  val_loss=-0.927007
Fine-tune [1047/100000]  val_loss=-0.919596
Fine-tune [1048/100000]  val_loss=-0.923351
Fine-tune [1049/100000]  val_loss=-0.918740
Fine-tune [1050/100000]  val_loss=-0.927026
Fine-tune [1051/100000]  val_loss=-0.946660
Fine-tune [1052/100000]  val_loss=-0.934864
Fine-tune [1053/100000]  val_loss=-0.927208
Fine-tune [1054/100000]  val_loss=-0.917162
Fine-tune [1055/100000]  val_loss=-0.915330
Fine-tune [1056/100000]  val_loss=-0.889415
Fine-tune [1057/100000]  val_loss=-0.887687
Fine-tune [1058/100000]  val_loss=-0.916894
Fine-tune [1059/100000]  val_loss=-0.926756
Fine-tune [1060/100000]  val_loss=-0.919583
Fine-tune [1061/100000]  val_loss=-0.910985
Fine-tune [1062/100000]  val_loss=-0.914661
Fine-tune [1063/100000]  val_loss=-0.893471
Fine-tune [1064/100000]  val_loss=-0.904969
Fine-tune [1065/100000]  val_loss=-0.916958
Fine-tune [1066/100000]  val_loss=-0.927769
Fine-tune [1067/100000]  val_loss=-0.909008
Fine-tune [1068/100000]  val_loss=-0.916654
Fine-tune [1069/100000]  val_loss=-0.918192
Fine-tune [1070/100000]  val_loss=-0.930266
Fine-tune [1071/100000]  val_loss=-0.924030
Fine-tune [1072/100000]  val_loss=-0.908694
Fine-tune [1073/100000]  val_loss=-0.901756
Fine-tune [1074/100000]  val_loss=-0.907228
Fine-tune [1075/100000]  val_loss=-0.909380
Fine-tune [1076/100000]  val_loss=-0.908850
Fine-tune [1077/100000]  val_loss=-0.906609
Fine-tune [1078/100000]  val_loss=-0.913317
Fine-tune [1079/100000]  val_loss=-0.913393
Fine-tune [1080/100000]  val_loss=-0.907575
Fine-tune [1081/100000]  val_loss=-0.904768
Fine-tune [1082/100000]  val_loss=-0.912953
Fine-tune [1083/100000]  val_loss=-0.916390
Fine-tune [1084/100000]  val_loss=-0.925517
Fine-tune [1085/100000]  val_loss=-0.906399
Fine-tune [1086/100000]  val_loss=-0.897150
Fine-tune [1087/100000]  val_loss=-0.916833
Fine-tune [1088/100000]  val_loss=-0.907718
Fine-tune [1089/100000]  val_loss=-0.913078
Fine-tune [1090/100000]  val_loss=-0.913419
Fine-tune [1091/100000]  val_loss=-0.930522
Fine-tune [1092/100000]  val_loss=-0.928328
Fine-tune [1093/100000]  val_loss=-0.921042
Fine-tune [1094/100000]  val_loss=-0.908223
Fine-tune [1095/100000]  val_loss=-0.889874
Fine-tune [1096/100000]  val_loss=-0.886528
Fine-tune [1097/100000]  val_loss=-0.898031
Fine-tune [1098/100000]  val_loss=-0.894519
Fine-tune [1099/100000]  val_loss=-0.885409
Fine-tune [1100/100000]  val_loss=-0.889531
Fine-tune [1101/100000]  val_loss=-0.905815
Fine-tune [1102/100000]  val_loss=-0.895433
Fine-tune [1103/100000]  val_loss=-0.892223
Fine-tune [1104/100000]  val_loss=-0.896526
Fine-tune [1105/100000]  val_loss=-0.901334
Fine-tune [1106/100000]  val_loss=-0.885336
Fine-tune [1107/100000]  val_loss=-0.892370
Fine-tune [1108/100000]  val_loss=-0.882237
Fine-tune [1109/100000]  val_loss=-0.886830
Fine-tune [1110/100000]  val_loss=-0.888703
Fine-tune [1111/100000]  val_loss=-0.896000
Fine-tune [1112/100000]  val_loss=-0.893666
Fine-tune [1113/100000]  val_loss=-0.889766
Fine-tune [1114/100000]  val_loss=-0.875342
Fine-tune [1115/100000]  val_loss=-0.851962
Fine-tune [1116/100000]  val_loss=-0.870532
Fine-tune [1117/100000]  val_loss=-0.891047
Fine-tune [1118/100000]  val_loss=-0.894017
Fine-tune [1119/100000]  val_loss=-0.883873
Fine-tune [1120/100000]  val_loss=-0.898091
Fine-tune [1121/100000]  val_loss=-0.919333
Fine-tune [1122/100000]  val_loss=-0.909148
Fine-tune [1123/100000]  val_loss=-0.888998
Fine-tune [1124/100000]  val_loss=-0.886306
Fine-tune [1125/100000]  val_loss=-0.880809
Fine-tune [1126/100000]  val_loss=-0.883792
Fine-tune [1127/100000]  val_loss=-0.903201
Fine-tune [1128/100000]  val_loss=-0.901236
Fine-tune [1129/100000]  val_loss=-0.895568
Fine-tune [1130/100000]  val_loss=-0.907246
Fine-tune [1131/100000]  val_loss=-0.897353
Fine-tune [1132/100000]  val_loss=-0.880968
Fine-tune [1133/100000]  val_loss=-0.897644
Fine-tune [1134/100000]  val_loss=-0.895351
Fine-tune [1135/100000]  val_loss=-0.877401
Fine-tune [1136/100000]  val_loss=-0.875906
Fine-tune [1137/100000]  val_loss=-0.900315
Fine-tune [1138/100000]  val_loss=-0.908302
Fine-tune [1139/100000]  val_loss=-0.915527
Fine-tune [1140/100000]  val_loss=-0.910403
Fine-tune [1141/100000]  val_loss=-0.900767
Fine-tune [1142/100000]  val_loss=-0.909391
Fine-tune [1143/100000]  val_loss=-0.913866
Fine-tune [1144/100000]  val_loss=-0.899266
Fine-tune [1145/100000]  val_loss=-0.889079
Fine-tune [1146/100000]  val_loss=-0.889738
Fine-tune [1147/100000]  val_loss=-0.888207
Fine-tune [1148/100000]  val_loss=-0.891664
Fine-tune [1149/100000]  val_loss=-0.876689
Fine-tune [1150/100000]  val_loss=-0.877561
Fine-tune [1151/100000]  val_loss=-0.875143
Fine-tune [1152/100000]  val_loss=-0.868701
Fine-tune [1153/100000]  val_loss=-0.886430
Fine-tune [1154/100000]  val_loss=-0.884780
Fine-tune [1155/100000]  val_loss=-0.884753
Fine-tune [1156/100000]  val_loss=-0.877627
Fine-tune [1157/100000]  val_loss=-0.883907
Fine-tune [1158/100000]  val_loss=-0.884430
Fine-tune [1159/100000]  val_loss=-0.881895
Fine-tune [1160/100000]  val_loss=-0.884634
Fine-tune [1161/100000]  val_loss=-0.885502
Fine-tune [1162/100000]  val_loss=-0.874254
Fine-tune [1163/100000]  val_loss=-0.896859
Fine-tune [1164/100000]  val_loss=-0.874291
Fine-tune [1165/100000]  val_loss=-0.873253
Fine-tune [1166/100000]  val_loss=-0.893944
Fine-tune [1167/100000]  val_loss=-0.878701
Fine-tune [1168/100000]  val_loss=-0.889391
Fine-tune [1169/100000]  val_loss=-0.888045
Fine-tune [1170/100000]  val_loss=-0.886212
Fine-tune [1171/100000]  val_loss=-0.881738
Fine-tune [1172/100000]  val_loss=-0.896579
Fine-tune [1173/100000]  val_loss=-0.887645
Fine-tune [1174/100000]  val_loss=-0.894036
Fine-tune [1175/100000]  val_loss=-0.897040
Fine-tune [1176/100000]  val_loss=-0.910350
Fine-tune [1177/100000]  val_loss=-0.912562
Fine-tune [1178/100000]  val_loss=-0.886653
Fine-tune [1179/100000]  val_loss=-0.878473
Fine-tune [1180/100000]  val_loss=-0.883907
Fine-tune [1181/100000]  val_loss=-0.882815
Fine-tune [1182/100000]  val_loss=-0.869774
Fine-tune [1183/100000]  val_loss=-0.858850
Fine-tune [1184/100000]  val_loss=-0.860898
Fine-tune [1185/100000]  val_loss=-0.848174
Fine-tune [1186/100000]  val_loss=-0.860118
Fine-tune [1187/100000]  val_loss=-0.882068
Fine-tune [1188/100000]  val_loss=-0.897132
Fine-tune [1189/100000]  val_loss=-0.878713
Fine-tune [1190/100000]  val_loss=-0.877399
Fine-tune [1191/100000]  val_loss=-0.887035
Fine-tune [1192/100000]  val_loss=-0.889861
Fine-tune [1193/100000]  val_loss=-0.879668
Fine-tune [1194/100000]  val_loss=-0.876301
Fine-tune [1195/100000]  val_loss=-0.868775
Fine-tune [1196/100000]  val_loss=-0.861125
Fine-tune [1197/100000]  val_loss=-0.860032
Fine-tune [1198/100000]  val_loss=-0.885691
Fine-tune [1199/100000]  val_loss=-0.888938
Fine-tune [1200/100000]  val_loss=-0.887065
Fine-tune [1201/100000]  val_loss=-0.897971
Fine-tune [1202/100000]  val_loss=-0.902859
Fine-tune [1203/100000]  val_loss=-0.888279
Fine-tune [1204/100000]  val_loss=-0.899574
Fine-tune [1205/100000]  val_loss=-0.881077
Fine-tune [1206/100000]  val_loss=-0.876828
Fine-tune [1207/100000]  val_loss=-0.886166
Fine-tune [1208/100000]  val_loss=-0.877576
Fine-tune [1209/100000]  val_loss=-0.859076
Fine-tune [1210/100000]  val_loss=-0.855895
Fine-tune [1211/100000]  val_loss=-0.876659
Fine-tune [1212/100000]  val_loss=-0.883683
Fine-tune [1213/100000]  val_loss=-0.895888
Fine-tune [1214/100000]  val_loss=-0.892567
Fine-tune [1215/100000]  val_loss=-0.885160
Fine-tune [1216/100000]  val_loss=-0.890385
Fine-tune [1217/100000]  val_loss=-0.866100
Fine-tune [1218/100000]  val_loss=-0.850969
Fine-tune [1219/100000]  val_loss=-0.855352
Fine-tune [1220/100000]  val_loss=-0.857258
Fine-tune [1221/100000]  val_loss=-0.852347
Fine-tune [1222/100000]  val_loss=-0.864540
Fine-tune [1223/100000]  val_loss=-0.871237
Fine-tune [1224/100000]  val_loss=-0.885759
Fine-tune [1225/100000]  val_loss=-0.889369
Fine-tune [1226/100000]  val_loss=-0.878711
Fine-tune [1227/100000]  val_loss=-0.876391
Fine-tune [1228/100000]  val_loss=-0.872249
Fine-tune [1229/100000]  val_loss=-0.871161
Fine-tune [1230/100000]  val_loss=-0.874744
Fine-tune [1231/100000]  val_loss=-0.888396
Fine-tune [1232/100000]  val_loss=-0.883753
Fine-tune [1233/100000]  val_loss=-0.877975
Fine-tune [1234/100000]  val_loss=-0.881689
Fine-tune [1235/100000]  val_loss=-0.885758
Fine-tune [1236/100000]  val_loss=-0.893244
Fine-tune [1237/100000]  val_loss=-0.895270
Fine-tune [1238/100000]  val_loss=-0.890458
Fine-tune [1239/100000]  val_loss=-0.897147
Fine-tune [1240/100000]  val_loss=-0.874966
Fine-tune [1241/100000]  val_loss=-0.880001
Fine-tune [1242/100000]  val_loss=-0.864170
Fine-tune [1243/100000]  val_loss=-0.882036
Fine-tune [1244/100000]  val_loss=-0.883504
Fine-tune [1245/100000]  val_loss=-0.880720
Fine-tune [1246/100000]  val_loss=-0.864263
Fine-tune [1247/100000]  val_loss=-0.867449
Fine-tune [1248/100000]  val_loss=-0.865836
Fine-tune [1249/100000]  val_loss=-0.867856
Fine-tune [1250/100000]  val_loss=-0.867225
Fine-tune [1251/100000]  val_loss=-0.877784
Fine-tune [1252/100000]  val_loss=-0.864179
Fine-tune [1253/100000]  val_loss=-0.864999
Fine-tune [1254/100000]  val_loss=-0.880748
Fine-tune [1255/100000]  val_loss=-0.890035
Fine-tune [1256/100000]  val_loss=-0.879008
Fine-tune [1257/100000]  val_loss=-0.864368
Fine-tune [1258/100000]  val_loss=-0.870007
Fine-tune [1259/100000]  val_loss=-0.877979
Fine-tune [1260/100000]  val_loss=-0.885095
Fine-tune [1261/100000]  val_loss=-0.870448
Fine-tune [1262/100000]  val_loss=-0.856210
Fine-tune [1263/100000]  val_loss=-0.862234
Fine-tune [1264/100000]  val_loss=-0.862210
Fine-tune [1265/100000]  val_loss=-0.872299
Fine-tune [1266/100000]  val_loss=-0.877507
Fine-tune [1267/100000]  val_loss=-0.883369
Fine-tune [1268/100000]  val_loss=-0.891114
Fine-tune [1269/100000]  val_loss=-0.895240
Fine-tune [1270/100000]  val_loss=-0.884476
Fine-tune [1271/100000]  val_loss=-0.872322
Fine-tune [1272/100000]  val_loss=-0.875579
Fine-tune [1273/100000]  val_loss=-0.873485
Fine-tune [1274/100000]  val_loss=-0.875847
Fine-tune [1275/100000]  val_loss=-0.873471
Fine-tune [1276/100000]  val_loss=-0.891766
Fine-tune [1277/100000]  val_loss=-0.893068
Fine-tune [1278/100000]  val_loss=-0.870785
Fine-tune [1279/100000]  val_loss=-0.872556
Fine-tune [1280/100000]  val_loss=-0.875604
Fine-tune [1281/100000]  val_loss=-0.889110
Fine-tune [1282/100000]  val_loss=-0.883249
Fine-tune [1283/100000]  val_loss=-0.857923
Fine-tune [1284/100000]  val_loss=-0.865181
Fine-tune [1285/100000]  val_loss=-0.861514
Fine-tune [1286/100000]  val_loss=-0.856665
Fine-tune [1287/100000]  val_loss=-0.845496
Fine-tune [1288/100000]  val_loss=-0.852865
Fine-tune [1289/100000]  val_loss=-0.849679
Fine-tune [1290/100000]  val_loss=-0.854335
Fine-tune [1291/100000]  val_loss=-0.846392
Fine-tune [1292/100000]  val_loss=-0.861131
Fine-tune [1293/100000]  val_loss=-0.874199
Fine-tune [1294/100000]  val_loss=-0.851748
Fine-tune [1295/100000]  val_loss=-0.832218
Fine-tune [1296/100000]  val_loss=-0.822446
Fine-tune [1297/100000]  val_loss=-0.835260
Fine-tune [1298/100000]  val_loss=-0.816817
Fine-tune [1299/100000]  val_loss=-0.846982
Fine-tune [1300/100000]  val_loss=-0.859500
Fine-tune [1301/100000]  val_loss=-0.857214
Fine-tune [1302/100000]  val_loss=-0.871323
Fine-tune [1303/100000]  val_loss=-0.871192
Fine-tune [1304/100000]  val_loss=-0.851577
Fine-tune [1305/100000]  val_loss=-0.839918
Fine-tune [1306/100000]  val_loss=-0.850631
Fine-tune [1307/100000]  val_loss=-0.861214
Fine-tune [1308/100000]  val_loss=-0.871454
Fine-tune [1309/100000]  val_loss=-0.866728
Fine-tune [1310/100000]  val_loss=-0.880823
Fine-tune [1311/100000]  val_loss=-0.879459
Fine-tune [1312/100000]  val_loss=-0.861323
Fine-tune [1313/100000]  val_loss=-0.864210
Fine-tune [1314/100000]  val_loss=-0.847398
Fine-tune [1315/100000]  val_loss=-0.861833
Fine-tune [1316/100000]  val_loss=-0.855436
Fine-tune [1317/100000]  val_loss=-0.868550
Fine-tune [1318/100000]  val_loss=-0.853735
Fine-tune [1319/100000]  val_loss=-0.835844
Fine-tune [1320/100000]  val_loss=-0.862941
Fine-tune [1321/100000]  val_loss=-0.856045
Fine-tune [1322/100000]  val_loss=-0.857159
Fine-tune [1323/100000]  val_loss=-0.853106
Fine-tune [1324/100000]  val_loss=-0.862440
Fine-tune [1325/100000]  val_loss=-0.851731
Fine-tune [1326/100000]  val_loss=-0.847279
Fine-tune [1327/100000]  val_loss=-0.847489
Fine-tune [1328/100000]  val_loss=-0.851797
Fine-tune [1329/100000]  val_loss=-0.847910
Fine-tune [1330/100000]  val_loss=-0.829117
Fine-tune [1331/100000]  val_loss=-0.832992
Fine-tune [1332/100000]  val_loss=-0.846877
Fine-tune [1333/100000]  val_loss=-0.855484
Fine-tune [1334/100000]  val_loss=-0.858878
Fine-tune [1335/100000]  val_loss=-0.847201
Fine-tune [1336/100000]  val_loss=-0.845108
Fine-tune [1337/100000]  val_loss=-0.835069
Fine-tune [1338/100000]  val_loss=-0.836691
Fine-tune [1339/100000]  val_loss=-0.851289
Fine-tune [1340/100000]  val_loss=-0.863944
Fine-tune [1341/100000]  val_loss=-0.850836
Fine-tune [1342/100000]  val_loss=-0.849426
Fine-tune [1343/100000]  val_loss=-0.867549
Fine-tune [1344/100000]  val_loss=-0.857196
Fine-tune [1345/100000]  val_loss=-0.855980
Fine-tune [1346/100000]  val_loss=-0.843404
Fine-tune [1347/100000]  val_loss=-0.849270
Fine-tune [1348/100000]  val_loss=-0.855045
Fine-tune [1349/100000]  val_loss=-0.847348
Fine-tune [1350/100000]  val_loss=-0.857343
Fine-tune [1351/100000]  val_loss=-0.858123
Fine-tune [1352/100000]  val_loss=-0.863726
Fine-tune [1353/100000]  val_loss=-0.868534
Fine-tune [1354/100000]  val_loss=-0.864646
Fine-tune [1355/100000]  val_loss=-0.860853
Fine-tune [1356/100000]  val_loss=-0.854066
Fine-tune [1357/100000]  val_loss=-0.822161
Fine-tune [1358/100000]  val_loss=-0.837812
Fine-tune [1359/100000]  val_loss=-0.827447
Fine-tune [1360/100000]  val_loss=-0.833771
Fine-tune [1361/100000]  val_loss=-0.833437
Fine-tune [1362/100000]  val_loss=-0.847683
Fine-tune [1363/100000]  val_loss=-0.850524
Fine-tune [1364/100000]  val_loss=-0.822793
Fine-tune [1365/100000]  val_loss=-0.827860
Fine-tune [1366/100000]  val_loss=-0.814374
Fine-tune [1367/100000]  val_loss=-0.804489
Fine-tune [1368/100000]  val_loss=-0.829745
Fine-tune [1369/100000]  val_loss=-0.836604
Fine-tune [1370/100000]  val_loss=-0.847819
Fine-tune [1371/100000]  val_loss=-0.859707
Fine-tune [1372/100000]  val_loss=-0.839772
Fine-tune [1373/100000]  val_loss=-0.827490
Fine-tune [1374/100000]  val_loss=-0.822830
Fine-tune [1375/100000]  val_loss=-0.816738
Fine-tune [1376/100000]  val_loss=-0.804004
Fine-tune [1377/100000]  val_loss=-0.820384
Fine-tune [1378/100000]  val_loss=-0.827575
Fine-tune [1379/100000]  val_loss=-0.831383
Fine-tune [1380/100000]  val_loss=-0.832718
Fine-tune [1381/100000]  val_loss=-0.836057
Fine-tune [1382/100000]  val_loss=-0.834740
Fine-tune [1383/100000]  val_loss=-0.834454
Fine-tune [1384/100000]  val_loss=-0.828581
Fine-tune [1385/100000]  val_loss=-0.844215
Fine-tune [1386/100000]  val_loss=-0.845816
Fine-tune [1387/100000]  val_loss=-0.830146
Fine-tune [1388/100000]  val_loss=-0.840997
Fine-tune [1389/100000]  val_loss=-0.832481
Fine-tune [1390/100000]  val_loss=-0.825519
Fine-tune [1391/100000]  val_loss=-0.840185
Fine-tune [1392/100000]  val_loss=-0.836069
Fine-tune [1393/100000]  val_loss=-0.853975
Fine-tune [1394/100000]  val_loss=-0.849569
Fine-tune [1395/100000]  val_loss=-0.849935
Fine-tune [1396/100000]  val_loss=-0.824192
Fine-tune [1397/100000]  val_loss=-0.823019
Fine-tune [1398/100000]  val_loss=-0.838639
Fine-tune [1399/100000]  val_loss=-0.856427
Fine-tune [1400/100000]  val_loss=-0.850452
Fine-tune [1401/100000]  val_loss=-0.825928
Fine-tune [1402/100000]  val_loss=-0.843809
Fine-tune [1403/100000]  val_loss=-0.847701
Fine-tune [1404/100000]  val_loss=-0.815122
Fine-tune [1405/100000]  val_loss=-0.833155
Fine-tune [1406/100000]  val_loss=-0.831329
Fine-tune [1407/100000]  val_loss=-0.836092
Fine-tune [1408/100000]  val_loss=-0.834192
Fine-tune [1409/100000]  val_loss=-0.845900
Fine-tune [1410/100000]  val_loss=-0.870195
Fine-tune [1411/100000]  val_loss=-0.845463
Fine-tune [1412/100000]  val_loss=-0.842482
Fine-tune [1413/100000]  val_loss=-0.835764
Fine-tune [1414/100000]  val_loss=-0.812666
Fine-tune [1415/100000]  val_loss=-0.819101
Fine-tune [1416/100000]  val_loss=-0.831806
Fine-tune [1417/100000]  val_loss=-0.834820
Fine-tune [1418/100000]  val_loss=-0.839111
Fine-tune [1419/100000]  val_loss=-0.847297
Fine-tune [1420/100000]  val_loss=-0.861617
Fine-tune [1421/100000]  val_loss=-0.860001
Fine-tune [1422/100000]  val_loss=-0.852393
Fine-tune [1423/100000]  val_loss=-0.838051
Fine-tune [1424/100000]  val_loss=-0.825320
Fine-tune [1425/100000]  val_loss=-0.848909
Fine-tune [1426/100000]  val_loss=-0.863615
Fine-tune [1427/100000]  val_loss=-0.873810
Fine-tune [1428/100000]  val_loss=-0.851609
Fine-tune [1429/100000]  val_loss=-0.851528
Fine-tune [1430/100000]  val_loss=-0.856571
Fine-tune [1431/100000]  val_loss=-0.831214
Fine-tune [1432/100000]  val_loss=-0.829097
Fine-tune [1433/100000]  val_loss=-0.825923
Fine-tune [1434/100000]  val_loss=-0.815003
Fine-tune [1435/100000]  val_loss=-0.825686
Fine-tune [1436/100000]  val_loss=-0.808654
Fine-tune [1437/100000]  val_loss=-0.811042
Fine-tune [1438/100000]  val_loss=-0.823928
Fine-tune [1439/100000]  val_loss=-0.829721
Fine-tune [1440/100000]  val_loss=-0.849050
Fine-tune [1441/100000]  val_loss=-0.829352
Fine-tune [1442/100000]  val_loss=-0.843092
Fine-tune [1443/100000]  val_loss=-0.834606
Fine-tune [1444/100000]  val_loss=-0.840263
Fine-tune [1445/100000]  val_loss=-0.844818
Fine-tune [1446/100000]  val_loss=-0.859377
Fine-tune [1447/100000]  val_loss=-0.855329
Fine-tune [1448/100000]  val_loss=-0.851419
Fine-tune [1449/100000]  val_loss=-0.853771
Fine-tune [1450/100000]  val_loss=-0.849779
Fine-tune [1451/100000]  val_loss=-0.827899
Fine-tune [1452/100000]  val_loss=-0.813157
Fine-tune [1453/100000]  val_loss=-0.798428
Fine-tune [1454/100000]  val_loss=-0.822244
Fine-tune [1455/100000]  val_loss=-0.835829
Fine-tune [1456/100000]  val_loss=-0.857038
Fine-tune [1457/100000]  val_loss=-0.863888
Fine-tune [1458/100000]  val_loss=-0.826074
Fine-tune [1459/100000]  val_loss=-0.834786
Fine-tune [1460/100000]  val_loss=-0.820476
Fine-tune [1461/100000]  val_loss=-0.785625
Fine-tune [1462/100000]  val_loss=-0.794351
Fine-tune [1463/100000]  val_loss=-0.805478
Fine-tune [1464/100000]  val_loss=-0.819544
Fine-tune [1465/100000]  val_loss=-0.830513
Fine-tune [1466/100000]  val_loss=-0.823843
Fine-tune [1467/100000]  val_loss=-0.817270
Fine-tune [1468/100000]  val_loss=-0.807366
Fine-tune [1469/100000]  val_loss=-0.808299
Fine-tune [1470/100000]  val_loss=-0.817791
Fine-tune [1471/100000]  val_loss=-0.843561
Fine-tune [1472/100000]  val_loss=-0.851651
Fine-tune [1473/100000]  val_loss=-0.841210
Fine-tune [1474/100000]  val_loss=-0.831603
Fine-tune [1475/100000]  val_loss=-0.847341
Fine-tune [1476/100000]  val_loss=-0.844433
Fine-tune [1477/100000]  val_loss=-0.832929
Fine-tune [1478/100000]  val_loss=-0.816034
Fine-tune [1479/100000]  val_loss=-0.812594
Fine-tune [1480/100000]  val_loss=-0.824257
Fine-tune [1481/100000]  val_loss=-0.820579
Fine-tune [1482/100000]  val_loss=-0.816347
Fine-tune [1483/100000]  val_loss=-0.831283
Fine-tune [1484/100000]  val_loss=-0.829452
Fine-tune [1485/100000]  val_loss=-0.816658
Fine-tune [1486/100000]  val_loss=-0.815241
Fine-tune [1487/100000]  val_loss=-0.816718
Fine-tune [1488/100000]  val_loss=-0.825140
Fine-tune [1489/100000]  val_loss=-0.842431
Fine-tune [1490/100000]  val_loss=-0.851487
Fine-tune [1491/100000]  val_loss=-0.852850
Fine-tune [1492/100000]  val_loss=-0.845389
Fine-tune [1493/100000]  val_loss=-0.825447
Fine-tune [1494/100000]  val_loss=-0.821414
Fine-tune [1495/100000]  val_loss=-0.849080
Fine-tune [1496/100000]  val_loss=-0.834154
Fine-tune [1497/100000]  val_loss=-0.835752
  -> 验证未改进 1000 次，早停。
[FINETUNE] 最佳验证损失=-1.001819 已保存。

--- 评估 [HD128_L2] ---

=== 本次试验参数 (Run Config) ===
opamp             : two_stage_opamp
hidden_dim        : 128
num_layers        : 2
lr_pretrain       : 0.003
epochs_pretrain   : 1000
patience_pretrain : 200
lr_finetune       : 0.0038
epochs_finetune   : 100000
patience_finetune : 1000
batch_a           : 128
batch_b           : 64
dropout_rate      : 0.2
alpha_r2          : 0.0
lambda_coral      : 0.1
seed              : 42
device            : cpu

--- [评估阶段] 开始计算指标 ---

=== 目标域验证集指标（物理单位）===
slewrate_pos    MSE=1.176e+14  MAE=8.181e+06  R2=0.7257
dc_gain         MSE=3.201e+07  MAE=1532  R2=0.1782
ugf             MSE=1.092e+14  MAE=6.571e+06  R2=0.7531
phase_margin    MSE=189.6  MAE=10.04  R2=0.8348
cmrr            MSE=8.477e+11  MAE=9.278e+04  R2=0.0213

Avg  (all dims)   MSE=4.555e+13  MAE=2.969e+06  R2=0.5026
[OK] HD128_L2 -> r2_avg=0.5026, mae_avg=2.969e+06, mse_avg=4.555e+13
===== [HD128_L2] 训练完成 =====

===== [HD128_L3] 训练开始 =====

--- [阶段一] Backbone 预训练 (source_train / source_val, HuberLoss) ---
Pretrain [1/1000]  train=0.268561  val=0.223953
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [2/1000]  train=0.202688  val=0.166604
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [3/1000]  train=0.174739  val=0.146337
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [4/1000]  train=0.159663  val=0.143892
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [5/1000]  train=0.148069  val=0.130653
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [6/1000]  train=0.141978  val=0.121306
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [7/1000]  train=0.137712  val=0.121446
Pretrain [8/1000]  train=0.131001  val=0.113814
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [9/1000]  train=0.126433  val=0.117389
Pretrain [10/1000]  train=0.124730  val=0.104819
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [11/1000]  train=0.119648  val=0.101820
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [12/1000]  train=0.118790  val=0.099019
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [13/1000]  train=0.115566  val=0.100208
Pretrain [14/1000]  train=0.112476  val=0.100407
Pretrain [15/1000]  train=0.109536  val=0.096556
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [16/1000]  train=0.107454  val=0.091947
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [17/1000]  train=0.107424  val=0.092116
Pretrain [18/1000]  train=0.107014  val=0.090841
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [19/1000]  train=0.103514  val=0.092436
Pretrain [20/1000]  train=0.104303  val=0.089442
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [21/1000]  train=0.101743  val=0.090098
Pretrain [22/1000]  train=0.101701  val=0.088353
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [23/1000]  train=0.100019  val=0.088978
Pretrain [24/1000]  train=0.098889  val=0.089722
Pretrain [25/1000]  train=0.097978  val=0.088569
Pretrain [26/1000]  train=0.097379  val=0.086623
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [27/1000]  train=0.098740  val=0.086342
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [28/1000]  train=0.093407  val=0.088126
Pretrain [29/1000]  train=0.095705  val=0.087855
Pretrain [30/1000]  train=0.097544  val=0.087049
Pretrain [31/1000]  train=0.094860  val=0.083318
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [32/1000]  train=0.097373  val=0.084992
Pretrain [33/1000]  train=0.092587  val=0.083454
Pretrain [34/1000]  train=0.089990  val=0.081153
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [35/1000]  train=0.092447  val=0.083856
Pretrain [36/1000]  train=0.091530  val=0.080995
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [37/1000]  train=0.091214  val=0.081410
Pretrain [38/1000]  train=0.090869  val=0.083984
Pretrain [39/1000]  train=0.090020  val=0.080323
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [40/1000]  train=0.089436  val=0.077700
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [41/1000]  train=0.088197  val=0.081760
Pretrain [42/1000]  train=0.089457  val=0.082389
Pretrain [43/1000]  train=0.087324  val=0.078430
Pretrain [44/1000]  train=0.087272  val=0.083676
Pretrain [45/1000]  train=0.086615  val=0.077392
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [46/1000]  train=0.087736  val=0.077880
Pretrain [47/1000]  train=0.085213  val=0.078564
Pretrain [48/1000]  train=0.083219  val=0.080358
Pretrain [49/1000]  train=0.086110  val=0.078858
Pretrain [50/1000]  train=0.086264  val=0.081692
Pretrain [51/1000]  train=0.085046  val=0.076722
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [52/1000]  train=0.085751  val=0.082839
Pretrain [53/1000]  train=0.083047  val=0.079105
Pretrain [54/1000]  train=0.082672  val=0.073922
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [55/1000]  train=0.083459  val=0.076682
Pretrain [56/1000]  train=0.081533  val=0.074701
Pretrain [57/1000]  train=0.081075  val=0.077226
Pretrain [58/1000]  train=0.082977  val=0.074721
Pretrain [59/1000]  train=0.082303  val=0.076160
Pretrain [60/1000]  train=0.082005  val=0.074584
Pretrain [61/1000]  train=0.082522  val=0.077305
Pretrain [62/1000]  train=0.083485  val=0.076571
Pretrain [63/1000]  train=0.081486  val=0.077993
Pretrain [64/1000]  train=0.081858  val=0.077759
Pretrain [65/1000]  train=0.081209  val=0.077118
Pretrain [66/1000]  train=0.079211  val=0.074127
Pretrain [67/1000]  train=0.078398  val=0.078620
Pretrain [68/1000]  train=0.081069  val=0.081446
Pretrain [69/1000]  train=0.078210  val=0.075196
Pretrain [70/1000]  train=0.078717  val=0.075500
Pretrain [71/1000]  train=0.079437  val=0.076046
Pretrain [72/1000]  train=0.078504  val=0.072774
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [73/1000]  train=0.075629  val=0.076487
Pretrain [74/1000]  train=0.078769  val=0.080065
Pretrain [75/1000]  train=0.080033  val=0.072683
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [76/1000]  train=0.076264  val=0.077984
Pretrain [77/1000]  train=0.075397  val=0.072720
Pretrain [78/1000]  train=0.076492  val=0.079808
Pretrain [79/1000]  train=0.074976  val=0.073525
Pretrain [80/1000]  train=0.077729  val=0.075147
Pretrain [81/1000]  train=0.073636  val=0.075048
Pretrain [82/1000]  train=0.075898  val=0.079591
Pretrain [83/1000]  train=0.073372  val=0.080832
Pretrain [84/1000]  train=0.073348  val=0.076370
Pretrain [85/1000]  train=0.073948  val=0.074494
Pretrain [86/1000]  train=0.072856  val=0.076249
Pretrain [87/1000]  train=0.071293  val=0.072764
Pretrain [88/1000]  train=0.071650  val=0.073853
Pretrain [89/1000]  train=0.072473  val=0.072126
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [90/1000]  train=0.071582  val=0.074813
Pretrain [91/1000]  train=0.072613  val=0.075154
Pretrain [92/1000]  train=0.074592  val=0.074175
Pretrain [93/1000]  train=0.070951  val=0.072329
Pretrain [94/1000]  train=0.071136  val=0.074671
Pretrain [95/1000]  train=0.068518  val=0.072062
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [96/1000]  train=0.069014  val=0.072278
Pretrain [97/1000]  train=0.070591  val=0.070410
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [98/1000]  train=0.067766  val=0.073923
Pretrain [99/1000]  train=0.069717  val=0.069634
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [100/1000]  train=0.068342  val=0.070814
Pretrain [101/1000]  train=0.068371  val=0.070889
Pretrain [102/1000]  train=0.068166  val=0.070263
Pretrain [103/1000]  train=0.066323  val=0.073710
Pretrain [104/1000]  train=0.067997  val=0.071212
Pretrain [105/1000]  train=0.067268  val=0.070882
Pretrain [106/1000]  train=0.067259  val=0.070256
Pretrain [107/1000]  train=0.066186  val=0.072260
Pretrain [108/1000]  train=0.067406  val=0.069690
Pretrain [109/1000]  train=0.066406  val=0.069342
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [110/1000]  train=0.067384  val=0.070266
Pretrain [111/1000]  train=0.065458  val=0.070261
Pretrain [112/1000]  train=0.065371  val=0.069980
Pretrain [113/1000]  train=0.066964  val=0.069532
Pretrain [114/1000]  train=0.066382  val=0.069629
Pretrain [115/1000]  train=0.063904  val=0.072162
Pretrain [116/1000]  train=0.065955  val=0.070681
Pretrain [117/1000]  train=0.065783  val=0.069693
Pretrain [118/1000]  train=0.063197  val=0.071724
Pretrain [119/1000]  train=0.065288  val=0.068763
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [120/1000]  train=0.063822  val=0.068803
Pretrain [121/1000]  train=0.064768  val=0.067971
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [122/1000]  train=0.064534  val=0.068969
Pretrain [123/1000]  train=0.063224  val=0.069403
Pretrain [124/1000]  train=0.063138  val=0.071677
Pretrain [125/1000]  train=0.065841  val=0.070591
Pretrain [126/1000]  train=0.063565  val=0.068964
Pretrain [127/1000]  train=0.063790  val=0.071150
Pretrain [128/1000]  train=0.060197  val=0.070966
Pretrain [129/1000]  train=0.061421  val=0.069936
Pretrain [130/1000]  train=0.063847  val=0.069130
Pretrain [131/1000]  train=0.062993  val=0.070701
Pretrain [132/1000]  train=0.063999  val=0.068652
Pretrain [133/1000]  train=0.062788  val=0.069770
Pretrain [134/1000]  train=0.061581  val=0.068019
Pretrain [135/1000]  train=0.060085  val=0.068448
Pretrain [136/1000]  train=0.059813  val=0.067290
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [137/1000]  train=0.059467  val=0.066812
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [138/1000]  train=0.060725  val=0.067548
Pretrain [139/1000]  train=0.060079  val=0.069050
Pretrain [140/1000]  train=0.060086  val=0.068706
Pretrain [141/1000]  train=0.059593  val=0.067530
Pretrain [142/1000]  train=0.060175  val=0.069158
Pretrain [143/1000]  train=0.058520  val=0.066098
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [144/1000]  train=0.059702  val=0.068613
Pretrain [145/1000]  train=0.060555  val=0.067350
Pretrain [146/1000]  train=0.057858  val=0.069803
Pretrain [147/1000]  train=0.059960  val=0.067426
Pretrain [148/1000]  train=0.058551  val=0.067446
Pretrain [149/1000]  train=0.057526  val=0.066590
Pretrain [150/1000]  train=0.060863  val=0.067476
Pretrain [151/1000]  train=0.057770  val=0.066596
Pretrain [152/1000]  train=0.057442  val=0.067278
Pretrain [153/1000]  train=0.058980  val=0.067657
Pretrain [154/1000]  train=0.058917  val=0.067066
Pretrain [155/1000]  train=0.059552  val=0.067119
Pretrain [156/1000]  train=0.058594  val=0.067029
Pretrain [157/1000]  train=0.057932  val=0.067747
Pretrain [158/1000]  train=0.058517  val=0.067101
Pretrain [159/1000]  train=0.057430  val=0.068096
Pretrain [160/1000]  train=0.056804  val=0.067364
Pretrain [161/1000]  train=0.056301  val=0.066664
Pretrain [162/1000]  train=0.057906  val=0.065887
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [163/1000]  train=0.055686  val=0.066710
Pretrain [164/1000]  train=0.057531  val=0.067753
Pretrain [165/1000]  train=0.058398  val=0.066960
Pretrain [166/1000]  train=0.056770  val=0.066738
Pretrain [167/1000]  train=0.056572  val=0.066732
Pretrain [168/1000]  train=0.056478  val=0.066750
Pretrain [169/1000]  train=0.056835  val=0.066859
Pretrain [170/1000]  train=0.055243  val=0.066517
Pretrain [171/1000]  train=0.055976  val=0.066182
Pretrain [172/1000]  train=0.056577  val=0.066065
Pretrain [173/1000]  train=0.056415  val=0.065850
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [174/1000]  train=0.058047  val=0.065910
Pretrain [175/1000]  train=0.055569  val=0.066550
Pretrain [176/1000]  train=0.056258  val=0.065929
Pretrain [177/1000]  train=0.055021  val=0.065530
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [178/1000]  train=0.057422  val=0.065725
Pretrain [179/1000]  train=0.056777  val=0.065906
Pretrain [180/1000]  train=0.053780  val=0.065731
Pretrain [181/1000]  train=0.056019  val=0.065481
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [182/1000]  train=0.055725  val=0.066298
Pretrain [183/1000]  train=0.055446  val=0.066061
Pretrain [184/1000]  train=0.058015  val=0.066378
Pretrain [185/1000]  train=0.057269  val=0.066329
Pretrain [186/1000]  train=0.056847  val=0.066115
Pretrain [187/1000]  train=0.054461  val=0.066037
Pretrain [188/1000]  train=0.055475  val=0.065926
Pretrain [189/1000]  train=0.055545  val=0.065816
Pretrain [190/1000]  train=0.054992  val=0.065839
Pretrain [191/1000]  train=0.055261  val=0.065923
Pretrain [192/1000]  train=0.056048  val=0.065969
Pretrain [193/1000]  train=0.056932  val=0.066100
Pretrain [194/1000]  train=0.053972  val=0.066069
Pretrain [195/1000]  train=0.056327  val=0.066050
Pretrain [196/1000]  train=0.057213  val=0.066062
Pretrain [197/1000]  train=0.055310  val=0.066083
Pretrain [198/1000]  train=0.056566  val=0.066084
Pretrain [199/1000]  train=0.054975  val=0.066082
Pretrain [200/1000]  train=0.055218  val=0.066083
Pretrain [201/1000]  train=0.068398  val=0.078852
Pretrain [202/1000]  train=0.078915  val=0.084445
Pretrain [203/1000]  train=0.077270  val=0.079584
Pretrain [204/1000]  train=0.078720  val=0.079745
Pretrain [205/1000]  train=0.077070  val=0.079666
Pretrain [206/1000]  train=0.075866  val=0.074076
Pretrain [207/1000]  train=0.076396  val=0.079316
Pretrain [208/1000]  train=0.076120  val=0.075609
Pretrain [209/1000]  train=0.076203  val=0.077150
Pretrain [210/1000]  train=0.075382  val=0.079895
Pretrain [211/1000]  train=0.078272  val=0.075739
Pretrain [212/1000]  train=0.076505  val=0.075819
Pretrain [213/1000]  train=0.073626  val=0.076254
Pretrain [214/1000]  train=0.074303  val=0.076359
Pretrain [215/1000]  train=0.074104  val=0.077494
Pretrain [216/1000]  train=0.073324  val=0.082312
Pretrain [217/1000]  train=0.073976  val=0.078014
Pretrain [218/1000]  train=0.073307  val=0.081586
Pretrain [219/1000]  train=0.073468  val=0.080433
Pretrain [220/1000]  train=0.073086  val=0.074025
Pretrain [221/1000]  train=0.069647  val=0.076388
Pretrain [222/1000]  train=0.072388  val=0.075841
Pretrain [223/1000]  train=0.072393  val=0.084625
Pretrain [224/1000]  train=0.070825  val=0.074799
Pretrain [225/1000]  train=0.073302  val=0.076452
Pretrain [226/1000]  train=0.075574  val=0.076840
Pretrain [227/1000]  train=0.073949  val=0.072653
Pretrain [228/1000]  train=0.072300  val=0.075027
Pretrain [229/1000]  train=0.072857  val=0.076360
Pretrain [230/1000]  train=0.072765  val=0.074214
Pretrain [231/1000]  train=0.071917  val=0.077495
Pretrain [232/1000]  train=0.069997  val=0.078944
Pretrain [233/1000]  train=0.071262  val=0.075926
Pretrain [234/1000]  train=0.070806  val=0.075748
Pretrain [235/1000]  train=0.070584  val=0.075821
Pretrain [236/1000]  train=0.069252  val=0.075126
Pretrain [237/1000]  train=0.070748  val=0.074952
Pretrain [238/1000]  train=0.070893  val=0.076344
Pretrain [239/1000]  train=0.069257  val=0.072709
Pretrain [240/1000]  train=0.070703  val=0.071556
Pretrain [241/1000]  train=0.069289  val=0.070538
Pretrain [242/1000]  train=0.070403  val=0.073123
Pretrain [243/1000]  train=0.069520  val=0.074916
Pretrain [244/1000]  train=0.070508  val=0.070885
Pretrain [245/1000]  train=0.070921  val=0.074061
Pretrain [246/1000]  train=0.068609  val=0.072337
Pretrain [247/1000]  train=0.068393  val=0.076766
Pretrain [248/1000]  train=0.068278  val=0.074109
Pretrain [249/1000]  train=0.069078  val=0.076520
Pretrain [250/1000]  train=0.068679  val=0.075016
Pretrain [251/1000]  train=0.068173  val=0.077335
Pretrain [252/1000]  train=0.069425  val=0.074917
Pretrain [253/1000]  train=0.066590  val=0.078516
Pretrain [254/1000]  train=0.069570  val=0.075831
Pretrain [255/1000]  train=0.067242  val=0.073948
Pretrain [256/1000]  train=0.067123  val=0.074668
Pretrain [257/1000]  train=0.067135  val=0.075156
Pretrain [258/1000]  train=0.063653  val=0.072466
Pretrain [259/1000]  train=0.063757  val=0.074560
Pretrain [260/1000]  train=0.066757  val=0.074531
Pretrain [261/1000]  train=0.067356  val=0.077173
Pretrain [262/1000]  train=0.065469  val=0.072266
Pretrain [263/1000]  train=0.066216  val=0.072880
Pretrain [264/1000]  train=0.065256  val=0.079308
Pretrain [265/1000]  train=0.066089  val=0.073598
Pretrain [266/1000]  train=0.064527  val=0.074276
Pretrain [267/1000]  train=0.066137  val=0.072622
Pretrain [268/1000]  train=0.067023  val=0.076266
Pretrain [269/1000]  train=0.063892  val=0.072983
Pretrain [270/1000]  train=0.064646  val=0.078179
Pretrain [271/1000]  train=0.063027  val=0.071950
Pretrain [272/1000]  train=0.064385  val=0.071057
Pretrain [273/1000]  train=0.066202  val=0.073131
Pretrain [274/1000]  train=0.066369  val=0.074101
Pretrain [275/1000]  train=0.062749  val=0.073972
Pretrain [276/1000]  train=0.062807  val=0.072706
Pretrain [277/1000]  train=0.062985  val=0.071492
Pretrain [278/1000]  train=0.063294  val=0.072354
Pretrain [279/1000]  train=0.058894  val=0.073317
Pretrain [280/1000]  train=0.064650  val=0.075221
Pretrain [281/1000]  train=0.062608  val=0.072707
Pretrain [282/1000]  train=0.060615  val=0.072219
Pretrain [283/1000]  train=0.061574  val=0.072997
Pretrain [284/1000]  train=0.061569  val=0.070352
Pretrain [285/1000]  train=0.061569  val=0.076853
Pretrain [286/1000]  train=0.061643  val=0.074045
Pretrain [287/1000]  train=0.060282  val=0.072709
Pretrain [288/1000]  train=0.061582  val=0.073459
Pretrain [289/1000]  train=0.059686  val=0.070862
Pretrain [290/1000]  train=0.062450  val=0.074352
Pretrain [291/1000]  train=0.060939  val=0.071434
Pretrain [292/1000]  train=0.061275  val=0.073969
Pretrain [293/1000]  train=0.061039  val=0.071604
Pretrain [294/1000]  train=0.061305  val=0.068861
Pretrain [295/1000]  train=0.059976  val=0.070092
Pretrain [296/1000]  train=0.060219  val=0.071511
Pretrain [297/1000]  train=0.059489  val=0.069745
Pretrain [298/1000]  train=0.058881  val=0.072591
Pretrain [299/1000]  train=0.060193  val=0.073385
Pretrain [300/1000]  train=0.060284  val=0.073080
Pretrain [301/1000]  train=0.059976  val=0.071307
Pretrain [302/1000]  train=0.060270  val=0.070016
Pretrain [303/1000]  train=0.057644  val=0.069773
Pretrain [304/1000]  train=0.057506  val=0.069850
Pretrain [305/1000]  train=0.058540  val=0.069772
Pretrain [306/1000]  train=0.059592  val=0.071219
Pretrain [307/1000]  train=0.058739  val=0.069340
Pretrain [308/1000]  train=0.058044  val=0.070942
Pretrain [309/1000]  train=0.058823  val=0.068754
Pretrain [310/1000]  train=0.057263  val=0.069491
Pretrain [311/1000]  train=0.056654  val=0.070204
Pretrain [312/1000]  train=0.055879  val=0.070937
Pretrain [313/1000]  train=0.057061  val=0.066454
Pretrain [314/1000]  train=0.058031  val=0.071488
Pretrain [315/1000]  train=0.057156  val=0.070930
Pretrain [316/1000]  train=0.055329  val=0.068599
Pretrain [317/1000]  train=0.055441  val=0.070269
Pretrain [318/1000]  train=0.057418  val=0.068070
Pretrain [319/1000]  train=0.056183  val=0.067196
Pretrain [320/1000]  train=0.055026  val=0.066902
Pretrain [321/1000]  train=0.053127  val=0.070609
Pretrain [322/1000]  train=0.055876  val=0.069176
Pretrain [323/1000]  train=0.055938  val=0.067694
Pretrain [324/1000]  train=0.054855  val=0.068011
Pretrain [325/1000]  train=0.054014  val=0.067256
Pretrain [326/1000]  train=0.054169  val=0.066838
Pretrain [327/1000]  train=0.054956  val=0.067736
Pretrain [328/1000]  train=0.055389  val=0.068983
Pretrain [329/1000]  train=0.054200  val=0.069962
Pretrain [330/1000]  train=0.052427  val=0.069175
Pretrain [331/1000]  train=0.052818  val=0.067440
Pretrain [332/1000]  train=0.053895  val=0.068391
Pretrain [333/1000]  train=0.054504  val=0.069397
Pretrain [334/1000]  train=0.052456  val=0.066537
Pretrain [335/1000]  train=0.052467  val=0.068717
Pretrain [336/1000]  train=0.052217  val=0.067490
Pretrain [337/1000]  train=0.053021  val=0.068028
Pretrain [338/1000]  train=0.052794  val=0.066523
Pretrain [339/1000]  train=0.054880  val=0.070071
Pretrain [340/1000]  train=0.053329  val=0.067955
Pretrain [341/1000]  train=0.052189  val=0.066621
Pretrain [342/1000]  train=0.051313  val=0.066777
Pretrain [343/1000]  train=0.053383  val=0.067892
Pretrain [344/1000]  train=0.051068  val=0.067312
Pretrain [345/1000]  train=0.053121  val=0.067109
Pretrain [346/1000]  train=0.053099  val=0.067654
Pretrain [347/1000]  train=0.051683  val=0.068317
Pretrain [348/1000]  train=0.053002  val=0.066631
Pretrain [349/1000]  train=0.051745  val=0.068191
Pretrain [350/1000]  train=0.051937  val=0.066834
Pretrain [351/1000]  train=0.052242  val=0.066599
Pretrain [352/1000]  train=0.049997  val=0.066770
Pretrain [353/1000]  train=0.051531  val=0.068443
Pretrain [354/1000]  train=0.048994  val=0.066913
Pretrain [355/1000]  train=0.050226  val=0.067673
Pretrain [356/1000]  train=0.048458  val=0.066370
Pretrain [357/1000]  train=0.049596  val=0.065436
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/pretrained.pth
Pretrain [358/1000]  train=0.048746  val=0.066115
Pretrain [359/1000]  train=0.052920  val=0.068444
Pretrain [360/1000]  train=0.050801  val=0.067822
Pretrain [361/1000]  train=0.049170  val=0.067014
Pretrain [362/1000]  train=0.048754  val=0.067531
Pretrain [363/1000]  train=0.049856  val=0.066330
Pretrain [364/1000]  train=0.049267  val=0.066954
Pretrain [365/1000]  train=0.048972  val=0.066169
Pretrain [366/1000]  train=0.049467  val=0.066843
Pretrain [367/1000]  train=0.049504  val=0.067240
Pretrain [368/1000]  train=0.048060  val=0.065827
Pretrain [369/1000]  train=0.050713  val=0.065769
Pretrain [370/1000]  train=0.050743  val=0.065780
Pretrain [371/1000]  train=0.049392  val=0.066635
Pretrain [372/1000]  train=0.049824  val=0.066967
Pretrain [373/1000]  train=0.048992  val=0.067078
Pretrain [374/1000]  train=0.049218  val=0.066476
Pretrain [375/1000]  train=0.048683  val=0.066661
Pretrain [376/1000]  train=0.048252  val=0.066202
Pretrain [377/1000]  train=0.047964  val=0.066390
Pretrain [378/1000]  train=0.048557  val=0.066558
Pretrain [379/1000]  train=0.048854  val=0.066692
Pretrain [380/1000]  train=0.048442  val=0.066798
Pretrain [381/1000]  train=0.047389  val=0.066917
Pretrain [382/1000]  train=0.048657  val=0.067016
Pretrain [383/1000]  train=0.049297  val=0.066638
Pretrain [384/1000]  train=0.049265  val=0.066472
Pretrain [385/1000]  train=0.050250  val=0.066375
Pretrain [386/1000]  train=0.049597  val=0.066508
Pretrain [387/1000]  train=0.048475  val=0.066790
Pretrain [388/1000]  train=0.047338  val=0.066776
Pretrain [389/1000]  train=0.049056  val=0.066690
Pretrain [390/1000]  train=0.047479  val=0.066576
Pretrain [391/1000]  train=0.049923  val=0.066557
Pretrain [392/1000]  train=0.048354  val=0.066424
Pretrain [393/1000]  train=0.049328  val=0.066478
Pretrain [394/1000]  train=0.047556  val=0.066539
Pretrain [395/1000]  train=0.048429  val=0.066540
Pretrain [396/1000]  train=0.047738  val=0.066502
Pretrain [397/1000]  train=0.050036  val=0.066496
Pretrain [398/1000]  train=0.048800  val=0.066497
Pretrain [399/1000]  train=0.047884  val=0.066505
Pretrain [400/1000]  train=0.049078  val=0.066510
Pretrain [401/1000]  train=0.062636  val=0.076492
Pretrain [402/1000]  train=0.066804  val=0.076428
Pretrain [403/1000]  train=0.069220  val=0.075780
Pretrain [404/1000]  train=0.074578  val=0.080347
Pretrain [405/1000]  train=0.072328  val=0.077861
Pretrain [406/1000]  train=0.071702  val=0.079756
Pretrain [407/1000]  train=0.067801  val=0.081411
Pretrain [408/1000]  train=0.070069  val=0.074041
Pretrain [409/1000]  train=0.071250  val=0.076192
Pretrain [410/1000]  train=0.069469  val=0.077449
Pretrain [411/1000]  train=0.069009  val=0.081356
Pretrain [412/1000]  train=0.065964  val=0.076453
Pretrain [413/1000]  train=0.068977  val=0.072686
Pretrain [414/1000]  train=0.069452  val=0.075265
Pretrain [415/1000]  train=0.067809  val=0.074484
Pretrain [416/1000]  train=0.071946  val=0.077376
Pretrain [417/1000]  train=0.070647  val=0.077297
Pretrain [418/1000]  train=0.066470  val=0.074886
Pretrain [419/1000]  train=0.069158  val=0.073350
Pretrain [420/1000]  train=0.069601  val=0.079452
Pretrain [421/1000]  train=0.068688  val=0.074452
Pretrain [422/1000]  train=0.066244  val=0.073986
Pretrain [423/1000]  train=0.066622  val=0.075215
Pretrain [424/1000]  train=0.065278  val=0.077138
Pretrain [425/1000]  train=0.068814  val=0.080056
Pretrain [426/1000]  train=0.067391  val=0.079209
Pretrain [427/1000]  train=0.068298  val=0.078508
Pretrain [428/1000]  train=0.066519  val=0.080693
Pretrain [429/1000]  train=0.066339  val=0.078505
Pretrain [430/1000]  train=0.069336  val=0.071497
Pretrain [431/1000]  train=0.071068  val=0.077275
Pretrain [432/1000]  train=0.068428  val=0.073955
Pretrain [433/1000]  train=0.065922  val=0.075525
Pretrain [434/1000]  train=0.066458  val=0.079009
Pretrain [435/1000]  train=0.066214  val=0.074326
Pretrain [436/1000]  train=0.065755  val=0.075768
Pretrain [437/1000]  train=0.065330  val=0.074582
Pretrain [438/1000]  train=0.064235  val=0.072604
Pretrain [439/1000]  train=0.066644  val=0.077521
Pretrain [440/1000]  train=0.068841  val=0.073945
Pretrain [441/1000]  train=0.063779  val=0.073534
Pretrain [442/1000]  train=0.063637  val=0.072894
Pretrain [443/1000]  train=0.063655  val=0.074610
Pretrain [444/1000]  train=0.064225  val=0.075212
Pretrain [445/1000]  train=0.064420  val=0.078587
Pretrain [446/1000]  train=0.063624  val=0.074473
Pretrain [447/1000]  train=0.063711  val=0.071269
Pretrain [448/1000]  train=0.064026  val=0.073354
Pretrain [449/1000]  train=0.062384  val=0.076579
Pretrain [450/1000]  train=0.064174  val=0.074274
Pretrain [451/1000]  train=0.063981  val=0.074744
Pretrain [452/1000]  train=0.063278  val=0.073716
Pretrain [453/1000]  train=0.064237  val=0.073509
Pretrain [454/1000]  train=0.062977  val=0.075319
Pretrain [455/1000]  train=0.062079  val=0.071116
Pretrain [456/1000]  train=0.063222  val=0.074342
Pretrain [457/1000]  train=0.062638  val=0.073522
Pretrain [458/1000]  train=0.061117  val=0.075046
Pretrain [459/1000]  train=0.062864  val=0.078030
Pretrain [460/1000]  train=0.062349  val=0.072558
Pretrain [461/1000]  train=0.063548  val=0.076795
Pretrain [462/1000]  train=0.060343  val=0.072868
Pretrain [463/1000]  train=0.062137  val=0.076324
Pretrain [464/1000]  train=0.061410  val=0.071225
Pretrain [465/1000]  train=0.060115  val=0.072653
Pretrain [466/1000]  train=0.060631  val=0.071356
Pretrain [467/1000]  train=0.063047  val=0.076581
Pretrain [468/1000]  train=0.061933  val=0.072886
Pretrain [469/1000]  train=0.060520  val=0.076984
Pretrain [470/1000]  train=0.061478  val=0.077144
Pretrain [471/1000]  train=0.061853  val=0.075164
Pretrain [472/1000]  train=0.059122  val=0.072300
Pretrain [473/1000]  train=0.058640  val=0.071829
Pretrain [474/1000]  train=0.059504  val=0.070638
Pretrain [475/1000]  train=0.059280  val=0.073053
Pretrain [476/1000]  train=0.060573  val=0.072341
Pretrain [477/1000]  train=0.059849  val=0.081152
Pretrain [478/1000]  train=0.058292  val=0.073487
Pretrain [479/1000]  train=0.059057  val=0.071668
Pretrain [480/1000]  train=0.059886  val=0.072710
Pretrain [481/1000]  train=0.058707  val=0.072091
Pretrain [482/1000]  train=0.057876  val=0.069812
Pretrain [483/1000]  train=0.058332  val=0.073399
Pretrain [484/1000]  train=0.058675  val=0.074046
Pretrain [485/1000]  train=0.060027  val=0.071824
Pretrain [486/1000]  train=0.058540  val=0.073696
Pretrain [487/1000]  train=0.057664  val=0.072696
Pretrain [488/1000]  train=0.059892  val=0.075234
Pretrain [489/1000]  train=0.058793  val=0.074876
Pretrain [490/1000]  train=0.056760  val=0.070049
Pretrain [491/1000]  train=0.057225  val=0.069442
Pretrain [492/1000]  train=0.056323  val=0.072230
Pretrain [493/1000]  train=0.055238  val=0.068523
Pretrain [494/1000]  train=0.056569  val=0.069399
Pretrain [495/1000]  train=0.057320  val=0.070179
Pretrain [496/1000]  train=0.055181  val=0.070409
Pretrain [497/1000]  train=0.056983  val=0.070760
Pretrain [498/1000]  train=0.056466  val=0.067727
Pretrain [499/1000]  train=0.056886  val=0.069217
Pretrain [500/1000]  train=0.055919  val=0.071605
Pretrain [501/1000]  train=0.054217  val=0.072726
Pretrain [502/1000]  train=0.055304  val=0.072393
Pretrain [503/1000]  train=0.055331  val=0.070603
Pretrain [504/1000]  train=0.053330  val=0.069769
Pretrain [505/1000]  train=0.053276  val=0.068504
Pretrain [506/1000]  train=0.052798  val=0.068379
Pretrain [507/1000]  train=0.054909  val=0.071626
Pretrain [508/1000]  train=0.054374  val=0.069842
Pretrain [509/1000]  train=0.054580  val=0.067960
Pretrain [510/1000]  train=0.055890  val=0.071584
Pretrain [511/1000]  train=0.055774  val=0.070344
Pretrain [512/1000]  train=0.053540  val=0.069576
Pretrain [513/1000]  train=0.055202  val=0.068273
Pretrain [514/1000]  train=0.054810  val=0.067792
Pretrain [515/1000]  train=0.053231  val=0.066710
Pretrain [516/1000]  train=0.052542  val=0.070874
Pretrain [517/1000]  train=0.053111  val=0.068803
Pretrain [518/1000]  train=0.053205  val=0.067062
Pretrain [519/1000]  train=0.051193  val=0.070192
Pretrain [520/1000]  train=0.051917  val=0.067551
Pretrain [521/1000]  train=0.051531  val=0.069093
Pretrain [522/1000]  train=0.053609  val=0.070381
Pretrain [523/1000]  train=0.051379  val=0.069778
Pretrain [524/1000]  train=0.051812  val=0.069189
Pretrain [525/1000]  train=0.051356  val=0.069397
Pretrain [526/1000]  train=0.050151  val=0.070295
Pretrain [527/1000]  train=0.050338  val=0.068276
Pretrain [528/1000]  train=0.052344  val=0.068046
Pretrain [529/1000]  train=0.050466  val=0.066248
Pretrain [530/1000]  train=0.050655  val=0.066789
Pretrain [531/1000]  train=0.050603  val=0.066186
Pretrain [532/1000]  train=0.051123  val=0.068136
Pretrain [533/1000]  train=0.050349  val=0.066883
Pretrain [534/1000]  train=0.049680  val=0.068594
Pretrain [535/1000]  train=0.047635  val=0.067713
Pretrain [536/1000]  train=0.050358  val=0.067424
Pretrain [537/1000]  train=0.050171  val=0.066685
Pretrain [538/1000]  train=0.050377  val=0.067032
Pretrain [539/1000]  train=0.050467  val=0.067792
Pretrain [540/1000]  train=0.048970  val=0.066267
Pretrain [541/1000]  train=0.048903  val=0.066725
Pretrain [542/1000]  train=0.048445  val=0.067205
Pretrain [543/1000]  train=0.048939  val=0.068207
Pretrain [544/1000]  train=0.049233  val=0.069316
Pretrain [545/1000]  train=0.051357  val=0.067392
Pretrain [546/1000]  train=0.049199  val=0.068625
Pretrain [547/1000]  train=0.049515  val=0.068842
Pretrain [548/1000]  train=0.048375  val=0.069712
Pretrain [549/1000]  train=0.049577  val=0.068371
Pretrain [550/1000]  train=0.047689  val=0.068627
Pretrain [551/1000]  train=0.049356  val=0.068233
Pretrain [552/1000]  train=0.048032  val=0.067690
Pretrain [553/1000]  train=0.048159  val=0.066948
Pretrain [554/1000]  train=0.047316  val=0.066976
Pretrain [555/1000]  train=0.047932  val=0.066861
Pretrain [556/1000]  train=0.049387  val=0.067772
Pretrain [557/1000]  train=0.047822  val=0.067349
  -> 验证未改进 200 次，早停。
[PRETRAIN] 最佳 val=0.065436 已保存。

--- [阶段二] 对齐微调 (NLL + α·(1−R2) + λ·CORAL) ---
Fine-tune [1/100000]  val_loss=0.411220
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [2/100000]  val_loss=0.239295
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [3/100000]  val_loss=0.066065
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [4/100000]  val_loss=-0.064256
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [5/100000]  val_loss=-0.156147
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [6/100000]  val_loss=-0.235443
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [7/100000]  val_loss=-0.301019
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [8/100000]  val_loss=-0.363032
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [9/100000]  val_loss=-0.415014
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [10/100000]  val_loss=-0.447002
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [11/100000]  val_loss=-0.476524
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [12/100000]  val_loss=-0.507394
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [13/100000]  val_loss=-0.540659
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [14/100000]  val_loss=-0.560358
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [15/100000]  val_loss=-0.585204
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [16/100000]  val_loss=-0.587615
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [17/100000]  val_loss=-0.616757
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [18/100000]  val_loss=-0.638184
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [19/100000]  val_loss=-0.655235
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [20/100000]  val_loss=-0.666238
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [21/100000]  val_loss=-0.681071
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [22/100000]  val_loss=-0.686885
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [23/100000]  val_loss=-0.695098
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [24/100000]  val_loss=-0.704604
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [25/100000]  val_loss=-0.710555
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [26/100000]  val_loss=-0.728126
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [27/100000]  val_loss=-0.739389
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [28/100000]  val_loss=-0.738639
Fine-tune [29/100000]  val_loss=-0.743945
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [30/100000]  val_loss=-0.747542
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [31/100000]  val_loss=-0.748559
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [32/100000]  val_loss=-0.778873
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [33/100000]  val_loss=-0.781607
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [34/100000]  val_loss=-0.772047
Fine-tune [35/100000]  val_loss=-0.786175
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [36/100000]  val_loss=-0.786498
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [37/100000]  val_loss=-0.795203
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [38/100000]  val_loss=-0.795975
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [39/100000]  val_loss=-0.796838
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [40/100000]  val_loss=-0.796761
Fine-tune [41/100000]  val_loss=-0.792654
Fine-tune [42/100000]  val_loss=-0.802486
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [43/100000]  val_loss=-0.799324
Fine-tune [44/100000]  val_loss=-0.810447
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [45/100000]  val_loss=-0.811138
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [46/100000]  val_loss=-0.826683
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [47/100000]  val_loss=-0.834591
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [48/100000]  val_loss=-0.834988
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [49/100000]  val_loss=-0.836006
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [50/100000]  val_loss=-0.826996
Fine-tune [51/100000]  val_loss=-0.839929
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [52/100000]  val_loss=-0.839001
Fine-tune [53/100000]  val_loss=-0.859825
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [54/100000]  val_loss=-0.867435
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [55/100000]  val_loss=-0.866520
Fine-tune [56/100000]  val_loss=-0.873448
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [57/100000]  val_loss=-0.874963
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [58/100000]  val_loss=-0.868406
Fine-tune [59/100000]  val_loss=-0.880103
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [60/100000]  val_loss=-0.882032
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [61/100000]  val_loss=-0.888233
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [62/100000]  val_loss=-0.879587
Fine-tune [63/100000]  val_loss=-0.874208
Fine-tune [64/100000]  val_loss=-0.884852
Fine-tune [65/100000]  val_loss=-0.889719
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [66/100000]  val_loss=-0.899379
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [67/100000]  val_loss=-0.893830
Fine-tune [68/100000]  val_loss=-0.892964
Fine-tune [69/100000]  val_loss=-0.898892
Fine-tune [70/100000]  val_loss=-0.898955
Fine-tune [71/100000]  val_loss=-0.888463
Fine-tune [72/100000]  val_loss=-0.901038
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [73/100000]  val_loss=-0.896696
Fine-tune [74/100000]  val_loss=-0.900055
Fine-tune [75/100000]  val_loss=-0.903390
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [76/100000]  val_loss=-0.908379
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [77/100000]  val_loss=-0.909806
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [78/100000]  val_loss=-0.899293
Fine-tune [79/100000]  val_loss=-0.916493
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [80/100000]  val_loss=-0.905609
Fine-tune [81/100000]  val_loss=-0.911756
Fine-tune [82/100000]  val_loss=-0.913853
Fine-tune [83/100000]  val_loss=-0.917267
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [84/100000]  val_loss=-0.910438
Fine-tune [85/100000]  val_loss=-0.906584
Fine-tune [86/100000]  val_loss=-0.920469
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [87/100000]  val_loss=-0.925833
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [88/100000]  val_loss=-0.921155
Fine-tune [89/100000]  val_loss=-0.906143
Fine-tune [90/100000]  val_loss=-0.927953
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [91/100000]  val_loss=-0.923257
Fine-tune [92/100000]  val_loss=-0.922256
Fine-tune [93/100000]  val_loss=-0.926673
Fine-tune [94/100000]  val_loss=-0.924066
Fine-tune [95/100000]  val_loss=-0.939128
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [96/100000]  val_loss=-0.932026
Fine-tune [97/100000]  val_loss=-0.943797
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [98/100000]  val_loss=-0.936945
Fine-tune [99/100000]  val_loss=-0.942446
Fine-tune [100/100000]  val_loss=-0.927799
Fine-tune [101/100000]  val_loss=-0.945573
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [102/100000]  val_loss=-0.939359
Fine-tune [103/100000]  val_loss=-0.936379
Fine-tune [104/100000]  val_loss=-0.932703
Fine-tune [105/100000]  val_loss=-0.948516
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [106/100000]  val_loss=-0.949215
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [107/100000]  val_loss=-0.949900
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [108/100000]  val_loss=-0.954863
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [109/100000]  val_loss=-0.944968
Fine-tune [110/100000]  val_loss=-0.940238
Fine-tune [111/100000]  val_loss=-0.936805
Fine-tune [112/100000]  val_loss=-0.945088
Fine-tune [113/100000]  val_loss=-0.937098
Fine-tune [114/100000]  val_loss=-0.941544
Fine-tune [115/100000]  val_loss=-0.935306
Fine-tune [116/100000]  val_loss=-0.948962
Fine-tune [117/100000]  val_loss=-0.947905
Fine-tune [118/100000]  val_loss=-0.954070
Fine-tune [119/100000]  val_loss=-0.953076
Fine-tune [120/100000]  val_loss=-0.954072
Fine-tune [121/100000]  val_loss=-0.956505
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [122/100000]  val_loss=-0.958170
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [123/100000]  val_loss=-0.970470
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [124/100000]  val_loss=-0.973733
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [125/100000]  val_loss=-0.957329
Fine-tune [126/100000]  val_loss=-0.950511
Fine-tune [127/100000]  val_loss=-0.955264
Fine-tune [128/100000]  val_loss=-0.943337
Fine-tune [129/100000]  val_loss=-0.966671
Fine-tune [130/100000]  val_loss=-0.953795
Fine-tune [131/100000]  val_loss=-0.965858
Fine-tune [132/100000]  val_loss=-0.959487
Fine-tune [133/100000]  val_loss=-0.950358
Fine-tune [134/100000]  val_loss=-0.971450
Fine-tune [135/100000]  val_loss=-0.978574
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [136/100000]  val_loss=-0.974788
Fine-tune [137/100000]  val_loss=-0.969434
Fine-tune [138/100000]  val_loss=-0.955608
Fine-tune [139/100000]  val_loss=-0.963739
Fine-tune [140/100000]  val_loss=-0.967321
Fine-tune [141/100000]  val_loss=-0.979488
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [142/100000]  val_loss=-0.973454
Fine-tune [143/100000]  val_loss=-0.974448
Fine-tune [144/100000]  val_loss=-0.960517
Fine-tune [145/100000]  val_loss=-0.964931
Fine-tune [146/100000]  val_loss=-0.958838
Fine-tune [147/100000]  val_loss=-0.974312
Fine-tune [148/100000]  val_loss=-0.972366
Fine-tune [149/100000]  val_loss=-0.975664
Fine-tune [150/100000]  val_loss=-0.962384
Fine-tune [151/100000]  val_loss=-0.971310
Fine-tune [152/100000]  val_loss=-0.961495
Fine-tune [153/100000]  val_loss=-0.975016
Fine-tune [154/100000]  val_loss=-0.965280
Fine-tune [155/100000]  val_loss=-0.982782
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [156/100000]  val_loss=-0.966939
Fine-tune [157/100000]  val_loss=-0.969391
Fine-tune [158/100000]  val_loss=-0.982695
Fine-tune [159/100000]  val_loss=-0.992774
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [160/100000]  val_loss=-0.989356
Fine-tune [161/100000]  val_loss=-0.964745
Fine-tune [162/100000]  val_loss=-0.983212
Fine-tune [163/100000]  val_loss=-0.982801
Fine-tune [164/100000]  val_loss=-0.988771
Fine-tune [165/100000]  val_loss=-0.982797
Fine-tune [166/100000]  val_loss=-0.994343
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [167/100000]  val_loss=-0.988105
Fine-tune [168/100000]  val_loss=-0.976297
Fine-tune [169/100000]  val_loss=-0.978348
Fine-tune [170/100000]  val_loss=-0.992566
Fine-tune [171/100000]  val_loss=-0.996423
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [172/100000]  val_loss=-1.005186
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [173/100000]  val_loss=-0.986552
Fine-tune [174/100000]  val_loss=-0.989231
Fine-tune [175/100000]  val_loss=-0.980585
Fine-tune [176/100000]  val_loss=-0.996527
Fine-tune [177/100000]  val_loss=-0.984952
Fine-tune [178/100000]  val_loss=-0.986870
Fine-tune [179/100000]  val_loss=-0.990218
Fine-tune [180/100000]  val_loss=-0.986426
Fine-tune [181/100000]  val_loss=-0.994675
Fine-tune [182/100000]  val_loss=-0.996743
Fine-tune [183/100000]  val_loss=-1.003272
Fine-tune [184/100000]  val_loss=-0.987433
Fine-tune [185/100000]  val_loss=-0.986046
Fine-tune [186/100000]  val_loss=-0.991368
Fine-tune [187/100000]  val_loss=-0.986328
Fine-tune [188/100000]  val_loss=-0.986456
Fine-tune [189/100000]  val_loss=-0.981229
Fine-tune [190/100000]  val_loss=-0.973251
Fine-tune [191/100000]  val_loss=-0.982846
Fine-tune [192/100000]  val_loss=-0.982357
Fine-tune [193/100000]  val_loss=-0.993952
Fine-tune [194/100000]  val_loss=-0.989317
Fine-tune [195/100000]  val_loss=-0.997719
Fine-tune [196/100000]  val_loss=-0.998613
Fine-tune [197/100000]  val_loss=-0.984762
Fine-tune [198/100000]  val_loss=-0.978975
Fine-tune [199/100000]  val_loss=-0.984615
Fine-tune [200/100000]  val_loss=-0.972574
Fine-tune [201/100000]  val_loss=-0.980598
Fine-tune [202/100000]  val_loss=-0.980511
Fine-tune [203/100000]  val_loss=-0.987098
Fine-tune [204/100000]  val_loss=-0.979040
Fine-tune [205/100000]  val_loss=-0.989190
Fine-tune [206/100000]  val_loss=-0.973583
Fine-tune [207/100000]  val_loss=-0.964802
Fine-tune [208/100000]  val_loss=-0.969890
Fine-tune [209/100000]  val_loss=-0.984683
Fine-tune [210/100000]  val_loss=-0.974952
Fine-tune [211/100000]  val_loss=-0.978953
Fine-tune [212/100000]  val_loss=-0.964138
Fine-tune [213/100000]  val_loss=-0.983315
Fine-tune [214/100000]  val_loss=-0.989938
Fine-tune [215/100000]  val_loss=-0.988862
Fine-tune [216/100000]  val_loss=-0.988779
Fine-tune [217/100000]  val_loss=-0.992056
Fine-tune [218/100000]  val_loss=-0.987108
Fine-tune [219/100000]  val_loss=-0.981547
Fine-tune [220/100000]  val_loss=-0.974966
Fine-tune [221/100000]  val_loss=-0.982764
Fine-tune [222/100000]  val_loss=-0.997305
Fine-tune [223/100000]  val_loss=-0.993021
Fine-tune [224/100000]  val_loss=-0.989465
Fine-tune [225/100000]  val_loss=-0.991068
Fine-tune [226/100000]  val_loss=-0.973117
Fine-tune [227/100000]  val_loss=-0.990626
Fine-tune [228/100000]  val_loss=-0.996556
Fine-tune [229/100000]  val_loss=-1.006561
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [230/100000]  val_loss=-0.992765
Fine-tune [231/100000]  val_loss=-0.991486
Fine-tune [232/100000]  val_loss=-1.010139
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [233/100000]  val_loss=-0.999422
Fine-tune [234/100000]  val_loss=-1.003453
Fine-tune [235/100000]  val_loss=-0.996709
Fine-tune [236/100000]  val_loss=-1.008067
Fine-tune [237/100000]  val_loss=-1.015356
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [238/100000]  val_loss=-1.001938
Fine-tune [239/100000]  val_loss=-1.009119
Fine-tune [240/100000]  val_loss=-0.996992
Fine-tune [241/100000]  val_loss=-1.001065
Fine-tune [242/100000]  val_loss=-1.010266
Fine-tune [243/100000]  val_loss=-1.011560
Fine-tune [244/100000]  val_loss=-1.007086
Fine-tune [245/100000]  val_loss=-1.003924
Fine-tune [246/100000]  val_loss=-1.003975
Fine-tune [247/100000]  val_loss=-1.014603
Fine-tune [248/100000]  val_loss=-1.002050
Fine-tune [249/100000]  val_loss=-1.017211
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [250/100000]  val_loss=-1.020271
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [251/100000]  val_loss=-1.033048
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [252/100000]  val_loss=-1.028216
Fine-tune [253/100000]  val_loss=-1.026104
Fine-tune [254/100000]  val_loss=-1.003416
Fine-tune [255/100000]  val_loss=-0.999770
Fine-tune [256/100000]  val_loss=-0.995660
Fine-tune [257/100000]  val_loss=-0.990099
Fine-tune [258/100000]  val_loss=-0.994163
Fine-tune [259/100000]  val_loss=-1.007616
Fine-tune [260/100000]  val_loss=-1.013210
Fine-tune [261/100000]  val_loss=-1.015606
Fine-tune [262/100000]  val_loss=-1.024871
Fine-tune [263/100000]  val_loss=-1.029264
Fine-tune [264/100000]  val_loss=-1.006092
Fine-tune [265/100000]  val_loss=-1.029932
Fine-tune [266/100000]  val_loss=-1.024216
Fine-tune [267/100000]  val_loss=-1.013354
Fine-tune [268/100000]  val_loss=-1.017885
Fine-tune [269/100000]  val_loss=-1.012813
Fine-tune [270/100000]  val_loss=-1.014788
Fine-tune [271/100000]  val_loss=-1.016585
Fine-tune [272/100000]  val_loss=-1.026638
Fine-tune [273/100000]  val_loss=-1.029656
Fine-tune [274/100000]  val_loss=-1.029148
Fine-tune [275/100000]  val_loss=-1.020908
Fine-tune [276/100000]  val_loss=-1.024961
Fine-tune [277/100000]  val_loss=-1.018257
Fine-tune [278/100000]  val_loss=-1.018072
Fine-tune [279/100000]  val_loss=-1.020715
Fine-tune [280/100000]  val_loss=-1.020088
Fine-tune [281/100000]  val_loss=-1.027329
Fine-tune [282/100000]  val_loss=-1.027742
Fine-tune [283/100000]  val_loss=-1.018989
Fine-tune [284/100000]  val_loss=-1.027194
Fine-tune [285/100000]  val_loss=-1.031752
Fine-tune [286/100000]  val_loss=-1.016627
Fine-tune [287/100000]  val_loss=-1.014925
Fine-tune [288/100000]  val_loss=-1.026288
Fine-tune [289/100000]  val_loss=-1.018101
Fine-tune [290/100000]  val_loss=-1.004541
Fine-tune [291/100000]  val_loss=-1.027773
Fine-tune [292/100000]  val_loss=-1.024752
Fine-tune [293/100000]  val_loss=-1.009249
Fine-tune [294/100000]  val_loss=-1.027880
Fine-tune [295/100000]  val_loss=-1.030239
Fine-tune [296/100000]  val_loss=-1.025507
Fine-tune [297/100000]  val_loss=-1.029352
Fine-tune [298/100000]  val_loss=-1.045823
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [299/100000]  val_loss=-1.034463
Fine-tune [300/100000]  val_loss=-1.031308
Fine-tune [301/100000]  val_loss=-1.039994
Fine-tune [302/100000]  val_loss=-1.031392
Fine-tune [303/100000]  val_loss=-1.024577
Fine-tune [304/100000]  val_loss=-1.037548
Fine-tune [305/100000]  val_loss=-1.030686
Fine-tune [306/100000]  val_loss=-1.023089
Fine-tune [307/100000]  val_loss=-1.023737
Fine-tune [308/100000]  val_loss=-1.021462
Fine-tune [309/100000]  val_loss=-1.031390
Fine-tune [310/100000]  val_loss=-1.032021
Fine-tune [311/100000]  val_loss=-1.027483
Fine-tune [312/100000]  val_loss=-1.016564
Fine-tune [313/100000]  val_loss=-1.019481
Fine-tune [314/100000]  val_loss=-1.023988
Fine-tune [315/100000]  val_loss=-1.032992
Fine-tune [316/100000]  val_loss=-1.039685
Fine-tune [317/100000]  val_loss=-1.034816
Fine-tune [318/100000]  val_loss=-1.016675
Fine-tune [319/100000]  val_loss=-1.016389
Fine-tune [320/100000]  val_loss=-1.015067
Fine-tune [321/100000]  val_loss=-1.029427
Fine-tune [322/100000]  val_loss=-1.026707
Fine-tune [323/100000]  val_loss=-1.012947
Fine-tune [324/100000]  val_loss=-1.016900
Fine-tune [325/100000]  val_loss=-1.028132
Fine-tune [326/100000]  val_loss=-1.012470
Fine-tune [327/100000]  val_loss=-1.021507
Fine-tune [328/100000]  val_loss=-1.021000
Fine-tune [329/100000]  val_loss=-1.027430
Fine-tune [330/100000]  val_loss=-1.019464
Fine-tune [331/100000]  val_loss=-1.009766
Fine-tune [332/100000]  val_loss=-1.030023
Fine-tune [333/100000]  val_loss=-1.027307
Fine-tune [334/100000]  val_loss=-1.045945
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [335/100000]  val_loss=-1.009324
Fine-tune [336/100000]  val_loss=-1.014201
Fine-tune [337/100000]  val_loss=-1.014591
Fine-tune [338/100000]  val_loss=-1.014926
Fine-tune [339/100000]  val_loss=-1.031383
Fine-tune [340/100000]  val_loss=-1.035482
Fine-tune [341/100000]  val_loss=-1.031884
Fine-tune [342/100000]  val_loss=-1.023506
Fine-tune [343/100000]  val_loss=-1.014814
Fine-tune [344/100000]  val_loss=-1.021918
Fine-tune [345/100000]  val_loss=-1.011895
Fine-tune [346/100000]  val_loss=-1.025788
Fine-tune [347/100000]  val_loss=-1.033214
Fine-tune [348/100000]  val_loss=-1.017106
Fine-tune [349/100000]  val_loss=-1.035284
Fine-tune [350/100000]  val_loss=-1.037592
Fine-tune [351/100000]  val_loss=-1.040725
Fine-tune [352/100000]  val_loss=-1.029881
Fine-tune [353/100000]  val_loss=-1.020544
Fine-tune [354/100000]  val_loss=-1.035701
Fine-tune [355/100000]  val_loss=-1.016849
Fine-tune [356/100000]  val_loss=-1.034828
Fine-tune [357/100000]  val_loss=-1.034787
Fine-tune [358/100000]  val_loss=-1.010283
Fine-tune [359/100000]  val_loss=-1.006847
Fine-tune [360/100000]  val_loss=-1.003835
Fine-tune [361/100000]  val_loss=-1.028215
Fine-tune [362/100000]  val_loss=-1.024300
Fine-tune [363/100000]  val_loss=-1.018134
Fine-tune [364/100000]  val_loss=-1.032194
Fine-tune [365/100000]  val_loss=-1.020923
Fine-tune [366/100000]  val_loss=-1.030875
Fine-tune [367/100000]  val_loss=-1.019627
Fine-tune [368/100000]  val_loss=-1.014273
Fine-tune [369/100000]  val_loss=-1.035532
Fine-tune [370/100000]  val_loss=-1.025512
Fine-tune [371/100000]  val_loss=-1.036505
Fine-tune [372/100000]  val_loss=-1.033146
Fine-tune [373/100000]  val_loss=-1.033417
Fine-tune [374/100000]  val_loss=-1.030172
Fine-tune [375/100000]  val_loss=-1.034476
Fine-tune [376/100000]  val_loss=-1.030150
Fine-tune [377/100000]  val_loss=-1.025878
Fine-tune [378/100000]  val_loss=-1.028400
Fine-tune [379/100000]  val_loss=-1.018889
Fine-tune [380/100000]  val_loss=-1.020882
Fine-tune [381/100000]  val_loss=-1.019813
Fine-tune [382/100000]  val_loss=-1.035025
Fine-tune [383/100000]  val_loss=-1.024661
Fine-tune [384/100000]  val_loss=-1.024216
Fine-tune [385/100000]  val_loss=-1.030119
Fine-tune [386/100000]  val_loss=-1.017194
Fine-tune [387/100000]  val_loss=-1.023859
Fine-tune [388/100000]  val_loss=-1.015025
Fine-tune [389/100000]  val_loss=-1.026333
Fine-tune [390/100000]  val_loss=-1.018349
Fine-tune [391/100000]  val_loss=-1.026732
Fine-tune [392/100000]  val_loss=-1.014797
Fine-tune [393/100000]  val_loss=-1.036342
Fine-tune [394/100000]  val_loss=-1.033970
Fine-tune [395/100000]  val_loss=-1.032738
Fine-tune [396/100000]  val_loss=-1.051140
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [397/100000]  val_loss=-1.050281
Fine-tune [398/100000]  val_loss=-1.027091
Fine-tune [399/100000]  val_loss=-1.026690
Fine-tune [400/100000]  val_loss=-1.040307
Fine-tune [401/100000]  val_loss=-1.027299
Fine-tune [402/100000]  val_loss=-1.027388
Fine-tune [403/100000]  val_loss=-1.020220
Fine-tune [404/100000]  val_loss=-1.040952
Fine-tune [405/100000]  val_loss=-1.031740
Fine-tune [406/100000]  val_loss=-1.032139
Fine-tune [407/100000]  val_loss=-1.012352
Fine-tune [408/100000]  val_loss=-1.022420
Fine-tune [409/100000]  val_loss=-1.013740
Fine-tune [410/100000]  val_loss=-1.031832
Fine-tune [411/100000]  val_loss=-1.040084
Fine-tune [412/100000]  val_loss=-1.042260
Fine-tune [413/100000]  val_loss=-1.038384
Fine-tune [414/100000]  val_loss=-1.032772
Fine-tune [415/100000]  val_loss=-1.024517
Fine-tune [416/100000]  val_loss=-1.042594
Fine-tune [417/100000]  val_loss=-1.035948
Fine-tune [418/100000]  val_loss=-1.039119
Fine-tune [419/100000]  val_loss=-1.036772
Fine-tune [420/100000]  val_loss=-1.025454
Fine-tune [421/100000]  val_loss=-1.032677
Fine-tune [422/100000]  val_loss=-1.024885
Fine-tune [423/100000]  val_loss=-1.037967
Fine-tune [424/100000]  val_loss=-1.034249
Fine-tune [425/100000]  val_loss=-1.029385
Fine-tune [426/100000]  val_loss=-1.024456
Fine-tune [427/100000]  val_loss=-1.025162
Fine-tune [428/100000]  val_loss=-1.029430
Fine-tune [429/100000]  val_loss=-1.037565
Fine-tune [430/100000]  val_loss=-1.033171
Fine-tune [431/100000]  val_loss=-1.062583
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [432/100000]  val_loss=-1.030803
Fine-tune [433/100000]  val_loss=-1.033761
Fine-tune [434/100000]  val_loss=-1.034384
Fine-tune [435/100000]  val_loss=-1.032684
Fine-tune [436/100000]  val_loss=-1.033549
Fine-tune [437/100000]  val_loss=-1.015937
Fine-tune [438/100000]  val_loss=-1.038581
Fine-tune [439/100000]  val_loss=-1.038280
Fine-tune [440/100000]  val_loss=-1.033951
Fine-tune [441/100000]  val_loss=-1.032875
Fine-tune [442/100000]  val_loss=-1.040733
Fine-tune [443/100000]  val_loss=-1.047053
Fine-tune [444/100000]  val_loss=-1.045906
Fine-tune [445/100000]  val_loss=-1.029099
Fine-tune [446/100000]  val_loss=-1.017435
Fine-tune [447/100000]  val_loss=-1.025780
Fine-tune [448/100000]  val_loss=-1.026782
Fine-tune [449/100000]  val_loss=-1.030029
Fine-tune [450/100000]  val_loss=-1.027992
Fine-tune [451/100000]  val_loss=-1.024650
Fine-tune [452/100000]  val_loss=-1.025340
Fine-tune [453/100000]  val_loss=-1.038294
Fine-tune [454/100000]  val_loss=-1.025811
Fine-tune [455/100000]  val_loss=-1.039828
Fine-tune [456/100000]  val_loss=-1.017866
Fine-tune [457/100000]  val_loss=-1.034132
Fine-tune [458/100000]  val_loss=-1.032702
Fine-tune [459/100000]  val_loss=-1.032866
Fine-tune [460/100000]  val_loss=-1.033069
Fine-tune [461/100000]  val_loss=-1.017978
Fine-tune [462/100000]  val_loss=-1.024831
Fine-tune [463/100000]  val_loss=-1.006565
Fine-tune [464/100000]  val_loss=-1.023114
Fine-tune [465/100000]  val_loss=-1.028654
Fine-tune [466/100000]  val_loss=-1.034660
Fine-tune [467/100000]  val_loss=-1.035334
Fine-tune [468/100000]  val_loss=-1.030030
Fine-tune [469/100000]  val_loss=-1.021582
Fine-tune [470/100000]  val_loss=-1.031348
Fine-tune [471/100000]  val_loss=-1.038803
Fine-tune [472/100000]  val_loss=-1.048792
Fine-tune [473/100000]  val_loss=-1.024232
Fine-tune [474/100000]  val_loss=-1.033000
Fine-tune [475/100000]  val_loss=-1.037246
Fine-tune [476/100000]  val_loss=-1.028806
Fine-tune [477/100000]  val_loss=-1.038830
Fine-tune [478/100000]  val_loss=-1.040383
Fine-tune [479/100000]  val_loss=-1.037764
Fine-tune [480/100000]  val_loss=-1.035977
Fine-tune [481/100000]  val_loss=-1.040825
Fine-tune [482/100000]  val_loss=-1.065126
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L3/finetuned.pth
Fine-tune [483/100000]  val_loss=-1.040297
Fine-tune [484/100000]  val_loss=-1.033837
Fine-tune [485/100000]  val_loss=-1.027095
Fine-tune [486/100000]  val_loss=-1.038391
Fine-tune [487/100000]  val_loss=-1.035198
Fine-tune [488/100000]  val_loss=-1.053258
Fine-tune [489/100000]  val_loss=-1.043809
Fine-tune [490/100000]  val_loss=-1.039431
Fine-tune [491/100000]  val_loss=-1.042711
Fine-tune [492/100000]  val_loss=-1.037878
Fine-tune [493/100000]  val_loss=-1.038237
Fine-tune [494/100000]  val_loss=-1.034597
Fine-tune [495/100000]  val_loss=-1.040324
Fine-tune [496/100000]  val_loss=-1.041523
Fine-tune [497/100000]  val_loss=-1.058268
Fine-tune [498/100000]  val_loss=-1.043533
Fine-tune [499/100000]  val_loss=-1.035379
Fine-tune [500/100000]  val_loss=-1.037905
Fine-tune [501/100000]  val_loss=-1.035914
Fine-tune [502/100000]  val_loss=-1.034539
Fine-tune [503/100000]  val_loss=-1.047158
Fine-tune [504/100000]  val_loss=-1.042780
Fine-tune [505/100000]  val_loss=-1.027593
Fine-tune [506/100000]  val_loss=-1.053576
Fine-tune [507/100000]  val_loss=-1.033204
Fine-tune [508/100000]  val_loss=-1.052291
Fine-tune [509/100000]  val_loss=-1.047086
Fine-tune [510/100000]  val_loss=-1.042276
Fine-tune [511/100000]  val_loss=-1.039473
Fine-tune [512/100000]  val_loss=-1.039994
Fine-tune [513/100000]  val_loss=-1.048938
Fine-tune [514/100000]  val_loss=-1.042833
Fine-tune [515/100000]  val_loss=-1.034532
Fine-tune [516/100000]  val_loss=-1.033949
Fine-tune [517/100000]  val_loss=-1.034328
Fine-tune [518/100000]  val_loss=-1.018810
Fine-tune [519/100000]  val_loss=-1.027136
Fine-tune [520/100000]  val_loss=-1.045360
Fine-tune [521/100000]  val_loss=-1.033672
Fine-tune [522/100000]  val_loss=-1.043272
Fine-tune [523/100000]  val_loss=-1.033764
Fine-tune [524/100000]  val_loss=-1.046489
Fine-tune [525/100000]  val_loss=-1.039858
Fine-tune [526/100000]  val_loss=-1.038125
Fine-tune [527/100000]  val_loss=-1.031446
Fine-tune [528/100000]  val_loss=-1.017478
Fine-tune [529/100000]  val_loss=-1.025954
Fine-tune [530/100000]  val_loss=-1.018725
Fine-tune [531/100000]  val_loss=-1.022121
Fine-tune [532/100000]  val_loss=-1.028011
Fine-tune [533/100000]  val_loss=-1.005768
Fine-tune [534/100000]  val_loss=-1.033220
Fine-tune [535/100000]  val_loss=-1.016413
Fine-tune [536/100000]  val_loss=-1.022838
Fine-tune [537/100000]  val_loss=-1.021478
Fine-tune [538/100000]  val_loss=-1.017833
Fine-tune [539/100000]  val_loss=-1.025231
Fine-tune [540/100000]  val_loss=-1.020751
Fine-tune [541/100000]  val_loss=-1.030695
Fine-tune [542/100000]  val_loss=-1.052061
Fine-tune [543/100000]  val_loss=-1.036354
Fine-tune [544/100000]  val_loss=-1.018345
Fine-tune [545/100000]  val_loss=-1.009847
Fine-tune [546/100000]  val_loss=-1.016444
Fine-tune [547/100000]  val_loss=-1.023523
Fine-tune [548/100000]  val_loss=-1.024802
Fine-tune [549/100000]  val_loss=-1.005086
Fine-tune [550/100000]  val_loss=-1.023924
Fine-tune [551/100000]  val_loss=-1.024848
Fine-tune [552/100000]  val_loss=-1.026878
Fine-tune [553/100000]  val_loss=-1.041209
Fine-tune [554/100000]  val_loss=-1.008975
Fine-tune [555/100000]  val_loss=-1.012370
Fine-tune [556/100000]  val_loss=-1.021147
Fine-tune [557/100000]  val_loss=-1.030542
Fine-tune [558/100000]  val_loss=-1.015915
Fine-tune [559/100000]  val_loss=-1.008202
Fine-tune [560/100000]  val_loss=-1.031248
Fine-tune [561/100000]  val_loss=-1.027315
Fine-tune [562/100000]  val_loss=-1.020504
Fine-tune [563/100000]  val_loss=-1.028341
Fine-tune [564/100000]  val_loss=-1.012913
Fine-tune [565/100000]  val_loss=-1.014845
Fine-tune [566/100000]  val_loss=-1.018272
Fine-tune [567/100000]  val_loss=-1.033235
Fine-tune [568/100000]  val_loss=-1.041447
Fine-tune [569/100000]  val_loss=-1.015561
Fine-tune [570/100000]  val_loss=-1.021037
Fine-tune [571/100000]  val_loss=-1.016404
Fine-tune [572/100000]  val_loss=-1.033514
Fine-tune [573/100000]  val_loss=-1.035846
Fine-tune [574/100000]  val_loss=-1.028374
Fine-tune [575/100000]  val_loss=-1.019695
Fine-tune [576/100000]  val_loss=-1.011987
Fine-tune [577/100000]  val_loss=-1.031791
Fine-tune [578/100000]  val_loss=-1.022284
Fine-tune [579/100000]  val_loss=-1.030840
Fine-tune [580/100000]  val_loss=-1.029053
Fine-tune [581/100000]  val_loss=-1.024308
Fine-tune [582/100000]  val_loss=-1.024813
Fine-tune [583/100000]  val_loss=-1.007866
Fine-tune [584/100000]  val_loss=-1.011782
Fine-tune [585/100000]  val_loss=-0.996172
Fine-tune [586/100000]  val_loss=-1.015939
Fine-tune [587/100000]  val_loss=-1.030343
Fine-tune [588/100000]  val_loss=-1.003809
Fine-tune [589/100000]  val_loss=-1.029348
Fine-tune [590/100000]  val_loss=-1.023492
Fine-tune [591/100000]  val_loss=-1.000574
Fine-tune [592/100000]  val_loss=-1.025261
Fine-tune [593/100000]  val_loss=-1.009010
Fine-tune [594/100000]  val_loss=-1.006911
Fine-tune [595/100000]  val_loss=-1.017516
Fine-tune [596/100000]  val_loss=-1.011706
Fine-tune [597/100000]  val_loss=-1.022193
Fine-tune [598/100000]  val_loss=-1.035094
Fine-tune [599/100000]  val_loss=-1.025674
Fine-tune [600/100000]  val_loss=-1.027563
Fine-tune [601/100000]  val_loss=-1.016277
Fine-tune [602/100000]  val_loss=-1.034325
Fine-tune [603/100000]  val_loss=-1.022246
Fine-tune [604/100000]  val_loss=-1.026081
Fine-tune [605/100000]  val_loss=-1.033184
Fine-tune [606/100000]  val_loss=-1.028870
Fine-tune [607/100000]  val_loss=-1.029143
Fine-tune [608/100000]  val_loss=-1.029104
Fine-tune [609/100000]  val_loss=-1.021259
Fine-tune [610/100000]  val_loss=-1.021654
Fine-tune [611/100000]  val_loss=-1.024165
Fine-tune [612/100000]  val_loss=-1.016760
Fine-tune [613/100000]  val_loss=-1.039122
Fine-tune [614/100000]  val_loss=-1.021153
Fine-tune [615/100000]  val_loss=-1.033265
Fine-tune [616/100000]  val_loss=-1.018381
Fine-tune [617/100000]  val_loss=-1.015545
Fine-tune [618/100000]  val_loss=-1.028533
Fine-tune [619/100000]  val_loss=-1.039300
Fine-tune [620/100000]  val_loss=-1.032834
Fine-tune [621/100000]  val_loss=-1.022644
Fine-tune [622/100000]  val_loss=-1.004769
Fine-tune [623/100000]  val_loss=-0.995555
Fine-tune [624/100000]  val_loss=-1.015604
Fine-tune [625/100000]  val_loss=-1.018065
Fine-tune [626/100000]  val_loss=-1.006031
Fine-tune [627/100000]  val_loss=-1.019640
Fine-tune [628/100000]  val_loss=-1.034026
Fine-tune [629/100000]  val_loss=-1.025420
Fine-tune [630/100000]  val_loss=-1.011778
Fine-tune [631/100000]  val_loss=-1.032317
Fine-tune [632/100000]  val_loss=-1.020669
Fine-tune [633/100000]  val_loss=-1.032856
Fine-tune [634/100000]  val_loss=-1.045850
Fine-tune [635/100000]  val_loss=-1.029540
Fine-tune [636/100000]  val_loss=-1.027021
Fine-tune [637/100000]  val_loss=-1.022907
Fine-tune [638/100000]  val_loss=-1.015448
Fine-tune [639/100000]  val_loss=-1.018539
Fine-tune [640/100000]  val_loss=-1.011221
Fine-tune [641/100000]  val_loss=-1.019409
Fine-tune [642/100000]  val_loss=-1.026716
Fine-tune [643/100000]  val_loss=-1.008255
Fine-tune [644/100000]  val_loss=-1.020216
Fine-tune [645/100000]  val_loss=-1.016533
Fine-tune [646/100000]  val_loss=-0.996667
Fine-tune [647/100000]  val_loss=-0.988923
Fine-tune [648/100000]  val_loss=-1.009053
Fine-tune [649/100000]  val_loss=-1.003430
Fine-tune [650/100000]  val_loss=-1.022477
Fine-tune [651/100000]  val_loss=-1.000696
Fine-tune [652/100000]  val_loss=-1.023464
Fine-tune [653/100000]  val_loss=-1.005355
Fine-tune [654/100000]  val_loss=-1.022367
Fine-tune [655/100000]  val_loss=-1.010409
Fine-tune [656/100000]  val_loss=-1.028546
Fine-tune [657/100000]  val_loss=-1.028048
Fine-tune [658/100000]  val_loss=-0.991857
Fine-tune [659/100000]  val_loss=-1.009030
Fine-tune [660/100000]  val_loss=-1.020266
Fine-tune [661/100000]  val_loss=-1.023998
Fine-tune [662/100000]  val_loss=-0.992493
Fine-tune [663/100000]  val_loss=-0.991712
Fine-tune [664/100000]  val_loss=-0.997150
Fine-tune [665/100000]  val_loss=-1.010136
Fine-tune [666/100000]  val_loss=-1.006778
Fine-tune [667/100000]  val_loss=-1.007070
Fine-tune [668/100000]  val_loss=-1.006539
Fine-tune [669/100000]  val_loss=-0.986340
Fine-tune [670/100000]  val_loss=-0.979389
Fine-tune [671/100000]  val_loss=-0.994377
Fine-tune [672/100000]  val_loss=-1.011368
Fine-tune [673/100000]  val_loss=-1.013087
Fine-tune [674/100000]  val_loss=-0.990938
Fine-tune [675/100000]  val_loss=-0.980866
Fine-tune [676/100000]  val_loss=-0.988981
Fine-tune [677/100000]  val_loss=-0.996949
Fine-tune [678/100000]  val_loss=-0.997101
Fine-tune [679/100000]  val_loss=-0.990546
Fine-tune [680/100000]  val_loss=-1.002552
Fine-tune [681/100000]  val_loss=-1.009875
Fine-tune [682/100000]  val_loss=-0.985777
Fine-tune [683/100000]  val_loss=-0.990691
Fine-tune [684/100000]  val_loss=-1.020287
Fine-tune [685/100000]  val_loss=-1.028205
Fine-tune [686/100000]  val_loss=-1.011817
Fine-tune [687/100000]  val_loss=-1.011456
Fine-tune [688/100000]  val_loss=-1.001806
Fine-tune [689/100000]  val_loss=-0.980793
Fine-tune [690/100000]  val_loss=-1.006807
Fine-tune [691/100000]  val_loss=-0.998569
Fine-tune [692/100000]  val_loss=-0.997119
Fine-tune [693/100000]  val_loss=-1.013322
Fine-tune [694/100000]  val_loss=-0.974386
Fine-tune [695/100000]  val_loss=-0.999143
Fine-tune [696/100000]  val_loss=-0.973457
Fine-tune [697/100000]  val_loss=-1.008109
Fine-tune [698/100000]  val_loss=-0.998356
Fine-tune [699/100000]  val_loss=-1.021336
Fine-tune [700/100000]  val_loss=-0.989578
Fine-tune [701/100000]  val_loss=-1.003486
Fine-tune [702/100000]  val_loss=-1.011709
Fine-tune [703/100000]  val_loss=-1.000235
Fine-tune [704/100000]  val_loss=-1.015279
Fine-tune [705/100000]  val_loss=-1.032698
Fine-tune [706/100000]  val_loss=-1.035814
Fine-tune [707/100000]  val_loss=-1.033705
Fine-tune [708/100000]  val_loss=-1.016945
Fine-tune [709/100000]  val_loss=-1.017660
Fine-tune [710/100000]  val_loss=-1.041399
Fine-tune [711/100000]  val_loss=-1.037554
Fine-tune [712/100000]  val_loss=-1.016286
Fine-tune [713/100000]  val_loss=-1.020378
Fine-tune [714/100000]  val_loss=-1.036421
Fine-tune [715/100000]  val_loss=-1.029186
Fine-tune [716/100000]  val_loss=-1.028212
Fine-tune [717/100000]  val_loss=-1.016375
Fine-tune [718/100000]  val_loss=-1.005932
Fine-tune [719/100000]  val_loss=-1.017085
Fine-tune [720/100000]  val_loss=-1.017403
Fine-tune [721/100000]  val_loss=-1.004572
Fine-tune [722/100000]  val_loss=-1.010771
Fine-tune [723/100000]  val_loss=-1.005575
Fine-tune [724/100000]  val_loss=-1.016153
Fine-tune [725/100000]  val_loss=-1.002166
Fine-tune [726/100000]  val_loss=-0.987919
Fine-tune [727/100000]  val_loss=-0.999555
Fine-tune [728/100000]  val_loss=-1.020020
Fine-tune [729/100000]  val_loss=-1.013048
Fine-tune [730/100000]  val_loss=-1.003823
Fine-tune [731/100000]  val_loss=-1.003702
Fine-tune [732/100000]  val_loss=-0.998689
Fine-tune [733/100000]  val_loss=-0.980090
Fine-tune [734/100000]  val_loss=-1.023734
Fine-tune [735/100000]  val_loss=-1.010144
Fine-tune [736/100000]  val_loss=-1.011549
Fine-tune [737/100000]  val_loss=-0.998689
Fine-tune [738/100000]  val_loss=-1.011789
Fine-tune [739/100000]  val_loss=-1.021726
Fine-tune [740/100000]  val_loss=-0.978454
Fine-tune [741/100000]  val_loss=-1.004581
Fine-tune [742/100000]  val_loss=-1.016089
Fine-tune [743/100000]  val_loss=-0.992857
Fine-tune [744/100000]  val_loss=-1.011241
Fine-tune [745/100000]  val_loss=-1.008467
Fine-tune [746/100000]  val_loss=-1.011646
Fine-tune [747/100000]  val_loss=-1.021091
Fine-tune [748/100000]  val_loss=-1.027597
Fine-tune [749/100000]  val_loss=-1.012362
Fine-tune [750/100000]  val_loss=-1.021789
Fine-tune [751/100000]  val_loss=-1.015963
Fine-tune [752/100000]  val_loss=-1.018076
Fine-tune [753/100000]  val_loss=-1.000479
Fine-tune [754/100000]  val_loss=-0.991912
Fine-tune [755/100000]  val_loss=-0.993613
Fine-tune [756/100000]  val_loss=-0.977195
Fine-tune [757/100000]  val_loss=-0.989240
Fine-tune [758/100000]  val_loss=-0.983502
Fine-tune [759/100000]  val_loss=-0.963574
Fine-tune [760/100000]  val_loss=-0.980331
Fine-tune [761/100000]  val_loss=-1.004379
Fine-tune [762/100000]  val_loss=-0.998283
Fine-tune [763/100000]  val_loss=-0.989765
Fine-tune [764/100000]  val_loss=-0.988605
Fine-tune [765/100000]  val_loss=-0.951782
Fine-tune [766/100000]  val_loss=-0.977759
Fine-tune [767/100000]  val_loss=-0.956401
Fine-tune [768/100000]  val_loss=-0.984003
Fine-tune [769/100000]  val_loss=-0.989038
Fine-tune [770/100000]  val_loss=-0.969085
Fine-tune [771/100000]  val_loss=-0.979106
Fine-tune [772/100000]  val_loss=-0.988568
Fine-tune [773/100000]  val_loss=-0.982386
Fine-tune [774/100000]  val_loss=-0.979567
Fine-tune [775/100000]  val_loss=-0.988437
Fine-tune [776/100000]  val_loss=-0.986604
Fine-tune [777/100000]  val_loss=-0.996591
Fine-tune [778/100000]  val_loss=-0.992083
Fine-tune [779/100000]  val_loss=-0.981805
Fine-tune [780/100000]  val_loss=-0.991676
Fine-tune [781/100000]  val_loss=-0.992479
Fine-tune [782/100000]  val_loss=-0.979466
Fine-tune [783/100000]  val_loss=-0.976663
Fine-tune [784/100000]  val_loss=-0.978722
Fine-tune [785/100000]  val_loss=-0.975380
Fine-tune [786/100000]  val_loss=-0.986603
Fine-tune [787/100000]  val_loss=-0.971252
Fine-tune [788/100000]  val_loss=-0.961803
Fine-tune [789/100000]  val_loss=-0.984558
Fine-tune [790/100000]  val_loss=-0.999155
Fine-tune [791/100000]  val_loss=-0.988120
Fine-tune [792/100000]  val_loss=-0.990301
Fine-tune [793/100000]  val_loss=-0.987346
Fine-tune [794/100000]  val_loss=-1.000709
Fine-tune [795/100000]  val_loss=-1.004737
Fine-tune [796/100000]  val_loss=-1.007868
Fine-tune [797/100000]  val_loss=-1.012215
Fine-tune [798/100000]  val_loss=-1.013596
Fine-tune [799/100000]  val_loss=-1.005826
Fine-tune [800/100000]  val_loss=-0.989495
Fine-tune [801/100000]  val_loss=-0.984575
Fine-tune [802/100000]  val_loss=-0.982259
Fine-tune [803/100000]  val_loss=-0.986246
Fine-tune [804/100000]  val_loss=-0.978942
Fine-tune [805/100000]  val_loss=-0.954997
Fine-tune [806/100000]  val_loss=-0.988132
Fine-tune [807/100000]  val_loss=-0.996246
Fine-tune [808/100000]  val_loss=-0.995778
Fine-tune [809/100000]  val_loss=-0.989371
Fine-tune [810/100000]  val_loss=-0.999380
Fine-tune [811/100000]  val_loss=-0.969686
Fine-tune [812/100000]  val_loss=-0.985191
Fine-tune [813/100000]  val_loss=-0.960378
Fine-tune [814/100000]  val_loss=-0.994407
Fine-tune [815/100000]  val_loss=-1.000998
Fine-tune [816/100000]  val_loss=-0.990186
Fine-tune [817/100000]  val_loss=-0.996473
Fine-tune [818/100000]  val_loss=-0.998183
Fine-tune [819/100000]  val_loss=-0.980812
Fine-tune [820/100000]  val_loss=-0.993079
Fine-tune [821/100000]  val_loss=-0.983231
Fine-tune [822/100000]  val_loss=-0.978157
Fine-tune [823/100000]  val_loss=-0.978988
Fine-tune [824/100000]  val_loss=-0.990949
Fine-tune [825/100000]  val_loss=-0.985192
Fine-tune [826/100000]  val_loss=-0.988430
Fine-tune [827/100000]  val_loss=-0.987604
Fine-tune [828/100000]  val_loss=-0.979941
Fine-tune [829/100000]  val_loss=-0.983396
Fine-tune [830/100000]  val_loss=-0.963644
Fine-tune [831/100000]  val_loss=-0.976734
Fine-tune [832/100000]  val_loss=-1.001787
Fine-tune [833/100000]  val_loss=-1.003771
Fine-tune [834/100000]  val_loss=-0.987893
Fine-tune [835/100000]  val_loss=-0.986530
Fine-tune [836/100000]  val_loss=-0.992449
Fine-tune [837/100000]  val_loss=-0.973169
Fine-tune [838/100000]  val_loss=-0.978990
Fine-tune [839/100000]  val_loss=-0.973209
Fine-tune [840/100000]  val_loss=-0.975845
Fine-tune [841/100000]  val_loss=-0.964280
Fine-tune [842/100000]  val_loss=-0.968830
Fine-tune [843/100000]  val_loss=-0.974622
Fine-tune [844/100000]  val_loss=-0.957250
Fine-tune [845/100000]  val_loss=-0.960801
Fine-tune [846/100000]  val_loss=-0.965193
Fine-tune [847/100000]  val_loss=-0.993654
Fine-tune [848/100000]  val_loss=-0.996626
Fine-tune [849/100000]  val_loss=-0.992086
Fine-tune [850/100000]  val_loss=-0.995303
Fine-tune [851/100000]  val_loss=-0.999575
Fine-tune [852/100000]  val_loss=-0.964503
Fine-tune [853/100000]  val_loss=-0.975147
Fine-tune [854/100000]  val_loss=-0.980685
Fine-tune [855/100000]  val_loss=-1.009778
Fine-tune [856/100000]  val_loss=-1.012669
Fine-tune [857/100000]  val_loss=-1.008044
Fine-tune [858/100000]  val_loss=-1.001747
Fine-tune [859/100000]  val_loss=-0.998877
Fine-tune [860/100000]  val_loss=-0.969941
Fine-tune [861/100000]  val_loss=-0.971640
Fine-tune [862/100000]  val_loss=-0.982304
Fine-tune [863/100000]  val_loss=-0.961881
Fine-tune [864/100000]  val_loss=-0.979785
Fine-tune [865/100000]  val_loss=-0.998839
Fine-tune [866/100000]  val_loss=-0.986892
Fine-tune [867/100000]  val_loss=-0.981594
Fine-tune [868/100000]  val_loss=-0.978013
Fine-tune [869/100000]  val_loss=-0.985922
Fine-tune [870/100000]  val_loss=-0.979771
Fine-tune [871/100000]  val_loss=-0.977054
Fine-tune [872/100000]  val_loss=-1.003374
Fine-tune [873/100000]  val_loss=-1.001599
Fine-tune [874/100000]  val_loss=-0.971950
Fine-tune [875/100000]  val_loss=-0.983400
Fine-tune [876/100000]  val_loss=-0.994274
Fine-tune [877/100000]  val_loss=-0.997636
Fine-tune [878/100000]  val_loss=-0.977226
Fine-tune [879/100000]  val_loss=-1.014631
Fine-tune [880/100000]  val_loss=-0.997906
Fine-tune [881/100000]  val_loss=-1.009144
Fine-tune [882/100000]  val_loss=-1.003008
Fine-tune [883/100000]  val_loss=-1.005259
Fine-tune [884/100000]  val_loss=-0.978935
Fine-tune [885/100000]  val_loss=-0.994813
Fine-tune [886/100000]  val_loss=-0.989062
Fine-tune [887/100000]  val_loss=-0.990836
Fine-tune [888/100000]  val_loss=-0.980047
Fine-tune [889/100000]  val_loss=-0.979962
Fine-tune [890/100000]  val_loss=-1.006888
Fine-tune [891/100000]  val_loss=-0.983923
Fine-tune [892/100000]  val_loss=-0.990591
Fine-tune [893/100000]  val_loss=-0.971407
Fine-tune [894/100000]  val_loss=-0.979370
Fine-tune [895/100000]  val_loss=-0.971352
Fine-tune [896/100000]  val_loss=-0.972176
Fine-tune [897/100000]  val_loss=-0.976273
Fine-tune [898/100000]  val_loss=-0.963966
Fine-tune [899/100000]  val_loss=-0.983259
Fine-tune [900/100000]  val_loss=-1.000558
Fine-tune [901/100000]  val_loss=-0.993744
Fine-tune [902/100000]  val_loss=-1.017731
Fine-tune [903/100000]  val_loss=-1.020032
Fine-tune [904/100000]  val_loss=-1.010433
Fine-tune [905/100000]  val_loss=-0.998873
Fine-tune [906/100000]  val_loss=-1.019584
Fine-tune [907/100000]  val_loss=-1.001562
Fine-tune [908/100000]  val_loss=-0.991654
Fine-tune [909/100000]  val_loss=-0.989025
Fine-tune [910/100000]  val_loss=-0.992865
Fine-tune [911/100000]  val_loss=-0.979838
Fine-tune [912/100000]  val_loss=-0.983116
Fine-tune [913/100000]  val_loss=-0.980991
Fine-tune [914/100000]  val_loss=-0.943937
Fine-tune [915/100000]  val_loss=-0.979002
Fine-tune [916/100000]  val_loss=-0.966558
Fine-tune [917/100000]  val_loss=-0.999954
Fine-tune [918/100000]  val_loss=-0.981265
Fine-tune [919/100000]  val_loss=-1.000874
Fine-tune [920/100000]  val_loss=-0.998924
Fine-tune [921/100000]  val_loss=-1.000266
Fine-tune [922/100000]  val_loss=-1.001517
Fine-tune [923/100000]  val_loss=-1.003745
Fine-tune [924/100000]  val_loss=-0.980501
Fine-tune [925/100000]  val_loss=-0.997926
Fine-tune [926/100000]  val_loss=-1.018184
Fine-tune [927/100000]  val_loss=-1.002327
Fine-tune [928/100000]  val_loss=-1.005619
Fine-tune [929/100000]  val_loss=-0.991681
Fine-tune [930/100000]  val_loss=-0.995023
Fine-tune [931/100000]  val_loss=-0.990661
Fine-tune [932/100000]  val_loss=-1.000478
Fine-tune [933/100000]  val_loss=-0.993239
Fine-tune [934/100000]  val_loss=-0.977273
Fine-tune [935/100000]  val_loss=-0.995455
Fine-tune [936/100000]  val_loss=-0.985232
Fine-tune [937/100000]  val_loss=-0.990360
Fine-tune [938/100000]  val_loss=-0.986976
Fine-tune [939/100000]  val_loss=-0.983789
Fine-tune [940/100000]  val_loss=-0.982349
Fine-tune [941/100000]  val_loss=-0.973585
Fine-tune [942/100000]  val_loss=-0.974179
Fine-tune [943/100000]  val_loss=-0.954950
Fine-tune [944/100000]  val_loss=-0.949441
Fine-tune [945/100000]  val_loss=-0.972511
Fine-tune [946/100000]  val_loss=-0.981708
Fine-tune [947/100000]  val_loss=-0.984778
Fine-tune [948/100000]  val_loss=-0.973753
Fine-tune [949/100000]  val_loss=-0.976856
Fine-tune [950/100000]  val_loss=-0.983294
Fine-tune [951/100000]  val_loss=-0.988186
Fine-tune [952/100000]  val_loss=-0.979469
Fine-tune [953/100000]  val_loss=-0.987300
Fine-tune [954/100000]  val_loss=-0.980250
Fine-tune [955/100000]  val_loss=-0.988226
Fine-tune [956/100000]  val_loss=-0.976269
Fine-tune [957/100000]  val_loss=-0.988783
Fine-tune [958/100000]  val_loss=-0.984155
Fine-tune [959/100000]  val_loss=-0.985775
Fine-tune [960/100000]  val_loss=-0.971414
Fine-tune [961/100000]  val_loss=-0.969292
Fine-tune [962/100000]  val_loss=-1.004538
Fine-tune [963/100000]  val_loss=-0.991941
Fine-tune [964/100000]  val_loss=-1.003673
Fine-tune [965/100000]  val_loss=-0.995429
Fine-tune [966/100000]  val_loss=-0.999177
Fine-tune [967/100000]  val_loss=-0.981873
Fine-tune [968/100000]  val_loss=-1.011982
Fine-tune [969/100000]  val_loss=-0.999495
Fine-tune [970/100000]  val_loss=-1.004883
Fine-tune [971/100000]  val_loss=-0.989339
Fine-tune [972/100000]  val_loss=-0.993937
Fine-tune [973/100000]  val_loss=-0.986504
Fine-tune [974/100000]  val_loss=-0.982180
Fine-tune [975/100000]  val_loss=-1.014205
Fine-tune [976/100000]  val_loss=-1.003235
Fine-tune [977/100000]  val_loss=-1.012213
Fine-tune [978/100000]  val_loss=-1.001913
Fine-tune [979/100000]  val_loss=-0.982548
Fine-tune [980/100000]  val_loss=-0.978855
Fine-tune [981/100000]  val_loss=-0.986355
Fine-tune [982/100000]  val_loss=-0.973638
Fine-tune [983/100000]  val_loss=-0.963166
Fine-tune [984/100000]  val_loss=-0.988690
Fine-tune [985/100000]  val_loss=-1.001135
Fine-tune [986/100000]  val_loss=-0.988481
Fine-tune [987/100000]  val_loss=-0.986552
Fine-tune [988/100000]  val_loss=-0.993542
Fine-tune [989/100000]  val_loss=-0.994743
Fine-tune [990/100000]  val_loss=-0.985479
Fine-tune [991/100000]  val_loss=-0.979533
Fine-tune [992/100000]  val_loss=-0.987849
Fine-tune [993/100000]  val_loss=-0.998806
Fine-tune [994/100000]  val_loss=-0.988744
Fine-tune [995/100000]  val_loss=-0.995123
Fine-tune [996/100000]  val_loss=-0.983405
Fine-tune [997/100000]  val_loss=-0.983845
Fine-tune [998/100000]  val_loss=-0.973636
Fine-tune [999/100000]  val_loss=-0.985921
Fine-tune [1000/100000]  val_loss=-0.979006
Fine-tune [1001/100000]  val_loss=-0.980749
Fine-tune [1002/100000]  val_loss=-0.991988
Fine-tune [1003/100000]  val_loss=-0.980283
Fine-tune [1004/100000]  val_loss=-1.010868
Fine-tune [1005/100000]  val_loss=-0.998487
Fine-tune [1006/100000]  val_loss=-1.019539
Fine-tune [1007/100000]  val_loss=-1.020294
Fine-tune [1008/100000]  val_loss=-1.025164
Fine-tune [1009/100000]  val_loss=-1.031546
Fine-tune [1010/100000]  val_loss=-1.010441
Fine-tune [1011/100000]  val_loss=-0.992082
Fine-tune [1012/100000]  val_loss=-1.013507
Fine-tune [1013/100000]  val_loss=-1.014324
Fine-tune [1014/100000]  val_loss=-1.011277
Fine-tune [1015/100000]  val_loss=-1.018267
Fine-tune [1016/100000]  val_loss=-1.009489
Fine-tune [1017/100000]  val_loss=-1.000898
Fine-tune [1018/100000]  val_loss=-1.004345
Fine-tune [1019/100000]  val_loss=-0.994301
Fine-tune [1020/100000]  val_loss=-0.997366
Fine-tune [1021/100000]  val_loss=-1.007932
Fine-tune [1022/100000]  val_loss=-1.007273
Fine-tune [1023/100000]  val_loss=-0.999227
Fine-tune [1024/100000]  val_loss=-1.005959
Fine-tune [1025/100000]  val_loss=-0.995554
Fine-tune [1026/100000]  val_loss=-1.000088
Fine-tune [1027/100000]  val_loss=-0.998587
Fine-tune [1028/100000]  val_loss=-0.984850
Fine-tune [1029/100000]  val_loss=-1.009578
Fine-tune [1030/100000]  val_loss=-0.977506
Fine-tune [1031/100000]  val_loss=-0.990530
Fine-tune [1032/100000]  val_loss=-1.019893
Fine-tune [1033/100000]  val_loss=-1.010602
Fine-tune [1034/100000]  val_loss=-0.992140
Fine-tune [1035/100000]  val_loss=-0.974776
Fine-tune [1036/100000]  val_loss=-0.986932
Fine-tune [1037/100000]  val_loss=-0.965703
Fine-tune [1038/100000]  val_loss=-0.984364
Fine-tune [1039/100000]  val_loss=-0.995840
Fine-tune [1040/100000]  val_loss=-0.999562
Fine-tune [1041/100000]  val_loss=-1.009084
Fine-tune [1042/100000]  val_loss=-0.983052
Fine-tune [1043/100000]  val_loss=-0.990710
Fine-tune [1044/100000]  val_loss=-0.987915
Fine-tune [1045/100000]  val_loss=-1.007947
Fine-tune [1046/100000]  val_loss=-0.997200
Fine-tune [1047/100000]  val_loss=-1.001809
Fine-tune [1048/100000]  val_loss=-0.985146
Fine-tune [1049/100000]  val_loss=-0.980231
Fine-tune [1050/100000]  val_loss=-0.974535
Fine-tune [1051/100000]  val_loss=-0.991744
Fine-tune [1052/100000]  val_loss=-0.997987
Fine-tune [1053/100000]  val_loss=-0.993596
Fine-tune [1054/100000]  val_loss=-0.998737
Fine-tune [1055/100000]  val_loss=-1.013715
Fine-tune [1056/100000]  val_loss=-0.990262
Fine-tune [1057/100000]  val_loss=-1.006863
Fine-tune [1058/100000]  val_loss=-1.008514
Fine-tune [1059/100000]  val_loss=-0.982355
Fine-tune [1060/100000]  val_loss=-1.000539
Fine-tune [1061/100000]  val_loss=-0.979159
Fine-tune [1062/100000]  val_loss=-0.989730
Fine-tune [1063/100000]  val_loss=-0.978072
Fine-tune [1064/100000]  val_loss=-0.989963
Fine-tune [1065/100000]  val_loss=-0.976592
Fine-tune [1066/100000]  val_loss=-0.981839
Fine-tune [1067/100000]  val_loss=-0.969230
Fine-tune [1068/100000]  val_loss=-0.993717
Fine-tune [1069/100000]  val_loss=-0.994756
Fine-tune [1070/100000]  val_loss=-0.997453
Fine-tune [1071/100000]  val_loss=-0.993100
Fine-tune [1072/100000]  val_loss=-0.974786
Fine-tune [1073/100000]  val_loss=-0.974186
Fine-tune [1074/100000]  val_loss=-0.989978
Fine-tune [1075/100000]  val_loss=-0.972674
Fine-tune [1076/100000]  val_loss=-0.980641
Fine-tune [1077/100000]  val_loss=-0.977139
Fine-tune [1078/100000]  val_loss=-0.985251
Fine-tune [1079/100000]  val_loss=-0.971180
Fine-tune [1080/100000]  val_loss=-0.968801
Fine-tune [1081/100000]  val_loss=-0.965449
Fine-tune [1082/100000]  val_loss=-0.960302
Fine-tune [1083/100000]  val_loss=-0.969949
Fine-tune [1084/100000]  val_loss=-0.972829
Fine-tune [1085/100000]  val_loss=-0.969414
Fine-tune [1086/100000]  val_loss=-0.974159
Fine-tune [1087/100000]  val_loss=-0.960139
Fine-tune [1088/100000]  val_loss=-0.955547
Fine-tune [1089/100000]  val_loss=-0.956487
Fine-tune [1090/100000]  val_loss=-0.953217
Fine-tune [1091/100000]  val_loss=-0.981545
Fine-tune [1092/100000]  val_loss=-0.966072
Fine-tune [1093/100000]  val_loss=-0.989282
Fine-tune [1094/100000]  val_loss=-0.988477
Fine-tune [1095/100000]  val_loss=-0.965595
Fine-tune [1096/100000]  val_loss=-0.961326
Fine-tune [1097/100000]  val_loss=-0.984867
Fine-tune [1098/100000]  val_loss=-0.966226
Fine-tune [1099/100000]  val_loss=-0.991355
Fine-tune [1100/100000]  val_loss=-0.982890
Fine-tune [1101/100000]  val_loss=-0.985942
Fine-tune [1102/100000]  val_loss=-0.979047
Fine-tune [1103/100000]  val_loss=-0.973213
Fine-tune [1104/100000]  val_loss=-0.988851
Fine-tune [1105/100000]  val_loss=-0.988455
Fine-tune [1106/100000]  val_loss=-0.999946
Fine-tune [1107/100000]  val_loss=-0.999489
Fine-tune [1108/100000]  val_loss=-0.997215
Fine-tune [1109/100000]  val_loss=-0.993226
Fine-tune [1110/100000]  val_loss=-0.995046
Fine-tune [1111/100000]  val_loss=-1.013210
Fine-tune [1112/100000]  val_loss=-0.997067
Fine-tune [1113/100000]  val_loss=-1.016686
Fine-tune [1114/100000]  val_loss=-0.985210
Fine-tune [1115/100000]  val_loss=-1.009067
Fine-tune [1116/100000]  val_loss=-1.016894
Fine-tune [1117/100000]  val_loss=-0.996009
Fine-tune [1118/100000]  val_loss=-1.000808
Fine-tune [1119/100000]  val_loss=-0.988517
Fine-tune [1120/100000]  val_loss=-0.986463
Fine-tune [1121/100000]  val_loss=-0.981478
Fine-tune [1122/100000]  val_loss=-0.986848
Fine-tune [1123/100000]  val_loss=-0.963113
Fine-tune [1124/100000]  val_loss=-0.950249
Fine-tune [1125/100000]  val_loss=-0.959412
Fine-tune [1126/100000]  val_loss=-0.963537
Fine-tune [1127/100000]  val_loss=-0.977015
Fine-tune [1128/100000]  val_loss=-0.974942
Fine-tune [1129/100000]  val_loss=-0.959631
Fine-tune [1130/100000]  val_loss=-0.977924
Fine-tune [1131/100000]  val_loss=-0.972791
Fine-tune [1132/100000]  val_loss=-0.976083
Fine-tune [1133/100000]  val_loss=-0.955787
Fine-tune [1134/100000]  val_loss=-0.952460
Fine-tune [1135/100000]  val_loss=-0.973122
Fine-tune [1136/100000]  val_loss=-0.987885
Fine-tune [1137/100000]  val_loss=-0.985084
Fine-tune [1138/100000]  val_loss=-0.975049
Fine-tune [1139/100000]  val_loss=-0.975082
Fine-tune [1140/100000]  val_loss=-0.975932
Fine-tune [1141/100000]  val_loss=-0.971773
Fine-tune [1142/100000]  val_loss=-0.997184
Fine-tune [1143/100000]  val_loss=-0.990570
Fine-tune [1144/100000]  val_loss=-0.949528
Fine-tune [1145/100000]  val_loss=-0.977721
Fine-tune [1146/100000]  val_loss=-0.962720
Fine-tune [1147/100000]  val_loss=-0.953501
Fine-tune [1148/100000]  val_loss=-0.988316
Fine-tune [1149/100000]  val_loss=-0.979315
Fine-tune [1150/100000]  val_loss=-0.998144
Fine-tune [1151/100000]  val_loss=-0.988833
Fine-tune [1152/100000]  val_loss=-0.999380
Fine-tune [1153/100000]  val_loss=-0.990290
Fine-tune [1154/100000]  val_loss=-0.992775
Fine-tune [1155/100000]  val_loss=-1.004157
Fine-tune [1156/100000]  val_loss=-0.995007
Fine-tune [1157/100000]  val_loss=-0.985516
Fine-tune [1158/100000]  val_loss=-0.994418
Fine-tune [1159/100000]  val_loss=-0.983067
Fine-tune [1160/100000]  val_loss=-0.982038
Fine-tune [1161/100000]  val_loss=-0.961286
Fine-tune [1162/100000]  val_loss=-0.969194
Fine-tune [1163/100000]  val_loss=-0.976371
Fine-tune [1164/100000]  val_loss=-0.972977
Fine-tune [1165/100000]  val_loss=-0.973878
Fine-tune [1166/100000]  val_loss=-0.940385
Fine-tune [1167/100000]  val_loss=-0.972711
Fine-tune [1168/100000]  val_loss=-0.981318
Fine-tune [1169/100000]  val_loss=-0.961693
Fine-tune [1170/100000]  val_loss=-0.969774
Fine-tune [1171/100000]  val_loss=-0.976682
Fine-tune [1172/100000]  val_loss=-0.966032
Fine-tune [1173/100000]  val_loss=-0.962411
Fine-tune [1174/100000]  val_loss=-0.974545
Fine-tune [1175/100000]  val_loss=-0.963699
Fine-tune [1176/100000]  val_loss=-0.977576
Fine-tune [1177/100000]  val_loss=-0.978532
Fine-tune [1178/100000]  val_loss=-0.992643
Fine-tune [1179/100000]  val_loss=-0.989751
Fine-tune [1180/100000]  val_loss=-0.954499
Fine-tune [1181/100000]  val_loss=-0.945584
Fine-tune [1182/100000]  val_loss=-0.953162
Fine-tune [1183/100000]  val_loss=-0.963926
Fine-tune [1184/100000]  val_loss=-0.944764
Fine-tune [1185/100000]  val_loss=-0.964536
Fine-tune [1186/100000]  val_loss=-0.948063
Fine-tune [1187/100000]  val_loss=-0.953452
Fine-tune [1188/100000]  val_loss=-0.965590
Fine-tune [1189/100000]  val_loss=-0.976025
Fine-tune [1190/100000]  val_loss=-0.948048
Fine-tune [1191/100000]  val_loss=-0.959849
Fine-tune [1192/100000]  val_loss=-0.969528
Fine-tune [1193/100000]  val_loss=-0.938256
Fine-tune [1194/100000]  val_loss=-0.959966
Fine-tune [1195/100000]  val_loss=-0.939212
Fine-tune [1196/100000]  val_loss=-0.959145
Fine-tune [1197/100000]  val_loss=-0.968834
Fine-tune [1198/100000]  val_loss=-0.969007
Fine-tune [1199/100000]  val_loss=-0.951743
Fine-tune [1200/100000]  val_loss=-0.959376
Fine-tune [1201/100000]  val_loss=-0.942747
Fine-tune [1202/100000]  val_loss=-0.951591
Fine-tune [1203/100000]  val_loss=-0.969710
Fine-tune [1204/100000]  val_loss=-0.958033
Fine-tune [1205/100000]  val_loss=-0.943706
Fine-tune [1206/100000]  val_loss=-0.969316
Fine-tune [1207/100000]  val_loss=-0.969648
Fine-tune [1208/100000]  val_loss=-0.946744
Fine-tune [1209/100000]  val_loss=-0.975002
Fine-tune [1210/100000]  val_loss=-0.944872
Fine-tune [1211/100000]  val_loss=-0.936594
Fine-tune [1212/100000]  val_loss=-0.954412
Fine-tune [1213/100000]  val_loss=-0.979361
Fine-tune [1214/100000]  val_loss=-0.979116
Fine-tune [1215/100000]  val_loss=-0.964957
Fine-tune [1216/100000]  val_loss=-0.988615
Fine-tune [1217/100000]  val_loss=-0.967094
Fine-tune [1218/100000]  val_loss=-0.987962
Fine-tune [1219/100000]  val_loss=-0.977503
Fine-tune [1220/100000]  val_loss=-0.979954
Fine-tune [1221/100000]  val_loss=-0.981202
Fine-tune [1222/100000]  val_loss=-0.987880
Fine-tune [1223/100000]  val_loss=-0.995156
Fine-tune [1224/100000]  val_loss=-0.996407
Fine-tune [1225/100000]  val_loss=-0.991117
Fine-tune [1226/100000]  val_loss=-0.994171
Fine-tune [1227/100000]  val_loss=-1.012605
Fine-tune [1228/100000]  val_loss=-1.001452
Fine-tune [1229/100000]  val_loss=-0.973379
Fine-tune [1230/100000]  val_loss=-1.002883
Fine-tune [1231/100000]  val_loss=-0.983878
Fine-tune [1232/100000]  val_loss=-0.980150
Fine-tune [1233/100000]  val_loss=-0.974268
Fine-tune [1234/100000]  val_loss=-0.967940
Fine-tune [1235/100000]  val_loss=-0.991294
Fine-tune [1236/100000]  val_loss=-0.999841
Fine-tune [1237/100000]  val_loss=-0.987532
Fine-tune [1238/100000]  val_loss=-0.990063
Fine-tune [1239/100000]  val_loss=-0.989622
Fine-tune [1240/100000]  val_loss=-0.980790
Fine-tune [1241/100000]  val_loss=-0.974072
Fine-tune [1242/100000]  val_loss=-0.989284
Fine-tune [1243/100000]  val_loss=-0.957607
Fine-tune [1244/100000]  val_loss=-0.974921
Fine-tune [1245/100000]  val_loss=-0.982577
Fine-tune [1246/100000]  val_loss=-0.971551
Fine-tune [1247/100000]  val_loss=-0.973707
Fine-tune [1248/100000]  val_loss=-0.969940
Fine-tune [1249/100000]  val_loss=-0.961186
Fine-tune [1250/100000]  val_loss=-0.957559
Fine-tune [1251/100000]  val_loss=-0.976465
Fine-tune [1252/100000]  val_loss=-0.974953
Fine-tune [1253/100000]  val_loss=-0.965266
Fine-tune [1254/100000]  val_loss=-0.975005
Fine-tune [1255/100000]  val_loss=-0.961976
Fine-tune [1256/100000]  val_loss=-0.954359
Fine-tune [1257/100000]  val_loss=-0.954232
Fine-tune [1258/100000]  val_loss=-0.956677
Fine-tune [1259/100000]  val_loss=-0.962203
Fine-tune [1260/100000]  val_loss=-0.962666
Fine-tune [1261/100000]  val_loss=-0.969758
Fine-tune [1262/100000]  val_loss=-0.970826
Fine-tune [1263/100000]  val_loss=-0.952922
Fine-tune [1264/100000]  val_loss=-0.936887
Fine-tune [1265/100000]  val_loss=-0.918681
Fine-tune [1266/100000]  val_loss=-0.958160
Fine-tune [1267/100000]  val_loss=-0.949217
Fine-tune [1268/100000]  val_loss=-0.951752
Fine-tune [1269/100000]  val_loss=-0.963459
Fine-tune [1270/100000]  val_loss=-0.954384
Fine-tune [1271/100000]  val_loss=-0.941527
Fine-tune [1272/100000]  val_loss=-0.959469
Fine-tune [1273/100000]  val_loss=-0.945970
Fine-tune [1274/100000]  val_loss=-0.943957
Fine-tune [1275/100000]  val_loss=-0.954902
Fine-tune [1276/100000]  val_loss=-0.938135
Fine-tune [1277/100000]  val_loss=-0.936706
Fine-tune [1278/100000]  val_loss=-0.928446
Fine-tune [1279/100000]  val_loss=-0.941770
Fine-tune [1280/100000]  val_loss=-0.951430
Fine-tune [1281/100000]  val_loss=-0.960857
Fine-tune [1282/100000]  val_loss=-0.973995
Fine-tune [1283/100000]  val_loss=-0.932585
Fine-tune [1284/100000]  val_loss=-0.964088
Fine-tune [1285/100000]  val_loss=-0.957845
Fine-tune [1286/100000]  val_loss=-0.962799
Fine-tune [1287/100000]  val_loss=-0.941951
Fine-tune [1288/100000]  val_loss=-0.940331
Fine-tune [1289/100000]  val_loss=-0.935403
Fine-tune [1290/100000]  val_loss=-0.928371
Fine-tune [1291/100000]  val_loss=-0.951513
Fine-tune [1292/100000]  val_loss=-0.920850
Fine-tune [1293/100000]  val_loss=-0.923284
Fine-tune [1294/100000]  val_loss=-0.938540
Fine-tune [1295/100000]  val_loss=-0.931544
Fine-tune [1296/100000]  val_loss=-0.920704
Fine-tune [1297/100000]  val_loss=-0.914196
Fine-tune [1298/100000]  val_loss=-0.924224
Fine-tune [1299/100000]  val_loss=-0.945699
Fine-tune [1300/100000]  val_loss=-0.927202
Fine-tune [1301/100000]  val_loss=-0.937344
Fine-tune [1302/100000]  val_loss=-0.928904
Fine-tune [1303/100000]  val_loss=-0.924066
Fine-tune [1304/100000]  val_loss=-0.960003
Fine-tune [1305/100000]  val_loss=-0.967449
Fine-tune [1306/100000]  val_loss=-0.940226
Fine-tune [1307/100000]  val_loss=-0.947504
Fine-tune [1308/100000]  val_loss=-0.967533
Fine-tune [1309/100000]  val_loss=-0.971087
Fine-tune [1310/100000]  val_loss=-0.971471
Fine-tune [1311/100000]  val_loss=-0.953896
Fine-tune [1312/100000]  val_loss=-0.931991
Fine-tune [1313/100000]  val_loss=-0.962428
Fine-tune [1314/100000]  val_loss=-0.962808
Fine-tune [1315/100000]  val_loss=-0.941082
Fine-tune [1316/100000]  val_loss=-0.958850
Fine-tune [1317/100000]  val_loss=-0.962501
Fine-tune [1318/100000]  val_loss=-0.947267
Fine-tune [1319/100000]  val_loss=-0.938268
Fine-tune [1320/100000]  val_loss=-0.945826
Fine-tune [1321/100000]  val_loss=-0.959058
Fine-tune [1322/100000]  val_loss=-0.960228
Fine-tune [1323/100000]  val_loss=-0.950524
Fine-tune [1324/100000]  val_loss=-0.949075
Fine-tune [1325/100000]  val_loss=-0.942953
Fine-tune [1326/100000]  val_loss=-0.970634
Fine-tune [1327/100000]  val_loss=-0.961114
Fine-tune [1328/100000]  val_loss=-0.947612
Fine-tune [1329/100000]  val_loss=-0.934230
Fine-tune [1330/100000]  val_loss=-0.909298
Fine-tune [1331/100000]  val_loss=-0.936391
Fine-tune [1332/100000]  val_loss=-0.934162
Fine-tune [1333/100000]  val_loss=-0.917046
Fine-tune [1334/100000]  val_loss=-0.956401
Fine-tune [1335/100000]  val_loss=-0.931551
Fine-tune [1336/100000]  val_loss=-0.935350
Fine-tune [1337/100000]  val_loss=-0.937884
Fine-tune [1338/100000]  val_loss=-0.915732
Fine-tune [1339/100000]  val_loss=-0.927674
Fine-tune [1340/100000]  val_loss=-0.936978
Fine-tune [1341/100000]  val_loss=-0.956911
Fine-tune [1342/100000]  val_loss=-0.956048
Fine-tune [1343/100000]  val_loss=-0.951856
Fine-tune [1344/100000]  val_loss=-0.944575
Fine-tune [1345/100000]  val_loss=-0.912980
Fine-tune [1346/100000]  val_loss=-0.929635
Fine-tune [1347/100000]  val_loss=-0.966099
Fine-tune [1348/100000]  val_loss=-0.943170
Fine-tune [1349/100000]  val_loss=-0.943553
Fine-tune [1350/100000]  val_loss=-0.950920
Fine-tune [1351/100000]  val_loss=-0.932494
Fine-tune [1352/100000]  val_loss=-0.941517
Fine-tune [1353/100000]  val_loss=-0.930892
Fine-tune [1354/100000]  val_loss=-0.949954
Fine-tune [1355/100000]  val_loss=-0.944527
Fine-tune [1356/100000]  val_loss=-0.944918
Fine-tune [1357/100000]  val_loss=-0.937735
Fine-tune [1358/100000]  val_loss=-0.923519
Fine-tune [1359/100000]  val_loss=-0.942106
Fine-tune [1360/100000]  val_loss=-0.920758
Fine-tune [1361/100000]  val_loss=-0.945746
Fine-tune [1362/100000]  val_loss=-0.950609
Fine-tune [1363/100000]  val_loss=-0.958888
Fine-tune [1364/100000]  val_loss=-0.949586
Fine-tune [1365/100000]  val_loss=-0.956118
Fine-tune [1366/100000]  val_loss=-0.953108
Fine-tune [1367/100000]  val_loss=-0.940091
Fine-tune [1368/100000]  val_loss=-0.938919
Fine-tune [1369/100000]  val_loss=-0.949085
Fine-tune [1370/100000]  val_loss=-0.943588
Fine-tune [1371/100000]  val_loss=-0.934295
Fine-tune [1372/100000]  val_loss=-0.940239
Fine-tune [1373/100000]  val_loss=-0.954918
Fine-tune [1374/100000]  val_loss=-0.969896
Fine-tune [1375/100000]  val_loss=-0.945578
Fine-tune [1376/100000]  val_loss=-0.936814
Fine-tune [1377/100000]  val_loss=-0.915713
Fine-tune [1378/100000]  val_loss=-0.918170
Fine-tune [1379/100000]  val_loss=-0.937929
Fine-tune [1380/100000]  val_loss=-0.957621
Fine-tune [1381/100000]  val_loss=-0.921632
Fine-tune [1382/100000]  val_loss=-0.953439
Fine-tune [1383/100000]  val_loss=-0.951140
Fine-tune [1384/100000]  val_loss=-0.919866
Fine-tune [1385/100000]  val_loss=-0.934394
Fine-tune [1386/100000]  val_loss=-0.949844
Fine-tune [1387/100000]  val_loss=-0.967212
Fine-tune [1388/100000]  val_loss=-0.956619
Fine-tune [1389/100000]  val_loss=-0.932711
Fine-tune [1390/100000]  val_loss=-0.942973
Fine-tune [1391/100000]  val_loss=-0.953838
Fine-tune [1392/100000]  val_loss=-0.963029
Fine-tune [1393/100000]  val_loss=-0.953414
Fine-tune [1394/100000]  val_loss=-0.963179
Fine-tune [1395/100000]  val_loss=-0.926212
Fine-tune [1396/100000]  val_loss=-0.945771
Fine-tune [1397/100000]  val_loss=-0.952850
Fine-tune [1398/100000]  val_loss=-0.935525
Fine-tune [1399/100000]  val_loss=-0.925532
Fine-tune [1400/100000]  val_loss=-0.942951
Fine-tune [1401/100000]  val_loss=-0.950663
Fine-tune [1402/100000]  val_loss=-0.971874
Fine-tune [1403/100000]  val_loss=-0.961953
Fine-tune [1404/100000]  val_loss=-0.984154
Fine-tune [1405/100000]  val_loss=-0.954363
Fine-tune [1406/100000]  val_loss=-0.956662
Fine-tune [1407/100000]  val_loss=-0.943740
Fine-tune [1408/100000]  val_loss=-0.965746
Fine-tune [1409/100000]  val_loss=-0.961405
Fine-tune [1410/100000]  val_loss=-0.968838
Fine-tune [1411/100000]  val_loss=-0.955591
Fine-tune [1412/100000]  val_loss=-0.941611
Fine-tune [1413/100000]  val_loss=-0.930240
Fine-tune [1414/100000]  val_loss=-0.929979
Fine-tune [1415/100000]  val_loss=-0.917884
Fine-tune [1416/100000]  val_loss=-0.944002
Fine-tune [1417/100000]  val_loss=-0.956788
Fine-tune [1418/100000]  val_loss=-0.950611
Fine-tune [1419/100000]  val_loss=-0.962322
Fine-tune [1420/100000]  val_loss=-0.979870
Fine-tune [1421/100000]  val_loss=-0.966947
Fine-tune [1422/100000]  val_loss=-0.961470
Fine-tune [1423/100000]  val_loss=-0.972378
Fine-tune [1424/100000]  val_loss=-0.959319
Fine-tune [1425/100000]  val_loss=-0.937109
Fine-tune [1426/100000]  val_loss=-0.951050
Fine-tune [1427/100000]  val_loss=-0.957242
Fine-tune [1428/100000]  val_loss=-0.955128
Fine-tune [1429/100000]  val_loss=-0.964423
Fine-tune [1430/100000]  val_loss=-0.962811
Fine-tune [1431/100000]  val_loss=-0.952804
Fine-tune [1432/100000]  val_loss=-0.932837
Fine-tune [1433/100000]  val_loss=-0.918377
Fine-tune [1434/100000]  val_loss=-0.899936
Fine-tune [1435/100000]  val_loss=-0.911673
Fine-tune [1436/100000]  val_loss=-0.930811
Fine-tune [1437/100000]  val_loss=-0.910554
Fine-tune [1438/100000]  val_loss=-0.930277
Fine-tune [1439/100000]  val_loss=-0.905205
Fine-tune [1440/100000]  val_loss=-0.936196
Fine-tune [1441/100000]  val_loss=-0.947183
Fine-tune [1442/100000]  val_loss=-0.968589
Fine-tune [1443/100000]  val_loss=-0.947326
Fine-tune [1444/100000]  val_loss=-0.986674
Fine-tune [1445/100000]  val_loss=-0.954827
Fine-tune [1446/100000]  val_loss=-0.952895
Fine-tune [1447/100000]  val_loss=-0.947473
Fine-tune [1448/100000]  val_loss=-0.959754
Fine-tune [1449/100000]  val_loss=-0.991243
Fine-tune [1450/100000]  val_loss=-0.984087
Fine-tune [1451/100000]  val_loss=-0.947775
Fine-tune [1452/100000]  val_loss=-0.963945
Fine-tune [1453/100000]  val_loss=-0.956504
Fine-tune [1454/100000]  val_loss=-0.961234
Fine-tune [1455/100000]  val_loss=-0.984284
Fine-tune [1456/100000]  val_loss=-0.967042
Fine-tune [1457/100000]  val_loss=-0.977874
Fine-tune [1458/100000]  val_loss=-0.945922
Fine-tune [1459/100000]  val_loss=-0.963882
Fine-tune [1460/100000]  val_loss=-0.966374
Fine-tune [1461/100000]  val_loss=-0.951791
Fine-tune [1462/100000]  val_loss=-0.943095
Fine-tune [1463/100000]  val_loss=-0.930859
Fine-tune [1464/100000]  val_loss=-0.953089
Fine-tune [1465/100000]  val_loss=-0.948435
Fine-tune [1466/100000]  val_loss=-0.971949
Fine-tune [1467/100000]  val_loss=-0.959835
Fine-tune [1468/100000]  val_loss=-0.930888
Fine-tune [1469/100000]  val_loss=-0.943179
Fine-tune [1470/100000]  val_loss=-0.991731
Fine-tune [1471/100000]  val_loss=-0.949493
Fine-tune [1472/100000]  val_loss=-0.956241
Fine-tune [1473/100000]  val_loss=-0.940742
Fine-tune [1474/100000]  val_loss=-0.958263
Fine-tune [1475/100000]  val_loss=-0.956490
Fine-tune [1476/100000]  val_loss=-0.966903
Fine-tune [1477/100000]  val_loss=-0.967502
Fine-tune [1478/100000]  val_loss=-0.949374
Fine-tune [1479/100000]  val_loss=-0.956103
Fine-tune [1480/100000]  val_loss=-0.945071
Fine-tune [1481/100000]  val_loss=-0.939557
Fine-tune [1482/100000]  val_loss=-0.947993
  -> 验证未改进 1000 次，早停。
[FINETUNE] 最佳验证损失=-1.065126 已保存。

--- 评估 [HD128_L3] ---

=== 本次试验参数 (Run Config) ===
opamp             : two_stage_opamp
hidden_dim        : 128
num_layers        : 3
lr_pretrain       : 0.003
epochs_pretrain   : 1000
patience_pretrain : 200
lr_finetune       : 0.0038
epochs_finetune   : 100000
patience_finetune : 1000
batch_a           : 128
batch_b           : 64
dropout_rate      : 0.2
alpha_r2          : 0.0
lambda_coral      : 0.1
seed              : 42
device            : cpu

--- [评估阶段] 开始计算指标 ---

=== 目标域验证集指标（物理单位）===
slewrate_pos    MSE=1.106e+14  MAE=7.909e+06  R2=0.7421
dc_gain         MSE=2.414e+07  MAE=1448  R2=0.3802
ugf             MSE=9.353e+13  MAE=6.258e+06  R2=0.7886
phase_margin    MSE=173.2  MAE=9.635  R2=0.8490
cmrr            MSE=8.368e+11  MAE=9.012e+04  R2=0.0339

Avg  (all dims)   MSE=4.1e+13  MAE=2.852e+06  R2=0.5588
[OK] HD128_L3 -> r2_avg=0.5588, mae_avg=2.852e+06, mse_avg=4.1e+13
===== [HD128_L3] 训练完成 =====

===== [HD128_L4] 训练开始 =====

--- [阶段一] Backbone 预训练 (source_train / source_val, HuberLoss) ---
Pretrain [1/1000]  train=0.270262  val=0.209176
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [2/1000]  train=0.204346  val=0.162503
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [3/1000]  train=0.173333  val=0.149704
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [4/1000]  train=0.162784  val=0.133383
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [5/1000]  train=0.151767  val=0.126754
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [6/1000]  train=0.144898  val=0.120326
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [7/1000]  train=0.141922  val=0.118286
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [8/1000]  train=0.137786  val=0.118548
Pretrain [9/1000]  train=0.131927  val=0.107653
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [10/1000]  train=0.129852  val=0.119754
Pretrain [11/1000]  train=0.127521  val=0.099762
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [12/1000]  train=0.123004  val=0.105317
Pretrain [13/1000]  train=0.119250  val=0.102468
Pretrain [14/1000]  train=0.117583  val=0.097265
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [15/1000]  train=0.116936  val=0.100260
Pretrain [16/1000]  train=0.116562  val=0.103437
Pretrain [17/1000]  train=0.114535  val=0.100841
Pretrain [18/1000]  train=0.109810  val=0.094478
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [19/1000]  train=0.111477  val=0.091060
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [20/1000]  train=0.109711  val=0.094471
Pretrain [21/1000]  train=0.110493  val=0.089030
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [22/1000]  train=0.104706  val=0.086106
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [23/1000]  train=0.105447  val=0.095196
Pretrain [24/1000]  train=0.104951  val=0.089825
Pretrain [25/1000]  train=0.104440  val=0.093648
Pretrain [26/1000]  train=0.103352  val=0.087415
Pretrain [27/1000]  train=0.105333  val=0.090945
Pretrain [28/1000]  train=0.101316  val=0.086665
Pretrain [29/1000]  train=0.100057  val=0.093413
Pretrain [30/1000]  train=0.101950  val=0.092049
Pretrain [31/1000]  train=0.102803  val=0.087341
Pretrain [32/1000]  train=0.098408  val=0.086549
Pretrain [33/1000]  train=0.099299  val=0.086601
Pretrain [34/1000]  train=0.098841  val=0.088287
Pretrain [35/1000]  train=0.098217  val=0.085499
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [36/1000]  train=0.097772  val=0.089360
Pretrain [37/1000]  train=0.098917  val=0.083151
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [38/1000]  train=0.095188  val=0.084740
Pretrain [39/1000]  train=0.095525  val=0.082172
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [40/1000]  train=0.096607  val=0.088918
Pretrain [41/1000]  train=0.095775  val=0.086353
Pretrain [42/1000]  train=0.097980  val=0.084014
Pretrain [43/1000]  train=0.093115  val=0.086365
Pretrain [44/1000]  train=0.095149  val=0.086385
Pretrain [45/1000]  train=0.096002  val=0.089006
Pretrain [46/1000]  train=0.094411  val=0.088536
Pretrain [47/1000]  train=0.093481  val=0.085235
Pretrain [48/1000]  train=0.093940  val=0.087617
Pretrain [49/1000]  train=0.095485  val=0.085642
Pretrain [50/1000]  train=0.091213  val=0.086421
Pretrain [51/1000]  train=0.090767  val=0.083611
Pretrain [52/1000]  train=0.090682  val=0.081020
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [53/1000]  train=0.088931  val=0.086164
Pretrain [54/1000]  train=0.090868  val=0.081276
Pretrain [55/1000]  train=0.089389  val=0.089986
Pretrain [56/1000]  train=0.089287  val=0.081774
Pretrain [57/1000]  train=0.089109  val=0.084423
Pretrain [58/1000]  train=0.089015  val=0.084948
Pretrain [59/1000]  train=0.085806  val=0.083748
Pretrain [60/1000]  train=0.087821  val=0.082949
Pretrain [61/1000]  train=0.088020  val=0.081066
Pretrain [62/1000]  train=0.089670  val=0.080014
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [63/1000]  train=0.085699  val=0.081797
Pretrain [64/1000]  train=0.084228  val=0.080950
Pretrain [65/1000]  train=0.085124  val=0.085456
Pretrain [66/1000]  train=0.084520  val=0.085740
Pretrain [67/1000]  train=0.085353  val=0.079644
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [68/1000]  train=0.086106  val=0.082407
Pretrain [69/1000]  train=0.085328  val=0.083289
Pretrain [70/1000]  train=0.086348  val=0.085755
Pretrain [71/1000]  train=0.083553  val=0.080047
Pretrain [72/1000]  train=0.083404  val=0.083072
Pretrain [73/1000]  train=0.085412  val=0.081360
Pretrain [74/1000]  train=0.082689  val=0.081474
Pretrain [75/1000]  train=0.085366  val=0.077958
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [76/1000]  train=0.082291  val=0.081967
Pretrain [77/1000]  train=0.083991  val=0.084025
Pretrain [78/1000]  train=0.081489  val=0.080943
Pretrain [79/1000]  train=0.080713  val=0.081144
Pretrain [80/1000]  train=0.082331  val=0.079171
Pretrain [81/1000]  train=0.084040  val=0.080866
Pretrain [82/1000]  train=0.078899  val=0.077164
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [83/1000]  train=0.079936  val=0.076802
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [84/1000]  train=0.080499  val=0.081460
Pretrain [85/1000]  train=0.076904  val=0.079476
Pretrain [86/1000]  train=0.078899  val=0.077536
Pretrain [87/1000]  train=0.077410  val=0.076062
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [88/1000]  train=0.078784  val=0.079493
Pretrain [89/1000]  train=0.078866  val=0.078672
Pretrain [90/1000]  train=0.078692  val=0.078010
Pretrain [91/1000]  train=0.078128  val=0.071484
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [92/1000]  train=0.078000  val=0.078733
Pretrain [93/1000]  train=0.076570  val=0.075612
Pretrain [94/1000]  train=0.075815  val=0.076450
Pretrain [95/1000]  train=0.075623  val=0.079042
Pretrain [96/1000]  train=0.074205  val=0.073589
Pretrain [97/1000]  train=0.075704  val=0.077060
Pretrain [98/1000]  train=0.075751  val=0.077830
Pretrain [99/1000]  train=0.073852  val=0.075435
Pretrain [100/1000]  train=0.074648  val=0.072557
Pretrain [101/1000]  train=0.071980  val=0.076382
Pretrain [102/1000]  train=0.074371  val=0.076690
Pretrain [103/1000]  train=0.072201  val=0.073740
Pretrain [104/1000]  train=0.072444  val=0.074930
Pretrain [105/1000]  train=0.072425  val=0.075287
Pretrain [106/1000]  train=0.071337  val=0.073150
Pretrain [107/1000]  train=0.072623  val=0.076726
Pretrain [108/1000]  train=0.072780  val=0.072184
Pretrain [109/1000]  train=0.071957  val=0.079389
Pretrain [110/1000]  train=0.072585  val=0.072920
Pretrain [111/1000]  train=0.070087  val=0.073937
Pretrain [112/1000]  train=0.071583  val=0.075990
Pretrain [113/1000]  train=0.069884  val=0.072550
Pretrain [114/1000]  train=0.070958  val=0.072020
Pretrain [115/1000]  train=0.069528  val=0.074795
Pretrain [116/1000]  train=0.068417  val=0.073569
Pretrain [117/1000]  train=0.067997  val=0.072055
Pretrain [118/1000]  train=0.068456  val=0.073387
Pretrain [119/1000]  train=0.069519  val=0.074045
Pretrain [120/1000]  train=0.068459  val=0.074920
Pretrain [121/1000]  train=0.066107  val=0.072295
Pretrain [122/1000]  train=0.067624  val=0.073907
Pretrain [123/1000]  train=0.067308  val=0.073846
Pretrain [124/1000]  train=0.066521  val=0.075551
Pretrain [125/1000]  train=0.067891  val=0.070935
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [126/1000]  train=0.066116  val=0.071636
Pretrain [127/1000]  train=0.065737  val=0.071330
Pretrain [128/1000]  train=0.066108  val=0.069935
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [129/1000]  train=0.064512  val=0.073802
Pretrain [130/1000]  train=0.064790  val=0.069350
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [131/1000]  train=0.065718  val=0.071326
Pretrain [132/1000]  train=0.064658  val=0.073653
Pretrain [133/1000]  train=0.063710  val=0.072958
Pretrain [134/1000]  train=0.064238  val=0.071357
Pretrain [135/1000]  train=0.064460  val=0.070560
Pretrain [136/1000]  train=0.065093  val=0.072272
Pretrain [137/1000]  train=0.064316  val=0.071953
Pretrain [138/1000]  train=0.064574  val=0.072653
Pretrain [139/1000]  train=0.062716  val=0.074674
Pretrain [140/1000]  train=0.064579  val=0.071355
Pretrain [141/1000]  train=0.063541  val=0.072131
Pretrain [142/1000]  train=0.064697  val=0.070285
Pretrain [143/1000]  train=0.060593  val=0.070190
Pretrain [144/1000]  train=0.064712  val=0.069872
Pretrain [145/1000]  train=0.062391  val=0.069148
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [146/1000]  train=0.061966  val=0.071325
Pretrain [147/1000]  train=0.062318  val=0.069170
Pretrain [148/1000]  train=0.063015  val=0.070300
Pretrain [149/1000]  train=0.061244  val=0.070497
Pretrain [150/1000]  train=0.060852  val=0.069840
Pretrain [151/1000]  train=0.060634  val=0.069501
Pretrain [152/1000]  train=0.061866  val=0.068227
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [153/1000]  train=0.062677  val=0.069995
Pretrain [154/1000]  train=0.059817  val=0.070026
Pretrain [155/1000]  train=0.060637  val=0.069240
Pretrain [156/1000]  train=0.060428  val=0.069049
Pretrain [157/1000]  train=0.060052  val=0.068583
Pretrain [158/1000]  train=0.059734  val=0.068623
Pretrain [159/1000]  train=0.059490  val=0.067716
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [160/1000]  train=0.059361  val=0.068174
Pretrain [161/1000]  train=0.058398  val=0.068668
Pretrain [162/1000]  train=0.059192  val=0.068445
Pretrain [163/1000]  train=0.059752  val=0.067459
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [164/1000]  train=0.059114  val=0.068644
Pretrain [165/1000]  train=0.058699  val=0.068056
Pretrain [166/1000]  train=0.058298  val=0.067578
Pretrain [167/1000]  train=0.057977  val=0.067712
Pretrain [168/1000]  train=0.056530  val=0.067476
Pretrain [169/1000]  train=0.057708  val=0.067810
Pretrain [170/1000]  train=0.056163  val=0.066587
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [171/1000]  train=0.058068  val=0.067215
Pretrain [172/1000]  train=0.058218  val=0.066321
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [173/1000]  train=0.059645  val=0.066237
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [174/1000]  train=0.058611  val=0.066317
Pretrain [175/1000]  train=0.057476  val=0.066342
Pretrain [176/1000]  train=0.057818  val=0.066392
Pretrain [177/1000]  train=0.057763  val=0.066884
Pretrain [178/1000]  train=0.059924  val=0.066792
Pretrain [179/1000]  train=0.057397  val=0.066341
Pretrain [180/1000]  train=0.058020  val=0.066706
Pretrain [181/1000]  train=0.058351  val=0.066832
Pretrain [182/1000]  train=0.058545  val=0.066778
Pretrain [183/1000]  train=0.057879  val=0.066426
Pretrain [184/1000]  train=0.057627  val=0.066862
Pretrain [185/1000]  train=0.058546  val=0.066195
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [186/1000]  train=0.056989  val=0.066419
Pretrain [187/1000]  train=0.057031  val=0.066480
Pretrain [188/1000]  train=0.057607  val=0.066420
Pretrain [189/1000]  train=0.057392  val=0.066643
Pretrain [190/1000]  train=0.056994  val=0.066567
Pretrain [191/1000]  train=0.057713  val=0.066505
Pretrain [192/1000]  train=0.056926  val=0.066386
Pretrain [193/1000]  train=0.056991  val=0.066418
Pretrain [194/1000]  train=0.057833  val=0.066412
Pretrain [195/1000]  train=0.056712  val=0.066502
Pretrain [196/1000]  train=0.056617  val=0.066507
Pretrain [197/1000]  train=0.056452  val=0.066465
Pretrain [198/1000]  train=0.057601  val=0.066438
Pretrain [199/1000]  train=0.056356  val=0.066422
Pretrain [200/1000]  train=0.056573  val=0.066418
Pretrain [201/1000]  train=0.073458  val=0.079974
Pretrain [202/1000]  train=0.083390  val=0.077482
Pretrain [203/1000]  train=0.086811  val=0.079894
Pretrain [204/1000]  train=0.084212  val=0.076399
Pretrain [205/1000]  train=0.082982  val=0.082736
Pretrain [206/1000]  train=0.079531  val=0.083919
Pretrain [207/1000]  train=0.087261  val=0.079840
Pretrain [208/1000]  train=0.084268  val=0.083621
Pretrain [209/1000]  train=0.080939  val=0.083822
Pretrain [210/1000]  train=0.082213  val=0.079022
Pretrain [211/1000]  train=0.081804  val=0.085502
Pretrain [212/1000]  train=0.086430  val=0.082903
Pretrain [213/1000]  train=0.082548  val=0.080778
Pretrain [214/1000]  train=0.080681  val=0.086650
Pretrain [215/1000]  train=0.081639  val=0.082684
Pretrain [216/1000]  train=0.083764  val=0.077701
Pretrain [217/1000]  train=0.080057  val=0.080010
Pretrain [218/1000]  train=0.082025  val=0.079774
Pretrain [219/1000]  train=0.080830  val=0.079170
Pretrain [220/1000]  train=0.081533  val=0.083525
Pretrain [221/1000]  train=0.078474  val=0.082820
Pretrain [222/1000]  train=0.079340  val=0.079218
Pretrain [223/1000]  train=0.081065  val=0.085461
Pretrain [224/1000]  train=0.079364  val=0.080289
Pretrain [225/1000]  train=0.076916  val=0.079853
Pretrain [226/1000]  train=0.081131  val=0.085080
Pretrain [227/1000]  train=0.080283  val=0.078135
Pretrain [228/1000]  train=0.079647  val=0.081700
Pretrain [229/1000]  train=0.077668  val=0.079631
Pretrain [230/1000]  train=0.078475  val=0.079371
Pretrain [231/1000]  train=0.080322  val=0.086447
Pretrain [232/1000]  train=0.081381  val=0.077106
Pretrain [233/1000]  train=0.079593  val=0.081589
Pretrain [234/1000]  train=0.078319  val=0.078461
Pretrain [235/1000]  train=0.077691  val=0.084033
Pretrain [236/1000]  train=0.074135  val=0.080108
Pretrain [237/1000]  train=0.077582  val=0.081516
Pretrain [238/1000]  train=0.080854  val=0.084824
Pretrain [239/1000]  train=0.075895  val=0.083347
Pretrain [240/1000]  train=0.078031  val=0.080912
Pretrain [241/1000]  train=0.076592  val=0.078696
Pretrain [242/1000]  train=0.077790  val=0.081777
Pretrain [243/1000]  train=0.077987  val=0.082884
Pretrain [244/1000]  train=0.073632  val=0.078485
Pretrain [245/1000]  train=0.078298  val=0.078880
Pretrain [246/1000]  train=0.074349  val=0.079286
Pretrain [247/1000]  train=0.073333  val=0.078402
Pretrain [248/1000]  train=0.077410  val=0.077729
Pretrain [249/1000]  train=0.073183  val=0.080680
Pretrain [250/1000]  train=0.074985  val=0.075502
Pretrain [251/1000]  train=0.071904  val=0.075913
Pretrain [252/1000]  train=0.073584  val=0.078308
Pretrain [253/1000]  train=0.073281  val=0.077655
Pretrain [254/1000]  train=0.075209  val=0.084660
Pretrain [255/1000]  train=0.075741  val=0.077885
Pretrain [256/1000]  train=0.075925  val=0.076345
Pretrain [257/1000]  train=0.071869  val=0.076018
Pretrain [258/1000]  train=0.072434  val=0.079748
Pretrain [259/1000]  train=0.072195  val=0.075987
Pretrain [260/1000]  train=0.074037  val=0.079455
Pretrain [261/1000]  train=0.071072  val=0.073545
Pretrain [262/1000]  train=0.070109  val=0.079253
Pretrain [263/1000]  train=0.071172  val=0.076329
Pretrain [264/1000]  train=0.070797  val=0.079416
Pretrain [265/1000]  train=0.075068  val=0.075044
Pretrain [266/1000]  train=0.072204  val=0.081543
Pretrain [267/1000]  train=0.071105  val=0.081571
Pretrain [268/1000]  train=0.067127  val=0.072628
Pretrain [269/1000]  train=0.069045  val=0.077831
Pretrain [270/1000]  train=0.070614  val=0.075805
Pretrain [271/1000]  train=0.070990  val=0.075043
Pretrain [272/1000]  train=0.070653  val=0.083060
Pretrain [273/1000]  train=0.070511  val=0.073125
Pretrain [274/1000]  train=0.071139  val=0.079819
Pretrain [275/1000]  train=0.069964  val=0.070829
Pretrain [276/1000]  train=0.068318  val=0.076829
Pretrain [277/1000]  train=0.068214  val=0.073135
Pretrain [278/1000]  train=0.069914  val=0.074646
Pretrain [279/1000]  train=0.068806  val=0.077072
Pretrain [280/1000]  train=0.067413  val=0.073151
Pretrain [281/1000]  train=0.068246  val=0.069254
Pretrain [282/1000]  train=0.068215  val=0.074535
Pretrain [283/1000]  train=0.065860  val=0.075266
Pretrain [284/1000]  train=0.061646  val=0.074092
Pretrain [285/1000]  train=0.064112  val=0.075571
Pretrain [286/1000]  train=0.065248  val=0.072282
Pretrain [287/1000]  train=0.067071  val=0.073031
Pretrain [288/1000]  train=0.062637  val=0.069893
Pretrain [289/1000]  train=0.062596  val=0.073132
Pretrain [290/1000]  train=0.065490  val=0.073837
Pretrain [291/1000]  train=0.065235  val=0.072385
Pretrain [292/1000]  train=0.064264  val=0.078960
Pretrain [293/1000]  train=0.066023  val=0.073260
Pretrain [294/1000]  train=0.064569  val=0.076729
Pretrain [295/1000]  train=0.064676  val=0.076537
Pretrain [296/1000]  train=0.064388  val=0.072066
Pretrain [297/1000]  train=0.063831  val=0.075726
Pretrain [298/1000]  train=0.062402  val=0.076302
Pretrain [299/1000]  train=0.063398  val=0.074728
Pretrain [300/1000]  train=0.062098  val=0.075423
Pretrain [301/1000]  train=0.064936  val=0.071573
Pretrain [302/1000]  train=0.061600  val=0.076782
Pretrain [303/1000]  train=0.063117  val=0.072941
Pretrain [304/1000]  train=0.061812  val=0.071603
Pretrain [305/1000]  train=0.061690  val=0.071657
Pretrain [306/1000]  train=0.059810  val=0.072407
Pretrain [307/1000]  train=0.061124  val=0.069888
Pretrain [308/1000]  train=0.063191  val=0.077260
Pretrain [309/1000]  train=0.061565  val=0.073005
Pretrain [310/1000]  train=0.060388  val=0.073201
Pretrain [311/1000]  train=0.061430  val=0.074174
Pretrain [312/1000]  train=0.058974  val=0.071104
Pretrain [313/1000]  train=0.058740  val=0.074511
Pretrain [314/1000]  train=0.059913  val=0.073128
Pretrain [315/1000]  train=0.058806  val=0.071842
Pretrain [316/1000]  train=0.059867  val=0.069703
Pretrain [317/1000]  train=0.059679  val=0.070529
Pretrain [318/1000]  train=0.060433  val=0.071938
Pretrain [319/1000]  train=0.057066  val=0.068064
Pretrain [320/1000]  train=0.058227  val=0.073638
Pretrain [321/1000]  train=0.059318  val=0.072815
Pretrain [322/1000]  train=0.056754  val=0.069863
Pretrain [323/1000]  train=0.058842  val=0.069150
Pretrain [324/1000]  train=0.059584  val=0.070069
Pretrain [325/1000]  train=0.057588  val=0.067854
Pretrain [326/1000]  train=0.056034  val=0.070475
Pretrain [327/1000]  train=0.056646  val=0.068093
Pretrain [328/1000]  train=0.057227  val=0.068291
Pretrain [329/1000]  train=0.058890  val=0.072142
Pretrain [330/1000]  train=0.055916  val=0.069899
Pretrain [331/1000]  train=0.055611  val=0.071845
Pretrain [332/1000]  train=0.056742  val=0.070600
Pretrain [333/1000]  train=0.056227  val=0.073273
Pretrain [334/1000]  train=0.055847  val=0.070883
Pretrain [335/1000]  train=0.055778  val=0.069724
Pretrain [336/1000]  train=0.054709  val=0.067818
Pretrain [337/1000]  train=0.054271  val=0.069780
Pretrain [338/1000]  train=0.054696  val=0.069541
Pretrain [339/1000]  train=0.053046  val=0.069666
Pretrain [340/1000]  train=0.055028  val=0.068648
Pretrain [341/1000]  train=0.052884  val=0.067765
Pretrain [342/1000]  train=0.053883  val=0.069340
Pretrain [343/1000]  train=0.054578  val=0.070782
Pretrain [344/1000]  train=0.054159  val=0.069602
Pretrain [345/1000]  train=0.052318  val=0.066432
Pretrain [346/1000]  train=0.052809  val=0.069083
Pretrain [347/1000]  train=0.052742  val=0.067360
Pretrain [348/1000]  train=0.053943  val=0.067387
Pretrain [349/1000]  train=0.055230  val=0.067147
Pretrain [350/1000]  train=0.051788  val=0.067580
Pretrain [351/1000]  train=0.053719  val=0.066012
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [352/1000]  train=0.051916  val=0.066421
Pretrain [353/1000]  train=0.052169  val=0.065704
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [354/1000]  train=0.051952  val=0.065969
Pretrain [355/1000]  train=0.054745  val=0.067005
Pretrain [356/1000]  train=0.053115  val=0.066817
Pretrain [357/1000]  train=0.051193  val=0.066772
Pretrain [358/1000]  train=0.052135  val=0.069016
Pretrain [359/1000]  train=0.050438  val=0.067719
Pretrain [360/1000]  train=0.051162  val=0.067138
Pretrain [361/1000]  train=0.050612  val=0.067100
Pretrain [362/1000]  train=0.052834  val=0.066822
Pretrain [363/1000]  train=0.052257  val=0.066983
Pretrain [364/1000]  train=0.051502  val=0.066784
Pretrain [365/1000]  train=0.051515  val=0.066184
Pretrain [366/1000]  train=0.050449  val=0.065878
Pretrain [367/1000]  train=0.051750  val=0.064484
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [368/1000]  train=0.050539  val=0.065200
Pretrain [369/1000]  train=0.051626  val=0.065457
Pretrain [370/1000]  train=0.050241  val=0.064760
Pretrain [371/1000]  train=0.051805  val=0.063962
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/pretrained.pth
Pretrain [372/1000]  train=0.050561  val=0.064203
Pretrain [373/1000]  train=0.051146  val=0.065093
Pretrain [374/1000]  train=0.050263  val=0.064804
Pretrain [375/1000]  train=0.051321  val=0.064858
Pretrain [376/1000]  train=0.051118  val=0.065286
Pretrain [377/1000]  train=0.048732  val=0.066163
Pretrain [378/1000]  train=0.051167  val=0.066638
Pretrain [379/1000]  train=0.050027  val=0.065761
Pretrain [380/1000]  train=0.050781  val=0.065784
Pretrain [381/1000]  train=0.049776  val=0.065908
Pretrain [382/1000]  train=0.049629  val=0.066008
Pretrain [383/1000]  train=0.049842  val=0.066035
Pretrain [384/1000]  train=0.049588  val=0.066568
Pretrain [385/1000]  train=0.050086  val=0.066501
Pretrain [386/1000]  train=0.051384  val=0.065975
Pretrain [387/1000]  train=0.050971  val=0.066026
Pretrain [388/1000]  train=0.050702  val=0.066142
Pretrain [389/1000]  train=0.048206  val=0.066228
Pretrain [390/1000]  train=0.050959  val=0.066286
Pretrain [391/1000]  train=0.048453  val=0.066348
Pretrain [392/1000]  train=0.049860  val=0.066335
Pretrain [393/1000]  train=0.049831  val=0.066062
Pretrain [394/1000]  train=0.049414  val=0.065952
Pretrain [395/1000]  train=0.048442  val=0.065968
Pretrain [396/1000]  train=0.048917  val=0.065977
Pretrain [397/1000]  train=0.049330  val=0.065962
Pretrain [398/1000]  train=0.050499  val=0.065955
Pretrain [399/1000]  train=0.049664  val=0.065958
Pretrain [400/1000]  train=0.051001  val=0.065962
Pretrain [401/1000]  train=0.063473  val=0.082179
Pretrain [402/1000]  train=0.077833  val=0.086464
Pretrain [403/1000]  train=0.079507  val=0.088737
Pretrain [404/1000]  train=0.082082  val=0.089209
Pretrain [405/1000]  train=0.082817  val=0.087201
Pretrain [406/1000]  train=0.077292  val=0.083780
Pretrain [407/1000]  train=0.074594  val=0.083383
Pretrain [408/1000]  train=0.075829  val=0.085030
Pretrain [409/1000]  train=0.074034  val=0.080048
Pretrain [410/1000]  train=0.077858  val=0.079589
Pretrain [411/1000]  train=0.076776  val=0.078567
Pretrain [412/1000]  train=0.074977  val=0.078266
Pretrain [413/1000]  train=0.076266  val=0.078833
Pretrain [414/1000]  train=0.076171  val=0.080021
Pretrain [415/1000]  train=0.072541  val=0.079404
Pretrain [416/1000]  train=0.074233  val=0.082416
Pretrain [417/1000]  train=0.077993  val=0.084269
Pretrain [418/1000]  train=0.073670  val=0.085257
Pretrain [419/1000]  train=0.075911  val=0.085851
Pretrain [420/1000]  train=0.077157  val=0.087480
Pretrain [421/1000]  train=0.074636  val=0.080387
Pretrain [422/1000]  train=0.074223  val=0.082350
Pretrain [423/1000]  train=0.073238  val=0.080223
Pretrain [424/1000]  train=0.072786  val=0.081885
Pretrain [425/1000]  train=0.077957  val=0.078901
Pretrain [426/1000]  train=0.076880  val=0.076959
Pretrain [427/1000]  train=0.073819  val=0.079882
Pretrain [428/1000]  train=0.071743  val=0.083455
Pretrain [429/1000]  train=0.075312  val=0.078636
Pretrain [430/1000]  train=0.072955  val=0.077110
Pretrain [431/1000]  train=0.072643  val=0.078705
Pretrain [432/1000]  train=0.070166  val=0.082289
Pretrain [433/1000]  train=0.070351  val=0.082730
Pretrain [434/1000]  train=0.072228  val=0.076606
Pretrain [435/1000]  train=0.071517  val=0.080474
Pretrain [436/1000]  train=0.069809  val=0.077910
Pretrain [437/1000]  train=0.072755  val=0.079884
Pretrain [438/1000]  train=0.067918  val=0.079274
Pretrain [439/1000]  train=0.067172  val=0.074554
Pretrain [440/1000]  train=0.070977  val=0.078166
Pretrain [441/1000]  train=0.069784  val=0.079855
Pretrain [442/1000]  train=0.071288  val=0.076241
Pretrain [443/1000]  train=0.071129  val=0.077045
Pretrain [444/1000]  train=0.068354  val=0.080035
Pretrain [445/1000]  train=0.072857  val=0.082094
Pretrain [446/1000]  train=0.068122  val=0.077383
Pretrain [447/1000]  train=0.069347  val=0.077805
Pretrain [448/1000]  train=0.073128  val=0.079525
Pretrain [449/1000]  train=0.072445  val=0.076595
Pretrain [450/1000]  train=0.068827  val=0.076904
Pretrain [451/1000]  train=0.070162  val=0.083011
Pretrain [452/1000]  train=0.069306  val=0.078898
Pretrain [453/1000]  train=0.070107  val=0.075594
Pretrain [454/1000]  train=0.070486  val=0.077496
Pretrain [455/1000]  train=0.066439  val=0.078145
Pretrain [456/1000]  train=0.067650  val=0.076538
Pretrain [457/1000]  train=0.066268  val=0.077118
Pretrain [458/1000]  train=0.065888  val=0.080875
Pretrain [459/1000]  train=0.065218  val=0.078570
Pretrain [460/1000]  train=0.064999  val=0.084203
Pretrain [461/1000]  train=0.069130  val=0.078475
Pretrain [462/1000]  train=0.069057  val=0.077443
Pretrain [463/1000]  train=0.065323  val=0.074772
Pretrain [464/1000]  train=0.063945  val=0.076173
Pretrain [465/1000]  train=0.066020  val=0.074573
Pretrain [466/1000]  train=0.063674  val=0.077053
Pretrain [467/1000]  train=0.067870  val=0.079602
Pretrain [468/1000]  train=0.067655  val=0.076092
Pretrain [469/1000]  train=0.067274  val=0.079784
Pretrain [470/1000]  train=0.065037  val=0.076068
Pretrain [471/1000]  train=0.064322  val=0.078110
Pretrain [472/1000]  train=0.063792  val=0.075256
Pretrain [473/1000]  train=0.065620  val=0.075355
Pretrain [474/1000]  train=0.063320  val=0.077712
Pretrain [475/1000]  train=0.066529  val=0.076764
Pretrain [476/1000]  train=0.062809  val=0.076099
Pretrain [477/1000]  train=0.063467  val=0.076729
Pretrain [478/1000]  train=0.062646  val=0.075093
Pretrain [479/1000]  train=0.064500  val=0.078048
Pretrain [480/1000]  train=0.062446  val=0.076903
Pretrain [481/1000]  train=0.063139  val=0.076023
Pretrain [482/1000]  train=0.061429  val=0.077378
Pretrain [483/1000]  train=0.062705  val=0.077479
Pretrain [484/1000]  train=0.063012  val=0.081540
Pretrain [485/1000]  train=0.062665  val=0.076330
Pretrain [486/1000]  train=0.064587  val=0.079243
Pretrain [487/1000]  train=0.061909  val=0.075954
Pretrain [488/1000]  train=0.060726  val=0.077162
Pretrain [489/1000]  train=0.060327  val=0.075820
Pretrain [490/1000]  train=0.059598  val=0.076091
Pretrain [491/1000]  train=0.060592  val=0.075819
Pretrain [492/1000]  train=0.058491  val=0.075104
Pretrain [493/1000]  train=0.060307  val=0.074921
Pretrain [494/1000]  train=0.060196  val=0.073962
Pretrain [495/1000]  train=0.060045  val=0.073917
Pretrain [496/1000]  train=0.057458  val=0.075963
Pretrain [497/1000]  train=0.058544  val=0.072166
Pretrain [498/1000]  train=0.057078  val=0.078017
Pretrain [499/1000]  train=0.058115  val=0.075112
Pretrain [500/1000]  train=0.059064  val=0.076333
Pretrain [501/1000]  train=0.060859  val=0.076892
Pretrain [502/1000]  train=0.059919  val=0.076000
Pretrain [503/1000]  train=0.058624  val=0.075423
Pretrain [504/1000]  train=0.058792  val=0.075570
Pretrain [505/1000]  train=0.058436  val=0.073959
Pretrain [506/1000]  train=0.059327  val=0.078084
Pretrain [507/1000]  train=0.057244  val=0.075933
Pretrain [508/1000]  train=0.057792  val=0.076586
Pretrain [509/1000]  train=0.055369  val=0.073841
Pretrain [510/1000]  train=0.056102  val=0.075411
Pretrain [511/1000]  train=0.055871  val=0.073546
Pretrain [512/1000]  train=0.056216  val=0.074927
Pretrain [513/1000]  train=0.053939  val=0.072408
Pretrain [514/1000]  train=0.055065  val=0.072047
Pretrain [515/1000]  train=0.055916  val=0.076451
Pretrain [516/1000]  train=0.054231  val=0.073829
Pretrain [517/1000]  train=0.055187  val=0.072736
Pretrain [518/1000]  train=0.054352  val=0.071877
Pretrain [519/1000]  train=0.056040  val=0.074144
Pretrain [520/1000]  train=0.055891  val=0.073027
Pretrain [521/1000]  train=0.054676  val=0.071303
Pretrain [522/1000]  train=0.056130  val=0.072302
Pretrain [523/1000]  train=0.054637  val=0.069677
Pretrain [524/1000]  train=0.054958  val=0.072422
Pretrain [525/1000]  train=0.054208  val=0.071302
Pretrain [526/1000]  train=0.053910  val=0.070137
Pretrain [527/1000]  train=0.052907  val=0.070960
Pretrain [528/1000]  train=0.051785  val=0.071984
Pretrain [529/1000]  train=0.053525  val=0.072367
Pretrain [530/1000]  train=0.051081  val=0.072607
Pretrain [531/1000]  train=0.053631  val=0.070246
Pretrain [532/1000]  train=0.052694  val=0.072808
Pretrain [533/1000]  train=0.052831  val=0.072503
Pretrain [534/1000]  train=0.053727  val=0.072073
Pretrain [535/1000]  train=0.052368  val=0.072495
Pretrain [536/1000]  train=0.051614  val=0.071815
Pretrain [537/1000]  train=0.051322  val=0.072861
Pretrain [538/1000]  train=0.050041  val=0.072628
Pretrain [539/1000]  train=0.051415  val=0.072911
Pretrain [540/1000]  train=0.050897  val=0.070419
Pretrain [541/1000]  train=0.048004  val=0.071201
Pretrain [542/1000]  train=0.051619  val=0.072485
Pretrain [543/1000]  train=0.050793  val=0.071908
Pretrain [544/1000]  train=0.049938  val=0.069568
Pretrain [545/1000]  train=0.050064  val=0.067871
Pretrain [546/1000]  train=0.052966  val=0.069494
Pretrain [547/1000]  train=0.050664  val=0.071435
Pretrain [548/1000]  train=0.050361  val=0.071992
Pretrain [549/1000]  train=0.049043  val=0.071156
Pretrain [550/1000]  train=0.052188  val=0.071226
Pretrain [551/1000]  train=0.049500  val=0.071662
Pretrain [552/1000]  train=0.051631  val=0.071104
Pretrain [553/1000]  train=0.049609  val=0.072264
Pretrain [554/1000]  train=0.047267  val=0.072392
Pretrain [555/1000]  train=0.049085  val=0.072799
Pretrain [556/1000]  train=0.050306  val=0.072894
Pretrain [557/1000]  train=0.048866  val=0.071786
Pretrain [558/1000]  train=0.049973  val=0.072798
Pretrain [559/1000]  train=0.050949  val=0.072902
Pretrain [560/1000]  train=0.050563  val=0.071658
Pretrain [561/1000]  train=0.047105  val=0.071608
Pretrain [562/1000]  train=0.048060  val=0.071680
Pretrain [563/1000]  train=0.048364  val=0.071281
Pretrain [564/1000]  train=0.048715  val=0.071299
Pretrain [565/1000]  train=0.047778  val=0.070993
Pretrain [566/1000]  train=0.048153  val=0.070487
Pretrain [567/1000]  train=0.048714  val=0.069956
Pretrain [568/1000]  train=0.048262  val=0.070586
Pretrain [569/1000]  train=0.047917  val=0.070067
Pretrain [570/1000]  train=0.047572  val=0.070198
Pretrain [571/1000]  train=0.048679  val=0.070407
  -> 验证未改进 200 次，早停。
[PRETRAIN] 最佳 val=0.063962 已保存。

--- [阶段二] 对齐微调 (NLL + α·(1−R2) + λ·CORAL) ---
Fine-tune [1/100000]  val_loss=0.287294
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [2/100000]  val_loss=0.179208
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [3/100000]  val_loss=0.082824
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [4/100000]  val_loss=-0.007420
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [5/100000]  val_loss=-0.092215
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [6/100000]  val_loss=-0.169098
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [7/100000]  val_loss=-0.233671
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [8/100000]  val_loss=-0.294001
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [9/100000]  val_loss=-0.333542
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [10/100000]  val_loss=-0.383576
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [11/100000]  val_loss=-0.423883
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [12/100000]  val_loss=-0.467313
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [13/100000]  val_loss=-0.491938
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [14/100000]  val_loss=-0.513596
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [15/100000]  val_loss=-0.547222
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [16/100000]  val_loss=-0.570670
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [17/100000]  val_loss=-0.582784
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [18/100000]  val_loss=-0.614726
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [19/100000]  val_loss=-0.630931
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [20/100000]  val_loss=-0.636643
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [21/100000]  val_loss=-0.653682
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [22/100000]  val_loss=-0.661399
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [23/100000]  val_loss=-0.677820
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [24/100000]  val_loss=-0.702470
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [25/100000]  val_loss=-0.702425
Fine-tune [26/100000]  val_loss=-0.718574
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [27/100000]  val_loss=-0.736758
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [28/100000]  val_loss=-0.733798
Fine-tune [29/100000]  val_loss=-0.730519
Fine-tune [30/100000]  val_loss=-0.734159
Fine-tune [31/100000]  val_loss=-0.746711
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [32/100000]  val_loss=-0.764887
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [33/100000]  val_loss=-0.775007
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [34/100000]  val_loss=-0.769313
Fine-tune [35/100000]  val_loss=-0.768114
Fine-tune [36/100000]  val_loss=-0.771630
Fine-tune [37/100000]  val_loss=-0.789699
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [38/100000]  val_loss=-0.789596
Fine-tune [39/100000]  val_loss=-0.795168
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [40/100000]  val_loss=-0.782014
Fine-tune [41/100000]  val_loss=-0.792386
Fine-tune [42/100000]  val_loss=-0.799365
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [43/100000]  val_loss=-0.800836
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [44/100000]  val_loss=-0.798949
Fine-tune [45/100000]  val_loss=-0.815211
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [46/100000]  val_loss=-0.803440
Fine-tune [47/100000]  val_loss=-0.814397
Fine-tune [48/100000]  val_loss=-0.826333
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [49/100000]  val_loss=-0.827587
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [50/100000]  val_loss=-0.823179
Fine-tune [51/100000]  val_loss=-0.828404
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [52/100000]  val_loss=-0.848258
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [53/100000]  val_loss=-0.835516
Fine-tune [54/100000]  val_loss=-0.836842
Fine-tune [55/100000]  val_loss=-0.847398
Fine-tune [56/100000]  val_loss=-0.853974
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [57/100000]  val_loss=-0.852856
Fine-tune [58/100000]  val_loss=-0.852728
Fine-tune [59/100000]  val_loss=-0.853433
Fine-tune [60/100000]  val_loss=-0.851137
Fine-tune [61/100000]  val_loss=-0.847904
Fine-tune [62/100000]  val_loss=-0.857140
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [63/100000]  val_loss=-0.852323
Fine-tune [64/100000]  val_loss=-0.868266
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [65/100000]  val_loss=-0.851699
Fine-tune [66/100000]  val_loss=-0.863906
Fine-tune [67/100000]  val_loss=-0.864903
Fine-tune [68/100000]  val_loss=-0.881787
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [69/100000]  val_loss=-0.885260
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [70/100000]  val_loss=-0.876723
Fine-tune [71/100000]  val_loss=-0.876052
Fine-tune [72/100000]  val_loss=-0.874876
Fine-tune [73/100000]  val_loss=-0.872252
Fine-tune [74/100000]  val_loss=-0.877725
Fine-tune [75/100000]  val_loss=-0.891731
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [76/100000]  val_loss=-0.884892
Fine-tune [77/100000]  val_loss=-0.892898
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [78/100000]  val_loss=-0.888484
Fine-tune [79/100000]  val_loss=-0.881965
Fine-tune [80/100000]  val_loss=-0.892835
Fine-tune [81/100000]  val_loss=-0.891275
Fine-tune [82/100000]  val_loss=-0.891144
Fine-tune [83/100000]  val_loss=-0.895918
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [84/100000]  val_loss=-0.893835
Fine-tune [85/100000]  val_loss=-0.890955
Fine-tune [86/100000]  val_loss=-0.891053
Fine-tune [87/100000]  val_loss=-0.898038
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [88/100000]  val_loss=-0.899788
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [89/100000]  val_loss=-0.895360
Fine-tune [90/100000]  val_loss=-0.902994
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [91/100000]  val_loss=-0.912208
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [92/100000]  val_loss=-0.912882
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [93/100000]  val_loss=-0.920931
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [94/100000]  val_loss=-0.910735
Fine-tune [95/100000]  val_loss=-0.919341
Fine-tune [96/100000]  val_loss=-0.900106
Fine-tune [97/100000]  val_loss=-0.902230
Fine-tune [98/100000]  val_loss=-0.920654
Fine-tune [99/100000]  val_loss=-0.908418
Fine-tune [100/100000]  val_loss=-0.913191
Fine-tune [101/100000]  val_loss=-0.904401
Fine-tune [102/100000]  val_loss=-0.919450
Fine-tune [103/100000]  val_loss=-0.916039
Fine-tune [104/100000]  val_loss=-0.902815
Fine-tune [105/100000]  val_loss=-0.913165
Fine-tune [106/100000]  val_loss=-0.928363
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [107/100000]  val_loss=-0.908669
Fine-tune [108/100000]  val_loss=-0.926479
Fine-tune [109/100000]  val_loss=-0.924969
Fine-tune [110/100000]  val_loss=-0.920994
Fine-tune [111/100000]  val_loss=-0.908673
Fine-tune [112/100000]  val_loss=-0.918908
Fine-tune [113/100000]  val_loss=-0.929325
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [114/100000]  val_loss=-0.917630
Fine-tune [115/100000]  val_loss=-0.914407
Fine-tune [116/100000]  val_loss=-0.921220
Fine-tune [117/100000]  val_loss=-0.936053
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [118/100000]  val_loss=-0.935666
Fine-tune [119/100000]  val_loss=-0.941319
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [120/100000]  val_loss=-0.929902
Fine-tune [121/100000]  val_loss=-0.937116
Fine-tune [122/100000]  val_loss=-0.939209
Fine-tune [123/100000]  val_loss=-0.926166
Fine-tune [124/100000]  val_loss=-0.941433
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [125/100000]  val_loss=-0.941381
Fine-tune [126/100000]  val_loss=-0.936253
Fine-tune [127/100000]  val_loss=-0.929211
Fine-tune [128/100000]  val_loss=-0.930157
Fine-tune [129/100000]  val_loss=-0.942992
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [130/100000]  val_loss=-0.947652
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [131/100000]  val_loss=-0.960035
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [132/100000]  val_loss=-0.943324
Fine-tune [133/100000]  val_loss=-0.952365
Fine-tune [134/100000]  val_loss=-0.946233
Fine-tune [135/100000]  val_loss=-0.944743
Fine-tune [136/100000]  val_loss=-0.944120
Fine-tune [137/100000]  val_loss=-0.940207
Fine-tune [138/100000]  val_loss=-0.941163
Fine-tune [139/100000]  val_loss=-0.934089
Fine-tune [140/100000]  val_loss=-0.940843
Fine-tune [141/100000]  val_loss=-0.947240
Fine-tune [142/100000]  val_loss=-0.951361
Fine-tune [143/100000]  val_loss=-0.943007
Fine-tune [144/100000]  val_loss=-0.946939
Fine-tune [145/100000]  val_loss=-0.945107
Fine-tune [146/100000]  val_loss=-0.944921
Fine-tune [147/100000]  val_loss=-0.926798
Fine-tune [148/100000]  val_loss=-0.937039
Fine-tune [149/100000]  val_loss=-0.955903
Fine-tune [150/100000]  val_loss=-0.957810
Fine-tune [151/100000]  val_loss=-0.963218
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [152/100000]  val_loss=-0.954109
Fine-tune [153/100000]  val_loss=-0.955153
Fine-tune [154/100000]  val_loss=-0.963451
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [155/100000]  val_loss=-0.951080
Fine-tune [156/100000]  val_loss=-0.960148
Fine-tune [157/100000]  val_loss=-0.952671
Fine-tune [158/100000]  val_loss=-0.958790
Fine-tune [159/100000]  val_loss=-0.955804
Fine-tune [160/100000]  val_loss=-0.952022
Fine-tune [161/100000]  val_loss=-0.950575
Fine-tune [162/100000]  val_loss=-0.946809
Fine-tune [163/100000]  val_loss=-0.951721
Fine-tune [164/100000]  val_loss=-0.964038
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [165/100000]  val_loss=-0.955930
Fine-tune [166/100000]  val_loss=-0.963981
Fine-tune [167/100000]  val_loss=-0.957028
Fine-tune [168/100000]  val_loss=-0.967661
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [169/100000]  val_loss=-0.953973
Fine-tune [170/100000]  val_loss=-0.964090
Fine-tune [171/100000]  val_loss=-0.966192
Fine-tune [172/100000]  val_loss=-0.973828
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [173/100000]  val_loss=-0.963625
Fine-tune [174/100000]  val_loss=-0.966796
Fine-tune [175/100000]  val_loss=-0.958072
Fine-tune [176/100000]  val_loss=-0.951860
Fine-tune [177/100000]  val_loss=-0.950616
Fine-tune [178/100000]  val_loss=-0.952790
Fine-tune [179/100000]  val_loss=-0.953418
Fine-tune [180/100000]  val_loss=-0.946274
Fine-tune [181/100000]  val_loss=-0.957369
Fine-tune [182/100000]  val_loss=-0.957425
Fine-tune [183/100000]  val_loss=-0.968092
Fine-tune [184/100000]  val_loss=-0.954551
Fine-tune [185/100000]  val_loss=-0.953934
Fine-tune [186/100000]  val_loss=-0.976299
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [187/100000]  val_loss=-0.964768
Fine-tune [188/100000]  val_loss=-0.953272
Fine-tune [189/100000]  val_loss=-0.966042
Fine-tune [190/100000]  val_loss=-0.973086
Fine-tune [191/100000]  val_loss=-0.977047
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [192/100000]  val_loss=-0.970984
Fine-tune [193/100000]  val_loss=-0.983414
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [194/100000]  val_loss=-0.980870
Fine-tune [195/100000]  val_loss=-0.974421
Fine-tune [196/100000]  val_loss=-0.966966
Fine-tune [197/100000]  val_loss=-0.985078
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [198/100000]  val_loss=-0.981224
Fine-tune [199/100000]  val_loss=-0.948599
Fine-tune [200/100000]  val_loss=-0.970984
Fine-tune [201/100000]  val_loss=-0.982942
Fine-tune [202/100000]  val_loss=-0.973177
Fine-tune [203/100000]  val_loss=-0.966042
Fine-tune [204/100000]  val_loss=-0.959787
Fine-tune [205/100000]  val_loss=-0.986565
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [206/100000]  val_loss=-0.974902
Fine-tune [207/100000]  val_loss=-0.972275
Fine-tune [208/100000]  val_loss=-0.973474
Fine-tune [209/100000]  val_loss=-0.975497
Fine-tune [210/100000]  val_loss=-0.965347
Fine-tune [211/100000]  val_loss=-0.982252
Fine-tune [212/100000]  val_loss=-0.979153
Fine-tune [213/100000]  val_loss=-0.986309
Fine-tune [214/100000]  val_loss=-0.981198
Fine-tune [215/100000]  val_loss=-0.971487
Fine-tune [216/100000]  val_loss=-0.981430
Fine-tune [217/100000]  val_loss=-0.975750
Fine-tune [218/100000]  val_loss=-0.987987
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [219/100000]  val_loss=-0.981985
Fine-tune [220/100000]  val_loss=-0.978901
Fine-tune [221/100000]  val_loss=-0.973371
Fine-tune [222/100000]  val_loss=-0.978401
Fine-tune [223/100000]  val_loss=-0.976071
Fine-tune [224/100000]  val_loss=-0.984221
Fine-tune [225/100000]  val_loss=-0.981391
Fine-tune [226/100000]  val_loss=-0.978475
Fine-tune [227/100000]  val_loss=-0.980100
Fine-tune [228/100000]  val_loss=-0.981406
Fine-tune [229/100000]  val_loss=-0.983743
Fine-tune [230/100000]  val_loss=-0.982445
Fine-tune [231/100000]  val_loss=-0.981002
Fine-tune [232/100000]  val_loss=-0.976351
Fine-tune [233/100000]  val_loss=-0.980493
Fine-tune [234/100000]  val_loss=-0.981807
Fine-tune [235/100000]  val_loss=-0.994465
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [236/100000]  val_loss=-1.000288
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [237/100000]  val_loss=-0.978745
Fine-tune [238/100000]  val_loss=-0.978747
Fine-tune [239/100000]  val_loss=-0.985092
Fine-tune [240/100000]  val_loss=-0.977720
Fine-tune [241/100000]  val_loss=-0.990953
Fine-tune [242/100000]  val_loss=-0.982113
Fine-tune [243/100000]  val_loss=-0.981315
Fine-tune [244/100000]  val_loss=-0.979832
Fine-tune [245/100000]  val_loss=-0.987887
Fine-tune [246/100000]  val_loss=-0.994136
Fine-tune [247/100000]  val_loss=-0.970403
Fine-tune [248/100000]  val_loss=-0.975732
Fine-tune [249/100000]  val_loss=-0.985901
Fine-tune [250/100000]  val_loss=-0.981904
Fine-tune [251/100000]  val_loss=-0.974676
Fine-tune [252/100000]  val_loss=-0.991629
Fine-tune [253/100000]  val_loss=-0.990096
Fine-tune [254/100000]  val_loss=-0.989960
Fine-tune [255/100000]  val_loss=-0.976222
Fine-tune [256/100000]  val_loss=-0.976719
Fine-tune [257/100000]  val_loss=-0.972589
Fine-tune [258/100000]  val_loss=-0.981755
Fine-tune [259/100000]  val_loss=-0.970773
Fine-tune [260/100000]  val_loss=-0.976407
Fine-tune [261/100000]  val_loss=-0.982001
Fine-tune [262/100000]  val_loss=-0.983050
Fine-tune [263/100000]  val_loss=-0.961566
Fine-tune [264/100000]  val_loss=-0.980211
Fine-tune [265/100000]  val_loss=-0.992300
Fine-tune [266/100000]  val_loss=-0.982316
Fine-tune [267/100000]  val_loss=-0.982064
Fine-tune [268/100000]  val_loss=-0.977658
Fine-tune [269/100000]  val_loss=-0.989136
Fine-tune [270/100000]  val_loss=-0.991011
Fine-tune [271/100000]  val_loss=-0.989280
Fine-tune [272/100000]  val_loss=-0.995128
Fine-tune [273/100000]  val_loss=-0.973320
Fine-tune [274/100000]  val_loss=-0.973733
Fine-tune [275/100000]  val_loss=-0.987497
Fine-tune [276/100000]  val_loss=-0.975022
Fine-tune [277/100000]  val_loss=-0.982899
Fine-tune [278/100000]  val_loss=-0.993731
Fine-tune [279/100000]  val_loss=-0.987750
Fine-tune [280/100000]  val_loss=-0.994220
Fine-tune [281/100000]  val_loss=-0.989376
Fine-tune [282/100000]  val_loss=-0.992335
Fine-tune [283/100000]  val_loss=-0.983611
Fine-tune [284/100000]  val_loss=-0.996513
Fine-tune [285/100000]  val_loss=-0.999292
Fine-tune [286/100000]  val_loss=-0.985225
Fine-tune [287/100000]  val_loss=-0.974440
Fine-tune [288/100000]  val_loss=-0.994079
Fine-tune [289/100000]  val_loss=-0.998618
Fine-tune [290/100000]  val_loss=-0.997425
Fine-tune [291/100000]  val_loss=-0.991979
Fine-tune [292/100000]  val_loss=-0.992304
Fine-tune [293/100000]  val_loss=-0.998916
Fine-tune [294/100000]  val_loss=-0.985336
Fine-tune [295/100000]  val_loss=-0.984821
Fine-tune [296/100000]  val_loss=-0.985298
Fine-tune [297/100000]  val_loss=-0.983596
Fine-tune [298/100000]  val_loss=-0.983523
Fine-tune [299/100000]  val_loss=-0.989374
Fine-tune [300/100000]  val_loss=-0.992948
Fine-tune [301/100000]  val_loss=-0.989193
Fine-tune [302/100000]  val_loss=-0.977326
Fine-tune [303/100000]  val_loss=-0.982360
Fine-tune [304/100000]  val_loss=-0.977496
Fine-tune [305/100000]  val_loss=-0.998620
Fine-tune [306/100000]  val_loss=-0.968240
Fine-tune [307/100000]  val_loss=-0.982948
Fine-tune [308/100000]  val_loss=-0.967718
Fine-tune [309/100000]  val_loss=-0.985943
Fine-tune [310/100000]  val_loss=-0.976606
Fine-tune [311/100000]  val_loss=-0.965175
Fine-tune [312/100000]  val_loss=-0.975348
Fine-tune [313/100000]  val_loss=-0.992739
Fine-tune [314/100000]  val_loss=-0.996357
Fine-tune [315/100000]  val_loss=-0.993548
Fine-tune [316/100000]  val_loss=-1.001157
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [317/100000]  val_loss=-0.981621
Fine-tune [318/100000]  val_loss=-0.965584
Fine-tune [319/100000]  val_loss=-0.970625
Fine-tune [320/100000]  val_loss=-0.970588
Fine-tune [321/100000]  val_loss=-0.972779
Fine-tune [322/100000]  val_loss=-0.979608
Fine-tune [323/100000]  val_loss=-0.961444
Fine-tune [324/100000]  val_loss=-0.979975
Fine-tune [325/100000]  val_loss=-0.975089
Fine-tune [326/100000]  val_loss=-0.981987
Fine-tune [327/100000]  val_loss=-0.995014
Fine-tune [328/100000]  val_loss=-0.989868
Fine-tune [329/100000]  val_loss=-0.970214
Fine-tune [330/100000]  val_loss=-0.981740
Fine-tune [331/100000]  val_loss=-0.979601
Fine-tune [332/100000]  val_loss=-0.981776
Fine-tune [333/100000]  val_loss=-0.987280
Fine-tune [334/100000]  val_loss=-0.977441
Fine-tune [335/100000]  val_loss=-0.977856
Fine-tune [336/100000]  val_loss=-0.968347
Fine-tune [337/100000]  val_loss=-0.974031
Fine-tune [338/100000]  val_loss=-0.966244
Fine-tune [339/100000]  val_loss=-0.956967
Fine-tune [340/100000]  val_loss=-0.966160
Fine-tune [341/100000]  val_loss=-0.969574
Fine-tune [342/100000]  val_loss=-0.981675
Fine-tune [343/100000]  val_loss=-0.976979
Fine-tune [344/100000]  val_loss=-0.973531
Fine-tune [345/100000]  val_loss=-0.969967
Fine-tune [346/100000]  val_loss=-0.983091
Fine-tune [347/100000]  val_loss=-0.992444
Fine-tune [348/100000]  val_loss=-0.994352
Fine-tune [349/100000]  val_loss=-0.979607
Fine-tune [350/100000]  val_loss=-0.972387
Fine-tune [351/100000]  val_loss=-0.973136
Fine-tune [352/100000]  val_loss=-0.990159
Fine-tune [353/100000]  val_loss=-0.993782
Fine-tune [354/100000]  val_loss=-0.989264
Fine-tune [355/100000]  val_loss=-0.979915
Fine-tune [356/100000]  val_loss=-0.988759
Fine-tune [357/100000]  val_loss=-0.983467
Fine-tune [358/100000]  val_loss=-0.976254
Fine-tune [359/100000]  val_loss=-0.974178
Fine-tune [360/100000]  val_loss=-0.965264
Fine-tune [361/100000]  val_loss=-0.959390
Fine-tune [362/100000]  val_loss=-0.977648
Fine-tune [363/100000]  val_loss=-0.973677
Fine-tune [364/100000]  val_loss=-0.977511
Fine-tune [365/100000]  val_loss=-0.970434
Fine-tune [366/100000]  val_loss=-0.970715
Fine-tune [367/100000]  val_loss=-0.971111
Fine-tune [368/100000]  val_loss=-0.982967
Fine-tune [369/100000]  val_loss=-0.970015
Fine-tune [370/100000]  val_loss=-0.983926
Fine-tune [371/100000]  val_loss=-0.971752
Fine-tune [372/100000]  val_loss=-0.979064
Fine-tune [373/100000]  val_loss=-0.967551
Fine-tune [374/100000]  val_loss=-0.967561
Fine-tune [375/100000]  val_loss=-0.981604
Fine-tune [376/100000]  val_loss=-0.978856
Fine-tune [377/100000]  val_loss=-0.971413
Fine-tune [378/100000]  val_loss=-0.965412
Fine-tune [379/100000]  val_loss=-0.976328
Fine-tune [380/100000]  val_loss=-0.977979
Fine-tune [381/100000]  val_loss=-0.979973
Fine-tune [382/100000]  val_loss=-0.969007
Fine-tune [383/100000]  val_loss=-0.980036
Fine-tune [384/100000]  val_loss=-0.988206
Fine-tune [385/100000]  val_loss=-0.989068
Fine-tune [386/100000]  val_loss=-0.987536
Fine-tune [387/100000]  val_loss=-0.981191
Fine-tune [388/100000]  val_loss=-0.979073
Fine-tune [389/100000]  val_loss=-0.978907
Fine-tune [390/100000]  val_loss=-0.988878
Fine-tune [391/100000]  val_loss=-0.978565
Fine-tune [392/100000]  val_loss=-0.980306
Fine-tune [393/100000]  val_loss=-0.995207
Fine-tune [394/100000]  val_loss=-0.992591
Fine-tune [395/100000]  val_loss=-0.986882
Fine-tune [396/100000]  val_loss=-1.000169
Fine-tune [397/100000]  val_loss=-0.989100
Fine-tune [398/100000]  val_loss=-0.996691
Fine-tune [399/100000]  val_loss=-0.996068
Fine-tune [400/100000]  val_loss=-0.979120
Fine-tune [401/100000]  val_loss=-0.986373
Fine-tune [402/100000]  val_loss=-0.984433
Fine-tune [403/100000]  val_loss=-0.993296
Fine-tune [404/100000]  val_loss=-1.008241
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD128_L4/finetuned.pth
Fine-tune [405/100000]  val_loss=-0.996480
Fine-tune [406/100000]  val_loss=-0.995520
Fine-tune [407/100000]  val_loss=-0.992926
Fine-tune [408/100000]  val_loss=-0.981834
Fine-tune [409/100000]  val_loss=-0.990313
Fine-tune [410/100000]  val_loss=-1.005984
Fine-tune [411/100000]  val_loss=-0.999413
Fine-tune [412/100000]  val_loss=-0.978979
Fine-tune [413/100000]  val_loss=-0.993059
Fine-tune [414/100000]  val_loss=-1.007277
Fine-tune [415/100000]  val_loss=-1.000366
Fine-tune [416/100000]  val_loss=-0.998728
Fine-tune [417/100000]  val_loss=-0.976550
Fine-tune [418/100000]  val_loss=-0.990385
Fine-tune [419/100000]  val_loss=-0.985074
Fine-tune [420/100000]  val_loss=-0.976598
Fine-tune [421/100000]  val_loss=-0.992703
Fine-tune [422/100000]  val_loss=-0.997912
Fine-tune [423/100000]  val_loss=-0.979076
Fine-tune [424/100000]  val_loss=-0.976313
Fine-tune [425/100000]  val_loss=-0.959157
Fine-tune [426/100000]  val_loss=-0.962825
Fine-tune [427/100000]  val_loss=-0.981878
Fine-tune [428/100000]  val_loss=-0.972475
Fine-tune [429/100000]  val_loss=-0.975934
Fine-tune [430/100000]  val_loss=-0.980174
Fine-tune [431/100000]  val_loss=-0.979224
Fine-tune [432/100000]  val_loss=-0.979012
Fine-tune [433/100000]  val_loss=-0.991716
Fine-tune [434/100000]  val_loss=-0.973714
Fine-tune [435/100000]  val_loss=-0.959786
Fine-tune [436/100000]  val_loss=-0.970497
Fine-tune [437/100000]  val_loss=-0.970599
Fine-tune [438/100000]  val_loss=-0.968158
Fine-tune [439/100000]  val_loss=-0.952782
Fine-tune [440/100000]  val_loss=-0.953582
Fine-tune [441/100000]  val_loss=-0.974510
Fine-tune [442/100000]  val_loss=-0.958571
Fine-tune [443/100000]  val_loss=-0.968703
Fine-tune [444/100000]  val_loss=-0.982159
Fine-tune [445/100000]  val_loss=-0.976816
Fine-tune [446/100000]  val_loss=-0.963992
Fine-tune [447/100000]  val_loss=-0.974929
Fine-tune [448/100000]  val_loss=-0.971451
Fine-tune [449/100000]  val_loss=-0.979618
Fine-tune [450/100000]  val_loss=-0.981789
Fine-tune [451/100000]  val_loss=-0.980261
Fine-tune [452/100000]  val_loss=-0.981523
Fine-tune [453/100000]  val_loss=-0.971237
Fine-tune [454/100000]  val_loss=-0.971719
Fine-tune [455/100000]  val_loss=-0.976148
Fine-tune [456/100000]  val_loss=-0.977576
Fine-tune [457/100000]  val_loss=-0.976092
Fine-tune [458/100000]  val_loss=-0.971874
Fine-tune [459/100000]  val_loss=-0.983558
Fine-tune [460/100000]  val_loss=-1.000466
Fine-tune [461/100000]  val_loss=-0.988896
Fine-tune [462/100000]  val_loss=-0.982960
Fine-tune [463/100000]  val_loss=-0.978314
Fine-tune [464/100000]  val_loss=-0.986979
Fine-tune [465/100000]  val_loss=-0.972210
Fine-tune [466/100000]  val_loss=-0.974745
Fine-tune [467/100000]  val_loss=-0.956873
Fine-tune [468/100000]  val_loss=-0.967434
Fine-tune [469/100000]  val_loss=-0.967704
Fine-tune [470/100000]  val_loss=-0.963935
Fine-tune [471/100000]  val_loss=-0.994512
Fine-tune [472/100000]  val_loss=-0.980331
Fine-tune [473/100000]  val_loss=-0.980784
Fine-tune [474/100000]  val_loss=-0.988606
Fine-tune [475/100000]  val_loss=-0.970620
Fine-tune [476/100000]  val_loss=-0.981909
Fine-tune [477/100000]  val_loss=-0.963732
Fine-tune [478/100000]  val_loss=-0.958931
Fine-tune [479/100000]  val_loss=-0.961205
Fine-tune [480/100000]  val_loss=-0.977799
Fine-tune [481/100000]  val_loss=-0.972813
Fine-tune [482/100000]  val_loss=-0.970268
Fine-tune [483/100000]  val_loss=-0.972348
Fine-tune [484/100000]  val_loss=-0.975228
Fine-tune [485/100000]  val_loss=-0.975767
Fine-tune [486/100000]  val_loss=-0.966199
Fine-tune [487/100000]  val_loss=-0.956140
Fine-tune [488/100000]  val_loss=-0.966179
Fine-tune [489/100000]  val_loss=-0.957901
Fine-tune [490/100000]  val_loss=-0.968696
Fine-tune [491/100000]  val_loss=-0.947929
Fine-tune [492/100000]  val_loss=-0.973658
Fine-tune [493/100000]  val_loss=-0.979119
Fine-tune [494/100000]  val_loss=-0.963304
Fine-tune [495/100000]  val_loss=-0.945196
Fine-tune [496/100000]  val_loss=-0.946478
Fine-tune [497/100000]  val_loss=-0.949831
Fine-tune [498/100000]  val_loss=-0.960628
Fine-tune [499/100000]  val_loss=-0.965875
Fine-tune [500/100000]  val_loss=-0.960686
Fine-tune [501/100000]  val_loss=-0.967080
Fine-tune [502/100000]  val_loss=-0.989249
Fine-tune [503/100000]  val_loss=-0.967121
Fine-tune [504/100000]  val_loss=-0.968184
Fine-tune [505/100000]  val_loss=-0.964365
Fine-tune [506/100000]  val_loss=-0.955491
Fine-tune [507/100000]  val_loss=-0.960584
Fine-tune [508/100000]  val_loss=-0.960109
Fine-tune [509/100000]  val_loss=-0.980032
Fine-tune [510/100000]  val_loss=-0.977293
Fine-tune [511/100000]  val_loss=-0.981797
Fine-tune [512/100000]  val_loss=-0.975404
Fine-tune [513/100000]  val_loss=-0.966282
Fine-tune [514/100000]  val_loss=-0.964483
Fine-tune [515/100000]  val_loss=-0.959835
Fine-tune [516/100000]  val_loss=-0.980256
Fine-tune [517/100000]  val_loss=-0.984198
Fine-tune [518/100000]  val_loss=-0.981093
Fine-tune [519/100000]  val_loss=-0.962022
Fine-tune [520/100000]  val_loss=-0.982467
Fine-tune [521/100000]  val_loss=-0.989767
Fine-tune [522/100000]  val_loss=-0.973470
Fine-tune [523/100000]  val_loss=-0.966716
Fine-tune [524/100000]  val_loss=-0.971618
Fine-tune [525/100000]  val_loss=-0.965283
Fine-tune [526/100000]  val_loss=-0.969708
Fine-tune [527/100000]  val_loss=-0.979129
Fine-tune [528/100000]  val_loss=-0.968941
Fine-tune [529/100000]  val_loss=-0.975129
Fine-tune [530/100000]  val_loss=-0.981460
Fine-tune [531/100000]  val_loss=-0.974839
Fine-tune [532/100000]  val_loss=-0.983301
Fine-tune [533/100000]  val_loss=-0.975583
Fine-tune [534/100000]  val_loss=-0.971321
Fine-tune [535/100000]  val_loss=-0.976303
Fine-tune [536/100000]  val_loss=-0.985638
Fine-tune [537/100000]  val_loss=-0.973196
Fine-tune [538/100000]  val_loss=-0.973755
Fine-tune [539/100000]  val_loss=-0.983336
Fine-tune [540/100000]  val_loss=-0.968981
Fine-tune [541/100000]  val_loss=-0.975329
Fine-tune [542/100000]  val_loss=-0.998444
Fine-tune [543/100000]  val_loss=-0.976898
Fine-tune [544/100000]  val_loss=-0.964115
Fine-tune [545/100000]  val_loss=-0.983410
Fine-tune [546/100000]  val_loss=-0.988696
Fine-tune [547/100000]  val_loss=-0.966937
Fine-tune [548/100000]  val_loss=-0.982837
Fine-tune [549/100000]  val_loss=-0.963844
Fine-tune [550/100000]  val_loss=-0.960451
Fine-tune [551/100000]  val_loss=-0.983110
Fine-tune [552/100000]  val_loss=-0.979287
Fine-tune [553/100000]  val_loss=-0.984505
Fine-tune [554/100000]  val_loss=-0.955702
Fine-tune [555/100000]  val_loss=-0.970918
Fine-tune [556/100000]  val_loss=-0.962709
Fine-tune [557/100000]  val_loss=-0.984119
Fine-tune [558/100000]  val_loss=-0.980414
Fine-tune [559/100000]  val_loss=-0.961532
Fine-tune [560/100000]  val_loss=-0.980179
Fine-tune [561/100000]  val_loss=-0.974314
Fine-tune [562/100000]  val_loss=-0.945542
Fine-tune [563/100000]  val_loss=-0.977499
Fine-tune [564/100000]  val_loss=-0.987909
Fine-tune [565/100000]  val_loss=-0.979874
Fine-tune [566/100000]  val_loss=-0.973346
Fine-tune [567/100000]  val_loss=-0.969931
Fine-tune [568/100000]  val_loss=-0.981494
Fine-tune [569/100000]  val_loss=-0.981513
Fine-tune [570/100000]  val_loss=-0.964942
Fine-tune [571/100000]  val_loss=-0.973575
Fine-tune [572/100000]  val_loss=-0.972142
Fine-tune [573/100000]  val_loss=-0.952633
Fine-tune [574/100000]  val_loss=-0.952907
Fine-tune [575/100000]  val_loss=-0.973681
Fine-tune [576/100000]  val_loss=-0.981316
Fine-tune [577/100000]  val_loss=-0.977745
Fine-tune [578/100000]  val_loss=-0.989800
Fine-tune [579/100000]  val_loss=-0.974417
Fine-tune [580/100000]  val_loss=-0.967539
Fine-tune [581/100000]  val_loss=-0.976156
Fine-tune [582/100000]  val_loss=-0.980738
Fine-tune [583/100000]  val_loss=-0.968031
Fine-tune [584/100000]  val_loss=-0.972434
Fine-tune [585/100000]  val_loss=-0.965009
Fine-tune [586/100000]  val_loss=-0.963947
Fine-tune [587/100000]  val_loss=-0.985445
Fine-tune [588/100000]  val_loss=-0.969540
Fine-tune [589/100000]  val_loss=-0.985700
Fine-tune [590/100000]  val_loss=-0.963049
Fine-tune [591/100000]  val_loss=-0.971855
Fine-tune [592/100000]  val_loss=-0.980955
Fine-tune [593/100000]  val_loss=-0.954656
Fine-tune [594/100000]  val_loss=-0.983012
Fine-tune [595/100000]  val_loss=-0.986476
Fine-tune [596/100000]  val_loss=-0.983207
Fine-tune [597/100000]  val_loss=-0.978875
Fine-tune [598/100000]  val_loss=-0.977887
Fine-tune [599/100000]  val_loss=-0.974315
Fine-tune [600/100000]  val_loss=-0.977620
Fine-tune [601/100000]  val_loss=-0.962016
Fine-tune [602/100000]  val_loss=-0.944978
Fine-tune [603/100000]  val_loss=-0.971594
Fine-tune [604/100000]  val_loss=-0.974064
Fine-tune [605/100000]  val_loss=-0.965457
Fine-tune [606/100000]  val_loss=-0.970701
Fine-tune [607/100000]  val_loss=-0.981389
Fine-tune [608/100000]  val_loss=-0.965874
Fine-tune [609/100000]  val_loss=-0.971026
Fine-tune [610/100000]  val_loss=-0.959399
Fine-tune [611/100000]  val_loss=-0.967438
Fine-tune [612/100000]  val_loss=-0.951925
Fine-tune [613/100000]  val_loss=-0.965871
Fine-tune [614/100000]  val_loss=-0.976525
Fine-tune [615/100000]  val_loss=-0.962173
Fine-tune [616/100000]  val_loss=-0.960894
Fine-tune [617/100000]  val_loss=-0.967633
Fine-tune [618/100000]  val_loss=-0.956469
Fine-tune [619/100000]  val_loss=-0.961686
Fine-tune [620/100000]  val_loss=-0.954002
Fine-tune [621/100000]  val_loss=-0.966986
Fine-tune [622/100000]  val_loss=-0.969031
Fine-tune [623/100000]  val_loss=-0.952744
Fine-tune [624/100000]  val_loss=-0.933246
Fine-tune [625/100000]  val_loss=-0.960630
Fine-tune [626/100000]  val_loss=-0.953436
Fine-tune [627/100000]  val_loss=-0.963659
Fine-tune [628/100000]  val_loss=-0.966653
Fine-tune [629/100000]  val_loss=-0.939180
Fine-tune [630/100000]  val_loss=-0.944973
Fine-tune [631/100000]  val_loss=-0.946151
Fine-tune [632/100000]  val_loss=-0.960710
Fine-tune [633/100000]  val_loss=-0.964072
Fine-tune [634/100000]  val_loss=-0.953801
Fine-tune [635/100000]  val_loss=-0.959335
Fine-tune [636/100000]  val_loss=-0.941221
Fine-tune [637/100000]  val_loss=-0.936792
Fine-tune [638/100000]  val_loss=-0.934099
Fine-tune [639/100000]  val_loss=-0.929615
Fine-tune [640/100000]  val_loss=-0.942447
Fine-tune [641/100000]  val_loss=-0.945105
Fine-tune [642/100000]  val_loss=-0.942841
Fine-tune [643/100000]  val_loss=-0.946761
Fine-tune [644/100000]  val_loss=-0.921299
Fine-tune [645/100000]  val_loss=-0.935369
Fine-tune [646/100000]  val_loss=-0.933953
Fine-tune [647/100000]  val_loss=-0.931159
Fine-tune [648/100000]  val_loss=-0.928768
Fine-tune [649/100000]  val_loss=-0.954092
Fine-tune [650/100000]  val_loss=-0.941180
Fine-tune [651/100000]  val_loss=-0.956378
Fine-tune [652/100000]  val_loss=-0.976821
Fine-tune [653/100000]  val_loss=-0.978307
Fine-tune [654/100000]  val_loss=-0.970957
Fine-tune [655/100000]  val_loss=-0.952809
Fine-tune [656/100000]  val_loss=-0.957773
Fine-tune [657/100000]  val_loss=-0.974878
Fine-tune [658/100000]  val_loss=-0.966734
Fine-tune [659/100000]  val_loss=-0.977082
Fine-tune [660/100000]  val_loss=-0.979665
Fine-tune [661/100000]  val_loss=-0.952543
Fine-tune [662/100000]  val_loss=-0.961576
Fine-tune [663/100000]  val_loss=-0.969791
Fine-tune [664/100000]  val_loss=-0.969595
Fine-tune [665/100000]  val_loss=-0.944686
Fine-tune [666/100000]  val_loss=-0.965700
Fine-tune [667/100000]  val_loss=-0.960776
Fine-tune [668/100000]  val_loss=-0.972606
Fine-tune [669/100000]  val_loss=-0.963144
Fine-tune [670/100000]  val_loss=-0.956734
Fine-tune [671/100000]  val_loss=-0.940704
Fine-tune [672/100000]  val_loss=-0.939761
Fine-tune [673/100000]  val_loss=-0.950896
Fine-tune [674/100000]  val_loss=-0.942165
Fine-tune [675/100000]  val_loss=-0.943713
Fine-tune [676/100000]  val_loss=-0.952360
Fine-tune [677/100000]  val_loss=-0.965540
Fine-tune [678/100000]  val_loss=-0.969748
Fine-tune [679/100000]  val_loss=-0.977091
Fine-tune [680/100000]  val_loss=-0.949460
Fine-tune [681/100000]  val_loss=-0.948937
Fine-tune [682/100000]  val_loss=-0.945987
Fine-tune [683/100000]  val_loss=-0.972385
Fine-tune [684/100000]  val_loss=-0.974343
Fine-tune [685/100000]  val_loss=-0.972461
Fine-tune [686/100000]  val_loss=-0.954434
Fine-tune [687/100000]  val_loss=-0.952277
Fine-tune [688/100000]  val_loss=-0.963066
Fine-tune [689/100000]  val_loss=-0.966689
Fine-tune [690/100000]  val_loss=-0.959438
Fine-tune [691/100000]  val_loss=-0.952674
Fine-tune [692/100000]  val_loss=-0.965746
Fine-tune [693/100000]  val_loss=-0.970935
Fine-tune [694/100000]  val_loss=-0.980724
Fine-tune [695/100000]  val_loss=-0.960330
Fine-tune [696/100000]  val_loss=-0.968563
Fine-tune [697/100000]  val_loss=-0.947525
Fine-tune [698/100000]  val_loss=-0.961646
Fine-tune [699/100000]  val_loss=-0.962884
Fine-tune [700/100000]  val_loss=-0.977759
Fine-tune [701/100000]  val_loss=-0.957821
Fine-tune [702/100000]  val_loss=-0.966121
Fine-tune [703/100000]  val_loss=-0.961050
Fine-tune [704/100000]  val_loss=-0.964445
Fine-tune [705/100000]  val_loss=-0.965570
Fine-tune [706/100000]  val_loss=-0.965637
Fine-tune [707/100000]  val_loss=-0.962239
Fine-tune [708/100000]  val_loss=-0.958759
Fine-tune [709/100000]  val_loss=-0.952777
Fine-tune [710/100000]  val_loss=-0.969808
Fine-tune [711/100000]  val_loss=-0.979561
Fine-tune [712/100000]  val_loss=-0.983519
Fine-tune [713/100000]  val_loss=-0.983146
Fine-tune [714/100000]  val_loss=-0.966599
Fine-tune [715/100000]  val_loss=-0.956424
Fine-tune [716/100000]  val_loss=-0.967941
Fine-tune [717/100000]  val_loss=-0.952610
Fine-tune [718/100000]  val_loss=-0.969145
Fine-tune [719/100000]  val_loss=-0.962887
Fine-tune [720/100000]  val_loss=-0.949832
Fine-tune [721/100000]  val_loss=-0.947653
Fine-tune [722/100000]  val_loss=-0.977692
Fine-tune [723/100000]  val_loss=-0.947208
Fine-tune [724/100000]  val_loss=-0.937809
Fine-tune [725/100000]  val_loss=-0.961597
Fine-tune [726/100000]  val_loss=-0.949796
Fine-tune [727/100000]  val_loss=-0.958180
Fine-tune [728/100000]  val_loss=-0.931436
Fine-tune [729/100000]  val_loss=-0.951010
Fine-tune [730/100000]  val_loss=-0.938377
Fine-tune [731/100000]  val_loss=-0.956230
Fine-tune [732/100000]  val_loss=-0.961477
Fine-tune [733/100000]  val_loss=-0.912220
Fine-tune [734/100000]  val_loss=-0.915064
Fine-tune [735/100000]  val_loss=-0.910387
Fine-tune [736/100000]  val_loss=-0.905637
Fine-tune [737/100000]  val_loss=-0.926581
Fine-tune [738/100000]  val_loss=-0.930344
Fine-tune [739/100000]  val_loss=-0.932716
Fine-tune [740/100000]  val_loss=-0.916294
Fine-tune [741/100000]  val_loss=-0.910875
Fine-tune [742/100000]  val_loss=-0.915593
Fine-tune [743/100000]  val_loss=-0.910748
Fine-tune [744/100000]  val_loss=-0.914001
Fine-tune [745/100000]  val_loss=-0.917901
Fine-tune [746/100000]  val_loss=-0.933893
Fine-tune [747/100000]  val_loss=-0.923491
Fine-tune [748/100000]  val_loss=-0.918062
Fine-tune [749/100000]  val_loss=-0.942680
Fine-tune [750/100000]  val_loss=-0.934343
Fine-tune [751/100000]  val_loss=-0.933179
Fine-tune [752/100000]  val_loss=-0.908662
Fine-tune [753/100000]  val_loss=-0.931140
Fine-tune [754/100000]  val_loss=-0.928305
Fine-tune [755/100000]  val_loss=-0.912251
Fine-tune [756/100000]  val_loss=-0.918009
Fine-tune [757/100000]  val_loss=-0.923982
Fine-tune [758/100000]  val_loss=-0.912630
Fine-tune [759/100000]  val_loss=-0.914844
Fine-tune [760/100000]  val_loss=-0.900685
Fine-tune [761/100000]  val_loss=-0.904990
Fine-tune [762/100000]  val_loss=-0.904980
Fine-tune [763/100000]  val_loss=-0.929336
Fine-tune [764/100000]  val_loss=-0.936959
Fine-tune [765/100000]  val_loss=-0.913637
Fine-tune [766/100000]  val_loss=-0.931032
Fine-tune [767/100000]  val_loss=-0.919039
Fine-tune [768/100000]  val_loss=-0.915641
Fine-tune [769/100000]  val_loss=-0.920735
Fine-tune [770/100000]  val_loss=-0.921912
Fine-tune [771/100000]  val_loss=-0.909458
Fine-tune [772/100000]  val_loss=-0.908252
Fine-tune [773/100000]  val_loss=-0.920097
Fine-tune [774/100000]  val_loss=-0.895387
Fine-tune [775/100000]  val_loss=-0.921519
Fine-tune [776/100000]  val_loss=-0.921234
Fine-tune [777/100000]  val_loss=-0.926954
Fine-tune [778/100000]  val_loss=-0.907530
Fine-tune [779/100000]  val_loss=-0.903889
Fine-tune [780/100000]  val_loss=-0.945508
Fine-tune [781/100000]  val_loss=-0.926003
Fine-tune [782/100000]  val_loss=-0.902037
Fine-tune [783/100000]  val_loss=-0.905322
Fine-tune [784/100000]  val_loss=-0.938586
Fine-tune [785/100000]  val_loss=-0.944910
Fine-tune [786/100000]  val_loss=-0.923470
Fine-tune [787/100000]  val_loss=-0.905850
Fine-tune [788/100000]  val_loss=-0.934049
Fine-tune [789/100000]  val_loss=-0.941697
Fine-tune [790/100000]  val_loss=-0.932732
Fine-tune [791/100000]  val_loss=-0.941184
Fine-tune [792/100000]  val_loss=-0.937926
Fine-tune [793/100000]  val_loss=-0.942966
Fine-tune [794/100000]  val_loss=-0.927641
Fine-tune [795/100000]  val_loss=-0.931131
Fine-tune [796/100000]  val_loss=-0.923745
Fine-tune [797/100000]  val_loss=-0.926536
Fine-tune [798/100000]  val_loss=-0.918666
Fine-tune [799/100000]  val_loss=-0.938266
Fine-tune [800/100000]  val_loss=-0.958948
Fine-tune [801/100000]  val_loss=-0.958815
Fine-tune [802/100000]  val_loss=-0.928163
Fine-tune [803/100000]  val_loss=-0.932272
Fine-tune [804/100000]  val_loss=-0.942982
Fine-tune [805/100000]  val_loss=-0.934577
Fine-tune [806/100000]  val_loss=-0.917845
Fine-tune [807/100000]  val_loss=-0.902506
Fine-tune [808/100000]  val_loss=-0.917500
Fine-tune [809/100000]  val_loss=-0.888148
Fine-tune [810/100000]  val_loss=-0.928566
Fine-tune [811/100000]  val_loss=-0.943731
Fine-tune [812/100000]  val_loss=-0.932887
Fine-tune [813/100000]  val_loss=-0.926345
Fine-tune [814/100000]  val_loss=-0.925612
Fine-tune [815/100000]  val_loss=-0.923291
Fine-tune [816/100000]  val_loss=-0.955607
Fine-tune [817/100000]  val_loss=-0.933435
Fine-tune [818/100000]  val_loss=-0.918296
Fine-tune [819/100000]  val_loss=-0.908694
Fine-tune [820/100000]  val_loss=-0.928023
Fine-tune [821/100000]  val_loss=-0.947479
Fine-tune [822/100000]  val_loss=-0.924793
Fine-tune [823/100000]  val_loss=-0.934224
Fine-tune [824/100000]  val_loss=-0.929086
Fine-tune [825/100000]  val_loss=-0.920602
Fine-tune [826/100000]  val_loss=-0.944761
Fine-tune [827/100000]  val_loss=-0.927397
Fine-tune [828/100000]  val_loss=-0.939165
Fine-tune [829/100000]  val_loss=-0.921574
Fine-tune [830/100000]  val_loss=-0.934162
Fine-tune [831/100000]  val_loss=-0.913502
Fine-tune [832/100000]  val_loss=-0.918318
Fine-tune [833/100000]  val_loss=-0.931122
Fine-tune [834/100000]  val_loss=-0.933179
Fine-tune [835/100000]  val_loss=-0.915042
Fine-tune [836/100000]  val_loss=-0.929718
Fine-tune [837/100000]  val_loss=-0.919212
Fine-tune [838/100000]  val_loss=-0.934522
Fine-tune [839/100000]  val_loss=-0.928622
Fine-tune [840/100000]  val_loss=-0.937100
Fine-tune [841/100000]  val_loss=-0.931040
Fine-tune [842/100000]  val_loss=-0.938551
Fine-tune [843/100000]  val_loss=-0.940030
Fine-tune [844/100000]  val_loss=-0.935983
Fine-tune [845/100000]  val_loss=-0.911349
Fine-tune [846/100000]  val_loss=-0.932182
Fine-tune [847/100000]  val_loss=-0.925110
Fine-tune [848/100000]  val_loss=-0.919776
Fine-tune [849/100000]  val_loss=-0.924934
Fine-tune [850/100000]  val_loss=-0.913105
Fine-tune [851/100000]  val_loss=-0.904581
Fine-tune [852/100000]  val_loss=-0.938426
Fine-tune [853/100000]  val_loss=-0.911118
Fine-tune [854/100000]  val_loss=-0.933624
Fine-tune [855/100000]  val_loss=-0.918354
Fine-tune [856/100000]  val_loss=-0.926723
Fine-tune [857/100000]  val_loss=-0.949396
Fine-tune [858/100000]  val_loss=-0.929197
Fine-tune [859/100000]  val_loss=-0.950090
Fine-tune [860/100000]  val_loss=-0.951235
Fine-tune [861/100000]  val_loss=-0.911566
Fine-tune [862/100000]  val_loss=-0.925934
Fine-tune [863/100000]  val_loss=-0.928063
Fine-tune [864/100000]  val_loss=-0.927974
Fine-tune [865/100000]  val_loss=-0.904976
Fine-tune [866/100000]  val_loss=-0.934354
Fine-tune [867/100000]  val_loss=-0.948884
Fine-tune [868/100000]  val_loss=-0.921747
Fine-tune [869/100000]  val_loss=-0.913577
Fine-tune [870/100000]  val_loss=-0.890139
Fine-tune [871/100000]  val_loss=-0.934377
Fine-tune [872/100000]  val_loss=-0.924576
Fine-tune [873/100000]  val_loss=-0.935732
Fine-tune [874/100000]  val_loss=-0.950595
Fine-tune [875/100000]  val_loss=-0.953608
Fine-tune [876/100000]  val_loss=-0.922637
Fine-tune [877/100000]  val_loss=-0.917941
Fine-tune [878/100000]  val_loss=-0.927997
Fine-tune [879/100000]  val_loss=-0.932751
Fine-tune [880/100000]  val_loss=-0.918874
Fine-tune [881/100000]  val_loss=-0.939658
Fine-tune [882/100000]  val_loss=-0.952056
Fine-tune [883/100000]  val_loss=-0.916220
Fine-tune [884/100000]  val_loss=-0.922858
Fine-tune [885/100000]  val_loss=-0.910472
Fine-tune [886/100000]  val_loss=-0.919266
Fine-tune [887/100000]  val_loss=-0.915479
Fine-tune [888/100000]  val_loss=-0.915686
Fine-tune [889/100000]  val_loss=-0.920806
Fine-tune [890/100000]  val_loss=-0.900273
Fine-tune [891/100000]  val_loss=-0.908777
Fine-tune [892/100000]  val_loss=-0.896528
Fine-tune [893/100000]  val_loss=-0.883545
Fine-tune [894/100000]  val_loss=-0.915674
Fine-tune [895/100000]  val_loss=-0.897519
Fine-tune [896/100000]  val_loss=-0.914874
Fine-tune [897/100000]  val_loss=-0.891651
Fine-tune [898/100000]  val_loss=-0.908561
Fine-tune [899/100000]  val_loss=-0.907927
Fine-tune [900/100000]  val_loss=-0.907896
Fine-tune [901/100000]  val_loss=-0.907413
Fine-tune [902/100000]  val_loss=-0.918895
Fine-tune [903/100000]  val_loss=-0.883364
Fine-tune [904/100000]  val_loss=-0.903961
Fine-tune [905/100000]  val_loss=-0.918219
Fine-tune [906/100000]  val_loss=-0.903961
Fine-tune [907/100000]  val_loss=-0.898204
Fine-tune [908/100000]  val_loss=-0.911890
Fine-tune [909/100000]  val_loss=-0.896540
Fine-tune [910/100000]  val_loss=-0.921692
Fine-tune [911/100000]  val_loss=-0.920571
Fine-tune [912/100000]  val_loss=-0.914278
Fine-tune [913/100000]  val_loss=-0.926578
Fine-tune [914/100000]  val_loss=-0.917422
Fine-tune [915/100000]  val_loss=-0.896091
Fine-tune [916/100000]  val_loss=-0.903331
Fine-tune [917/100000]  val_loss=-0.887732
Fine-tune [918/100000]  val_loss=-0.902369
Fine-tune [919/100000]  val_loss=-0.919463
Fine-tune [920/100000]  val_loss=-0.898210
Fine-tune [921/100000]  val_loss=-0.899292
Fine-tune [922/100000]  val_loss=-0.891159
Fine-tune [923/100000]  val_loss=-0.897132
Fine-tune [924/100000]  val_loss=-0.907367
Fine-tune [925/100000]  val_loss=-0.913920
Fine-tune [926/100000]  val_loss=-0.910444
Fine-tune [927/100000]  val_loss=-0.901827
Fine-tune [928/100000]  val_loss=-0.902401
Fine-tune [929/100000]  val_loss=-0.893238
Fine-tune [930/100000]  val_loss=-0.899929
Fine-tune [931/100000]  val_loss=-0.904621
Fine-tune [932/100000]  val_loss=-0.915934
Fine-tune [933/100000]  val_loss=-0.910667
Fine-tune [934/100000]  val_loss=-0.895053
Fine-tune [935/100000]  val_loss=-0.895775
Fine-tune [936/100000]  val_loss=-0.887126
Fine-tune [937/100000]  val_loss=-0.911263
Fine-tune [938/100000]  val_loss=-0.916827
Fine-tune [939/100000]  val_loss=-0.914727
Fine-tune [940/100000]  val_loss=-0.934162
Fine-tune [941/100000]  val_loss=-0.908949
Fine-tune [942/100000]  val_loss=-0.914448
Fine-tune [943/100000]  val_loss=-0.917252
Fine-tune [944/100000]  val_loss=-0.925885
Fine-tune [945/100000]  val_loss=-0.902139
Fine-tune [946/100000]  val_loss=-0.903449
Fine-tune [947/100000]  val_loss=-0.921322
Fine-tune [948/100000]  val_loss=-0.929769
Fine-tune [949/100000]  val_loss=-0.915008
Fine-tune [950/100000]  val_loss=-0.916997
Fine-tune [951/100000]  val_loss=-0.901350
Fine-tune [952/100000]  val_loss=-0.891415
Fine-tune [953/100000]  val_loss=-0.914113
Fine-tune [954/100000]  val_loss=-0.906179
Fine-tune [955/100000]  val_loss=-0.884370
Fine-tune [956/100000]  val_loss=-0.884400
Fine-tune [957/100000]  val_loss=-0.897492
Fine-tune [958/100000]  val_loss=-0.912697
Fine-tune [959/100000]  val_loss=-0.896495
Fine-tune [960/100000]  val_loss=-0.891875
Fine-tune [961/100000]  val_loss=-0.873055
Fine-tune [962/100000]  val_loss=-0.880934
Fine-tune [963/100000]  val_loss=-0.867452
Fine-tune [964/100000]  val_loss=-0.857574
Fine-tune [965/100000]  val_loss=-0.877228
Fine-tune [966/100000]  val_loss=-0.912362
Fine-tune [967/100000]  val_loss=-0.903902
Fine-tune [968/100000]  val_loss=-0.896217
Fine-tune [969/100000]  val_loss=-0.895541
Fine-tune [970/100000]  val_loss=-0.926304
Fine-tune [971/100000]  val_loss=-0.904046
Fine-tune [972/100000]  val_loss=-0.867617
Fine-tune [973/100000]  val_loss=-0.875800
Fine-tune [974/100000]  val_loss=-0.906889
Fine-tune [975/100000]  val_loss=-0.918433
Fine-tune [976/100000]  val_loss=-0.913878
Fine-tune [977/100000]  val_loss=-0.930262
Fine-tune [978/100000]  val_loss=-0.922453
Fine-tune [979/100000]  val_loss=-0.928315
Fine-tune [980/100000]  val_loss=-0.910096
Fine-tune [981/100000]  val_loss=-0.914981
Fine-tune [982/100000]  val_loss=-0.909789
Fine-tune [983/100000]  val_loss=-0.894956
Fine-tune [984/100000]  val_loss=-0.906394
Fine-tune [985/100000]  val_loss=-0.911315
Fine-tune [986/100000]  val_loss=-0.944782
Fine-tune [987/100000]  val_loss=-0.902915
Fine-tune [988/100000]  val_loss=-0.919193
Fine-tune [989/100000]  val_loss=-0.889883
Fine-tune [990/100000]  val_loss=-0.903492
Fine-tune [991/100000]  val_loss=-0.902809
Fine-tune [992/100000]  val_loss=-0.927522
Fine-tune [993/100000]  val_loss=-0.918091
Fine-tune [994/100000]  val_loss=-0.895092
Fine-tune [995/100000]  val_loss=-0.910710
Fine-tune [996/100000]  val_loss=-0.910733
Fine-tune [997/100000]  val_loss=-0.905103
Fine-tune [998/100000]  val_loss=-0.868111
Fine-tune [999/100000]  val_loss=-0.932224
Fine-tune [1000/100000]  val_loss=-0.919147
Fine-tune [1001/100000]  val_loss=-0.914856
Fine-tune [1002/100000]  val_loss=-0.921300
Fine-tune [1003/100000]  val_loss=-0.912595
Fine-tune [1004/100000]  val_loss=-0.888620
Fine-tune [1005/100000]  val_loss=-0.887605
Fine-tune [1006/100000]  val_loss=-0.915012
Fine-tune [1007/100000]  val_loss=-0.888923
Fine-tune [1008/100000]  val_loss=-0.916007
Fine-tune [1009/100000]  val_loss=-0.921349
Fine-tune [1010/100000]  val_loss=-0.893300
Fine-tune [1011/100000]  val_loss=-0.865097
Fine-tune [1012/100000]  val_loss=-0.843810
Fine-tune [1013/100000]  val_loss=-0.905717
Fine-tune [1014/100000]  val_loss=-0.904675
Fine-tune [1015/100000]  val_loss=-0.924641
Fine-tune [1016/100000]  val_loss=-0.917625
Fine-tune [1017/100000]  val_loss=-0.907233
Fine-tune [1018/100000]  val_loss=-0.910664
Fine-tune [1019/100000]  val_loss=-0.903355
Fine-tune [1020/100000]  val_loss=-0.883836
Fine-tune [1021/100000]  val_loss=-0.910586
Fine-tune [1022/100000]  val_loss=-0.875002
Fine-tune [1023/100000]  val_loss=-0.854451
Fine-tune [1024/100000]  val_loss=-0.882307
Fine-tune [1025/100000]  val_loss=-0.898548
Fine-tune [1026/100000]  val_loss=-0.900901
Fine-tune [1027/100000]  val_loss=-0.881224
Fine-tune [1028/100000]  val_loss=-0.894378
Fine-tune [1029/100000]  val_loss=-0.891640
Fine-tune [1030/100000]  val_loss=-0.908061
Fine-tune [1031/100000]  val_loss=-0.905019
Fine-tune [1032/100000]  val_loss=-0.913320
Fine-tune [1033/100000]  val_loss=-0.905060
Fine-tune [1034/100000]  val_loss=-0.889841
Fine-tune [1035/100000]  val_loss=-0.907468
Fine-tune [1036/100000]  val_loss=-0.914179
Fine-tune [1037/100000]  val_loss=-0.867382
Fine-tune [1038/100000]  val_loss=-0.883552
Fine-tune [1039/100000]  val_loss=-0.903757
Fine-tune [1040/100000]  val_loss=-0.916177
Fine-tune [1041/100000]  val_loss=-0.906590
Fine-tune [1042/100000]  val_loss=-0.898979
Fine-tune [1043/100000]  val_loss=-0.895791
Fine-tune [1044/100000]  val_loss=-0.885928
Fine-tune [1045/100000]  val_loss=-0.901975
Fine-tune [1046/100000]  val_loss=-0.880917
Fine-tune [1047/100000]  val_loss=-0.894356
Fine-tune [1048/100000]  val_loss=-0.873165
Fine-tune [1049/100000]  val_loss=-0.891225
Fine-tune [1050/100000]  val_loss=-0.901121
Fine-tune [1051/100000]  val_loss=-0.891184
Fine-tune [1052/100000]  val_loss=-0.905735
Fine-tune [1053/100000]  val_loss=-0.898662
Fine-tune [1054/100000]  val_loss=-0.872326
Fine-tune [1055/100000]  val_loss=-0.885558
Fine-tune [1056/100000]  val_loss=-0.893945
Fine-tune [1057/100000]  val_loss=-0.878027
Fine-tune [1058/100000]  val_loss=-0.888259
Fine-tune [1059/100000]  val_loss=-0.881598
Fine-tune [1060/100000]  val_loss=-0.874831
Fine-tune [1061/100000]  val_loss=-0.896570
Fine-tune [1062/100000]  val_loss=-0.892844
Fine-tune [1063/100000]  val_loss=-0.884475
Fine-tune [1064/100000]  val_loss=-0.879811
Fine-tune [1065/100000]  val_loss=-0.881405
Fine-tune [1066/100000]  val_loss=-0.887010
Fine-tune [1067/100000]  val_loss=-0.909379
Fine-tune [1068/100000]  val_loss=-0.907449
Fine-tune [1069/100000]  val_loss=-0.899604
Fine-tune [1070/100000]  val_loss=-0.887613
Fine-tune [1071/100000]  val_loss=-0.882639
Fine-tune [1072/100000]  val_loss=-0.897159
Fine-tune [1073/100000]  val_loss=-0.879938
Fine-tune [1074/100000]  val_loss=-0.912388
Fine-tune [1075/100000]  val_loss=-0.916036
Fine-tune [1076/100000]  val_loss=-0.902182
Fine-tune [1077/100000]  val_loss=-0.895433
Fine-tune [1078/100000]  val_loss=-0.873540
Fine-tune [1079/100000]  val_loss=-0.895876
Fine-tune [1080/100000]  val_loss=-0.892668
Fine-tune [1081/100000]  val_loss=-0.896375
Fine-tune [1082/100000]  val_loss=-0.908154
Fine-tune [1083/100000]  val_loss=-0.888550
Fine-tune [1084/100000]  val_loss=-0.877349
Fine-tune [1085/100000]  val_loss=-0.872380
Fine-tune [1086/100000]  val_loss=-0.875524
Fine-tune [1087/100000]  val_loss=-0.875831
Fine-tune [1088/100000]  val_loss=-0.885613
Fine-tune [1089/100000]  val_loss=-0.881414
Fine-tune [1090/100000]  val_loss=-0.911211
Fine-tune [1091/100000]  val_loss=-0.929273
Fine-tune [1092/100000]  val_loss=-0.882507
Fine-tune [1093/100000]  val_loss=-0.870064
Fine-tune [1094/100000]  val_loss=-0.881965
Fine-tune [1095/100000]  val_loss=-0.906123
Fine-tune [1096/100000]  val_loss=-0.863457
Fine-tune [1097/100000]  val_loss=-0.886208
Fine-tune [1098/100000]  val_loss=-0.905942
Fine-tune [1099/100000]  val_loss=-0.900678
Fine-tune [1100/100000]  val_loss=-0.892911
Fine-tune [1101/100000]  val_loss=-0.902012
Fine-tune [1102/100000]  val_loss=-0.891415
Fine-tune [1103/100000]  val_loss=-0.914735
Fine-tune [1104/100000]  val_loss=-0.877095
Fine-tune [1105/100000]  val_loss=-0.911904
Fine-tune [1106/100000]  val_loss=-0.905766
Fine-tune [1107/100000]  val_loss=-0.880347
Fine-tune [1108/100000]  val_loss=-0.906879
Fine-tune [1109/100000]  val_loss=-0.907401
Fine-tune [1110/100000]  val_loss=-0.894356
Fine-tune [1111/100000]  val_loss=-0.889416
Fine-tune [1112/100000]  val_loss=-0.894003
Fine-tune [1113/100000]  val_loss=-0.861564
Fine-tune [1114/100000]  val_loss=-0.862746
Fine-tune [1115/100000]  val_loss=-0.880132
Fine-tune [1116/100000]  val_loss=-0.901489
Fine-tune [1117/100000]  val_loss=-0.915009
Fine-tune [1118/100000]  val_loss=-0.913168
Fine-tune [1119/100000]  val_loss=-0.889854
Fine-tune [1120/100000]  val_loss=-0.907777
Fine-tune [1121/100000]  val_loss=-0.863327
Fine-tune [1122/100000]  val_loss=-0.873200
Fine-tune [1123/100000]  val_loss=-0.872754
Fine-tune [1124/100000]  val_loss=-0.857330
Fine-tune [1125/100000]  val_loss=-0.868510
Fine-tune [1126/100000]  val_loss=-0.894242
Fine-tune [1127/100000]  val_loss=-0.903810
Fine-tune [1128/100000]  val_loss=-0.874564
Fine-tune [1129/100000]  val_loss=-0.878594
Fine-tune [1130/100000]  val_loss=-0.893558
Fine-tune [1131/100000]  val_loss=-0.879295
Fine-tune [1132/100000]  val_loss=-0.885555
Fine-tune [1133/100000]  val_loss=-0.890432
Fine-tune [1134/100000]  val_loss=-0.879557
Fine-tune [1135/100000]  val_loss=-0.894259
Fine-tune [1136/100000]  val_loss=-0.874012
Fine-tune [1137/100000]  val_loss=-0.874432
Fine-tune [1138/100000]  val_loss=-0.887781
Fine-tune [1139/100000]  val_loss=-0.882871
Fine-tune [1140/100000]  val_loss=-0.880535
Fine-tune [1141/100000]  val_loss=-0.877437
Fine-tune [1142/100000]  val_loss=-0.868544
Fine-tune [1143/100000]  val_loss=-0.868486
Fine-tune [1144/100000]  val_loss=-0.882425
Fine-tune [1145/100000]  val_loss=-0.874161
Fine-tune [1146/100000]  val_loss=-0.871403
Fine-tune [1147/100000]  val_loss=-0.880268
Fine-tune [1148/100000]  val_loss=-0.891115
Fine-tune [1149/100000]  val_loss=-0.909512
Fine-tune [1150/100000]  val_loss=-0.913349
Fine-tune [1151/100000]  val_loss=-0.883941
Fine-tune [1152/100000]  val_loss=-0.903119
Fine-tune [1153/100000]  val_loss=-0.884584
Fine-tune [1154/100000]  val_loss=-0.882098
Fine-tune [1155/100000]  val_loss=-0.899163
Fine-tune [1156/100000]  val_loss=-0.879867
Fine-tune [1157/100000]  val_loss=-0.885457
Fine-tune [1158/100000]  val_loss=-0.894813
Fine-tune [1159/100000]  val_loss=-0.865651
Fine-tune [1160/100000]  val_loss=-0.899205
Fine-tune [1161/100000]  val_loss=-0.893097
Fine-tune [1162/100000]  val_loss=-0.899280
Fine-tune [1163/100000]  val_loss=-0.902013
Fine-tune [1164/100000]  val_loss=-0.905722
Fine-tune [1165/100000]  val_loss=-0.916494
Fine-tune [1166/100000]  val_loss=-0.904771
Fine-tune [1167/100000]  val_loss=-0.895160
Fine-tune [1168/100000]  val_loss=-0.889349
Fine-tune [1169/100000]  val_loss=-0.893249
Fine-tune [1170/100000]  val_loss=-0.870565
Fine-tune [1171/100000]  val_loss=-0.916817
Fine-tune [1172/100000]  val_loss=-0.905178
Fine-tune [1173/100000]  val_loss=-0.922920
Fine-tune [1174/100000]  val_loss=-0.919768
Fine-tune [1175/100000]  val_loss=-0.930379
Fine-tune [1176/100000]  val_loss=-0.905670
Fine-tune [1177/100000]  val_loss=-0.895118
Fine-tune [1178/100000]  val_loss=-0.910249
Fine-tune [1179/100000]  val_loss=-0.914969
Fine-tune [1180/100000]  val_loss=-0.926687
Fine-tune [1181/100000]  val_loss=-0.914004
Fine-tune [1182/100000]  val_loss=-0.901879
Fine-tune [1183/100000]  val_loss=-0.916354
Fine-tune [1184/100000]  val_loss=-0.905870
Fine-tune [1185/100000]  val_loss=-0.891295
Fine-tune [1186/100000]  val_loss=-0.913442
Fine-tune [1187/100000]  val_loss=-0.886567
Fine-tune [1188/100000]  val_loss=-0.882201
Fine-tune [1189/100000]  val_loss=-0.866216
Fine-tune [1190/100000]  val_loss=-0.887107
Fine-tune [1191/100000]  val_loss=-0.894994
Fine-tune [1192/100000]  val_loss=-0.882185
Fine-tune [1193/100000]  val_loss=-0.904461
Fine-tune [1194/100000]  val_loss=-0.893637
Fine-tune [1195/100000]  val_loss=-0.891617
Fine-tune [1196/100000]  val_loss=-0.912854
Fine-tune [1197/100000]  val_loss=-0.925368
Fine-tune [1198/100000]  val_loss=-0.922606
Fine-tune [1199/100000]  val_loss=-0.919470
Fine-tune [1200/100000]  val_loss=-0.923383
Fine-tune [1201/100000]  val_loss=-0.892837
Fine-tune [1202/100000]  val_loss=-0.901342
Fine-tune [1203/100000]  val_loss=-0.899596
Fine-tune [1204/100000]  val_loss=-0.877595
Fine-tune [1205/100000]  val_loss=-0.893024
Fine-tune [1206/100000]  val_loss=-0.900516
Fine-tune [1207/100000]  val_loss=-0.920491
Fine-tune [1208/100000]  val_loss=-0.909228
Fine-tune [1209/100000]  val_loss=-0.903323
Fine-tune [1210/100000]  val_loss=-0.854439
Fine-tune [1211/100000]  val_loss=-0.888295
Fine-tune [1212/100000]  val_loss=-0.894755
Fine-tune [1213/100000]  val_loss=-0.870884
Fine-tune [1214/100000]  val_loss=-0.874209
Fine-tune [1215/100000]  val_loss=-0.872840
Fine-tune [1216/100000]  val_loss=-0.891317
Fine-tune [1217/100000]  val_loss=-0.868308
Fine-tune [1218/100000]  val_loss=-0.898554
Fine-tune [1219/100000]  val_loss=-0.891829
Fine-tune [1220/100000]  val_loss=-0.892150
Fine-tune [1221/100000]  val_loss=-0.885877
Fine-tune [1222/100000]  val_loss=-0.889409
Fine-tune [1223/100000]  val_loss=-0.875546
Fine-tune [1224/100000]  val_loss=-0.891567
Fine-tune [1225/100000]  val_loss=-0.881712
Fine-tune [1226/100000]  val_loss=-0.884824
Fine-tune [1227/100000]  val_loss=-0.887152
Fine-tune [1228/100000]  val_loss=-0.867366
Fine-tune [1229/100000]  val_loss=-0.887056
Fine-tune [1230/100000]  val_loss=-0.889014
Fine-tune [1231/100000]  val_loss=-0.866252
Fine-tune [1232/100000]  val_loss=-0.867202
Fine-tune [1233/100000]  val_loss=-0.890470
Fine-tune [1234/100000]  val_loss=-0.875501
Fine-tune [1235/100000]  val_loss=-0.848801
Fine-tune [1236/100000]  val_loss=-0.877746
Fine-tune [1237/100000]  val_loss=-0.866038
Fine-tune [1238/100000]  val_loss=-0.877481
Fine-tune [1239/100000]  val_loss=-0.880783
Fine-tune [1240/100000]  val_loss=-0.887677
Fine-tune [1241/100000]  val_loss=-0.896108
Fine-tune [1242/100000]  val_loss=-0.879647
Fine-tune [1243/100000]  val_loss=-0.884262
Fine-tune [1244/100000]  val_loss=-0.887559
Fine-tune [1245/100000]  val_loss=-0.906458
Fine-tune [1246/100000]  val_loss=-0.924129
Fine-tune [1247/100000]  val_loss=-0.898080
Fine-tune [1248/100000]  val_loss=-0.882020
Fine-tune [1249/100000]  val_loss=-0.866597
Fine-tune [1250/100000]  val_loss=-0.857647
Fine-tune [1251/100000]  val_loss=-0.876253
Fine-tune [1252/100000]  val_loss=-0.888910
Fine-tune [1253/100000]  val_loss=-0.887185
Fine-tune [1254/100000]  val_loss=-0.906961
Fine-tune [1255/100000]  val_loss=-0.903041
Fine-tune [1256/100000]  val_loss=-0.891273
Fine-tune [1257/100000]  val_loss=-0.894375
Fine-tune [1258/100000]  val_loss=-0.918366
Fine-tune [1259/100000]  val_loss=-0.926236
Fine-tune [1260/100000]  val_loss=-0.914764
Fine-tune [1261/100000]  val_loss=-0.919500
Fine-tune [1262/100000]  val_loss=-0.918878
Fine-tune [1263/100000]  val_loss=-0.896576
Fine-tune [1264/100000]  val_loss=-0.888738
Fine-tune [1265/100000]  val_loss=-0.900533
Fine-tune [1266/100000]  val_loss=-0.891785
Fine-tune [1267/100000]  val_loss=-0.895879
Fine-tune [1268/100000]  val_loss=-0.897406
Fine-tune [1269/100000]  val_loss=-0.859548
Fine-tune [1270/100000]  val_loss=-0.902409
Fine-tune [1271/100000]  val_loss=-0.906643
Fine-tune [1272/100000]  val_loss=-0.917752
Fine-tune [1273/100000]  val_loss=-0.902015
Fine-tune [1274/100000]  val_loss=-0.897774
Fine-tune [1275/100000]  val_loss=-0.888275
Fine-tune [1276/100000]  val_loss=-0.901786
Fine-tune [1277/100000]  val_loss=-0.885426
Fine-tune [1278/100000]  val_loss=-0.908985
Fine-tune [1279/100000]  val_loss=-0.886951
Fine-tune [1280/100000]  val_loss=-0.922768
Fine-tune [1281/100000]  val_loss=-0.916539
Fine-tune [1282/100000]  val_loss=-0.886160
Fine-tune [1283/100000]  val_loss=-0.928474
Fine-tune [1284/100000]  val_loss=-0.908288
Fine-tune [1285/100000]  val_loss=-0.888811
Fine-tune [1286/100000]  val_loss=-0.883131
Fine-tune [1287/100000]  val_loss=-0.906008
Fine-tune [1288/100000]  val_loss=-0.906292
Fine-tune [1289/100000]  val_loss=-0.922085
Fine-tune [1290/100000]  val_loss=-0.927816
Fine-tune [1291/100000]  val_loss=-0.922813
Fine-tune [1292/100000]  val_loss=-0.936701
Fine-tune [1293/100000]  val_loss=-0.912884
Fine-tune [1294/100000]  val_loss=-0.910521
Fine-tune [1295/100000]  val_loss=-0.930727
Fine-tune [1296/100000]  val_loss=-0.900266
Fine-tune [1297/100000]  val_loss=-0.907082
Fine-tune [1298/100000]  val_loss=-0.884361
Fine-tune [1299/100000]  val_loss=-0.876341
Fine-tune [1300/100000]  val_loss=-0.888854
Fine-tune [1301/100000]  val_loss=-0.895217
Fine-tune [1302/100000]  val_loss=-0.894706
Fine-tune [1303/100000]  val_loss=-0.897480
Fine-tune [1304/100000]  val_loss=-0.898922
Fine-tune [1305/100000]  val_loss=-0.916584
Fine-tune [1306/100000]  val_loss=-0.930904
Fine-tune [1307/100000]  val_loss=-0.930958
Fine-tune [1308/100000]  val_loss=-0.914437
Fine-tune [1309/100000]  val_loss=-0.919821
Fine-tune [1310/100000]  val_loss=-0.870117
Fine-tune [1311/100000]  val_loss=-0.873212
Fine-tune [1312/100000]  val_loss=-0.885861
Fine-tune [1313/100000]  val_loss=-0.891088
Fine-tune [1314/100000]  val_loss=-0.900001
Fine-tune [1315/100000]  val_loss=-0.898008
Fine-tune [1316/100000]  val_loss=-0.881957
Fine-tune [1317/100000]  val_loss=-0.911437
Fine-tune [1318/100000]  val_loss=-0.915388
Fine-tune [1319/100000]  val_loss=-0.875230
Fine-tune [1320/100000]  val_loss=-0.893872
Fine-tune [1321/100000]  val_loss=-0.878746
Fine-tune [1322/100000]  val_loss=-0.862493
Fine-tune [1323/100000]  val_loss=-0.867699
Fine-tune [1324/100000]  val_loss=-0.888885
Fine-tune [1325/100000]  val_loss=-0.895299
Fine-tune [1326/100000]  val_loss=-0.912508
Fine-tune [1327/100000]  val_loss=-0.896888
Fine-tune [1328/100000]  val_loss=-0.920736
Fine-tune [1329/100000]  val_loss=-0.911461
Fine-tune [1330/100000]  val_loss=-0.901090
Fine-tune [1331/100000]  val_loss=-0.915301
Fine-tune [1332/100000]  val_loss=-0.891018
Fine-tune [1333/100000]  val_loss=-0.890386
Fine-tune [1334/100000]  val_loss=-0.882424
Fine-tune [1335/100000]  val_loss=-0.885695
Fine-tune [1336/100000]  val_loss=-0.855671
Fine-tune [1337/100000]  val_loss=-0.874745
Fine-tune [1338/100000]  val_loss=-0.903499
Fine-tune [1339/100000]  val_loss=-0.881222
Fine-tune [1340/100000]  val_loss=-0.888363
Fine-tune [1341/100000]  val_loss=-0.877792
Fine-tune [1342/100000]  val_loss=-0.894741
Fine-tune [1343/100000]  val_loss=-0.900060
Fine-tune [1344/100000]  val_loss=-0.874883
Fine-tune [1345/100000]  val_loss=-0.877628
Fine-tune [1346/100000]  val_loss=-0.873662
Fine-tune [1347/100000]  val_loss=-0.866509
Fine-tune [1348/100000]  val_loss=-0.862850
Fine-tune [1349/100000]  val_loss=-0.871896
Fine-tune [1350/100000]  val_loss=-0.874877
Fine-tune [1351/100000]  val_loss=-0.858807
Fine-tune [1352/100000]  val_loss=-0.869867
Fine-tune [1353/100000]  val_loss=-0.847173
Fine-tune [1354/100000]  val_loss=-0.854700
Fine-tune [1355/100000]  val_loss=-0.888703
Fine-tune [1356/100000]  val_loss=-0.893769
Fine-tune [1357/100000]  val_loss=-0.884689
Fine-tune [1358/100000]  val_loss=-0.877552
Fine-tune [1359/100000]  val_loss=-0.895611
Fine-tune [1360/100000]  val_loss=-0.907288
Fine-tune [1361/100000]  val_loss=-0.894519
Fine-tune [1362/100000]  val_loss=-0.893377
Fine-tune [1363/100000]  val_loss=-0.894382
Fine-tune [1364/100000]  val_loss=-0.894744
Fine-tune [1365/100000]  val_loss=-0.860807
Fine-tune [1366/100000]  val_loss=-0.873704
Fine-tune [1367/100000]  val_loss=-0.888517
Fine-tune [1368/100000]  val_loss=-0.907450
Fine-tune [1369/100000]  val_loss=-0.896629
Fine-tune [1370/100000]  val_loss=-0.884491
Fine-tune [1371/100000]  val_loss=-0.896482
Fine-tune [1372/100000]  val_loss=-0.889495
Fine-tune [1373/100000]  val_loss=-0.875001
Fine-tune [1374/100000]  val_loss=-0.852505
Fine-tune [1375/100000]  val_loss=-0.860706
Fine-tune [1376/100000]  val_loss=-0.904280
Fine-tune [1377/100000]  val_loss=-0.889953
Fine-tune [1378/100000]  val_loss=-0.883433
Fine-tune [1379/100000]  val_loss=-0.862197
Fine-tune [1380/100000]  val_loss=-0.876593
Fine-tune [1381/100000]  val_loss=-0.860415
Fine-tune [1382/100000]  val_loss=-0.846056
Fine-tune [1383/100000]  val_loss=-0.857589
Fine-tune [1384/100000]  val_loss=-0.887559
Fine-tune [1385/100000]  val_loss=-0.865507
Fine-tune [1386/100000]  val_loss=-0.869767
Fine-tune [1387/100000]  val_loss=-0.899365
Fine-tune [1388/100000]  val_loss=-0.881231
Fine-tune [1389/100000]  val_loss=-0.872336
Fine-tune [1390/100000]  val_loss=-0.860068
Fine-tune [1391/100000]  val_loss=-0.871404
Fine-tune [1392/100000]  val_loss=-0.890531
Fine-tune [1393/100000]  val_loss=-0.891247
Fine-tune [1394/100000]  val_loss=-0.879837
Fine-tune [1395/100000]  val_loss=-0.887836
Fine-tune [1396/100000]  val_loss=-0.895334
Fine-tune [1397/100000]  val_loss=-0.862407
Fine-tune [1398/100000]  val_loss=-0.861244
Fine-tune [1399/100000]  val_loss=-0.857545
Fine-tune [1400/100000]  val_loss=-0.859597
Fine-tune [1401/100000]  val_loss=-0.879772
Fine-tune [1402/100000]  val_loss=-0.862027
Fine-tune [1403/100000]  val_loss=-0.894887
Fine-tune [1404/100000]  val_loss=-0.868739
  -> 验证未改进 1000 次，早停。
[FINETUNE] 最佳验证损失=-1.008241 已保存。

--- 评估 [HD128_L4] ---

=== 本次试验参数 (Run Config) ===
opamp             : two_stage_opamp
hidden_dim        : 128
num_layers        : 4
lr_pretrain       : 0.003
epochs_pretrain   : 1000
patience_pretrain : 200
lr_finetune       : 0.0038
epochs_finetune   : 100000
patience_finetune : 1000
batch_a           : 128
batch_b           : 64
dropout_rate      : 0.2
alpha_r2          : 0.0
lambda_coral      : 0.1
seed              : 42
device            : cpu

--- [评估阶段] 开始计算指标 ---

=== 目标域验证集指标（物理单位）===
slewrate_pos    MSE=1.417e+14  MAE=8.835e+06  R2=0.6696
dc_gain         MSE=2.645e+07  MAE=1534  R2=0.3209
ugf             MSE=1.196e+14  MAE=6.554e+06  R2=0.7297
phase_margin    MSE=190.5  MAE=10.37  R2=0.8340
cmrr            MSE=8.251e+11  MAE=8.957e+04  R2=0.0474

Avg  (all dims)   MSE=5.242e+13  MAE=3.096e+06  R2=0.5203
[OK] HD128_L4 -> r2_avg=0.5203, mae_avg=3.096e+06, mse_avg=5.242e+13
===== [HD128_L4] 训练完成 =====

===== [HD256_L2] 训练开始 =====

--- [阶段一] Backbone 预训练 (source_train / source_val, HuberLoss) ---
Pretrain [1/1000]  train=0.248168  val=0.202441
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [2/1000]  train=0.190006  val=0.169994
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [3/1000]  train=0.167537  val=0.158106
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [4/1000]  train=0.155356  val=0.144717
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [5/1000]  train=0.147799  val=0.137316
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [6/1000]  train=0.140130  val=0.128392
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [7/1000]  train=0.131452  val=0.127951
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [8/1000]  train=0.127384  val=0.120817
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [9/1000]  train=0.120971  val=0.117893
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [10/1000]  train=0.119741  val=0.116855
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [11/1000]  train=0.116407  val=0.110895
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [12/1000]  train=0.113640  val=0.109198
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [13/1000]  train=0.110180  val=0.108774
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [14/1000]  train=0.110359  val=0.109581
Pretrain [15/1000]  train=0.108332  val=0.107880
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [16/1000]  train=0.106994  val=0.112341
Pretrain [17/1000]  train=0.103729  val=0.104408
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [18/1000]  train=0.100626  val=0.100277
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [19/1000]  train=0.099958  val=0.101158
Pretrain [20/1000]  train=0.100248  val=0.099453
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [21/1000]  train=0.100839  val=0.102348
Pretrain [22/1000]  train=0.098450  val=0.102590
Pretrain [23/1000]  train=0.097813  val=0.098490
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [24/1000]  train=0.096930  val=0.099829
Pretrain [25/1000]  train=0.094145  val=0.097247
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [26/1000]  train=0.092682  val=0.097561
Pretrain [27/1000]  train=0.093617  val=0.100630
Pretrain [28/1000]  train=0.093521  val=0.096116
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [29/1000]  train=0.091633  val=0.095029
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [30/1000]  train=0.090179  val=0.095857
Pretrain [31/1000]  train=0.089825  val=0.094188
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [32/1000]  train=0.090168  val=0.103641
Pretrain [33/1000]  train=0.090601  val=0.094404
Pretrain [34/1000]  train=0.089239  val=0.097119
Pretrain [35/1000]  train=0.089735  val=0.094712
Pretrain [36/1000]  train=0.089597  val=0.095664
Pretrain [37/1000]  train=0.087092  val=0.093844
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [38/1000]  train=0.086362  val=0.093270
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [39/1000]  train=0.086777  val=0.098937
Pretrain [40/1000]  train=0.084759  val=0.096831
Pretrain [41/1000]  train=0.087433  val=0.092759
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [42/1000]  train=0.086244  val=0.095952
Pretrain [43/1000]  train=0.085660  val=0.093071
Pretrain [44/1000]  train=0.084940  val=0.094522
Pretrain [45/1000]  train=0.083286  val=0.092722
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [46/1000]  train=0.083518  val=0.095843
Pretrain [47/1000]  train=0.081902  val=0.093981
Pretrain [48/1000]  train=0.082657  val=0.094230
Pretrain [49/1000]  train=0.080969  val=0.089341
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [50/1000]  train=0.079994  val=0.092961
Pretrain [51/1000]  train=0.081113  val=0.091177
Pretrain [52/1000]  train=0.079699  val=0.093368
Pretrain [53/1000]  train=0.080599  val=0.092763
Pretrain [54/1000]  train=0.078890  val=0.093608
Pretrain [55/1000]  train=0.079355  val=0.090453
Pretrain [56/1000]  train=0.079293  val=0.093571
Pretrain [57/1000]  train=0.078843  val=0.090360
Pretrain [58/1000]  train=0.077101  val=0.095367
Pretrain [59/1000]  train=0.078843  val=0.092191
Pretrain [60/1000]  train=0.077030  val=0.094654
Pretrain [61/1000]  train=0.074922  val=0.090539
Pretrain [62/1000]  train=0.076808  val=0.089480
Pretrain [63/1000]  train=0.076160  val=0.092847
Pretrain [64/1000]  train=0.074380  val=0.091352
Pretrain [65/1000]  train=0.074799  val=0.092376
Pretrain [66/1000]  train=0.074652  val=0.093390
Pretrain [67/1000]  train=0.074981  val=0.088553
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [68/1000]  train=0.073459  val=0.090761
Pretrain [69/1000]  train=0.074023  val=0.090299
Pretrain [70/1000]  train=0.072711  val=0.089460
Pretrain [71/1000]  train=0.073820  val=0.089280
Pretrain [72/1000]  train=0.072835  val=0.090190
Pretrain [73/1000]  train=0.073681  val=0.089220
Pretrain [74/1000]  train=0.075010  val=0.093193
Pretrain [75/1000]  train=0.070934  val=0.091576
Pretrain [76/1000]  train=0.072718  val=0.090590
Pretrain [77/1000]  train=0.070816  val=0.092923
Pretrain [78/1000]  train=0.070894  val=0.088570
Pretrain [79/1000]  train=0.069313  val=0.089155
Pretrain [80/1000]  train=0.067919  val=0.089258
Pretrain [81/1000]  train=0.069031  val=0.090446
Pretrain [82/1000]  train=0.069232  val=0.090582
Pretrain [83/1000]  train=0.068197  val=0.088118
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [84/1000]  train=0.068332  val=0.089350
Pretrain [85/1000]  train=0.070108  val=0.089114
Pretrain [86/1000]  train=0.069890  val=0.087377
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [87/1000]  train=0.068602  val=0.090611
Pretrain [88/1000]  train=0.067808  val=0.088926
Pretrain [89/1000]  train=0.066507  val=0.088905
Pretrain [90/1000]  train=0.066590  val=0.090114
Pretrain [91/1000]  train=0.066299  val=0.089941
Pretrain [92/1000]  train=0.068285  val=0.089646
Pretrain [93/1000]  train=0.065939  val=0.088979
Pretrain [94/1000]  train=0.067715  val=0.088099
Pretrain [95/1000]  train=0.066260  val=0.088766
Pretrain [96/1000]  train=0.066112  val=0.089034
Pretrain [97/1000]  train=0.066023  val=0.089805
Pretrain [98/1000]  train=0.064950  val=0.086968
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [99/1000]  train=0.064612  val=0.087267
Pretrain [100/1000]  train=0.065034  val=0.087657
Pretrain [101/1000]  train=0.064109  val=0.085454
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/pretrained.pth
Pretrain [102/1000]  train=0.062626  val=0.090218
Pretrain [103/1000]  train=0.063209  val=0.089558
Pretrain [104/1000]  train=0.064093  val=0.087708
Pretrain [105/1000]  train=0.062959  val=0.090581
Pretrain [106/1000]  train=0.062852  val=0.087701
Pretrain [107/1000]  train=0.062613  val=0.086977
Pretrain [108/1000]  train=0.062874  val=0.087021
Pretrain [109/1000]  train=0.063058  val=0.089779
Pretrain [110/1000]  train=0.063248  val=0.087970
Pretrain [111/1000]  train=0.061442  val=0.088569
Pretrain [112/1000]  train=0.061440  val=0.089165
Pretrain [113/1000]  train=0.062006  val=0.090103
Pretrain [114/1000]  train=0.060173  val=0.087189
Pretrain [115/1000]  train=0.060577  val=0.088158
Pretrain [116/1000]  train=0.060401  val=0.089150
Pretrain [117/1000]  train=0.060142  val=0.086874
Pretrain [118/1000]  train=0.060744  val=0.088628
Pretrain [119/1000]  train=0.059257  val=0.087088
Pretrain [120/1000]  train=0.060809  val=0.088972
Pretrain [121/1000]  train=0.059140  val=0.087707
Pretrain [122/1000]  train=0.058200  val=0.089145
Pretrain [123/1000]  train=0.058989  val=0.088660
Pretrain [124/1000]  train=0.058662  val=0.087533
Pretrain [125/1000]  train=0.057553  val=0.088221
Pretrain [126/1000]  train=0.060016  val=0.087207
Pretrain [127/1000]  train=0.058499  val=0.087468
Pretrain [128/1000]  train=0.058111  val=0.087325
Pretrain [129/1000]  train=0.057792  val=0.085972
Pretrain [130/1000]  train=0.058781  val=0.087683
Pretrain [131/1000]  train=0.059706  val=0.088236
Pretrain [132/1000]  train=0.056787  val=0.087758
Pretrain [133/1000]  train=0.058006  val=0.088569
Pretrain [134/1000]  train=0.056151  val=0.089010
Pretrain [135/1000]  train=0.055917  val=0.086973
Pretrain [136/1000]  train=0.057014  val=0.087969
Pretrain [137/1000]  train=0.056518  val=0.086591
Pretrain [138/1000]  train=0.056091  val=0.086935
Pretrain [139/1000]  train=0.055732  val=0.086912
Pretrain [140/1000]  train=0.056002  val=0.085982
Pretrain [141/1000]  train=0.056166  val=0.088827
Pretrain [142/1000]  train=0.055974  val=0.088206
Pretrain [143/1000]  train=0.055596  val=0.087517
Pretrain [144/1000]  train=0.055288  val=0.088151
Pretrain [145/1000]  train=0.054437  val=0.086710
Pretrain [146/1000]  train=0.056581  val=0.087176
Pretrain [147/1000]  train=0.055089  val=0.087121
Pretrain [148/1000]  train=0.056072  val=0.088730
Pretrain [149/1000]  train=0.054587  val=0.086741
Pretrain [150/1000]  train=0.055668  val=0.087470
Pretrain [151/1000]  train=0.055472  val=0.087896
Pretrain [152/1000]  train=0.054691  val=0.086548
Pretrain [153/1000]  train=0.053896  val=0.087816
Pretrain [154/1000]  train=0.053560  val=0.087055
Pretrain [155/1000]  train=0.055294  val=0.086838
Pretrain [156/1000]  train=0.054043  val=0.087168
Pretrain [157/1000]  train=0.054723  val=0.086639
Pretrain [158/1000]  train=0.053723  val=0.087259
Pretrain [159/1000]  train=0.052832  val=0.086832
Pretrain [160/1000]  train=0.054654  val=0.087218
Pretrain [161/1000]  train=0.053262  val=0.087749
Pretrain [162/1000]  train=0.053353  val=0.087584
Pretrain [163/1000]  train=0.052349  val=0.087198
Pretrain [164/1000]  train=0.053329  val=0.087545
Pretrain [165/1000]  train=0.052029  val=0.087315
Pretrain [166/1000]  train=0.052094  val=0.087397
Pretrain [167/1000]  train=0.053030  val=0.086682
Pretrain [168/1000]  train=0.053362  val=0.086863
Pretrain [169/1000]  train=0.053119  val=0.086938
Pretrain [170/1000]  train=0.051177  val=0.087891
Pretrain [171/1000]  train=0.053034  val=0.086964
Pretrain [172/1000]  train=0.052554  val=0.087305
Pretrain [173/1000]  train=0.051673  val=0.087781
Pretrain [174/1000]  train=0.052286  val=0.087101
Pretrain [175/1000]  train=0.052842  val=0.087215
Pretrain [176/1000]  train=0.052396  val=0.086831
Pretrain [177/1000]  train=0.052404  val=0.087116
Pretrain [178/1000]  train=0.052440  val=0.087050
Pretrain [179/1000]  train=0.052150  val=0.087012
Pretrain [180/1000]  train=0.051382  val=0.086778
Pretrain [181/1000]  train=0.053228  val=0.086860
Pretrain [182/1000]  train=0.051622  val=0.086704
Pretrain [183/1000]  train=0.052491  val=0.086774
Pretrain [184/1000]  train=0.052718  val=0.087183
Pretrain [185/1000]  train=0.051719  val=0.087117
Pretrain [186/1000]  train=0.051551  val=0.087126
Pretrain [187/1000]  train=0.053866  val=0.086966
Pretrain [188/1000]  train=0.051492  val=0.086962
Pretrain [189/1000]  train=0.051414  val=0.087111
Pretrain [190/1000]  train=0.051324  val=0.086941
Pretrain [191/1000]  train=0.051973  val=0.087085
Pretrain [192/1000]  train=0.050337  val=0.087110
Pretrain [193/1000]  train=0.052918  val=0.087102
Pretrain [194/1000]  train=0.053494  val=0.087096
Pretrain [195/1000]  train=0.052516  val=0.087068
Pretrain [196/1000]  train=0.052072  val=0.087096
Pretrain [197/1000]  train=0.052469  val=0.087068
Pretrain [198/1000]  train=0.051992  val=0.087065
Pretrain [199/1000]  train=0.051824  val=0.087066
Pretrain [200/1000]  train=0.051651  val=0.087066
Pretrain [201/1000]  train=0.064420  val=0.096875
Pretrain [202/1000]  train=0.073040  val=0.093867
Pretrain [203/1000]  train=0.070349  val=0.095424
Pretrain [204/1000]  train=0.072102  val=0.096307
Pretrain [205/1000]  train=0.071174  val=0.093964
Pretrain [206/1000]  train=0.069055  val=0.091198
Pretrain [207/1000]  train=0.069186  val=0.092935
Pretrain [208/1000]  train=0.070114  val=0.092440
Pretrain [209/1000]  train=0.070510  val=0.095177
Pretrain [210/1000]  train=0.071107  val=0.094442
Pretrain [211/1000]  train=0.070304  val=0.093190
Pretrain [212/1000]  train=0.069129  val=0.093831
Pretrain [213/1000]  train=0.069054  val=0.094237
Pretrain [214/1000]  train=0.068496  val=0.096690
Pretrain [215/1000]  train=0.067940  val=0.093011
Pretrain [216/1000]  train=0.067826  val=0.094570
Pretrain [217/1000]  train=0.067071  val=0.091361
Pretrain [218/1000]  train=0.068744  val=0.096463
Pretrain [219/1000]  train=0.066026  val=0.092725
Pretrain [220/1000]  train=0.068767  val=0.093086
Pretrain [221/1000]  train=0.067596  val=0.095187
Pretrain [222/1000]  train=0.067398  val=0.091130
Pretrain [223/1000]  train=0.065583  val=0.092678
Pretrain [224/1000]  train=0.069219  val=0.093551
Pretrain [225/1000]  train=0.065611  val=0.096125
Pretrain [226/1000]  train=0.066191  val=0.092808
Pretrain [227/1000]  train=0.065741  val=0.092445
Pretrain [228/1000]  train=0.067093  val=0.099377
Pretrain [229/1000]  train=0.066804  val=0.092556
Pretrain [230/1000]  train=0.063806  val=0.095900
Pretrain [231/1000]  train=0.064584  val=0.093395
Pretrain [232/1000]  train=0.063883  val=0.092042
Pretrain [233/1000]  train=0.065205  val=0.090764
Pretrain [234/1000]  train=0.066709  val=0.091532
Pretrain [235/1000]  train=0.064976  val=0.093092
Pretrain [236/1000]  train=0.063815  val=0.093869
Pretrain [237/1000]  train=0.063173  val=0.092664
Pretrain [238/1000]  train=0.064316  val=0.093178
Pretrain [239/1000]  train=0.063275  val=0.093598
Pretrain [240/1000]  train=0.061626  val=0.092526
Pretrain [241/1000]  train=0.064600  val=0.090891
Pretrain [242/1000]  train=0.065106  val=0.091999
Pretrain [243/1000]  train=0.061431  val=0.092976
Pretrain [244/1000]  train=0.062028  val=0.095483
Pretrain [245/1000]  train=0.062562  val=0.089515
Pretrain [246/1000]  train=0.062225  val=0.094315
Pretrain [247/1000]  train=0.060821  val=0.093028
Pretrain [248/1000]  train=0.061083  val=0.093124
Pretrain [249/1000]  train=0.063534  val=0.092436
Pretrain [250/1000]  train=0.060959  val=0.091953
Pretrain [251/1000]  train=0.059236  val=0.093436
Pretrain [252/1000]  train=0.060704  val=0.091782
Pretrain [253/1000]  train=0.059638  val=0.092821
Pretrain [254/1000]  train=0.060137  val=0.092560
Pretrain [255/1000]  train=0.060995  val=0.092381
Pretrain [256/1000]  train=0.060020  val=0.090609
Pretrain [257/1000]  train=0.059566  val=0.092961
Pretrain [258/1000]  train=0.060299  val=0.096069
Pretrain [259/1000]  train=0.059777  val=0.091525
Pretrain [260/1000]  train=0.059195  val=0.092545
Pretrain [261/1000]  train=0.060577  val=0.094792
Pretrain [262/1000]  train=0.058725  val=0.094076
Pretrain [263/1000]  train=0.058773  val=0.092087
Pretrain [264/1000]  train=0.058362  val=0.092557
Pretrain [265/1000]  train=0.057483  val=0.095817
Pretrain [266/1000]  train=0.059964  val=0.091298
Pretrain [267/1000]  train=0.059273  val=0.091305
Pretrain [268/1000]  train=0.058748  val=0.092298
Pretrain [269/1000]  train=0.058767  val=0.090422
Pretrain [270/1000]  train=0.059115  val=0.090968
Pretrain [271/1000]  train=0.056237  val=0.092255
Pretrain [272/1000]  train=0.057083  val=0.091455
Pretrain [273/1000]  train=0.058062  val=0.091837
Pretrain [274/1000]  train=0.055689  val=0.090344
Pretrain [275/1000]  train=0.056553  val=0.091237
Pretrain [276/1000]  train=0.057449  val=0.092678
Pretrain [277/1000]  train=0.057563  val=0.090579
Pretrain [278/1000]  train=0.055372  val=0.091231
Pretrain [279/1000]  train=0.055321  val=0.090560
Pretrain [280/1000]  train=0.056538  val=0.093409
Pretrain [281/1000]  train=0.056685  val=0.092801
Pretrain [282/1000]  train=0.054683  val=0.091041
Pretrain [283/1000]  train=0.054128  val=0.091587
Pretrain [284/1000]  train=0.054534  val=0.093022
Pretrain [285/1000]  train=0.054874  val=0.089797
Pretrain [286/1000]  train=0.054540  val=0.090097
Pretrain [287/1000]  train=0.053998  val=0.089704
Pretrain [288/1000]  train=0.054096  val=0.094081
Pretrain [289/1000]  train=0.054772  val=0.091964
Pretrain [290/1000]  train=0.054745  val=0.092890
Pretrain [291/1000]  train=0.053221  val=0.091809
Pretrain [292/1000]  train=0.052946  val=0.092880
Pretrain [293/1000]  train=0.054036  val=0.090312
Pretrain [294/1000]  train=0.054260  val=0.093190
Pretrain [295/1000]  train=0.054460  val=0.090726
Pretrain [296/1000]  train=0.051283  val=0.090584
Pretrain [297/1000]  train=0.053006  val=0.090359
Pretrain [298/1000]  train=0.053630  val=0.090100
Pretrain [299/1000]  train=0.052990  val=0.093701
Pretrain [300/1000]  train=0.052491  val=0.091112
Pretrain [301/1000]  train=0.052234  val=0.091826
  -> 验证未改进 200 次，早停。
[PRETRAIN] 最佳 val=0.085454 已保存。

--- [阶段二] 对齐微调 (NLL + α·(1−R2) + λ·CORAL) ---
Fine-tune [1/100000]  val_loss=0.341986
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [2/100000]  val_loss=0.183255
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [3/100000]  val_loss=0.048071
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [4/100000]  val_loss=-0.057881
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [5/100000]  val_loss=-0.145354
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [6/100000]  val_loss=-0.226510
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [7/100000]  val_loss=-0.300083
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [8/100000]  val_loss=-0.355634
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [9/100000]  val_loss=-0.394877
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [10/100000]  val_loss=-0.441723
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [11/100000]  val_loss=-0.473157
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [12/100000]  val_loss=-0.500038
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [13/100000]  val_loss=-0.523334
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [14/100000]  val_loss=-0.538766
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [15/100000]  val_loss=-0.569071
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [16/100000]  val_loss=-0.589454
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [17/100000]  val_loss=-0.600579
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [18/100000]  val_loss=-0.617638
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [19/100000]  val_loss=-0.621509
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [20/100000]  val_loss=-0.641771
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [21/100000]  val_loss=-0.644279
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [22/100000]  val_loss=-0.651229
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [23/100000]  val_loss=-0.665536
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [24/100000]  val_loss=-0.672463
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [25/100000]  val_loss=-0.684121
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [26/100000]  val_loss=-0.683764
Fine-tune [27/100000]  val_loss=-0.688806
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [28/100000]  val_loss=-0.702355
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [29/100000]  val_loss=-0.715549
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [30/100000]  val_loss=-0.726716
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [31/100000]  val_loss=-0.732949
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [32/100000]  val_loss=-0.737791
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [33/100000]  val_loss=-0.731884
Fine-tune [34/100000]  val_loss=-0.720676
Fine-tune [35/100000]  val_loss=-0.743282
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [36/100000]  val_loss=-0.746304
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [37/100000]  val_loss=-0.766878
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [38/100000]  val_loss=-0.767807
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [39/100000]  val_loss=-0.774456
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [40/100000]  val_loss=-0.764358
Fine-tune [41/100000]  val_loss=-0.779232
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [42/100000]  val_loss=-0.784700
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [43/100000]  val_loss=-0.793043
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [44/100000]  val_loss=-0.789204
Fine-tune [45/100000]  val_loss=-0.788971
Fine-tune [46/100000]  val_loss=-0.803010
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [47/100000]  val_loss=-0.805932
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [48/100000]  val_loss=-0.819477
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [49/100000]  val_loss=-0.812718
Fine-tune [50/100000]  val_loss=-0.830181
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [51/100000]  val_loss=-0.833684
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [52/100000]  val_loss=-0.833735
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [53/100000]  val_loss=-0.837804
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [54/100000]  val_loss=-0.830091
Fine-tune [55/100000]  val_loss=-0.844308
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [56/100000]  val_loss=-0.829312
Fine-tune [57/100000]  val_loss=-0.845722
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [58/100000]  val_loss=-0.849997
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [59/100000]  val_loss=-0.837311
Fine-tune [60/100000]  val_loss=-0.855114
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [61/100000]  val_loss=-0.860376
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [62/100000]  val_loss=-0.852692
Fine-tune [63/100000]  val_loss=-0.871639
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [64/100000]  val_loss=-0.846107
Fine-tune [65/100000]  val_loss=-0.857520
Fine-tune [66/100000]  val_loss=-0.862520
Fine-tune [67/100000]  val_loss=-0.864205
Fine-tune [68/100000]  val_loss=-0.881198
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [69/100000]  val_loss=-0.883150
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [70/100000]  val_loss=-0.886031
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [71/100000]  val_loss=-0.900471
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [72/100000]  val_loss=-0.892142
Fine-tune [73/100000]  val_loss=-0.899369
Fine-tune [74/100000]  val_loss=-0.902721
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [75/100000]  val_loss=-0.909735
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [76/100000]  val_loss=-0.902904
Fine-tune [77/100000]  val_loss=-0.909644
Fine-tune [78/100000]  val_loss=-0.926994
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [79/100000]  val_loss=-0.916321
Fine-tune [80/100000]  val_loss=-0.922921
Fine-tune [81/100000]  val_loss=-0.912159
Fine-tune [82/100000]  val_loss=-0.921809
Fine-tune [83/100000]  val_loss=-0.914524
Fine-tune [84/100000]  val_loss=-0.916154
Fine-tune [85/100000]  val_loss=-0.908870
Fine-tune [86/100000]  val_loss=-0.933417
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [87/100000]  val_loss=-0.919540
Fine-tune [88/100000]  val_loss=-0.935200
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [89/100000]  val_loss=-0.922040
Fine-tune [90/100000]  val_loss=-0.923481
Fine-tune [91/100000]  val_loss=-0.938058
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [92/100000]  val_loss=-0.931763
Fine-tune [93/100000]  val_loss=-0.938371
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [94/100000]  val_loss=-0.957617
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [95/100000]  val_loss=-0.953759
Fine-tune [96/100000]  val_loss=-0.953284
Fine-tune [97/100000]  val_loss=-0.965178
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [98/100000]  val_loss=-0.952780
Fine-tune [99/100000]  val_loss=-0.948240
Fine-tune [100/100000]  val_loss=-0.950707
Fine-tune [101/100000]  val_loss=-0.962391
Fine-tune [102/100000]  val_loss=-0.950819
Fine-tune [103/100000]  val_loss=-0.966086
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [104/100000]  val_loss=-0.961136
Fine-tune [105/100000]  val_loss=-0.932370
Fine-tune [106/100000]  val_loss=-0.957068
Fine-tune [107/100000]  val_loss=-0.961693
Fine-tune [108/100000]  val_loss=-0.970080
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [109/100000]  val_loss=-0.967373
Fine-tune [110/100000]  val_loss=-0.976306
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [111/100000]  val_loss=-0.972715
Fine-tune [112/100000]  val_loss=-0.953536
Fine-tune [113/100000]  val_loss=-0.970822
Fine-tune [114/100000]  val_loss=-0.967877
Fine-tune [115/100000]  val_loss=-0.958820
Fine-tune [116/100000]  val_loss=-0.962922
Fine-tune [117/100000]  val_loss=-0.960785
Fine-tune [118/100000]  val_loss=-0.965925
Fine-tune [119/100000]  val_loss=-0.969247
Fine-tune [120/100000]  val_loss=-0.971179
Fine-tune [121/100000]  val_loss=-0.969620
Fine-tune [122/100000]  val_loss=-0.974241
Fine-tune [123/100000]  val_loss=-0.955572
Fine-tune [124/100000]  val_loss=-0.960843
Fine-tune [125/100000]  val_loss=-0.988271
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [126/100000]  val_loss=-0.984286
Fine-tune [127/100000]  val_loss=-0.984972
Fine-tune [128/100000]  val_loss=-0.970685
Fine-tune [129/100000]  val_loss=-0.967484
Fine-tune [130/100000]  val_loss=-0.975835
Fine-tune [131/100000]  val_loss=-0.958597
Fine-tune [132/100000]  val_loss=-0.983055
Fine-tune [133/100000]  val_loss=-0.983189
Fine-tune [134/100000]  val_loss=-0.985806
Fine-tune [135/100000]  val_loss=-0.975463
Fine-tune [136/100000]  val_loss=-0.971314
Fine-tune [137/100000]  val_loss=-0.983386
Fine-tune [138/100000]  val_loss=-0.986317
Fine-tune [139/100000]  val_loss=-0.970965
Fine-tune [140/100000]  val_loss=-0.974854
Fine-tune [141/100000]  val_loss=-0.982419
Fine-tune [142/100000]  val_loss=-0.991232
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [143/100000]  val_loss=-0.987714
Fine-tune [144/100000]  val_loss=-0.983725
Fine-tune [145/100000]  val_loss=-0.989767
Fine-tune [146/100000]  val_loss=-0.979719
Fine-tune [147/100000]  val_loss=-0.977964
Fine-tune [148/100000]  val_loss=-0.966764
Fine-tune [149/100000]  val_loss=-0.983980
Fine-tune [150/100000]  val_loss=-0.985457
Fine-tune [151/100000]  val_loss=-0.986229
Fine-tune [152/100000]  val_loss=-0.995204
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [153/100000]  val_loss=-1.006648
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [154/100000]  val_loss=-1.005571
Fine-tune [155/100000]  val_loss=-0.991332
Fine-tune [156/100000]  val_loss=-0.988259
Fine-tune [157/100000]  val_loss=-0.987150
Fine-tune [158/100000]  val_loss=-1.005080
Fine-tune [159/100000]  val_loss=-0.992638
Fine-tune [160/100000]  val_loss=-0.993017
Fine-tune [161/100000]  val_loss=-0.985771
Fine-tune [162/100000]  val_loss=-1.000167
Fine-tune [163/100000]  val_loss=-0.983680
Fine-tune [164/100000]  val_loss=-0.984105
Fine-tune [165/100000]  val_loss=-0.991033
Fine-tune [166/100000]  val_loss=-0.980896
Fine-tune [167/100000]  val_loss=-0.988429
Fine-tune [168/100000]  val_loss=-0.986978
Fine-tune [169/100000]  val_loss=-0.990478
Fine-tune [170/100000]  val_loss=-0.993144
Fine-tune [171/100000]  val_loss=-0.978974
Fine-tune [172/100000]  val_loss=-0.986909
Fine-tune [173/100000]  val_loss=-0.989577
Fine-tune [174/100000]  val_loss=-1.004466
Fine-tune [175/100000]  val_loss=-1.002953
Fine-tune [176/100000]  val_loss=-0.992505
Fine-tune [177/100000]  val_loss=-0.964052
Fine-tune [178/100000]  val_loss=-0.994126
Fine-tune [179/100000]  val_loss=-0.987568
Fine-tune [180/100000]  val_loss=-0.988945
Fine-tune [181/100000]  val_loss=-0.988005
Fine-tune [182/100000]  val_loss=-0.994976
Fine-tune [183/100000]  val_loss=-0.996766
Fine-tune [184/100000]  val_loss=-0.988423
Fine-tune [185/100000]  val_loss=-0.993610
Fine-tune [186/100000]  val_loss=-0.997754
Fine-tune [187/100000]  val_loss=-0.989765
Fine-tune [188/100000]  val_loss=-0.994493
Fine-tune [189/100000]  val_loss=-1.000846
Fine-tune [190/100000]  val_loss=-1.002267
Fine-tune [191/100000]  val_loss=-1.004909
Fine-tune [192/100000]  val_loss=-0.999228
Fine-tune [193/100000]  val_loss=-0.999763
Fine-tune [194/100000]  val_loss=-1.007588
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [195/100000]  val_loss=-1.014765
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [196/100000]  val_loss=-1.001355
Fine-tune [197/100000]  val_loss=-1.003915
Fine-tune [198/100000]  val_loss=-1.011713
Fine-tune [199/100000]  val_loss=-1.006762
Fine-tune [200/100000]  val_loss=-1.002473
Fine-tune [201/100000]  val_loss=-1.011368
Fine-tune [202/100000]  val_loss=-0.992660
Fine-tune [203/100000]  val_loss=-0.998039
Fine-tune [204/100000]  val_loss=-0.996514
Fine-tune [205/100000]  val_loss=-0.998337
Fine-tune [206/100000]  val_loss=-1.002891
Fine-tune [207/100000]  val_loss=-0.991020
Fine-tune [208/100000]  val_loss=-0.991153
Fine-tune [209/100000]  val_loss=-0.992717
Fine-tune [210/100000]  val_loss=-1.013399
Fine-tune [211/100000]  val_loss=-1.007892
Fine-tune [212/100000]  val_loss=-1.015904
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [213/100000]  val_loss=-1.015560
Fine-tune [214/100000]  val_loss=-1.021237
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [215/100000]  val_loss=-1.010047
Fine-tune [216/100000]  val_loss=-1.001621
Fine-tune [217/100000]  val_loss=-1.003599
Fine-tune [218/100000]  val_loss=-0.986751
Fine-tune [219/100000]  val_loss=-1.001291
Fine-tune [220/100000]  val_loss=-1.002122
Fine-tune [221/100000]  val_loss=-0.998186
Fine-tune [222/100000]  val_loss=-1.007667
Fine-tune [223/100000]  val_loss=-1.006110
Fine-tune [224/100000]  val_loss=-1.001304
Fine-tune [225/100000]  val_loss=-1.006370
Fine-tune [226/100000]  val_loss=-0.998235
Fine-tune [227/100000]  val_loss=-1.009974
Fine-tune [228/100000]  val_loss=-1.009945
Fine-tune [229/100000]  val_loss=-1.003885
Fine-tune [230/100000]  val_loss=-0.992503
Fine-tune [231/100000]  val_loss=-1.001228
Fine-tune [232/100000]  val_loss=-1.001620
Fine-tune [233/100000]  val_loss=-0.998228
Fine-tune [234/100000]  val_loss=-1.005298
Fine-tune [235/100000]  val_loss=-1.004872
Fine-tune [236/100000]  val_loss=-1.010060
Fine-tune [237/100000]  val_loss=-1.001708
Fine-tune [238/100000]  val_loss=-1.000950
Fine-tune [239/100000]  val_loss=-1.001748
Fine-tune [240/100000]  val_loss=-1.012042
Fine-tune [241/100000]  val_loss=-1.005812
Fine-tune [242/100000]  val_loss=-0.998362
Fine-tune [243/100000]  val_loss=-1.001497
Fine-tune [244/100000]  val_loss=-1.001871
Fine-tune [245/100000]  val_loss=-0.999449
Fine-tune [246/100000]  val_loss=-1.010846
Fine-tune [247/100000]  val_loss=-0.997152
Fine-tune [248/100000]  val_loss=-0.994768
Fine-tune [249/100000]  val_loss=-1.004991
Fine-tune [250/100000]  val_loss=-1.000833
Fine-tune [251/100000]  val_loss=-1.014741
Fine-tune [252/100000]  val_loss=-1.009582
Fine-tune [253/100000]  val_loss=-1.001118
Fine-tune [254/100000]  val_loss=-0.997192
Fine-tune [255/100000]  val_loss=-1.003297
Fine-tune [256/100000]  val_loss=-0.998477
Fine-tune [257/100000]  val_loss=-1.001781
Fine-tune [258/100000]  val_loss=-1.009322
Fine-tune [259/100000]  val_loss=-0.993318
Fine-tune [260/100000]  val_loss=-0.999663
Fine-tune [261/100000]  val_loss=-1.007005
Fine-tune [262/100000]  val_loss=-1.009224
Fine-tune [263/100000]  val_loss=-1.005189
Fine-tune [264/100000]  val_loss=-0.990904
Fine-tune [265/100000]  val_loss=-1.008839
Fine-tune [266/100000]  val_loss=-1.005787
Fine-tune [267/100000]  val_loss=-0.997649
Fine-tune [268/100000]  val_loss=-0.993500
Fine-tune [269/100000]  val_loss=-0.980608
Fine-tune [270/100000]  val_loss=-0.997064
Fine-tune [271/100000]  val_loss=-1.007257
Fine-tune [272/100000]  val_loss=-1.010291
Fine-tune [273/100000]  val_loss=-1.012556
Fine-tune [274/100000]  val_loss=-0.997886
Fine-tune [275/100000]  val_loss=-1.001506
Fine-tune [276/100000]  val_loss=-1.009331
Fine-tune [277/100000]  val_loss=-0.996188
Fine-tune [278/100000]  val_loss=-0.999766
Fine-tune [279/100000]  val_loss=-1.000830
Fine-tune [280/100000]  val_loss=-1.004949
Fine-tune [281/100000]  val_loss=-0.994967
Fine-tune [282/100000]  val_loss=-1.002496
Fine-tune [283/100000]  val_loss=-1.010001
Fine-tune [284/100000]  val_loss=-1.011044
Fine-tune [285/100000]  val_loss=-1.009259
Fine-tune [286/100000]  val_loss=-0.990839
Fine-tune [287/100000]  val_loss=-0.994522
Fine-tune [288/100000]  val_loss=-0.995566
Fine-tune [289/100000]  val_loss=-1.017306
Fine-tune [290/100000]  val_loss=-1.021401
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [291/100000]  val_loss=-1.019471
Fine-tune [292/100000]  val_loss=-1.011924
Fine-tune [293/100000]  val_loss=-1.003943
Fine-tune [294/100000]  val_loss=-1.005019
Fine-tune [295/100000]  val_loss=-1.007267
Fine-tune [296/100000]  val_loss=-1.019861
Fine-tune [297/100000]  val_loss=-1.008430
Fine-tune [298/100000]  val_loss=-1.008731
Fine-tune [299/100000]  val_loss=-1.004895
Fine-tune [300/100000]  val_loss=-1.012682
Fine-tune [301/100000]  val_loss=-1.015983
Fine-tune [302/100000]  val_loss=-0.993257
Fine-tune [303/100000]  val_loss=-1.016522
Fine-tune [304/100000]  val_loss=-1.007163
Fine-tune [305/100000]  val_loss=-0.998671
Fine-tune [306/100000]  val_loss=-1.018398
Fine-tune [307/100000]  val_loss=-1.004943
Fine-tune [308/100000]  val_loss=-1.005898
Fine-tune [309/100000]  val_loss=-1.000817
Fine-tune [310/100000]  val_loss=-1.014700
Fine-tune [311/100000]  val_loss=-1.010110
Fine-tune [312/100000]  val_loss=-1.011425
Fine-tune [313/100000]  val_loss=-1.010229
Fine-tune [314/100000]  val_loss=-1.009521
Fine-tune [315/100000]  val_loss=-1.015335
Fine-tune [316/100000]  val_loss=-1.026112
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L2/finetuned.pth
Fine-tune [317/100000]  val_loss=-1.015819
Fine-tune [318/100000]  val_loss=-1.024119
Fine-tune [319/100000]  val_loss=-1.005603
Fine-tune [320/100000]  val_loss=-0.998215
Fine-tune [321/100000]  val_loss=-1.010578
Fine-tune [322/100000]  val_loss=-0.997993
Fine-tune [323/100000]  val_loss=-1.008562
Fine-tune [324/100000]  val_loss=-1.013390
Fine-tune [325/100000]  val_loss=-1.010593
Fine-tune [326/100000]  val_loss=-1.007637
Fine-tune [327/100000]  val_loss=-0.991402
Fine-tune [328/100000]  val_loss=-0.990441
Fine-tune [329/100000]  val_loss=-1.018728
Fine-tune [330/100000]  val_loss=-1.002155
Fine-tune [331/100000]  val_loss=-1.011742
Fine-tune [332/100000]  val_loss=-1.009958
Fine-tune [333/100000]  val_loss=-0.997732
Fine-tune [334/100000]  val_loss=-1.004466
Fine-tune [335/100000]  val_loss=-1.005362
Fine-tune [336/100000]  val_loss=-1.000872
Fine-tune [337/100000]  val_loss=-0.994416
Fine-tune [338/100000]  val_loss=-0.989811
Fine-tune [339/100000]  val_loss=-0.986783
Fine-tune [340/100000]  val_loss=-0.995766
Fine-tune [341/100000]  val_loss=-1.009552
Fine-tune [342/100000]  val_loss=-0.992341
Fine-tune [343/100000]  val_loss=-0.998556
Fine-tune [344/100000]  val_loss=-1.000977
Fine-tune [345/100000]  val_loss=-0.987242
Fine-tune [346/100000]  val_loss=-0.991701
Fine-tune [347/100000]  val_loss=-0.984233
Fine-tune [348/100000]  val_loss=-0.990556
Fine-tune [349/100000]  val_loss=-0.992064
Fine-tune [350/100000]  val_loss=-1.000821
Fine-tune [351/100000]  val_loss=-0.987647
Fine-tune [352/100000]  val_loss=-0.981510
Fine-tune [353/100000]  val_loss=-0.997419
Fine-tune [354/100000]  val_loss=-1.011981
Fine-tune [355/100000]  val_loss=-1.000685
Fine-tune [356/100000]  val_loss=-0.992307
Fine-tune [357/100000]  val_loss=-0.981230
Fine-tune [358/100000]  val_loss=-1.007681
Fine-tune [359/100000]  val_loss=-1.009357
Fine-tune [360/100000]  val_loss=-0.995641
Fine-tune [361/100000]  val_loss=-0.981537
Fine-tune [362/100000]  val_loss=-0.979721
Fine-tune [363/100000]  val_loss=-0.999612
Fine-tune [364/100000]  val_loss=-1.008826
Fine-tune [365/100000]  val_loss=-1.005077
Fine-tune [366/100000]  val_loss=-0.999060
Fine-tune [367/100000]  val_loss=-1.013544
Fine-tune [368/100000]  val_loss=-0.997889
Fine-tune [369/100000]  val_loss=-0.999738
Fine-tune [370/100000]  val_loss=-0.990859
Fine-tune [371/100000]  val_loss=-0.999387
Fine-tune [372/100000]  val_loss=-1.004668
Fine-tune [373/100000]  val_loss=-1.002167
Fine-tune [374/100000]  val_loss=-0.994913
Fine-tune [375/100000]  val_loss=-0.988609
Fine-tune [376/100000]  val_loss=-1.015978
Fine-tune [377/100000]  val_loss=-1.005956
Fine-tune [378/100000]  val_loss=-1.004447
Fine-tune [379/100000]  val_loss=-0.990151
Fine-tune [380/100000]  val_loss=-0.981050
Fine-tune [381/100000]  val_loss=-1.009147
Fine-tune [382/100000]  val_loss=-1.002875
Fine-tune [383/100000]  val_loss=-1.006536
Fine-tune [384/100000]  val_loss=-0.993527
Fine-tune [385/100000]  val_loss=-1.009595
Fine-tune [386/100000]  val_loss=-0.988209
Fine-tune [387/100000]  val_loss=-0.982529
Fine-tune [388/100000]  val_loss=-0.993213
Fine-tune [389/100000]  val_loss=-0.991083
Fine-tune [390/100000]  val_loss=-0.989942
Fine-tune [391/100000]  val_loss=-0.982627
Fine-tune [392/100000]  val_loss=-0.974960
Fine-tune [393/100000]  val_loss=-0.995391
Fine-tune [394/100000]  val_loss=-0.998609
Fine-tune [395/100000]  val_loss=-0.985551
Fine-tune [396/100000]  val_loss=-0.968094
Fine-tune [397/100000]  val_loss=-0.987014
Fine-tune [398/100000]  val_loss=-0.984842
Fine-tune [399/100000]  val_loss=-0.988541
Fine-tune [400/100000]  val_loss=-0.978816
Fine-tune [401/100000]  val_loss=-0.983503
Fine-tune [402/100000]  val_loss=-0.969184
Fine-tune [403/100000]  val_loss=-0.957710
Fine-tune [404/100000]  val_loss=-0.964818
Fine-tune [405/100000]  val_loss=-0.973233
Fine-tune [406/100000]  val_loss=-0.980252
Fine-tune [407/100000]  val_loss=-0.971348
Fine-tune [408/100000]  val_loss=-0.971621
Fine-tune [409/100000]  val_loss=-0.953872
Fine-tune [410/100000]  val_loss=-0.965244
Fine-tune [411/100000]  val_loss=-0.969195
Fine-tune [412/100000]  val_loss=-0.972142
Fine-tune [413/100000]  val_loss=-0.969578
Fine-tune [414/100000]  val_loss=-0.972396
Fine-tune [415/100000]  val_loss=-0.977283
Fine-tune [416/100000]  val_loss=-0.979742
Fine-tune [417/100000]  val_loss=-0.975481
Fine-tune [418/100000]  val_loss=-0.963721
Fine-tune [419/100000]  val_loss=-0.975903
Fine-tune [420/100000]  val_loss=-0.979903
Fine-tune [421/100000]  val_loss=-0.973062
Fine-tune [422/100000]  val_loss=-0.978764
Fine-tune [423/100000]  val_loss=-0.989825
Fine-tune [424/100000]  val_loss=-0.983767
Fine-tune [425/100000]  val_loss=-0.992428
Fine-tune [426/100000]  val_loss=-1.009948
Fine-tune [427/100000]  val_loss=-0.999207
Fine-tune [428/100000]  val_loss=-0.992249
Fine-tune [429/100000]  val_loss=-0.996416
Fine-tune [430/100000]  val_loss=-0.990411
Fine-tune [431/100000]  val_loss=-0.993833
Fine-tune [432/100000]  val_loss=-0.996010
Fine-tune [433/100000]  val_loss=-0.988968
Fine-tune [434/100000]  val_loss=-1.001569
Fine-tune [435/100000]  val_loss=-1.001230
Fine-tune [436/100000]  val_loss=-0.967829
Fine-tune [437/100000]  val_loss=-0.961298
Fine-tune [438/100000]  val_loss=-0.955844
Fine-tune [439/100000]  val_loss=-0.952074
Fine-tune [440/100000]  val_loss=-0.981529
Fine-tune [441/100000]  val_loss=-0.983674
Fine-tune [442/100000]  val_loss=-0.967609
Fine-tune [443/100000]  val_loss=-0.962139
Fine-tune [444/100000]  val_loss=-0.968040
Fine-tune [445/100000]  val_loss=-0.955257
Fine-tune [446/100000]  val_loss=-0.970092
Fine-tune [447/100000]  val_loss=-0.969818
Fine-tune [448/100000]  val_loss=-0.963400
Fine-tune [449/100000]  val_loss=-0.980414
Fine-tune [450/100000]  val_loss=-0.956088
Fine-tune [451/100000]  val_loss=-0.970556
Fine-tune [452/100000]  val_loss=-0.981951
Fine-tune [453/100000]  val_loss=-0.977240
Fine-tune [454/100000]  val_loss=-0.981337
Fine-tune [455/100000]  val_loss=-0.983364
Fine-tune [456/100000]  val_loss=-0.970411
Fine-tune [457/100000]  val_loss=-0.950999
Fine-tune [458/100000]  val_loss=-0.944913
Fine-tune [459/100000]  val_loss=-0.946031
Fine-tune [460/100000]  val_loss=-0.948171
Fine-tune [461/100000]  val_loss=-0.951742
Fine-tune [462/100000]  val_loss=-0.955222
Fine-tune [463/100000]  val_loss=-0.976862
Fine-tune [464/100000]  val_loss=-0.967539
Fine-tune [465/100000]  val_loss=-0.968776
Fine-tune [466/100000]  val_loss=-0.980275
Fine-tune [467/100000]  val_loss=-0.970427
Fine-tune [468/100000]  val_loss=-0.985242
Fine-tune [469/100000]  val_loss=-0.976800
Fine-tune [470/100000]  val_loss=-0.971946
Fine-tune [471/100000]  val_loss=-0.973565
Fine-tune [472/100000]  val_loss=-0.957707
Fine-tune [473/100000]  val_loss=-0.953074
Fine-tune [474/100000]  val_loss=-0.964808
Fine-tune [475/100000]  val_loss=-0.966303
Fine-tune [476/100000]  val_loss=-0.975217
Fine-tune [477/100000]  val_loss=-0.969787
Fine-tune [478/100000]  val_loss=-0.956762
Fine-tune [479/100000]  val_loss=-0.960522
Fine-tune [480/100000]  val_loss=-0.979084
Fine-tune [481/100000]  val_loss=-0.954486
Fine-tune [482/100000]  val_loss=-0.972645
Fine-tune [483/100000]  val_loss=-0.963812
Fine-tune [484/100000]  val_loss=-0.978459
Fine-tune [485/100000]  val_loss=-0.953462
Fine-tune [486/100000]  val_loss=-0.965377
Fine-tune [487/100000]  val_loss=-0.973007
Fine-tune [488/100000]  val_loss=-0.958387
Fine-tune [489/100000]  val_loss=-0.965245
Fine-tune [490/100000]  val_loss=-0.974640
Fine-tune [491/100000]  val_loss=-0.969424
Fine-tune [492/100000]  val_loss=-0.962434
Fine-tune [493/100000]  val_loss=-0.973773
Fine-tune [494/100000]  val_loss=-0.967572
Fine-tune [495/100000]  val_loss=-0.947184
Fine-tune [496/100000]  val_loss=-0.953467
Fine-tune [497/100000]  val_loss=-0.936168
Fine-tune [498/100000]  val_loss=-0.935099
Fine-tune [499/100000]  val_loss=-0.939648
Fine-tune [500/100000]  val_loss=-0.929700
Fine-tune [501/100000]  val_loss=-0.937182
Fine-tune [502/100000]  val_loss=-0.949623
Fine-tune [503/100000]  val_loss=-0.941917
Fine-tune [504/100000]  val_loss=-0.935200
Fine-tune [505/100000]  val_loss=-0.937125
Fine-tune [506/100000]  val_loss=-0.933945
Fine-tune [507/100000]  val_loss=-0.935813
Fine-tune [508/100000]  val_loss=-0.939544
Fine-tune [509/100000]  val_loss=-0.934625
Fine-tune [510/100000]  val_loss=-0.946527
Fine-tune [511/100000]  val_loss=-0.939965
Fine-tune [512/100000]  val_loss=-0.950509
Fine-tune [513/100000]  val_loss=-0.952059
Fine-tune [514/100000]  val_loss=-0.945635
Fine-tune [515/100000]  val_loss=-0.958694
Fine-tune [516/100000]  val_loss=-0.945889
Fine-tune [517/100000]  val_loss=-0.943252
Fine-tune [518/100000]  val_loss=-0.958473
Fine-tune [519/100000]  val_loss=-0.946454
Fine-tune [520/100000]  val_loss=-0.938938
Fine-tune [521/100000]  val_loss=-0.931285
Fine-tune [522/100000]  val_loss=-0.979714
Fine-tune [523/100000]  val_loss=-0.970794
Fine-tune [524/100000]  val_loss=-0.966233
Fine-tune [525/100000]  val_loss=-0.953010
Fine-tune [526/100000]  val_loss=-0.942645
Fine-tune [527/100000]  val_loss=-0.951842
Fine-tune [528/100000]  val_loss=-0.955131
Fine-tune [529/100000]  val_loss=-0.933448
Fine-tune [530/100000]  val_loss=-0.932202
Fine-tune [531/100000]  val_loss=-0.949374
Fine-tune [532/100000]  val_loss=-0.954321
Fine-tune [533/100000]  val_loss=-0.945934
Fine-tune [534/100000]  val_loss=-0.934285
Fine-tune [535/100000]  val_loss=-0.944422
Fine-tune [536/100000]  val_loss=-0.946687
Fine-tune [537/100000]  val_loss=-0.964224
Fine-tune [538/100000]  val_loss=-0.959282
Fine-tune [539/100000]  val_loss=-0.958410
Fine-tune [540/100000]  val_loss=-0.930148
Fine-tune [541/100000]  val_loss=-0.951282
Fine-tune [542/100000]  val_loss=-0.944579
Fine-tune [543/100000]  val_loss=-0.934547
Fine-tune [544/100000]  val_loss=-0.956964
Fine-tune [545/100000]  val_loss=-0.963847
Fine-tune [546/100000]  val_loss=-0.964175
Fine-tune [547/100000]  val_loss=-0.943278
Fine-tune [548/100000]  val_loss=-0.926872
Fine-tune [549/100000]  val_loss=-0.945445
Fine-tune [550/100000]  val_loss=-0.929719
Fine-tune [551/100000]  val_loss=-0.946982
Fine-tune [552/100000]  val_loss=-0.949281
Fine-tune [553/100000]  val_loss=-0.954132
Fine-tune [554/100000]  val_loss=-0.923946
Fine-tune [555/100000]  val_loss=-0.953155
Fine-tune [556/100000]  val_loss=-0.946246
Fine-tune [557/100000]  val_loss=-0.954225
Fine-tune [558/100000]  val_loss=-0.957157
Fine-tune [559/100000]  val_loss=-0.953629
Fine-tune [560/100000]  val_loss=-0.936540
Fine-tune [561/100000]  val_loss=-0.948360
Fine-tune [562/100000]  val_loss=-0.946030
Fine-tune [563/100000]  val_loss=-0.932929
Fine-tune [564/100000]  val_loss=-0.934927
Fine-tune [565/100000]  val_loss=-0.928396
Fine-tune [566/100000]  val_loss=-0.916476
Fine-tune [567/100000]  val_loss=-0.914678
Fine-tune [568/100000]  val_loss=-0.931061
Fine-tune [569/100000]  val_loss=-0.940556
Fine-tune [570/100000]  val_loss=-0.931503
Fine-tune [571/100000]  val_loss=-0.944896
Fine-tune [572/100000]  val_loss=-0.926097
Fine-tune [573/100000]  val_loss=-0.912658
Fine-tune [574/100000]  val_loss=-0.951288
Fine-tune [575/100000]  val_loss=-0.936647
Fine-tune [576/100000]  val_loss=-0.921567
Fine-tune [577/100000]  val_loss=-0.942072
Fine-tune [578/100000]  val_loss=-0.945693
Fine-tune [579/100000]  val_loss=-0.921855
Fine-tune [580/100000]  val_loss=-0.932969
Fine-tune [581/100000]  val_loss=-0.920009
Fine-tune [582/100000]  val_loss=-0.923826
Fine-tune [583/100000]  val_loss=-0.937905
Fine-tune [584/100000]  val_loss=-0.916988
Fine-tune [585/100000]  val_loss=-0.923946
Fine-tune [586/100000]  val_loss=-0.935493
Fine-tune [587/100000]  val_loss=-0.942947
Fine-tune [588/100000]  val_loss=-0.941664
Fine-tune [589/100000]  val_loss=-0.920456
Fine-tune [590/100000]  val_loss=-0.915608
Fine-tune [591/100000]  val_loss=-0.915815
Fine-tune [592/100000]  val_loss=-0.922445
Fine-tune [593/100000]  val_loss=-0.923029
Fine-tune [594/100000]  val_loss=-0.918170
Fine-tune [595/100000]  val_loss=-0.905395
Fine-tune [596/100000]  val_loss=-0.925593
Fine-tune [597/100000]  val_loss=-0.921984
Fine-tune [598/100000]  val_loss=-0.933172
Fine-tune [599/100000]  val_loss=-0.920389
Fine-tune [600/100000]  val_loss=-0.923124
Fine-tune [601/100000]  val_loss=-0.904708
Fine-tune [602/100000]  val_loss=-0.918059
Fine-tune [603/100000]  val_loss=-0.933807
Fine-tune [604/100000]  val_loss=-0.942786
Fine-tune [605/100000]  val_loss=-0.928193
Fine-tune [606/100000]  val_loss=-0.937078
Fine-tune [607/100000]  val_loss=-0.929677
Fine-tune [608/100000]  val_loss=-0.929323
Fine-tune [609/100000]  val_loss=-0.933093
Fine-tune [610/100000]  val_loss=-0.917689
Fine-tune [611/100000]  val_loss=-0.908462
Fine-tune [612/100000]  val_loss=-0.914787
Fine-tune [613/100000]  val_loss=-0.937010
Fine-tune [614/100000]  val_loss=-0.932444
Fine-tune [615/100000]  val_loss=-0.913873
Fine-tune [616/100000]  val_loss=-0.912474
Fine-tune [617/100000]  val_loss=-0.920461
Fine-tune [618/100000]  val_loss=-0.911629
Fine-tune [619/100000]  val_loss=-0.919815
Fine-tune [620/100000]  val_loss=-0.941730
Fine-tune [621/100000]  val_loss=-0.941188
Fine-tune [622/100000]  val_loss=-0.940893
Fine-tune [623/100000]  val_loss=-0.917432
Fine-tune [624/100000]  val_loss=-0.909240
Fine-tune [625/100000]  val_loss=-0.918663
Fine-tune [626/100000]  val_loss=-0.907275
Fine-tune [627/100000]  val_loss=-0.895943
Fine-tune [628/100000]  val_loss=-0.871803
Fine-tune [629/100000]  val_loss=-0.888452
Fine-tune [630/100000]  val_loss=-0.896780
Fine-tune [631/100000]  val_loss=-0.881468
Fine-tune [632/100000]  val_loss=-0.889282
Fine-tune [633/100000]  val_loss=-0.899434
Fine-tune [634/100000]  val_loss=-0.910577
Fine-tune [635/100000]  val_loss=-0.900340
Fine-tune [636/100000]  val_loss=-0.905973
Fine-tune [637/100000]  val_loss=-0.898529
Fine-tune [638/100000]  val_loss=-0.913505
Fine-tune [639/100000]  val_loss=-0.898054
Fine-tune [640/100000]  val_loss=-0.932243
Fine-tune [641/100000]  val_loss=-0.920250
Fine-tune [642/100000]  val_loss=-0.912090
Fine-tune [643/100000]  val_loss=-0.901995
Fine-tune [644/100000]  val_loss=-0.896905
Fine-tune [645/100000]  val_loss=-0.904055
Fine-tune [646/100000]  val_loss=-0.896092
Fine-tune [647/100000]  val_loss=-0.912324
Fine-tune [648/100000]  val_loss=-0.902082
Fine-tune [649/100000]  val_loss=-0.892638
Fine-tune [650/100000]  val_loss=-0.906509
Fine-tune [651/100000]  val_loss=-0.928055
Fine-tune [652/100000]  val_loss=-0.911027
Fine-tune [653/100000]  val_loss=-0.925196
Fine-tune [654/100000]  val_loss=-0.936683
Fine-tune [655/100000]  val_loss=-0.922878
Fine-tune [656/100000]  val_loss=-0.893920
Fine-tune [657/100000]  val_loss=-0.895551
Fine-tune [658/100000]  val_loss=-0.897069
Fine-tune [659/100000]  val_loss=-0.906198
Fine-tune [660/100000]  val_loss=-0.881872
Fine-tune [661/100000]  val_loss=-0.891414
Fine-tune [662/100000]  val_loss=-0.907943
Fine-tune [663/100000]  val_loss=-0.915565
Fine-tune [664/100000]  val_loss=-0.903039
Fine-tune [665/100000]  val_loss=-0.918151
Fine-tune [666/100000]  val_loss=-0.896868
Fine-tune [667/100000]  val_loss=-0.911147
Fine-tune [668/100000]  val_loss=-0.913546
Fine-tune [669/100000]  val_loss=-0.891515
Fine-tune [670/100000]  val_loss=-0.915629
Fine-tune [671/100000]  val_loss=-0.919463
Fine-tune [672/100000]  val_loss=-0.894041
Fine-tune [673/100000]  val_loss=-0.885696
Fine-tune [674/100000]  val_loss=-0.879394
Fine-tune [675/100000]  val_loss=-0.899987
Fine-tune [676/100000]  val_loss=-0.900226
Fine-tune [677/100000]  val_loss=-0.900173
Fine-tune [678/100000]  val_loss=-0.891773
Fine-tune [679/100000]  val_loss=-0.894369
Fine-tune [680/100000]  val_loss=-0.891510
Fine-tune [681/100000]  val_loss=-0.920278
Fine-tune [682/100000]  val_loss=-0.888247
Fine-tune [683/100000]  val_loss=-0.871998
Fine-tune [684/100000]  val_loss=-0.862529
Fine-tune [685/100000]  val_loss=-0.888310
Fine-tune [686/100000]  val_loss=-0.918767
Fine-tune [687/100000]  val_loss=-0.907060
Fine-tune [688/100000]  val_loss=-0.883980
Fine-tune [689/100000]  val_loss=-0.871971
Fine-tune [690/100000]  val_loss=-0.891235
Fine-tune [691/100000]  val_loss=-0.895460
Fine-tune [692/100000]  val_loss=-0.919104
Fine-tune [693/100000]  val_loss=-0.919736
Fine-tune [694/100000]  val_loss=-0.913971
Fine-tune [695/100000]  val_loss=-0.891615
Fine-tune [696/100000]  val_loss=-0.876746
Fine-tune [697/100000]  val_loss=-0.897183
Fine-tune [698/100000]  val_loss=-0.892242
Fine-tune [699/100000]  val_loss=-0.897379
Fine-tune [700/100000]  val_loss=-0.901982
Fine-tune [701/100000]  val_loss=-0.898597
Fine-tune [702/100000]  val_loss=-0.875829
Fine-tune [703/100000]  val_loss=-0.887509
Fine-tune [704/100000]  val_loss=-0.886111
Fine-tune [705/100000]  val_loss=-0.882033
Fine-tune [706/100000]  val_loss=-0.909280
Fine-tune [707/100000]  val_loss=-0.912885
Fine-tune [708/100000]  val_loss=-0.922266
Fine-tune [709/100000]  val_loss=-0.903937
Fine-tune [710/100000]  val_loss=-0.882043
Fine-tune [711/100000]  val_loss=-0.886934
Fine-tune [712/100000]  val_loss=-0.892102
Fine-tune [713/100000]  val_loss=-0.879859
Fine-tune [714/100000]  val_loss=-0.858584
Fine-tune [715/100000]  val_loss=-0.873495
Fine-tune [716/100000]  val_loss=-0.862320
Fine-tune [717/100000]  val_loss=-0.845804
Fine-tune [718/100000]  val_loss=-0.870575
Fine-tune [719/100000]  val_loss=-0.875371
Fine-tune [720/100000]  val_loss=-0.883050
Fine-tune [721/100000]  val_loss=-0.897183
Fine-tune [722/100000]  val_loss=-0.891776
Fine-tune [723/100000]  val_loss=-0.911183
Fine-tune [724/100000]  val_loss=-0.881632
Fine-tune [725/100000]  val_loss=-0.889833
Fine-tune [726/100000]  val_loss=-0.890314
Fine-tune [727/100000]  val_loss=-0.892091
Fine-tune [728/100000]  val_loss=-0.889302
Fine-tune [729/100000]  val_loss=-0.889908
Fine-tune [730/100000]  val_loss=-0.888144
Fine-tune [731/100000]  val_loss=-0.899988
Fine-tune [732/100000]  val_loss=-0.871978
Fine-tune [733/100000]  val_loss=-0.886805
Fine-tune [734/100000]  val_loss=-0.876819
Fine-tune [735/100000]  val_loss=-0.878474
Fine-tune [736/100000]  val_loss=-0.880647
Fine-tune [737/100000]  val_loss=-0.879287
Fine-tune [738/100000]  val_loss=-0.884833
Fine-tune [739/100000]  val_loss=-0.869371
Fine-tune [740/100000]  val_loss=-0.864459
Fine-tune [741/100000]  val_loss=-0.866768
Fine-tune [742/100000]  val_loss=-0.876629
Fine-tune [743/100000]  val_loss=-0.882959
Fine-tune [744/100000]  val_loss=-0.862283
Fine-tune [745/100000]  val_loss=-0.869129
Fine-tune [746/100000]  val_loss=-0.878643
Fine-tune [747/100000]  val_loss=-0.879025
Fine-tune [748/100000]  val_loss=-0.868305
Fine-tune [749/100000]  val_loss=-0.880838
Fine-tune [750/100000]  val_loss=-0.886488
Fine-tune [751/100000]  val_loss=-0.862042
Fine-tune [752/100000]  val_loss=-0.877257
Fine-tune [753/100000]  val_loss=-0.865306
Fine-tune [754/100000]  val_loss=-0.868095
Fine-tune [755/100000]  val_loss=-0.887984
Fine-tune [756/100000]  val_loss=-0.916950
Fine-tune [757/100000]  val_loss=-0.895007
Fine-tune [758/100000]  val_loss=-0.892221
Fine-tune [759/100000]  val_loss=-0.884364
Fine-tune [760/100000]  val_loss=-0.892431
Fine-tune [761/100000]  val_loss=-0.903533
Fine-tune [762/100000]  val_loss=-0.887546
Fine-tune [763/100000]  val_loss=-0.852293
Fine-tune [764/100000]  val_loss=-0.854047
Fine-tune [765/100000]  val_loss=-0.876979
Fine-tune [766/100000]  val_loss=-0.896658
Fine-tune [767/100000]  val_loss=-0.877543
Fine-tune [768/100000]  val_loss=-0.872424
Fine-tune [769/100000]  val_loss=-0.855941
Fine-tune [770/100000]  val_loss=-0.838908
Fine-tune [771/100000]  val_loss=-0.851996
Fine-tune [772/100000]  val_loss=-0.850768
Fine-tune [773/100000]  val_loss=-0.834414
Fine-tune [774/100000]  val_loss=-0.862050
Fine-tune [775/100000]  val_loss=-0.846996
Fine-tune [776/100000]  val_loss=-0.838392
Fine-tune [777/100000]  val_loss=-0.849045
Fine-tune [778/100000]  val_loss=-0.814404
Fine-tune [779/100000]  val_loss=-0.811345
Fine-tune [780/100000]  val_loss=-0.827667
Fine-tune [781/100000]  val_loss=-0.846732
Fine-tune [782/100000]  val_loss=-0.838951
Fine-tune [783/100000]  val_loss=-0.842993
Fine-tune [784/100000]  val_loss=-0.849555
Fine-tune [785/100000]  val_loss=-0.844156
Fine-tune [786/100000]  val_loss=-0.833948
Fine-tune [787/100000]  val_loss=-0.858269
Fine-tune [788/100000]  val_loss=-0.824070
Fine-tune [789/100000]  val_loss=-0.841858
Fine-tune [790/100000]  val_loss=-0.834052
Fine-tune [791/100000]  val_loss=-0.861932
Fine-tune [792/100000]  val_loss=-0.819209
Fine-tune [793/100000]  val_loss=-0.818183
Fine-tune [794/100000]  val_loss=-0.845652
Fine-tune [795/100000]  val_loss=-0.864274
Fine-tune [796/100000]  val_loss=-0.840803
Fine-tune [797/100000]  val_loss=-0.851752
Fine-tune [798/100000]  val_loss=-0.859545
Fine-tune [799/100000]  val_loss=-0.855235
Fine-tune [800/100000]  val_loss=-0.832750
Fine-tune [801/100000]  val_loss=-0.816754
Fine-tune [802/100000]  val_loss=-0.830485
Fine-tune [803/100000]  val_loss=-0.827322
Fine-tune [804/100000]  val_loss=-0.843124
Fine-tune [805/100000]  val_loss=-0.826435
Fine-tune [806/100000]  val_loss=-0.844687
Fine-tune [807/100000]  val_loss=-0.826176
Fine-tune [808/100000]  val_loss=-0.854669
Fine-tune [809/100000]  val_loss=-0.859079
Fine-tune [810/100000]  val_loss=-0.866068
Fine-tune [811/100000]  val_loss=-0.853600
Fine-tune [812/100000]  val_loss=-0.857266
Fine-tune [813/100000]  val_loss=-0.825643
Fine-tune [814/100000]  val_loss=-0.854216
Fine-tune [815/100000]  val_loss=-0.878560
Fine-tune [816/100000]  val_loss=-0.875534
Fine-tune [817/100000]  val_loss=-0.838376
Fine-tune [818/100000]  val_loss=-0.808818
Fine-tune [819/100000]  val_loss=-0.835005
Fine-tune [820/100000]  val_loss=-0.862453
Fine-tune [821/100000]  val_loss=-0.842693
Fine-tune [822/100000]  val_loss=-0.847802
Fine-tune [823/100000]  val_loss=-0.832896
Fine-tune [824/100000]  val_loss=-0.825623
Fine-tune [825/100000]  val_loss=-0.824149
Fine-tune [826/100000]  val_loss=-0.825542
Fine-tune [827/100000]  val_loss=-0.824712
Fine-tune [828/100000]  val_loss=-0.846086
Fine-tune [829/100000]  val_loss=-0.825018
Fine-tune [830/100000]  val_loss=-0.860001
Fine-tune [831/100000]  val_loss=-0.860120
Fine-tune [832/100000]  val_loss=-0.873811
Fine-tune [833/100000]  val_loss=-0.854101
Fine-tune [834/100000]  val_loss=-0.844729
Fine-tune [835/100000]  val_loss=-0.850929
Fine-tune [836/100000]  val_loss=-0.830461
Fine-tune [837/100000]  val_loss=-0.843770
Fine-tune [838/100000]  val_loss=-0.814366
Fine-tune [839/100000]  val_loss=-0.850492
Fine-tune [840/100000]  val_loss=-0.859433
Fine-tune [841/100000]  val_loss=-0.837141
Fine-tune [842/100000]  val_loss=-0.846085
Fine-tune [843/100000]  val_loss=-0.845219
Fine-tune [844/100000]  val_loss=-0.868675
Fine-tune [845/100000]  val_loss=-0.839267
Fine-tune [846/100000]  val_loss=-0.834714
Fine-tune [847/100000]  val_loss=-0.826281
Fine-tune [848/100000]  val_loss=-0.853770
Fine-tune [849/100000]  val_loss=-0.841245
Fine-tune [850/100000]  val_loss=-0.827809
Fine-tune [851/100000]  val_loss=-0.808511
Fine-tune [852/100000]  val_loss=-0.823286
Fine-tune [853/100000]  val_loss=-0.797443
Fine-tune [854/100000]  val_loss=-0.845501
Fine-tune [855/100000]  val_loss=-0.828031
Fine-tune [856/100000]  val_loss=-0.837600
Fine-tune [857/100000]  val_loss=-0.823351
Fine-tune [858/100000]  val_loss=-0.839364
Fine-tune [859/100000]  val_loss=-0.831531
Fine-tune [860/100000]  val_loss=-0.874138
Fine-tune [861/100000]  val_loss=-0.851008
Fine-tune [862/100000]  val_loss=-0.864156
Fine-tune [863/100000]  val_loss=-0.827138
Fine-tune [864/100000]  val_loss=-0.815154
Fine-tune [865/100000]  val_loss=-0.815122
Fine-tune [866/100000]  val_loss=-0.836644
Fine-tune [867/100000]  val_loss=-0.809166
Fine-tune [868/100000]  val_loss=-0.832780
Fine-tune [869/100000]  val_loss=-0.803491
Fine-tune [870/100000]  val_loss=-0.804765
Fine-tune [871/100000]  val_loss=-0.821961
Fine-tune [872/100000]  val_loss=-0.831116
Fine-tune [873/100000]  val_loss=-0.833807
Fine-tune [874/100000]  val_loss=-0.814971
Fine-tune [875/100000]  val_loss=-0.828349
Fine-tune [876/100000]  val_loss=-0.820588
Fine-tune [877/100000]  val_loss=-0.813434
Fine-tune [878/100000]  val_loss=-0.794112
Fine-tune [879/100000]  val_loss=-0.787159
Fine-tune [880/100000]  val_loss=-0.805282
Fine-tune [881/100000]  val_loss=-0.785841
Fine-tune [882/100000]  val_loss=-0.783004
Fine-tune [883/100000]  val_loss=-0.788643
Fine-tune [884/100000]  val_loss=-0.788173
Fine-tune [885/100000]  val_loss=-0.804848
Fine-tune [886/100000]  val_loss=-0.800159
Fine-tune [887/100000]  val_loss=-0.802160
Fine-tune [888/100000]  val_loss=-0.806000
Fine-tune [889/100000]  val_loss=-0.805657
Fine-tune [890/100000]  val_loss=-0.785913
Fine-tune [891/100000]  val_loss=-0.786629
Fine-tune [892/100000]  val_loss=-0.805505
Fine-tune [893/100000]  val_loss=-0.812714
Fine-tune [894/100000]  val_loss=-0.823746
Fine-tune [895/100000]  val_loss=-0.832926
Fine-tune [896/100000]  val_loss=-0.808243
Fine-tune [897/100000]  val_loss=-0.809182
Fine-tune [898/100000]  val_loss=-0.816216
Fine-tune [899/100000]  val_loss=-0.797136
Fine-tune [900/100000]  val_loss=-0.793933
Fine-tune [901/100000]  val_loss=-0.792209
Fine-tune [902/100000]  val_loss=-0.810564
Fine-tune [903/100000]  val_loss=-0.812270
Fine-tune [904/100000]  val_loss=-0.816372
Fine-tune [905/100000]  val_loss=-0.810726
Fine-tune [906/100000]  val_loss=-0.818854
Fine-tune [907/100000]  val_loss=-0.811931
Fine-tune [908/100000]  val_loss=-0.824380
Fine-tune [909/100000]  val_loss=-0.837389
Fine-tune [910/100000]  val_loss=-0.849730
Fine-tune [911/100000]  val_loss=-0.861428
Fine-tune [912/100000]  val_loss=-0.847947
Fine-tune [913/100000]  val_loss=-0.818735
Fine-tune [914/100000]  val_loss=-0.817632
Fine-tune [915/100000]  val_loss=-0.837961
Fine-tune [916/100000]  val_loss=-0.811554
Fine-tune [917/100000]  val_loss=-0.813352
Fine-tune [918/100000]  val_loss=-0.815261
Fine-tune [919/100000]  val_loss=-0.801958
Fine-tune [920/100000]  val_loss=-0.794642
Fine-tune [921/100000]  val_loss=-0.819700
Fine-tune [922/100000]  val_loss=-0.800764
Fine-tune [923/100000]  val_loss=-0.814871
Fine-tune [924/100000]  val_loss=-0.824804
Fine-tune [925/100000]  val_loss=-0.822262
Fine-tune [926/100000]  val_loss=-0.824802
Fine-tune [927/100000]  val_loss=-0.798461
Fine-tune [928/100000]  val_loss=-0.778934
Fine-tune [929/100000]  val_loss=-0.762867
Fine-tune [930/100000]  val_loss=-0.793758
Fine-tune [931/100000]  val_loss=-0.810917
Fine-tune [932/100000]  val_loss=-0.815475
Fine-tune [933/100000]  val_loss=-0.816253
Fine-tune [934/100000]  val_loss=-0.825195
Fine-tune [935/100000]  val_loss=-0.793567
Fine-tune [936/100000]  val_loss=-0.782648
Fine-tune [937/100000]  val_loss=-0.792634
Fine-tune [938/100000]  val_loss=-0.815637
Fine-tune [939/100000]  val_loss=-0.823090
Fine-tune [940/100000]  val_loss=-0.796606
Fine-tune [941/100000]  val_loss=-0.774951
Fine-tune [942/100000]  val_loss=-0.810739
Fine-tune [943/100000]  val_loss=-0.810906
Fine-tune [944/100000]  val_loss=-0.820112
Fine-tune [945/100000]  val_loss=-0.827075
Fine-tune [946/100000]  val_loss=-0.788753
Fine-tune [947/100000]  val_loss=-0.786659
Fine-tune [948/100000]  val_loss=-0.767980
Fine-tune [949/100000]  val_loss=-0.798810
Fine-tune [950/100000]  val_loss=-0.774062
Fine-tune [951/100000]  val_loss=-0.781343
Fine-tune [952/100000]  val_loss=-0.770867
Fine-tune [953/100000]  val_loss=-0.755260
Fine-tune [954/100000]  val_loss=-0.766942
Fine-tune [955/100000]  val_loss=-0.750066
Fine-tune [956/100000]  val_loss=-0.727787
Fine-tune [957/100000]  val_loss=-0.780438
Fine-tune [958/100000]  val_loss=-0.775889
Fine-tune [959/100000]  val_loss=-0.762120
Fine-tune [960/100000]  val_loss=-0.759421
Fine-tune [961/100000]  val_loss=-0.737418
Fine-tune [962/100000]  val_loss=-0.746104
Fine-tune [963/100000]  val_loss=-0.762639
Fine-tune [964/100000]  val_loss=-0.794469
Fine-tune [965/100000]  val_loss=-0.787555
Fine-tune [966/100000]  val_loss=-0.748772
Fine-tune [967/100000]  val_loss=-0.735945
Fine-tune [968/100000]  val_loss=-0.765284
Fine-tune [969/100000]  val_loss=-0.783980
Fine-tune [970/100000]  val_loss=-0.796259
Fine-tune [971/100000]  val_loss=-0.796544
Fine-tune [972/100000]  val_loss=-0.788367
Fine-tune [973/100000]  val_loss=-0.765198
Fine-tune [974/100000]  val_loss=-0.785164
Fine-tune [975/100000]  val_loss=-0.761854
Fine-tune [976/100000]  val_loss=-0.760807
Fine-tune [977/100000]  val_loss=-0.751318
Fine-tune [978/100000]  val_loss=-0.761707
Fine-tune [979/100000]  val_loss=-0.757479
Fine-tune [980/100000]  val_loss=-0.771345
Fine-tune [981/100000]  val_loss=-0.739410
Fine-tune [982/100000]  val_loss=-0.751477
Fine-tune [983/100000]  val_loss=-0.762793
Fine-tune [984/100000]  val_loss=-0.760076
Fine-tune [985/100000]  val_loss=-0.736214
Fine-tune [986/100000]  val_loss=-0.726640
Fine-tune [987/100000]  val_loss=-0.725790
Fine-tune [988/100000]  val_loss=-0.768403
Fine-tune [989/100000]  val_loss=-0.785344
Fine-tune [990/100000]  val_loss=-0.780955
Fine-tune [991/100000]  val_loss=-0.764103
Fine-tune [992/100000]  val_loss=-0.749111
Fine-tune [993/100000]  val_loss=-0.770277
Fine-tune [994/100000]  val_loss=-0.781504
Fine-tune [995/100000]  val_loss=-0.751267
Fine-tune [996/100000]  val_loss=-0.772621
Fine-tune [997/100000]  val_loss=-0.773577
Fine-tune [998/100000]  val_loss=-0.795867
Fine-tune [999/100000]  val_loss=-0.782215
Fine-tune [1000/100000]  val_loss=-0.808646
Fine-tune [1001/100000]  val_loss=-0.787499
Fine-tune [1002/100000]  val_loss=-0.790068
Fine-tune [1003/100000]  val_loss=-0.755084
Fine-tune [1004/100000]  val_loss=-0.760184
Fine-tune [1005/100000]  val_loss=-0.773153
Fine-tune [1006/100000]  val_loss=-0.774544
Fine-tune [1007/100000]  val_loss=-0.761020
Fine-tune [1008/100000]  val_loss=-0.728806
Fine-tune [1009/100000]  val_loss=-0.710650
Fine-tune [1010/100000]  val_loss=-0.729743
Fine-tune [1011/100000]  val_loss=-0.708499
Fine-tune [1012/100000]  val_loss=-0.744415
Fine-tune [1013/100000]  val_loss=-0.765879
Fine-tune [1014/100000]  val_loss=-0.787915
Fine-tune [1015/100000]  val_loss=-0.781179
Fine-tune [1016/100000]  val_loss=-0.739459
Fine-tune [1017/100000]  val_loss=-0.730221
Fine-tune [1018/100000]  val_loss=-0.742283
Fine-tune [1019/100000]  val_loss=-0.747392
Fine-tune [1020/100000]  val_loss=-0.705038
Fine-tune [1021/100000]  val_loss=-0.724913
Fine-tune [1022/100000]  val_loss=-0.708069
Fine-tune [1023/100000]  val_loss=-0.704136
Fine-tune [1024/100000]  val_loss=-0.753606
Fine-tune [1025/100000]  val_loss=-0.731726
Fine-tune [1026/100000]  val_loss=-0.748632
Fine-tune [1027/100000]  val_loss=-0.752337
Fine-tune [1028/100000]  val_loss=-0.739489
Fine-tune [1029/100000]  val_loss=-0.721876
Fine-tune [1030/100000]  val_loss=-0.722687
Fine-tune [1031/100000]  val_loss=-0.722306
Fine-tune [1032/100000]  val_loss=-0.710854
Fine-tune [1033/100000]  val_loss=-0.726967
Fine-tune [1034/100000]  val_loss=-0.705420
Fine-tune [1035/100000]  val_loss=-0.725505
Fine-tune [1036/100000]  val_loss=-0.733001
Fine-tune [1037/100000]  val_loss=-0.719052
Fine-tune [1038/100000]  val_loss=-0.751583
Fine-tune [1039/100000]  val_loss=-0.756245
Fine-tune [1040/100000]  val_loss=-0.751078
Fine-tune [1041/100000]  val_loss=-0.753339
Fine-tune [1042/100000]  val_loss=-0.777768
Fine-tune [1043/100000]  val_loss=-0.749451
Fine-tune [1044/100000]  val_loss=-0.737024
Fine-tune [1045/100000]  val_loss=-0.723162
Fine-tune [1046/100000]  val_loss=-0.732472
Fine-tune [1047/100000]  val_loss=-0.740150
Fine-tune [1048/100000]  val_loss=-0.765558
Fine-tune [1049/100000]  val_loss=-0.746313
Fine-tune [1050/100000]  val_loss=-0.740787
Fine-tune [1051/100000]  val_loss=-0.716852
Fine-tune [1052/100000]  val_loss=-0.746431
Fine-tune [1053/100000]  val_loss=-0.729080
Fine-tune [1054/100000]  val_loss=-0.750307
Fine-tune [1055/100000]  val_loss=-0.767568
Fine-tune [1056/100000]  val_loss=-0.749767
Fine-tune [1057/100000]  val_loss=-0.716038
Fine-tune [1058/100000]  val_loss=-0.723539
Fine-tune [1059/100000]  val_loss=-0.762011
Fine-tune [1060/100000]  val_loss=-0.747354
Fine-tune [1061/100000]  val_loss=-0.745437
Fine-tune [1062/100000]  val_loss=-0.752640
Fine-tune [1063/100000]  val_loss=-0.777061
Fine-tune [1064/100000]  val_loss=-0.743408
Fine-tune [1065/100000]  val_loss=-0.755190
Fine-tune [1066/100000]  val_loss=-0.747469
Fine-tune [1067/100000]  val_loss=-0.702263
Fine-tune [1068/100000]  val_loss=-0.759384
Fine-tune [1069/100000]  val_loss=-0.748311
Fine-tune [1070/100000]  val_loss=-0.717081
Fine-tune [1071/100000]  val_loss=-0.694449
Fine-tune [1072/100000]  val_loss=-0.678695
Fine-tune [1073/100000]  val_loss=-0.733703
Fine-tune [1074/100000]  val_loss=-0.723685
Fine-tune [1075/100000]  val_loss=-0.709619
Fine-tune [1076/100000]  val_loss=-0.699372
Fine-tune [1077/100000]  val_loss=-0.733173
Fine-tune [1078/100000]  val_loss=-0.737320
Fine-tune [1079/100000]  val_loss=-0.731993
Fine-tune [1080/100000]  val_loss=-0.749029
Fine-tune [1081/100000]  val_loss=-0.768943
Fine-tune [1082/100000]  val_loss=-0.730374
Fine-tune [1083/100000]  val_loss=-0.721301
Fine-tune [1084/100000]  val_loss=-0.725198
Fine-tune [1085/100000]  val_loss=-0.705243
Fine-tune [1086/100000]  val_loss=-0.719623
Fine-tune [1087/100000]  val_loss=-0.721178
Fine-tune [1088/100000]  val_loss=-0.742859
Fine-tune [1089/100000]  val_loss=-0.741222
Fine-tune [1090/100000]  val_loss=-0.750246
Fine-tune [1091/100000]  val_loss=-0.743811
Fine-tune [1092/100000]  val_loss=-0.715165
Fine-tune [1093/100000]  val_loss=-0.715224
Fine-tune [1094/100000]  val_loss=-0.708349
Fine-tune [1095/100000]  val_loss=-0.735042
Fine-tune [1096/100000]  val_loss=-0.740386
Fine-tune [1097/100000]  val_loss=-0.715517
Fine-tune [1098/100000]  val_loss=-0.703064
Fine-tune [1099/100000]  val_loss=-0.723947
Fine-tune [1100/100000]  val_loss=-0.762354
Fine-tune [1101/100000]  val_loss=-0.741157
Fine-tune [1102/100000]  val_loss=-0.723634
Fine-tune [1103/100000]  val_loss=-0.709593
Fine-tune [1104/100000]  val_loss=-0.741003
Fine-tune [1105/100000]  val_loss=-0.713313
Fine-tune [1106/100000]  val_loss=-0.708659
Fine-tune [1107/100000]  val_loss=-0.727882
Fine-tune [1108/100000]  val_loss=-0.707872
Fine-tune [1109/100000]  val_loss=-0.712294
Fine-tune [1110/100000]  val_loss=-0.725588
Fine-tune [1111/100000]  val_loss=-0.737534
Fine-tune [1112/100000]  val_loss=-0.722862
Fine-tune [1113/100000]  val_loss=-0.750841
Fine-tune [1114/100000]  val_loss=-0.742941
Fine-tune [1115/100000]  val_loss=-0.729948
Fine-tune [1116/100000]  val_loss=-0.732842
Fine-tune [1117/100000]  val_loss=-0.710571
Fine-tune [1118/100000]  val_loss=-0.715605
Fine-tune [1119/100000]  val_loss=-0.729579
Fine-tune [1120/100000]  val_loss=-0.724818
Fine-tune [1121/100000]  val_loss=-0.728143
Fine-tune [1122/100000]  val_loss=-0.692255
Fine-tune [1123/100000]  val_loss=-0.748081
Fine-tune [1124/100000]  val_loss=-0.763286
Fine-tune [1125/100000]  val_loss=-0.751168
Fine-tune [1126/100000]  val_loss=-0.734037
Fine-tune [1127/100000]  val_loss=-0.733081
Fine-tune [1128/100000]  val_loss=-0.695795
Fine-tune [1129/100000]  val_loss=-0.695347
Fine-tune [1130/100000]  val_loss=-0.700262
Fine-tune [1131/100000]  val_loss=-0.716600
Fine-tune [1132/100000]  val_loss=-0.743828
Fine-tune [1133/100000]  val_loss=-0.757895
Fine-tune [1134/100000]  val_loss=-0.764531
Fine-tune [1135/100000]  val_loss=-0.754573
Fine-tune [1136/100000]  val_loss=-0.718523
Fine-tune [1137/100000]  val_loss=-0.726888
Fine-tune [1138/100000]  val_loss=-0.691437
Fine-tune [1139/100000]  val_loss=-0.690033
Fine-tune [1140/100000]  val_loss=-0.706313
Fine-tune [1141/100000]  val_loss=-0.715869
Fine-tune [1142/100000]  val_loss=-0.724136
Fine-tune [1143/100000]  val_loss=-0.691624
Fine-tune [1144/100000]  val_loss=-0.673301
Fine-tune [1145/100000]  val_loss=-0.719373
Fine-tune [1146/100000]  val_loss=-0.706223
Fine-tune [1147/100000]  val_loss=-0.754364
Fine-tune [1148/100000]  val_loss=-0.728316
Fine-tune [1149/100000]  val_loss=-0.724902
Fine-tune [1150/100000]  val_loss=-0.754703
Fine-tune [1151/100000]  val_loss=-0.731941
Fine-tune [1152/100000]  val_loss=-0.738740
Fine-tune [1153/100000]  val_loss=-0.753315
Fine-tune [1154/100000]  val_loss=-0.715711
Fine-tune [1155/100000]  val_loss=-0.702943
Fine-tune [1156/100000]  val_loss=-0.725242
Fine-tune [1157/100000]  val_loss=-0.726497
Fine-tune [1158/100000]  val_loss=-0.713458
Fine-tune [1159/100000]  val_loss=-0.718387
Fine-tune [1160/100000]  val_loss=-0.730767
Fine-tune [1161/100000]  val_loss=-0.761619
Fine-tune [1162/100000]  val_loss=-0.769544
Fine-tune [1163/100000]  val_loss=-0.755645
Fine-tune [1164/100000]  val_loss=-0.703910
Fine-tune [1165/100000]  val_loss=-0.698131
Fine-tune [1166/100000]  val_loss=-0.675275
Fine-tune [1167/100000]  val_loss=-0.681780
Fine-tune [1168/100000]  val_loss=-0.690806
Fine-tune [1169/100000]  val_loss=-0.681729
Fine-tune [1170/100000]  val_loss=-0.706487
Fine-tune [1171/100000]  val_loss=-0.715002
Fine-tune [1172/100000]  val_loss=-0.673363
Fine-tune [1173/100000]  val_loss=-0.684603
Fine-tune [1174/100000]  val_loss=-0.693302
Fine-tune [1175/100000]  val_loss=-0.703525
Fine-tune [1176/100000]  val_loss=-0.725043
Fine-tune [1177/100000]  val_loss=-0.701129
Fine-tune [1178/100000]  val_loss=-0.688768
Fine-tune [1179/100000]  val_loss=-0.680341
Fine-tune [1180/100000]  val_loss=-0.709799
Fine-tune [1181/100000]  val_loss=-0.721385
Fine-tune [1182/100000]  val_loss=-0.744582
Fine-tune [1183/100000]  val_loss=-0.739598
Fine-tune [1184/100000]  val_loss=-0.731130
Fine-tune [1185/100000]  val_loss=-0.744080
Fine-tune [1186/100000]  val_loss=-0.731620
Fine-tune [1187/100000]  val_loss=-0.688031
Fine-tune [1188/100000]  val_loss=-0.718460
Fine-tune [1189/100000]  val_loss=-0.684195
Fine-tune [1190/100000]  val_loss=-0.719300
Fine-tune [1191/100000]  val_loss=-0.729533
Fine-tune [1192/100000]  val_loss=-0.720146
Fine-tune [1193/100000]  val_loss=-0.758096
Fine-tune [1194/100000]  val_loss=-0.716130
Fine-tune [1195/100000]  val_loss=-0.720731
Fine-tune [1196/100000]  val_loss=-0.719870
Fine-tune [1197/100000]  val_loss=-0.720227
Fine-tune [1198/100000]  val_loss=-0.723089
Fine-tune [1199/100000]  val_loss=-0.686955
Fine-tune [1200/100000]  val_loss=-0.682263
Fine-tune [1201/100000]  val_loss=-0.694788
Fine-tune [1202/100000]  val_loss=-0.691473
Fine-tune [1203/100000]  val_loss=-0.709016
Fine-tune [1204/100000]  val_loss=-0.682439
Fine-tune [1205/100000]  val_loss=-0.715042
Fine-tune [1206/100000]  val_loss=-0.691414
Fine-tune [1207/100000]  val_loss=-0.683910
Fine-tune [1208/100000]  val_loss=-0.700045
Fine-tune [1209/100000]  val_loss=-0.705534
Fine-tune [1210/100000]  val_loss=-0.705794
Fine-tune [1211/100000]  val_loss=-0.689835
Fine-tune [1212/100000]  val_loss=-0.693917
Fine-tune [1213/100000]  val_loss=-0.711254
Fine-tune [1214/100000]  val_loss=-0.665974
Fine-tune [1215/100000]  val_loss=-0.703965
Fine-tune [1216/100000]  val_loss=-0.723536
Fine-tune [1217/100000]  val_loss=-0.712796
Fine-tune [1218/100000]  val_loss=-0.693981
Fine-tune [1219/100000]  val_loss=-0.712285
Fine-tune [1220/100000]  val_loss=-0.680945
Fine-tune [1221/100000]  val_loss=-0.681184
Fine-tune [1222/100000]  val_loss=-0.697402
Fine-tune [1223/100000]  val_loss=-0.694063
Fine-tune [1224/100000]  val_loss=-0.678895
Fine-tune [1225/100000]  val_loss=-0.682663
Fine-tune [1226/100000]  val_loss=-0.692769
Fine-tune [1227/100000]  val_loss=-0.705978
Fine-tune [1228/100000]  val_loss=-0.706144
Fine-tune [1229/100000]  val_loss=-0.698934
Fine-tune [1230/100000]  val_loss=-0.706473
Fine-tune [1231/100000]  val_loss=-0.715658
Fine-tune [1232/100000]  val_loss=-0.712553
Fine-tune [1233/100000]  val_loss=-0.697423
Fine-tune [1234/100000]  val_loss=-0.736378
Fine-tune [1235/100000]  val_loss=-0.739044
Fine-tune [1236/100000]  val_loss=-0.754161
Fine-tune [1237/100000]  val_loss=-0.699608
Fine-tune [1238/100000]  val_loss=-0.711114
Fine-tune [1239/100000]  val_loss=-0.703600
Fine-tune [1240/100000]  val_loss=-0.676159
Fine-tune [1241/100000]  val_loss=-0.698327
Fine-tune [1242/100000]  val_loss=-0.667362
Fine-tune [1243/100000]  val_loss=-0.639383
Fine-tune [1244/100000]  val_loss=-0.659540
Fine-tune [1245/100000]  val_loss=-0.631834
Fine-tune [1246/100000]  val_loss=-0.668527
Fine-tune [1247/100000]  val_loss=-0.659176
Fine-tune [1248/100000]  val_loss=-0.635761
Fine-tune [1249/100000]  val_loss=-0.676269
Fine-tune [1250/100000]  val_loss=-0.646987
Fine-tune [1251/100000]  val_loss=-0.646005
Fine-tune [1252/100000]  val_loss=-0.660150
Fine-tune [1253/100000]  val_loss=-0.693576
Fine-tune [1254/100000]  val_loss=-0.664772
Fine-tune [1255/100000]  val_loss=-0.668455
Fine-tune [1256/100000]  val_loss=-0.700677
Fine-tune [1257/100000]  val_loss=-0.684716
Fine-tune [1258/100000]  val_loss=-0.699989
Fine-tune [1259/100000]  val_loss=-0.673999
Fine-tune [1260/100000]  val_loss=-0.678251
Fine-tune [1261/100000]  val_loss=-0.653903
Fine-tune [1262/100000]  val_loss=-0.629018
Fine-tune [1263/100000]  val_loss=-0.660440
Fine-tune [1264/100000]  val_loss=-0.688679
Fine-tune [1265/100000]  val_loss=-0.648883
Fine-tune [1266/100000]  val_loss=-0.654779
Fine-tune [1267/100000]  val_loss=-0.680957
Fine-tune [1268/100000]  val_loss=-0.660613
Fine-tune [1269/100000]  val_loss=-0.653371
Fine-tune [1270/100000]  val_loss=-0.623358
Fine-tune [1271/100000]  val_loss=-0.642183
Fine-tune [1272/100000]  val_loss=-0.680862
Fine-tune [1273/100000]  val_loss=-0.650295
Fine-tune [1274/100000]  val_loss=-0.643902
Fine-tune [1275/100000]  val_loss=-0.683307
Fine-tune [1276/100000]  val_loss=-0.684801
Fine-tune [1277/100000]  val_loss=-0.695836
Fine-tune [1278/100000]  val_loss=-0.673308
Fine-tune [1279/100000]  val_loss=-0.649920
Fine-tune [1280/100000]  val_loss=-0.663603
Fine-tune [1281/100000]  val_loss=-0.699641
Fine-tune [1282/100000]  val_loss=-0.679908
Fine-tune [1283/100000]  val_loss=-0.683033
Fine-tune [1284/100000]  val_loss=-0.680833
Fine-tune [1285/100000]  val_loss=-0.685753
Fine-tune [1286/100000]  val_loss=-0.689192
Fine-tune [1287/100000]  val_loss=-0.694552
Fine-tune [1288/100000]  val_loss=-0.700577
Fine-tune [1289/100000]  val_loss=-0.718056
Fine-tune [1290/100000]  val_loss=-0.719221
Fine-tune [1291/100000]  val_loss=-0.655956
Fine-tune [1292/100000]  val_loss=-0.648763
Fine-tune [1293/100000]  val_loss=-0.659410
Fine-tune [1294/100000]  val_loss=-0.660063
Fine-tune [1295/100000]  val_loss=-0.672672
Fine-tune [1296/100000]  val_loss=-0.688949
Fine-tune [1297/100000]  val_loss=-0.691368
Fine-tune [1298/100000]  val_loss=-0.668544
Fine-tune [1299/100000]  val_loss=-0.703826
Fine-tune [1300/100000]  val_loss=-0.686561
Fine-tune [1301/100000]  val_loss=-0.669652
Fine-tune [1302/100000]  val_loss=-0.673620
Fine-tune [1303/100000]  val_loss=-0.632813
Fine-tune [1304/100000]  val_loss=-0.631856
Fine-tune [1305/100000]  val_loss=-0.679524
Fine-tune [1306/100000]  val_loss=-0.667544
Fine-tune [1307/100000]  val_loss=-0.680343
Fine-tune [1308/100000]  val_loss=-0.688076
Fine-tune [1309/100000]  val_loss=-0.665449
Fine-tune [1310/100000]  val_loss=-0.661144
Fine-tune [1311/100000]  val_loss=-0.687664
Fine-tune [1312/100000]  val_loss=-0.672735
Fine-tune [1313/100000]  val_loss=-0.669475
Fine-tune [1314/100000]  val_loss=-0.656072
Fine-tune [1315/100000]  val_loss=-0.677809
Fine-tune [1316/100000]  val_loss=-0.699174
  -> 验证未改进 1000 次，早停。
[FINETUNE] 最佳验证损失=-1.026112 已保存。

--- 评估 [HD256_L2] ---

=== 本次试验参数 (Run Config) ===
opamp             : two_stage_opamp
hidden_dim        : 256
num_layers        : 2
lr_pretrain       : 0.003
epochs_pretrain   : 1000
patience_pretrain : 200
lr_finetune       : 0.0038
epochs_finetune   : 100000
patience_finetune : 1000
batch_a           : 128
batch_b           : 64
dropout_rate      : 0.2
alpha_r2          : 0.0
lambda_coral      : 0.1
seed              : 42
device            : cpu

--- [评估阶段] 开始计算指标 ---

=== 目标域验证集指标（物理单位）===
slewrate_pos    MSE=1.119e+14  MAE=7.959e+06  R2=0.7391
dc_gain         MSE=2.867e+07  MAE=1470  R2=0.2640
ugf             MSE=8.629e+13  MAE=5.836e+06  R2=0.8049
phase_margin    MSE=174.2  MAE=9.7  R2=0.8482
cmrr            MSE=8.448e+11  MAE=9.145e+04  R2=0.0246

Avg  (all dims)   MSE=3.98e+13  MAE=2.778e+06  R2=0.5362
[OK] HD256_L2 -> r2_avg=0.5362, mae_avg=2.778e+06, mse_avg=3.98e+13
===== [HD256_L2] 训练完成 =====

===== [HD256_L3] 训练开始 =====

--- [阶段一] Backbone 预训练 (source_train / source_val, HuberLoss) ---
Pretrain [1/1000]  train=0.243324  val=0.186995
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [2/1000]  train=0.177783  val=0.151220
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [3/1000]  train=0.155131  val=0.132115
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [4/1000]  train=0.144956  val=0.128503
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [5/1000]  train=0.137351  val=0.118189
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [6/1000]  train=0.125225  val=0.109482
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [7/1000]  train=0.122421  val=0.107708
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [8/1000]  train=0.121121  val=0.108320
Pretrain [9/1000]  train=0.116794  val=0.102040
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [10/1000]  train=0.111879  val=0.102574
Pretrain [11/1000]  train=0.109318  val=0.095366
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [12/1000]  train=0.106512  val=0.098569
Pretrain [13/1000]  train=0.106481  val=0.092271
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [14/1000]  train=0.103210  val=0.101026
Pretrain [15/1000]  train=0.101368  val=0.092362
Pretrain [16/1000]  train=0.099883  val=0.092538
Pretrain [17/1000]  train=0.100835  val=0.089198
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [18/1000]  train=0.095998  val=0.089391
Pretrain [19/1000]  train=0.094494  val=0.090640
Pretrain [20/1000]  train=0.093824  val=0.088996
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [21/1000]  train=0.094810  val=0.088699
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [22/1000]  train=0.092380  val=0.088992
Pretrain [23/1000]  train=0.091990  val=0.087569
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [24/1000]  train=0.088782  val=0.087331
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [25/1000]  train=0.090529  val=0.089213
Pretrain [26/1000]  train=0.086894  val=0.087565
Pretrain [27/1000]  train=0.085390  val=0.087182
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [28/1000]  train=0.084587  val=0.087073
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [29/1000]  train=0.082754  val=0.089995
Pretrain [30/1000]  train=0.085369  val=0.084739
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [31/1000]  train=0.082704  val=0.085950
Pretrain [32/1000]  train=0.083353  val=0.083903
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [33/1000]  train=0.082957  val=0.081456
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [34/1000]  train=0.080937  val=0.081256
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [35/1000]  train=0.080877  val=0.081004
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [36/1000]  train=0.080817  val=0.079450
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [37/1000]  train=0.077454  val=0.082527
Pretrain [38/1000]  train=0.078105  val=0.080580
Pretrain [39/1000]  train=0.076370  val=0.081857
Pretrain [40/1000]  train=0.077522  val=0.078973
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [41/1000]  train=0.077557  val=0.083707
Pretrain [42/1000]  train=0.076785  val=0.082129
Pretrain [43/1000]  train=0.075427  val=0.078555
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [44/1000]  train=0.075708  val=0.079874
Pretrain [45/1000]  train=0.075381  val=0.076504
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [46/1000]  train=0.073074  val=0.079834
Pretrain [47/1000]  train=0.071920  val=0.082584
Pretrain [48/1000]  train=0.070744  val=0.080575
Pretrain [49/1000]  train=0.070170  val=0.079602
Pretrain [50/1000]  train=0.073339  val=0.078514
Pretrain [51/1000]  train=0.071963  val=0.078427
Pretrain [52/1000]  train=0.068884  val=0.076438
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [53/1000]  train=0.071540  val=0.080746
Pretrain [54/1000]  train=0.068516  val=0.072870
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [55/1000]  train=0.067875  val=0.077804
Pretrain [56/1000]  train=0.069148  val=0.076888
Pretrain [57/1000]  train=0.066515  val=0.080166
Pretrain [58/1000]  train=0.067163  val=0.079532
Pretrain [59/1000]  train=0.066598  val=0.079852
Pretrain [60/1000]  train=0.064622  val=0.076319
Pretrain [61/1000]  train=0.064524  val=0.078593
Pretrain [62/1000]  train=0.064514  val=0.075786
Pretrain [63/1000]  train=0.065212  val=0.076227
Pretrain [64/1000]  train=0.063373  val=0.073186
Pretrain [65/1000]  train=0.062387  val=0.075962
Pretrain [66/1000]  train=0.062402  val=0.075541
Pretrain [67/1000]  train=0.062385  val=0.074654
Pretrain [68/1000]  train=0.063163  val=0.076637
Pretrain [69/1000]  train=0.061891  val=0.075376
Pretrain [70/1000]  train=0.060189  val=0.077859
Pretrain [71/1000]  train=0.059568  val=0.074762
Pretrain [72/1000]  train=0.060258  val=0.072763
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [73/1000]  train=0.058512  val=0.078018
Pretrain [74/1000]  train=0.059167  val=0.076860
Pretrain [75/1000]  train=0.059295  val=0.075959
Pretrain [76/1000]  train=0.059182  val=0.074606
Pretrain [77/1000]  train=0.055571  val=0.075548
Pretrain [78/1000]  train=0.057412  val=0.076945
Pretrain [79/1000]  train=0.057618  val=0.075602
Pretrain [80/1000]  train=0.056227  val=0.074913
Pretrain [81/1000]  train=0.055975  val=0.075618
Pretrain [82/1000]  train=0.055740  val=0.072016
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [83/1000]  train=0.055696  val=0.071241
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [84/1000]  train=0.055270  val=0.071981
Pretrain [85/1000]  train=0.054883  val=0.080600
Pretrain [86/1000]  train=0.055161  val=0.073208
Pretrain [87/1000]  train=0.053517  val=0.076808
Pretrain [88/1000]  train=0.053668  val=0.077179
Pretrain [89/1000]  train=0.053786  val=0.073861
Pretrain [90/1000]  train=0.054142  val=0.072785
Pretrain [91/1000]  train=0.053767  val=0.072900
Pretrain [92/1000]  train=0.055083  val=0.075683
Pretrain [93/1000]  train=0.052655  val=0.074553
Pretrain [94/1000]  train=0.051960  val=0.076544
Pretrain [95/1000]  train=0.050172  val=0.071576
Pretrain [96/1000]  train=0.049481  val=0.072885
Pretrain [97/1000]  train=0.051079  val=0.074306
Pretrain [98/1000]  train=0.049167  val=0.071663
Pretrain [99/1000]  train=0.050726  val=0.075551
Pretrain [100/1000]  train=0.051578  val=0.073082
Pretrain [101/1000]  train=0.048248  val=0.071314
Pretrain [102/1000]  train=0.049044  val=0.070112
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [103/1000]  train=0.047858  val=0.072054
Pretrain [104/1000]  train=0.047176  val=0.071760
Pretrain [105/1000]  train=0.047890  val=0.073442
Pretrain [106/1000]  train=0.048533  val=0.070921
Pretrain [107/1000]  train=0.047693  val=0.073393
Pretrain [108/1000]  train=0.046773  val=0.074644
Pretrain [109/1000]  train=0.047542  val=0.073647
Pretrain [110/1000]  train=0.046523  val=0.074658
Pretrain [111/1000]  train=0.046418  val=0.073850
Pretrain [112/1000]  train=0.047526  val=0.074387
Pretrain [113/1000]  train=0.045853  val=0.073823
Pretrain [114/1000]  train=0.045105  val=0.072666
Pretrain [115/1000]  train=0.046850  val=0.074315
Pretrain [116/1000]  train=0.046069  val=0.075043
Pretrain [117/1000]  train=0.046464  val=0.072119
Pretrain [118/1000]  train=0.043863  val=0.074779
Pretrain [119/1000]  train=0.045020  val=0.072469
Pretrain [120/1000]  train=0.044854  val=0.070836
Pretrain [121/1000]  train=0.044046  val=0.073787
Pretrain [122/1000]  train=0.042641  val=0.074889
Pretrain [123/1000]  train=0.044541  val=0.071589
Pretrain [124/1000]  train=0.041637  val=0.072355
Pretrain [125/1000]  train=0.041833  val=0.070911
Pretrain [126/1000]  train=0.041798  val=0.073184
Pretrain [127/1000]  train=0.042826  val=0.073130
Pretrain [128/1000]  train=0.040415  val=0.071937
Pretrain [129/1000]  train=0.041974  val=0.072773
Pretrain [130/1000]  train=0.040984  val=0.070250
Pretrain [131/1000]  train=0.040878  val=0.068820
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [132/1000]  train=0.041058  val=0.068836
Pretrain [133/1000]  train=0.041526  val=0.070629
Pretrain [134/1000]  train=0.039670  val=0.071190
Pretrain [135/1000]  train=0.040351  val=0.069465
Pretrain [136/1000]  train=0.040574  val=0.066404
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/pretrained.pth
Pretrain [137/1000]  train=0.039304  val=0.068874
Pretrain [138/1000]  train=0.039723  val=0.067518
Pretrain [139/1000]  train=0.040921  val=0.067573
Pretrain [140/1000]  train=0.039111  val=0.068546
Pretrain [141/1000]  train=0.039702  val=0.066597
Pretrain [142/1000]  train=0.038499  val=0.067445
Pretrain [143/1000]  train=0.039141  val=0.068364
Pretrain [144/1000]  train=0.039538  val=0.066680
Pretrain [145/1000]  train=0.039209  val=0.067228
Pretrain [146/1000]  train=0.037888  val=0.068327
Pretrain [147/1000]  train=0.038229  val=0.068062
Pretrain [148/1000]  train=0.037266  val=0.067409
Pretrain [149/1000]  train=0.038141  val=0.068964
Pretrain [150/1000]  train=0.037935  val=0.067921
Pretrain [151/1000]  train=0.038794  val=0.067102
Pretrain [152/1000]  train=0.038181  val=0.070194
Pretrain [153/1000]  train=0.037831  val=0.068294
Pretrain [154/1000]  train=0.038066  val=0.070187
Pretrain [155/1000]  train=0.036548  val=0.069941
Pretrain [156/1000]  train=0.038330  val=0.068827
Pretrain [157/1000]  train=0.035431  val=0.070467
Pretrain [158/1000]  train=0.036003  val=0.069807
Pretrain [159/1000]  train=0.035889  val=0.069030
Pretrain [160/1000]  train=0.036433  val=0.069057
Pretrain [161/1000]  train=0.036700  val=0.069609
Pretrain [162/1000]  train=0.035974  val=0.069095
Pretrain [163/1000]  train=0.035976  val=0.068615
Pretrain [164/1000]  train=0.035233  val=0.068373
Pretrain [165/1000]  train=0.036498  val=0.069393
Pretrain [166/1000]  train=0.035960  val=0.068225
Pretrain [167/1000]  train=0.035457  val=0.068265
Pretrain [168/1000]  train=0.035756  val=0.067397
Pretrain [169/1000]  train=0.035697  val=0.068159
Pretrain [170/1000]  train=0.035830  val=0.067316
Pretrain [171/1000]  train=0.034131  val=0.067400
Pretrain [172/1000]  train=0.035047  val=0.067265
Pretrain [173/1000]  train=0.034012  val=0.068004
Pretrain [174/1000]  train=0.034969  val=0.068038
Pretrain [175/1000]  train=0.035776  val=0.067998
Pretrain [176/1000]  train=0.035533  val=0.067917
Pretrain [177/1000]  train=0.035591  val=0.067857
Pretrain [178/1000]  train=0.034867  val=0.067414
Pretrain [179/1000]  train=0.034432  val=0.067395
Pretrain [180/1000]  train=0.035339  val=0.067792
Pretrain [181/1000]  train=0.035113  val=0.067495
Pretrain [182/1000]  train=0.035473  val=0.066851
Pretrain [183/1000]  train=0.034631  val=0.066531
Pretrain [184/1000]  train=0.035933  val=0.067300
Pretrain [185/1000]  train=0.035000  val=0.067530
Pretrain [186/1000]  train=0.034226  val=0.067462
Pretrain [187/1000]  train=0.036331  val=0.067914
Pretrain [188/1000]  train=0.033844  val=0.067543
Pretrain [189/1000]  train=0.034857  val=0.067722
Pretrain [190/1000]  train=0.034320  val=0.067663
Pretrain [191/1000]  train=0.035562  val=0.067811
Pretrain [192/1000]  train=0.034388  val=0.067726
Pretrain [193/1000]  train=0.035339  val=0.067773
Pretrain [194/1000]  train=0.033961  val=0.067738
Pretrain [195/1000]  train=0.034911  val=0.067590
Pretrain [196/1000]  train=0.033660  val=0.067607
Pretrain [197/1000]  train=0.035431  val=0.067580
Pretrain [198/1000]  train=0.035532  val=0.067600
Pretrain [199/1000]  train=0.033953  val=0.067592
Pretrain [200/1000]  train=0.034254  val=0.067610
Pretrain [201/1000]  train=0.054136  val=0.079808
Pretrain [202/1000]  train=0.065838  val=0.079152
Pretrain [203/1000]  train=0.066707  val=0.084599
Pretrain [204/1000]  train=0.065357  val=0.083972
Pretrain [205/1000]  train=0.062488  val=0.084367
Pretrain [206/1000]  train=0.067141  val=0.084680
Pretrain [207/1000]  train=0.062881  val=0.082816
Pretrain [208/1000]  train=0.063437  val=0.087202
Pretrain [209/1000]  train=0.063534  val=0.079599
Pretrain [210/1000]  train=0.063031  val=0.075919
Pretrain [211/1000]  train=0.059214  val=0.079369
Pretrain [212/1000]  train=0.058932  val=0.082160
Pretrain [213/1000]  train=0.060079  val=0.077590
Pretrain [214/1000]  train=0.058298  val=0.080230
Pretrain [215/1000]  train=0.056550  val=0.077987
Pretrain [216/1000]  train=0.056185  val=0.078100
Pretrain [217/1000]  train=0.054972  val=0.077806
Pretrain [218/1000]  train=0.055147  val=0.084280
Pretrain [219/1000]  train=0.054772  val=0.076338
Pretrain [220/1000]  train=0.055576  val=0.082394
Pretrain [221/1000]  train=0.055662  val=0.079367
Pretrain [222/1000]  train=0.054290  val=0.080623
Pretrain [223/1000]  train=0.054488  val=0.076227
Pretrain [224/1000]  train=0.051920  val=0.075698
Pretrain [225/1000]  train=0.053582  val=0.076925
Pretrain [226/1000]  train=0.051943  val=0.079814
Pretrain [227/1000]  train=0.054284  val=0.078147
Pretrain [228/1000]  train=0.053222  val=0.077202
Pretrain [229/1000]  train=0.052432  val=0.080196
Pretrain [230/1000]  train=0.053349  val=0.078505
Pretrain [231/1000]  train=0.053269  val=0.074990
Pretrain [232/1000]  train=0.053830  val=0.076981
Pretrain [233/1000]  train=0.051849  val=0.079285
Pretrain [234/1000]  train=0.053768  val=0.076108
Pretrain [235/1000]  train=0.051497  val=0.079540
Pretrain [236/1000]  train=0.054203  val=0.075541
Pretrain [237/1000]  train=0.051817  val=0.079568
Pretrain [238/1000]  train=0.050681  val=0.077522
Pretrain [239/1000]  train=0.051865  val=0.078530
Pretrain [240/1000]  train=0.053611  val=0.075934
Pretrain [241/1000]  train=0.050937  val=0.075475
Pretrain [242/1000]  train=0.050866  val=0.075596
Pretrain [243/1000]  train=0.051870  val=0.077156
Pretrain [244/1000]  train=0.048304  val=0.077113
Pretrain [245/1000]  train=0.049994  val=0.075157
Pretrain [246/1000]  train=0.048374  val=0.074251
Pretrain [247/1000]  train=0.050756  val=0.076566
Pretrain [248/1000]  train=0.050552  val=0.076339
Pretrain [249/1000]  train=0.047706  val=0.074364
Pretrain [250/1000]  train=0.048372  val=0.072008
Pretrain [251/1000]  train=0.049984  val=0.077226
Pretrain [252/1000]  train=0.048501  val=0.075494
Pretrain [253/1000]  train=0.047145  val=0.072691
Pretrain [254/1000]  train=0.045831  val=0.070596
Pretrain [255/1000]  train=0.046599  val=0.076457
Pretrain [256/1000]  train=0.047195  val=0.075957
Pretrain [257/1000]  train=0.045641  val=0.071981
Pretrain [258/1000]  train=0.046914  val=0.076378
Pretrain [259/1000]  train=0.045285  val=0.073162
Pretrain [260/1000]  train=0.048381  val=0.076597
Pretrain [261/1000]  train=0.047653  val=0.076450
Pretrain [262/1000]  train=0.046055  val=0.077532
Pretrain [263/1000]  train=0.046409  val=0.075751
Pretrain [264/1000]  train=0.046674  val=0.075372
Pretrain [265/1000]  train=0.046434  val=0.074911
Pretrain [266/1000]  train=0.045358  val=0.076890
Pretrain [267/1000]  train=0.044095  val=0.077773
Pretrain [268/1000]  train=0.044479  val=0.074900
Pretrain [269/1000]  train=0.044955  val=0.083162
Pretrain [270/1000]  train=0.046238  val=0.077709
Pretrain [271/1000]  train=0.045378  val=0.076924
Pretrain [272/1000]  train=0.045003  val=0.077955
Pretrain [273/1000]  train=0.041586  val=0.076382
Pretrain [274/1000]  train=0.044426  val=0.076193
Pretrain [275/1000]  train=0.041769  val=0.077163
Pretrain [276/1000]  train=0.041165  val=0.076454
Pretrain [277/1000]  train=0.043008  val=0.077165
Pretrain [278/1000]  train=0.043687  val=0.073292
Pretrain [279/1000]  train=0.044340  val=0.074496
Pretrain [280/1000]  train=0.042511  val=0.077997
Pretrain [281/1000]  train=0.040919  val=0.075892
Pretrain [282/1000]  train=0.042380  val=0.076954
Pretrain [283/1000]  train=0.040014  val=0.077142
Pretrain [284/1000]  train=0.042303  val=0.073688
Pretrain [285/1000]  train=0.042822  val=0.071540
Pretrain [286/1000]  train=0.041543  val=0.075870
Pretrain [287/1000]  train=0.040972  val=0.074309
Pretrain [288/1000]  train=0.040611  val=0.073224
Pretrain [289/1000]  train=0.040343  val=0.071226
Pretrain [290/1000]  train=0.041875  val=0.073449
Pretrain [291/1000]  train=0.039589  val=0.072591
Pretrain [292/1000]  train=0.041211  val=0.075096
Pretrain [293/1000]  train=0.039284  val=0.071761
Pretrain [294/1000]  train=0.038051  val=0.074981
Pretrain [295/1000]  train=0.039202  val=0.071689
Pretrain [296/1000]  train=0.040614  val=0.076203
Pretrain [297/1000]  train=0.038844  val=0.073339
Pretrain [298/1000]  train=0.039930  val=0.073011
Pretrain [299/1000]  train=0.038066  val=0.072191
Pretrain [300/1000]  train=0.038704  val=0.073711
Pretrain [301/1000]  train=0.038471  val=0.076175
Pretrain [302/1000]  train=0.037761  val=0.073158
Pretrain [303/1000]  train=0.038540  val=0.071733
Pretrain [304/1000]  train=0.038097  val=0.069970
Pretrain [305/1000]  train=0.037331  val=0.074769
Pretrain [306/1000]  train=0.037302  val=0.071120
Pretrain [307/1000]  train=0.036308  val=0.072663
Pretrain [308/1000]  train=0.037733  val=0.075169
Pretrain [309/1000]  train=0.037654  val=0.070697
Pretrain [310/1000]  train=0.037151  val=0.071529
Pretrain [311/1000]  train=0.035932  val=0.071055
Pretrain [312/1000]  train=0.035575  val=0.069107
Pretrain [313/1000]  train=0.035605  val=0.070003
Pretrain [314/1000]  train=0.036079  val=0.068523
Pretrain [315/1000]  train=0.036302  val=0.070353
Pretrain [316/1000]  train=0.037069  val=0.070109
Pretrain [317/1000]  train=0.035962  val=0.070007
Pretrain [318/1000]  train=0.034472  val=0.071068
Pretrain [319/1000]  train=0.033639  val=0.070636
Pretrain [320/1000]  train=0.035368  val=0.071509
Pretrain [321/1000]  train=0.034804  val=0.070447
Pretrain [322/1000]  train=0.034542  val=0.071449
Pretrain [323/1000]  train=0.034859  val=0.069937
Pretrain [324/1000]  train=0.033345  val=0.068703
Pretrain [325/1000]  train=0.033747  val=0.070064
Pretrain [326/1000]  train=0.034362  val=0.070077
Pretrain [327/1000]  train=0.034372  val=0.068846
Pretrain [328/1000]  train=0.033763  val=0.069174
Pretrain [329/1000]  train=0.034761  val=0.069826
Pretrain [330/1000]  train=0.033900  val=0.069067
Pretrain [331/1000]  train=0.032708  val=0.068336
Pretrain [332/1000]  train=0.032850  val=0.070193
Pretrain [333/1000]  train=0.032441  val=0.067832
Pretrain [334/1000]  train=0.031556  val=0.068680
Pretrain [335/1000]  train=0.033685  val=0.070065
Pretrain [336/1000]  train=0.032658  val=0.069699
  -> 验证未改进 200 次，早停。
[PRETRAIN] 最佳 val=0.066404 已保存。

--- [阶段二] 对齐微调 (NLL + α·(1−R2) + λ·CORAL) ---
Fine-tune [1/100000]  val_loss=0.260279
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [2/100000]  val_loss=0.129714
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [3/100000]  val_loss=0.003621
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [4/100000]  val_loss=-0.112524
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [5/100000]  val_loss=-0.205772
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [6/100000]  val_loss=-0.286219
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [7/100000]  val_loss=-0.355898
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [8/100000]  val_loss=-0.407090
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [9/100000]  val_loss=-0.453045
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [10/100000]  val_loss=-0.496081
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [11/100000]  val_loss=-0.523088
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [12/100000]  val_loss=-0.555349
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [13/100000]  val_loss=-0.576933
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [14/100000]  val_loss=-0.605640
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [15/100000]  val_loss=-0.609859
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [16/100000]  val_loss=-0.629110
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [17/100000]  val_loss=-0.639906
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [18/100000]  val_loss=-0.658170
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [19/100000]  val_loss=-0.664005
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [20/100000]  val_loss=-0.676687
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [21/100000]  val_loss=-0.699432
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [22/100000]  val_loss=-0.718352
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [23/100000]  val_loss=-0.713548
Fine-tune [24/100000]  val_loss=-0.720037
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [25/100000]  val_loss=-0.729311
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [26/100000]  val_loss=-0.751972
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [27/100000]  val_loss=-0.759913
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [28/100000]  val_loss=-0.771459
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [29/100000]  val_loss=-0.776158
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [30/100000]  val_loss=-0.765987
Fine-tune [31/100000]  val_loss=-0.783307
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [32/100000]  val_loss=-0.799191
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [33/100000]  val_loss=-0.800692
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [34/100000]  val_loss=-0.800150
Fine-tune [35/100000]  val_loss=-0.811345
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [36/100000]  val_loss=-0.833517
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [37/100000]  val_loss=-0.824586
Fine-tune [38/100000]  val_loss=-0.839705
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [39/100000]  val_loss=-0.850501
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [40/100000]  val_loss=-0.855366
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [41/100000]  val_loss=-0.854835
Fine-tune [42/100000]  val_loss=-0.843193
Fine-tune [43/100000]  val_loss=-0.851562
Fine-tune [44/100000]  val_loss=-0.849564
Fine-tune [45/100000]  val_loss=-0.851017
Fine-tune [46/100000]  val_loss=-0.861383
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [47/100000]  val_loss=-0.847786
Fine-tune [48/100000]  val_loss=-0.868732
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [49/100000]  val_loss=-0.870056
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [50/100000]  val_loss=-0.870448
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [51/100000]  val_loss=-0.867894
Fine-tune [52/100000]  val_loss=-0.874038
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [53/100000]  val_loss=-0.883112
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [54/100000]  val_loss=-0.878110
Fine-tune [55/100000]  val_loss=-0.878323
Fine-tune [56/100000]  val_loss=-0.895655
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [57/100000]  val_loss=-0.905237
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [58/100000]  val_loss=-0.915335
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [59/100000]  val_loss=-0.907369
Fine-tune [60/100000]  val_loss=-0.917570
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [61/100000]  val_loss=-0.913582
Fine-tune [62/100000]  val_loss=-0.924361
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [63/100000]  val_loss=-0.935227
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [64/100000]  val_loss=-0.916852
Fine-tune [65/100000]  val_loss=-0.928416
Fine-tune [66/100000]  val_loss=-0.930236
Fine-tune [67/100000]  val_loss=-0.929672
Fine-tune [68/100000]  val_loss=-0.928123
Fine-tune [69/100000]  val_loss=-0.941197
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [70/100000]  val_loss=-0.944491
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [71/100000]  val_loss=-0.957042
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [72/100000]  val_loss=-0.950782
Fine-tune [73/100000]  val_loss=-0.946192
Fine-tune [74/100000]  val_loss=-0.945286
Fine-tune [75/100000]  val_loss=-0.955685
Fine-tune [76/100000]  val_loss=-0.954037
Fine-tune [77/100000]  val_loss=-0.950103
Fine-tune [78/100000]  val_loss=-0.957230
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [79/100000]  val_loss=-0.956336
Fine-tune [80/100000]  val_loss=-0.963384
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [81/100000]  val_loss=-0.962115
Fine-tune [82/100000]  val_loss=-0.970300
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [83/100000]  val_loss=-0.970919
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [84/100000]  val_loss=-0.960682
Fine-tune [85/100000]  val_loss=-0.973150
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [86/100000]  val_loss=-0.975246
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [87/100000]  val_loss=-0.959843
Fine-tune [88/100000]  val_loss=-0.971387
Fine-tune [89/100000]  val_loss=-0.973693
Fine-tune [90/100000]  val_loss=-0.987141
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [91/100000]  val_loss=-0.981368
Fine-tune [92/100000]  val_loss=-0.968726
Fine-tune [93/100000]  val_loss=-0.940956
Fine-tune [94/100000]  val_loss=-0.967635
Fine-tune [95/100000]  val_loss=-0.972913
Fine-tune [96/100000]  val_loss=-0.982701
Fine-tune [97/100000]  val_loss=-0.976177
Fine-tune [98/100000]  val_loss=-0.969872
Fine-tune [99/100000]  val_loss=-0.988340
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [100/100000]  val_loss=-0.986626
Fine-tune [101/100000]  val_loss=-0.968641
Fine-tune [102/100000]  val_loss=-0.972696
Fine-tune [103/100000]  val_loss=-0.979158
Fine-tune [104/100000]  val_loss=-0.986757
Fine-tune [105/100000]  val_loss=-0.988480
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [106/100000]  val_loss=-0.988006
Fine-tune [107/100000]  val_loss=-0.975086
Fine-tune [108/100000]  val_loss=-0.996448
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [109/100000]  val_loss=-0.999802
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [110/100000]  val_loss=-0.992272
Fine-tune [111/100000]  val_loss=-1.003161
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [112/100000]  val_loss=-0.997459
Fine-tune [113/100000]  val_loss=-0.995651
Fine-tune [114/100000]  val_loss=-1.006553
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [115/100000]  val_loss=-1.009622
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [116/100000]  val_loss=-0.992628
Fine-tune [117/100000]  val_loss=-1.007011
Fine-tune [118/100000]  val_loss=-1.015734
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [119/100000]  val_loss=-1.009835
Fine-tune [120/100000]  val_loss=-1.010619
Fine-tune [121/100000]  val_loss=-0.988788
Fine-tune [122/100000]  val_loss=-0.995884
Fine-tune [123/100000]  val_loss=-0.993500
Fine-tune [124/100000]  val_loss=-1.001366
Fine-tune [125/100000]  val_loss=-1.010397
Fine-tune [126/100000]  val_loss=-0.994734
Fine-tune [127/100000]  val_loss=-0.992318
Fine-tune [128/100000]  val_loss=-0.985983
Fine-tune [129/100000]  val_loss=-1.002076
Fine-tune [130/100000]  val_loss=-0.999708
Fine-tune [131/100000]  val_loss=-1.009574
Fine-tune [132/100000]  val_loss=-0.997830
Fine-tune [133/100000]  val_loss=-1.009066
Fine-tune [134/100000]  val_loss=-1.007086
Fine-tune [135/100000]  val_loss=-1.001545
Fine-tune [136/100000]  val_loss=-1.014341
Fine-tune [137/100000]  val_loss=-1.005955
Fine-tune [138/100000]  val_loss=-1.002704
Fine-tune [139/100000]  val_loss=-1.020687
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [140/100000]  val_loss=-1.012803
Fine-tune [141/100000]  val_loss=-1.009692
Fine-tune [142/100000]  val_loss=-1.017424
Fine-tune [143/100000]  val_loss=-1.019426
Fine-tune [144/100000]  val_loss=-1.011100
Fine-tune [145/100000]  val_loss=-1.006624
Fine-tune [146/100000]  val_loss=-1.015202
Fine-tune [147/100000]  val_loss=-1.002441
Fine-tune [148/100000]  val_loss=-1.017073
Fine-tune [149/100000]  val_loss=-1.003947
Fine-tune [150/100000]  val_loss=-0.997071
Fine-tune [151/100000]  val_loss=-1.021795
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [152/100000]  val_loss=-1.007092
Fine-tune [153/100000]  val_loss=-1.011812
Fine-tune [154/100000]  val_loss=-1.013097
Fine-tune [155/100000]  val_loss=-0.998840
Fine-tune [156/100000]  val_loss=-1.018346
Fine-tune [157/100000]  val_loss=-1.018266
Fine-tune [158/100000]  val_loss=-1.034239
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [159/100000]  val_loss=-1.013937
Fine-tune [160/100000]  val_loss=-0.999405
Fine-tune [161/100000]  val_loss=-1.009908
Fine-tune [162/100000]  val_loss=-1.015360
Fine-tune [163/100000]  val_loss=-1.018157
Fine-tune [164/100000]  val_loss=-1.028422
Fine-tune [165/100000]  val_loss=-1.033804
Fine-tune [166/100000]  val_loss=-0.998834
Fine-tune [167/100000]  val_loss=-0.997892
Fine-tune [168/100000]  val_loss=-1.017829
Fine-tune [169/100000]  val_loss=-1.005237
Fine-tune [170/100000]  val_loss=-0.996522
Fine-tune [171/100000]  val_loss=-0.995819
Fine-tune [172/100000]  val_loss=-1.001841
Fine-tune [173/100000]  val_loss=-0.998844
Fine-tune [174/100000]  val_loss=-1.012449
Fine-tune [175/100000]  val_loss=-1.032307
Fine-tune [176/100000]  val_loss=-1.028571
Fine-tune [177/100000]  val_loss=-1.014782
Fine-tune [178/100000]  val_loss=-1.001989
Fine-tune [179/100000]  val_loss=-1.021471
Fine-tune [180/100000]  val_loss=-1.030837
Fine-tune [181/100000]  val_loss=-1.022695
Fine-tune [182/100000]  val_loss=-1.028710
Fine-tune [183/100000]  val_loss=-1.013376
Fine-tune [184/100000]  val_loss=-1.030298
Fine-tune [185/100000]  val_loss=-1.024039
Fine-tune [186/100000]  val_loss=-1.009248
Fine-tune [187/100000]  val_loss=-1.021257
Fine-tune [188/100000]  val_loss=-1.018819
Fine-tune [189/100000]  val_loss=-1.028977
Fine-tune [190/100000]  val_loss=-1.045088
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [191/100000]  val_loss=-1.030482
Fine-tune [192/100000]  val_loss=-1.045827
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [193/100000]  val_loss=-1.030271
Fine-tune [194/100000]  val_loss=-1.040336
Fine-tune [195/100000]  val_loss=-1.041764
Fine-tune [196/100000]  val_loss=-1.046998
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L3/finetuned.pth
Fine-tune [197/100000]  val_loss=-1.030427
Fine-tune [198/100000]  val_loss=-1.035648
Fine-tune [199/100000]  val_loss=-1.032389
Fine-tune [200/100000]  val_loss=-1.011910
Fine-tune [201/100000]  val_loss=-1.005074
Fine-tune [202/100000]  val_loss=-1.019599
Fine-tune [203/100000]  val_loss=-1.024794
Fine-tune [204/100000]  val_loss=-1.002854
Fine-tune [205/100000]  val_loss=-0.995220
Fine-tune [206/100000]  val_loss=-1.000664
Fine-tune [207/100000]  val_loss=-1.016852
Fine-tune [208/100000]  val_loss=-1.028504
Fine-tune [209/100000]  val_loss=-1.030629
Fine-tune [210/100000]  val_loss=-1.011585
Fine-tune [211/100000]  val_loss=-1.020875
Fine-tune [212/100000]  val_loss=-1.010243
Fine-tune [213/100000]  val_loss=-1.002180
Fine-tune [214/100000]  val_loss=-1.009672
Fine-tune [215/100000]  val_loss=-1.030576
Fine-tune [216/100000]  val_loss=-1.014404
Fine-tune [217/100000]  val_loss=-1.022794
Fine-tune [218/100000]  val_loss=-1.015181
Fine-tune [219/100000]  val_loss=-1.032164
Fine-tune [220/100000]  val_loss=-0.998842
Fine-tune [221/100000]  val_loss=-0.998000
Fine-tune [222/100000]  val_loss=-1.002790
Fine-tune [223/100000]  val_loss=-1.002410
Fine-tune [224/100000]  val_loss=-1.008560
Fine-tune [225/100000]  val_loss=-1.005150
Fine-tune [226/100000]  val_loss=-0.995384
Fine-tune [227/100000]  val_loss=-1.018770
Fine-tune [228/100000]  val_loss=-1.018618
Fine-tune [229/100000]  val_loss=-1.001337
Fine-tune [230/100000]  val_loss=-1.004766
Fine-tune [231/100000]  val_loss=-1.004787
Fine-tune [232/100000]  val_loss=-1.031732
Fine-tune [233/100000]  val_loss=-1.012244
Fine-tune [234/100000]  val_loss=-1.040215
Fine-tune [235/100000]  val_loss=-1.013611
Fine-tune [236/100000]  val_loss=-1.029407
Fine-tune [237/100000]  val_loss=-1.017111
Fine-tune [238/100000]  val_loss=-1.016586
Fine-tune [239/100000]  val_loss=-1.020887
Fine-tune [240/100000]  val_loss=-1.025090
Fine-tune [241/100000]  val_loss=-0.993250
Fine-tune [242/100000]  val_loss=-1.000805
Fine-tune [243/100000]  val_loss=-0.998599
Fine-tune [244/100000]  val_loss=-0.988200
Fine-tune [245/100000]  val_loss=-0.982720
Fine-tune [246/100000]  val_loss=-0.974230
Fine-tune [247/100000]  val_loss=-0.981619
Fine-tune [248/100000]  val_loss=-1.005483
Fine-tune [249/100000]  val_loss=-1.029626
Fine-tune [250/100000]  val_loss=-0.998998
Fine-tune [251/100000]  val_loss=-1.007125
Fine-tune [252/100000]  val_loss=-1.010104
Fine-tune [253/100000]  val_loss=-0.987923
Fine-tune [254/100000]  val_loss=-0.995045
Fine-tune [255/100000]  val_loss=-0.991419
Fine-tune [256/100000]  val_loss=-0.999449
Fine-tune [257/100000]  val_loss=-0.996719
Fine-tune [258/100000]  val_loss=-0.987457
Fine-tune [259/100000]  val_loss=-0.965715
Fine-tune [260/100000]  val_loss=-0.982692
Fine-tune [261/100000]  val_loss=-0.989231
Fine-tune [262/100000]  val_loss=-1.003511
Fine-tune [263/100000]  val_loss=-0.979329
Fine-tune [264/100000]  val_loss=-0.970645
Fine-tune [265/100000]  val_loss=-0.963184
Fine-tune [266/100000]  val_loss=-0.988172
Fine-tune [267/100000]  val_loss=-1.003711
Fine-tune [268/100000]  val_loss=-1.010763
Fine-tune [269/100000]  val_loss=-0.996170
Fine-tune [270/100000]  val_loss=-0.976574
Fine-tune [271/100000]  val_loss=-0.991198
Fine-tune [272/100000]  val_loss=-1.008858
Fine-tune [273/100000]  val_loss=-0.995822
Fine-tune [274/100000]  val_loss=-0.991244
Fine-tune [275/100000]  val_loss=-0.972082
Fine-tune [276/100000]  val_loss=-0.965706
Fine-tune [277/100000]  val_loss=-0.973571
Fine-tune [278/100000]  val_loss=-0.991201
Fine-tune [279/100000]  val_loss=-0.992251
Fine-tune [280/100000]  val_loss=-0.961785
Fine-tune [281/100000]  val_loss=-0.952487
Fine-tune [282/100000]  val_loss=-0.982754
Fine-tune [283/100000]  val_loss=-0.978968
Fine-tune [284/100000]  val_loss=-0.999152
Fine-tune [285/100000]  val_loss=-1.015818
Fine-tune [286/100000]  val_loss=-1.006654
Fine-tune [287/100000]  val_loss=-0.983227
Fine-tune [288/100000]  val_loss=-0.980355
Fine-tune [289/100000]  val_loss=-0.993486
Fine-tune [290/100000]  val_loss=-0.994065
Fine-tune [291/100000]  val_loss=-0.970137
Fine-tune [292/100000]  val_loss=-0.983860
Fine-tune [293/100000]  val_loss=-0.970465
Fine-tune [294/100000]  val_loss=-0.965610
Fine-tune [295/100000]  val_loss=-0.982690
Fine-tune [296/100000]  val_loss=-0.997526
Fine-tune [297/100000]  val_loss=-0.996876
Fine-tune [298/100000]  val_loss=-0.978688
Fine-tune [299/100000]  val_loss=-0.997001
Fine-tune [300/100000]  val_loss=-0.991791
Fine-tune [301/100000]  val_loss=-0.985826
Fine-tune [302/100000]  val_loss=-0.970948
Fine-tune [303/100000]  val_loss=-0.952234
Fine-tune [304/100000]  val_loss=-0.965441
Fine-tune [305/100000]  val_loss=-0.946778
Fine-tune [306/100000]  val_loss=-0.985786
Fine-tune [307/100000]  val_loss=-0.980770
Fine-tune [308/100000]  val_loss=-0.974006
Fine-tune [309/100000]  val_loss=-0.986699
Fine-tune [310/100000]  val_loss=-0.983822
Fine-tune [311/100000]  val_loss=-0.993606
Fine-tune [312/100000]  val_loss=-0.982886
Fine-tune [313/100000]  val_loss=-1.000254
Fine-tune [314/100000]  val_loss=-0.996046
Fine-tune [315/100000]  val_loss=-0.966901
Fine-tune [316/100000]  val_loss=-0.979848
Fine-tune [317/100000]  val_loss=-0.974157
Fine-tune [318/100000]  val_loss=-0.965333
Fine-tune [319/100000]  val_loss=-0.972449
Fine-tune [320/100000]  val_loss=-0.991157
Fine-tune [321/100000]  val_loss=-0.990769
Fine-tune [322/100000]  val_loss=-0.978816
Fine-tune [323/100000]  val_loss=-0.992073
Fine-tune [324/100000]  val_loss=-0.988550
Fine-tune [325/100000]  val_loss=-0.974601
Fine-tune [326/100000]  val_loss=-0.973935
Fine-tune [327/100000]  val_loss=-0.962360
Fine-tune [328/100000]  val_loss=-0.985795
Fine-tune [329/100000]  val_loss=-0.979635
Fine-tune [330/100000]  val_loss=-0.984949
Fine-tune [331/100000]  val_loss=-0.983405
Fine-tune [332/100000]  val_loss=-0.960089
Fine-tune [333/100000]  val_loss=-0.961004
Fine-tune [334/100000]  val_loss=-0.951991
Fine-tune [335/100000]  val_loss=-0.961929
Fine-tune [336/100000]  val_loss=-0.988892
Fine-tune [337/100000]  val_loss=-0.983498
Fine-tune [338/100000]  val_loss=-0.967147
Fine-tune [339/100000]  val_loss=-0.970694
Fine-tune [340/100000]  val_loss=-0.976255
Fine-tune [341/100000]  val_loss=-0.983214
Fine-tune [342/100000]  val_loss=-0.967827
Fine-tune [343/100000]  val_loss=-0.975434
Fine-tune [344/100000]  val_loss=-0.967700
Fine-tune [345/100000]  val_loss=-0.973375
Fine-tune [346/100000]  val_loss=-0.957178
Fine-tune [347/100000]  val_loss=-0.970189
Fine-tune [348/100000]  val_loss=-0.996215
Fine-tune [349/100000]  val_loss=-0.985563
Fine-tune [350/100000]  val_loss=-0.974380
Fine-tune [351/100000]  val_loss=-0.962707
Fine-tune [352/100000]  val_loss=-0.975484
Fine-tune [353/100000]  val_loss=-0.997993
Fine-tune [354/100000]  val_loss=-0.990055
Fine-tune [355/100000]  val_loss=-0.968761
Fine-tune [356/100000]  val_loss=-0.973924
Fine-tune [357/100000]  val_loss=-0.984405
Fine-tune [358/100000]  val_loss=-0.971542
Fine-tune [359/100000]  val_loss=-0.972052
Fine-tune [360/100000]  val_loss=-0.936255
Fine-tune [361/100000]  val_loss=-0.949677
Fine-tune [362/100000]  val_loss=-0.976579
Fine-tune [363/100000]  val_loss=-0.960483
Fine-tune [364/100000]  val_loss=-0.957562
Fine-tune [365/100000]  val_loss=-0.958616
Fine-tune [366/100000]  val_loss=-0.972468
Fine-tune [367/100000]  val_loss=-0.957347
Fine-tune [368/100000]  val_loss=-0.957288
Fine-tune [369/100000]  val_loss=-0.947961
Fine-tune [370/100000]  val_loss=-0.972208
Fine-tune [371/100000]  val_loss=-0.957874
Fine-tune [372/100000]  val_loss=-0.957606
Fine-tune [373/100000]  val_loss=-0.944244
Fine-tune [374/100000]  val_loss=-0.935424
Fine-tune [375/100000]  val_loss=-0.949891
Fine-tune [376/100000]  val_loss=-0.952664
Fine-tune [377/100000]  val_loss=-0.970088
Fine-tune [378/100000]  val_loss=-0.950976
Fine-tune [379/100000]  val_loss=-0.933001
Fine-tune [380/100000]  val_loss=-0.935752
Fine-tune [381/100000]  val_loss=-0.948752
Fine-tune [382/100000]  val_loss=-0.930575
Fine-tune [383/100000]  val_loss=-0.941332
Fine-tune [384/100000]  val_loss=-0.938231
Fine-tune [385/100000]  val_loss=-0.949488
Fine-tune [386/100000]  val_loss=-0.935316
Fine-tune [387/100000]  val_loss=-0.944577
Fine-tune [388/100000]  val_loss=-0.943549
Fine-tune [389/100000]  val_loss=-0.950691
Fine-tune [390/100000]  val_loss=-0.958512
Fine-tune [391/100000]  val_loss=-0.946635
Fine-tune [392/100000]  val_loss=-0.907845
Fine-tune [393/100000]  val_loss=-0.931778
Fine-tune [394/100000]  val_loss=-0.919738
Fine-tune [395/100000]  val_loss=-0.933305
Fine-tune [396/100000]  val_loss=-0.977354
Fine-tune [397/100000]  val_loss=-0.960695
Fine-tune [398/100000]  val_loss=-0.956153
Fine-tune [399/100000]  val_loss=-0.971091
Fine-tune [400/100000]  val_loss=-0.950049
Fine-tune [401/100000]  val_loss=-0.963537
Fine-tune [402/100000]  val_loss=-0.936879
Fine-tune [403/100000]  val_loss=-0.950581
Fine-tune [404/100000]  val_loss=-0.961280
Fine-tune [405/100000]  val_loss=-0.927027
Fine-tune [406/100000]  val_loss=-0.950398
Fine-tune [407/100000]  val_loss=-0.949250
Fine-tune [408/100000]  val_loss=-0.952130
Fine-tune [409/100000]  val_loss=-0.917768
Fine-tune [410/100000]  val_loss=-0.934602
Fine-tune [411/100000]  val_loss=-0.921901
Fine-tune [412/100000]  val_loss=-0.941577
Fine-tune [413/100000]  val_loss=-0.928282
Fine-tune [414/100000]  val_loss=-0.966964
Fine-tune [415/100000]  val_loss=-0.951497
Fine-tune [416/100000]  val_loss=-0.974747
Fine-tune [417/100000]  val_loss=-0.956520
Fine-tune [418/100000]  val_loss=-0.947402
Fine-tune [419/100000]  val_loss=-0.951745
Fine-tune [420/100000]  val_loss=-0.947103
Fine-tune [421/100000]  val_loss=-0.917242
Fine-tune [422/100000]  val_loss=-0.935581
Fine-tune [423/100000]  val_loss=-0.916605
Fine-tune [424/100000]  val_loss=-0.921271
Fine-tune [425/100000]  val_loss=-0.943420
Fine-tune [426/100000]  val_loss=-0.944440
Fine-tune [427/100000]  val_loss=-0.938015
Fine-tune [428/100000]  val_loss=-0.938105
Fine-tune [429/100000]  val_loss=-0.945579
Fine-tune [430/100000]  val_loss=-0.929954
Fine-tune [431/100000]  val_loss=-0.949464
Fine-tune [432/100000]  val_loss=-0.960572
Fine-tune [433/100000]  val_loss=-0.953858
Fine-tune [434/100000]  val_loss=-0.951938
Fine-tune [435/100000]  val_loss=-0.939017
Fine-tune [436/100000]  val_loss=-0.929563
Fine-tune [437/100000]  val_loss=-0.949494
Fine-tune [438/100000]  val_loss=-0.954469
Fine-tune [439/100000]  val_loss=-0.961253
Fine-tune [440/100000]  val_loss=-0.975262
Fine-tune [441/100000]  val_loss=-0.971703
Fine-tune [442/100000]  val_loss=-0.964540
Fine-tune [443/100000]  val_loss=-0.974173
Fine-tune [444/100000]  val_loss=-0.956005
Fine-tune [445/100000]  val_loss=-0.944195
Fine-tune [446/100000]  val_loss=-0.939576
Fine-tune [447/100000]  val_loss=-0.915688
Fine-tune [448/100000]  val_loss=-0.928771
Fine-tune [449/100000]  val_loss=-0.930049
Fine-tune [450/100000]  val_loss=-0.945842
Fine-tune [451/100000]  val_loss=-0.923353
Fine-tune [452/100000]  val_loss=-0.933275
Fine-tune [453/100000]  val_loss=-0.926685
Fine-tune [454/100000]  val_loss=-0.929679
Fine-tune [455/100000]  val_loss=-0.931043
Fine-tune [456/100000]  val_loss=-0.930329
Fine-tune [457/100000]  val_loss=-0.884584
Fine-tune [458/100000]  val_loss=-0.933781
Fine-tune [459/100000]  val_loss=-0.942707
Fine-tune [460/100000]  val_loss=-0.938604
Fine-tune [461/100000]  val_loss=-0.954867
Fine-tune [462/100000]  val_loss=-0.934348
Fine-tune [463/100000]  val_loss=-0.916980
Fine-tune [464/100000]  val_loss=-0.946735
Fine-tune [465/100000]  val_loss=-0.927388
Fine-tune [466/100000]  val_loss=-0.924339
Fine-tune [467/100000]  val_loss=-0.941324
Fine-tune [468/100000]  val_loss=-0.907401
Fine-tune [469/100000]  val_loss=-0.933257
Fine-tune [470/100000]  val_loss=-0.936559
Fine-tune [471/100000]  val_loss=-0.917420
Fine-tune [472/100000]  val_loss=-0.933213
Fine-tune [473/100000]  val_loss=-0.955091
Fine-tune [474/100000]  val_loss=-0.916763
Fine-tune [475/100000]  val_loss=-0.924370
Fine-tune [476/100000]  val_loss=-0.920631
Fine-tune [477/100000]  val_loss=-0.918576
Fine-tune [478/100000]  val_loss=-0.934210
Fine-tune [479/100000]  val_loss=-0.914432
Fine-tune [480/100000]  val_loss=-0.926799
Fine-tune [481/100000]  val_loss=-0.872074
Fine-tune [482/100000]  val_loss=-0.881476
Fine-tune [483/100000]  val_loss=-0.918394
Fine-tune [484/100000]  val_loss=-0.918208
Fine-tune [485/100000]  val_loss=-0.943541
Fine-tune [486/100000]  val_loss=-0.929398
Fine-tune [487/100000]  val_loss=-0.941316
Fine-tune [488/100000]  val_loss=-0.929218
Fine-tune [489/100000]  val_loss=-0.920724
Fine-tune [490/100000]  val_loss=-0.904128
Fine-tune [491/100000]  val_loss=-0.908825
Fine-tune [492/100000]  val_loss=-0.889862
Fine-tune [493/100000]  val_loss=-0.883828
Fine-tune [494/100000]  val_loss=-0.917282
Fine-tune [495/100000]  val_loss=-0.926772
Fine-tune [496/100000]  val_loss=-0.900670
Fine-tune [497/100000]  val_loss=-0.910198
Fine-tune [498/100000]  val_loss=-0.893726
Fine-tune [499/100000]  val_loss=-0.894067
Fine-tune [500/100000]  val_loss=-0.901349
Fine-tune [501/100000]  val_loss=-0.905544
Fine-tune [502/100000]  val_loss=-0.900289
Fine-tune [503/100000]  val_loss=-0.880290
Fine-tune [504/100000]  val_loss=-0.904908
Fine-tune [505/100000]  val_loss=-0.895064
Fine-tune [506/100000]  val_loss=-0.905996
Fine-tune [507/100000]  val_loss=-0.930830
Fine-tune [508/100000]  val_loss=-0.909099
Fine-tune [509/100000]  val_loss=-0.935645
Fine-tune [510/100000]  val_loss=-0.901002
Fine-tune [511/100000]  val_loss=-0.917228
Fine-tune [512/100000]  val_loss=-0.894483
Fine-tune [513/100000]  val_loss=-0.893287
Fine-tune [514/100000]  val_loss=-0.863877
Fine-tune [515/100000]  val_loss=-0.867946
Fine-tune [516/100000]  val_loss=-0.885926
Fine-tune [517/100000]  val_loss=-0.858670
Fine-tune [518/100000]  val_loss=-0.879553
Fine-tune [519/100000]  val_loss=-0.874089
Fine-tune [520/100000]  val_loss=-0.902163
Fine-tune [521/100000]  val_loss=-0.872105
Fine-tune [522/100000]  val_loss=-0.900275
Fine-tune [523/100000]  val_loss=-0.869019
Fine-tune [524/100000]  val_loss=-0.875859
Fine-tune [525/100000]  val_loss=-0.873154
Fine-tune [526/100000]  val_loss=-0.845967
Fine-tune [527/100000]  val_loss=-0.875140
Fine-tune [528/100000]  val_loss=-0.858362
Fine-tune [529/100000]  val_loss=-0.871269
Fine-tune [530/100000]  val_loss=-0.832791
Fine-tune [531/100000]  val_loss=-0.831196
Fine-tune [532/100000]  val_loss=-0.850707
Fine-tune [533/100000]  val_loss=-0.867279
Fine-tune [534/100000]  val_loss=-0.881856
Fine-tune [535/100000]  val_loss=-0.866003
Fine-tune [536/100000]  val_loss=-0.860569
Fine-tune [537/100000]  val_loss=-0.836854
Fine-tune [538/100000]  val_loss=-0.843460
Fine-tune [539/100000]  val_loss=-0.835600
Fine-tune [540/100000]  val_loss=-0.841374
Fine-tune [541/100000]  val_loss=-0.839640
Fine-tune [542/100000]  val_loss=-0.818088
Fine-tune [543/100000]  val_loss=-0.807979
Fine-tune [544/100000]  val_loss=-0.857775
Fine-tune [545/100000]  val_loss=-0.864073
Fine-tune [546/100000]  val_loss=-0.890440
Fine-tune [547/100000]  val_loss=-0.876614
Fine-tune [548/100000]  val_loss=-0.873395
Fine-tune [549/100000]  val_loss=-0.864991
Fine-tune [550/100000]  val_loss=-0.864190
Fine-tune [551/100000]  val_loss=-0.883127
Fine-tune [552/100000]  val_loss=-0.862858
Fine-tune [553/100000]  val_loss=-0.803036
Fine-tune [554/100000]  val_loss=-0.827527
Fine-tune [555/100000]  val_loss=-0.837273
Fine-tune [556/100000]  val_loss=-0.853191
Fine-tune [557/100000]  val_loss=-0.841249
Fine-tune [558/100000]  val_loss=-0.870585
Fine-tune [559/100000]  val_loss=-0.859674
Fine-tune [560/100000]  val_loss=-0.866698
Fine-tune [561/100000]  val_loss=-0.870042
Fine-tune [562/100000]  val_loss=-0.869062
Fine-tune [563/100000]  val_loss=-0.854589
Fine-tune [564/100000]  val_loss=-0.861395
Fine-tune [565/100000]  val_loss=-0.864806
Fine-tune [566/100000]  val_loss=-0.867174
Fine-tune [567/100000]  val_loss=-0.840877
Fine-tune [568/100000]  val_loss=-0.818540
Fine-tune [569/100000]  val_loss=-0.778123
Fine-tune [570/100000]  val_loss=-0.822958
Fine-tune [571/100000]  val_loss=-0.854357
Fine-tune [572/100000]  val_loss=-0.850416
Fine-tune [573/100000]  val_loss=-0.819224
Fine-tune [574/100000]  val_loss=-0.826666
Fine-tune [575/100000]  val_loss=-0.803429
Fine-tune [576/100000]  val_loss=-0.836276
Fine-tune [577/100000]  val_loss=-0.820102
Fine-tune [578/100000]  val_loss=-0.805548
Fine-tune [579/100000]  val_loss=-0.818996
Fine-tune [580/100000]  val_loss=-0.842929
Fine-tune [581/100000]  val_loss=-0.846445
Fine-tune [582/100000]  val_loss=-0.834730
Fine-tune [583/100000]  val_loss=-0.830169
Fine-tune [584/100000]  val_loss=-0.844865
Fine-tune [585/100000]  val_loss=-0.859744
Fine-tune [586/100000]  val_loss=-0.849278
Fine-tune [587/100000]  val_loss=-0.859072
Fine-tune [588/100000]  val_loss=-0.841995
Fine-tune [589/100000]  val_loss=-0.784858
Fine-tune [590/100000]  val_loss=-0.804982
Fine-tune [591/100000]  val_loss=-0.781965
Fine-tune [592/100000]  val_loss=-0.796279
Fine-tune [593/100000]  val_loss=-0.799418
Fine-tune [594/100000]  val_loss=-0.824047
Fine-tune [595/100000]  val_loss=-0.821537
Fine-tune [596/100000]  val_loss=-0.811083
Fine-tune [597/100000]  val_loss=-0.808350
Fine-tune [598/100000]  val_loss=-0.805786
Fine-tune [599/100000]  val_loss=-0.839227
Fine-tune [600/100000]  val_loss=-0.844298
Fine-tune [601/100000]  val_loss=-0.826192
Fine-tune [602/100000]  val_loss=-0.845104
Fine-tune [603/100000]  val_loss=-0.814670
Fine-tune [604/100000]  val_loss=-0.826573
Fine-tune [605/100000]  val_loss=-0.848807
Fine-tune [606/100000]  val_loss=-0.847040
Fine-tune [607/100000]  val_loss=-0.854916
Fine-tune [608/100000]  val_loss=-0.834546
Fine-tune [609/100000]  val_loss=-0.836482
Fine-tune [610/100000]  val_loss=-0.813195
Fine-tune [611/100000]  val_loss=-0.816103
Fine-tune [612/100000]  val_loss=-0.832636
Fine-tune [613/100000]  val_loss=-0.852906
Fine-tune [614/100000]  val_loss=-0.838653
Fine-tune [615/100000]  val_loss=-0.836697
Fine-tune [616/100000]  val_loss=-0.803326
Fine-tune [617/100000]  val_loss=-0.778708
Fine-tune [618/100000]  val_loss=-0.790659
Fine-tune [619/100000]  val_loss=-0.783341
Fine-tune [620/100000]  val_loss=-0.804283
Fine-tune [621/100000]  val_loss=-0.796577
Fine-tune [622/100000]  val_loss=-0.809965
Fine-tune [623/100000]  val_loss=-0.777067
Fine-tune [624/100000]  val_loss=-0.769179
Fine-tune [625/100000]  val_loss=-0.780866
Fine-tune [626/100000]  val_loss=-0.792739
Fine-tune [627/100000]  val_loss=-0.800115
Fine-tune [628/100000]  val_loss=-0.809687
Fine-tune [629/100000]  val_loss=-0.795520
Fine-tune [630/100000]  val_loss=-0.807157
Fine-tune [631/100000]  val_loss=-0.788448
Fine-tune [632/100000]  val_loss=-0.756383
Fine-tune [633/100000]  val_loss=-0.765028
Fine-tune [634/100000]  val_loss=-0.730670
Fine-tune [635/100000]  val_loss=-0.729335
Fine-tune [636/100000]  val_loss=-0.781496
Fine-tune [637/100000]  val_loss=-0.789291
Fine-tune [638/100000]  val_loss=-0.755236
Fine-tune [639/100000]  val_loss=-0.791711
Fine-tune [640/100000]  val_loss=-0.816472
Fine-tune [641/100000]  val_loss=-0.806040
Fine-tune [642/100000]  val_loss=-0.789123
Fine-tune [643/100000]  val_loss=-0.814620
Fine-tune [644/100000]  val_loss=-0.785991
Fine-tune [645/100000]  val_loss=-0.774519
Fine-tune [646/100000]  val_loss=-0.769082
Fine-tune [647/100000]  val_loss=-0.765242
Fine-tune [648/100000]  val_loss=-0.772364
Fine-tune [649/100000]  val_loss=-0.748750
Fine-tune [650/100000]  val_loss=-0.729773
Fine-tune [651/100000]  val_loss=-0.737962
Fine-tune [652/100000]  val_loss=-0.757971
Fine-tune [653/100000]  val_loss=-0.752171
Fine-tune [654/100000]  val_loss=-0.759132
Fine-tune [655/100000]  val_loss=-0.724889
Fine-tune [656/100000]  val_loss=-0.727866
Fine-tune [657/100000]  val_loss=-0.768961
Fine-tune [658/100000]  val_loss=-0.766571
Fine-tune [659/100000]  val_loss=-0.785343
Fine-tune [660/100000]  val_loss=-0.738437
Fine-tune [661/100000]  val_loss=-0.743364
Fine-tune [662/100000]  val_loss=-0.731987
Fine-tune [663/100000]  val_loss=-0.776837
Fine-tune [664/100000]  val_loss=-0.745141
Fine-tune [665/100000]  val_loss=-0.775638
Fine-tune [666/100000]  val_loss=-0.765869
Fine-tune [667/100000]  val_loss=-0.772884
Fine-tune [668/100000]  val_loss=-0.768904
Fine-tune [669/100000]  val_loss=-0.792025
Fine-tune [670/100000]  val_loss=-0.801705
Fine-tune [671/100000]  val_loss=-0.781946
Fine-tune [672/100000]  val_loss=-0.769430
Fine-tune [673/100000]  val_loss=-0.785095
Fine-tune [674/100000]  val_loss=-0.732667
Fine-tune [675/100000]  val_loss=-0.764194
Fine-tune [676/100000]  val_loss=-0.738714
Fine-tune [677/100000]  val_loss=-0.720747
Fine-tune [678/100000]  val_loss=-0.703554
Fine-tune [679/100000]  val_loss=-0.714091
Fine-tune [680/100000]  val_loss=-0.786585
Fine-tune [681/100000]  val_loss=-0.790737
Fine-tune [682/100000]  val_loss=-0.770018
Fine-tune [683/100000]  val_loss=-0.740087
Fine-tune [684/100000]  val_loss=-0.743843
Fine-tune [685/100000]  val_loss=-0.751044
Fine-tune [686/100000]  val_loss=-0.719303
Fine-tune [687/100000]  val_loss=-0.717513
Fine-tune [688/100000]  val_loss=-0.761850
Fine-tune [689/100000]  val_loss=-0.753468
Fine-tune [690/100000]  val_loss=-0.783933
Fine-tune [691/100000]  val_loss=-0.775934
Fine-tune [692/100000]  val_loss=-0.763935
Fine-tune [693/100000]  val_loss=-0.762963
Fine-tune [694/100000]  val_loss=-0.733018
Fine-tune [695/100000]  val_loss=-0.719606
Fine-tune [696/100000]  val_loss=-0.709458
Fine-tune [697/100000]  val_loss=-0.714037
Fine-tune [698/100000]  val_loss=-0.680524
Fine-tune [699/100000]  val_loss=-0.702688
Fine-tune [700/100000]  val_loss=-0.731751
Fine-tune [701/100000]  val_loss=-0.742686
Fine-tune [702/100000]  val_loss=-0.740402
Fine-tune [703/100000]  val_loss=-0.768590
Fine-tune [704/100000]  val_loss=-0.775331
Fine-tune [705/100000]  val_loss=-0.721717
Fine-tune [706/100000]  val_loss=-0.765186
Fine-tune [707/100000]  val_loss=-0.770067
Fine-tune [708/100000]  val_loss=-0.767387
Fine-tune [709/100000]  val_loss=-0.709118
Fine-tune [710/100000]  val_loss=-0.684337
Fine-tune [711/100000]  val_loss=-0.726273
Fine-tune [712/100000]  val_loss=-0.743923
Fine-tune [713/100000]  val_loss=-0.773118
Fine-tune [714/100000]  val_loss=-0.734176
Fine-tune [715/100000]  val_loss=-0.706153
Fine-tune [716/100000]  val_loss=-0.694098
Fine-tune [717/100000]  val_loss=-0.708264
Fine-tune [718/100000]  val_loss=-0.667703
Fine-tune [719/100000]  val_loss=-0.694190
Fine-tune [720/100000]  val_loss=-0.684902
Fine-tune [721/100000]  val_loss=-0.723577
Fine-tune [722/100000]  val_loss=-0.710311
Fine-tune [723/100000]  val_loss=-0.693311
Fine-tune [724/100000]  val_loss=-0.734016
Fine-tune [725/100000]  val_loss=-0.741505
Fine-tune [726/100000]  val_loss=-0.752349
Fine-tune [727/100000]  val_loss=-0.766196
Fine-tune [728/100000]  val_loss=-0.739862
Fine-tune [729/100000]  val_loss=-0.758670
Fine-tune [730/100000]  val_loss=-0.740529
Fine-tune [731/100000]  val_loss=-0.754066
Fine-tune [732/100000]  val_loss=-0.732896
Fine-tune [733/100000]  val_loss=-0.727923
Fine-tune [734/100000]  val_loss=-0.718657
Fine-tune [735/100000]  val_loss=-0.708197
Fine-tune [736/100000]  val_loss=-0.690761
Fine-tune [737/100000]  val_loss=-0.704507
Fine-tune [738/100000]  val_loss=-0.727348
Fine-tune [739/100000]  val_loss=-0.745914
Fine-tune [740/100000]  val_loss=-0.708680
Fine-tune [741/100000]  val_loss=-0.676307
Fine-tune [742/100000]  val_loss=-0.704310
Fine-tune [743/100000]  val_loss=-0.723825
Fine-tune [744/100000]  val_loss=-0.764197
Fine-tune [745/100000]  val_loss=-0.730576
Fine-tune [746/100000]  val_loss=-0.692382
Fine-tune [747/100000]  val_loss=-0.644984
Fine-tune [748/100000]  val_loss=-0.648949
Fine-tune [749/100000]  val_loss=-0.684502
Fine-tune [750/100000]  val_loss=-0.696908
Fine-tune [751/100000]  val_loss=-0.711193
Fine-tune [752/100000]  val_loss=-0.729957
Fine-tune [753/100000]  val_loss=-0.734337
Fine-tune [754/100000]  val_loss=-0.740225
Fine-tune [755/100000]  val_loss=-0.717180
Fine-tune [756/100000]  val_loss=-0.694378
Fine-tune [757/100000]  val_loss=-0.681889
Fine-tune [758/100000]  val_loss=-0.660025
Fine-tune [759/100000]  val_loss=-0.701533
Fine-tune [760/100000]  val_loss=-0.733322
Fine-tune [761/100000]  val_loss=-0.723282
Fine-tune [762/100000]  val_loss=-0.707974
Fine-tune [763/100000]  val_loss=-0.704217
Fine-tune [764/100000]  val_loss=-0.701501
Fine-tune [765/100000]  val_loss=-0.730051
Fine-tune [766/100000]  val_loss=-0.748858
Fine-tune [767/100000]  val_loss=-0.730923
Fine-tune [768/100000]  val_loss=-0.716920
Fine-tune [769/100000]  val_loss=-0.707328
Fine-tune [770/100000]  val_loss=-0.756955
Fine-tune [771/100000]  val_loss=-0.754033
Fine-tune [772/100000]  val_loss=-0.751668
Fine-tune [773/100000]  val_loss=-0.671814
Fine-tune [774/100000]  val_loss=-0.681992
Fine-tune [775/100000]  val_loss=-0.670335
Fine-tune [776/100000]  val_loss=-0.716823
Fine-tune [777/100000]  val_loss=-0.735111
Fine-tune [778/100000]  val_loss=-0.672357
Fine-tune [779/100000]  val_loss=-0.690937
Fine-tune [780/100000]  val_loss=-0.643722
Fine-tune [781/100000]  val_loss=-0.696418
Fine-tune [782/100000]  val_loss=-0.714216
Fine-tune [783/100000]  val_loss=-0.716084
Fine-tune [784/100000]  val_loss=-0.690418
Fine-tune [785/100000]  val_loss=-0.720238
Fine-tune [786/100000]  val_loss=-0.705316
Fine-tune [787/100000]  val_loss=-0.715673
Fine-tune [788/100000]  val_loss=-0.714716
Fine-tune [789/100000]  val_loss=-0.717958
Fine-tune [790/100000]  val_loss=-0.727124
Fine-tune [791/100000]  val_loss=-0.736029
Fine-tune [792/100000]  val_loss=-0.672567
Fine-tune [793/100000]  val_loss=-0.724456
Fine-tune [794/100000]  val_loss=-0.733157
Fine-tune [795/100000]  val_loss=-0.731093
Fine-tune [796/100000]  val_loss=-0.760365
Fine-tune [797/100000]  val_loss=-0.738722
Fine-tune [798/100000]  val_loss=-0.698479
Fine-tune [799/100000]  val_loss=-0.716096
Fine-tune [800/100000]  val_loss=-0.694393
Fine-tune [801/100000]  val_loss=-0.713885
Fine-tune [802/100000]  val_loss=-0.719311
Fine-tune [803/100000]  val_loss=-0.739205
Fine-tune [804/100000]  val_loss=-0.710638
Fine-tune [805/100000]  val_loss=-0.713570
Fine-tune [806/100000]  val_loss=-0.745190
Fine-tune [807/100000]  val_loss=-0.741403
Fine-tune [808/100000]  val_loss=-0.748153
Fine-tune [809/100000]  val_loss=-0.737706
Fine-tune [810/100000]  val_loss=-0.718828
Fine-tune [811/100000]  val_loss=-0.731735
Fine-tune [812/100000]  val_loss=-0.743567
Fine-tune [813/100000]  val_loss=-0.753430
Fine-tune [814/100000]  val_loss=-0.723789
Fine-tune [815/100000]  val_loss=-0.704101
Fine-tune [816/100000]  val_loss=-0.707590
Fine-tune [817/100000]  val_loss=-0.704916
Fine-tune [818/100000]  val_loss=-0.737693
Fine-tune [819/100000]  val_loss=-0.731995
Fine-tune [820/100000]  val_loss=-0.737126
Fine-tune [821/100000]  val_loss=-0.729850
Fine-tune [822/100000]  val_loss=-0.716809
Fine-tune [823/100000]  val_loss=-0.705286
Fine-tune [824/100000]  val_loss=-0.671335
Fine-tune [825/100000]  val_loss=-0.677576
Fine-tune [826/100000]  val_loss=-0.670960
Fine-tune [827/100000]  val_loss=-0.684074
Fine-tune [828/100000]  val_loss=-0.636251
Fine-tune [829/100000]  val_loss=-0.654159
Fine-tune [830/100000]  val_loss=-0.651916
Fine-tune [831/100000]  val_loss=-0.626929
Fine-tune [832/100000]  val_loss=-0.615458
Fine-tune [833/100000]  val_loss=-0.597032
Fine-tune [834/100000]  val_loss=-0.662199
Fine-tune [835/100000]  val_loss=-0.634808
Fine-tune [836/100000]  val_loss=-0.633635
Fine-tune [837/100000]  val_loss=-0.642589
Fine-tune [838/100000]  val_loss=-0.698218
Fine-tune [839/100000]  val_loss=-0.660483
Fine-tune [840/100000]  val_loss=-0.696933
Fine-tune [841/100000]  val_loss=-0.672097
Fine-tune [842/100000]  val_loss=-0.662966
Fine-tune [843/100000]  val_loss=-0.637453
Fine-tune [844/100000]  val_loss=-0.605724
Fine-tune [845/100000]  val_loss=-0.586024
Fine-tune [846/100000]  val_loss=-0.583553
Fine-tune [847/100000]  val_loss=-0.609740
Fine-tune [848/100000]  val_loss=-0.625197
Fine-tune [849/100000]  val_loss=-0.600921
Fine-tune [850/100000]  val_loss=-0.604058
Fine-tune [851/100000]  val_loss=-0.640741
Fine-tune [852/100000]  val_loss=-0.682904
Fine-tune [853/100000]  val_loss=-0.650241
Fine-tune [854/100000]  val_loss=-0.656296
Fine-tune [855/100000]  val_loss=-0.623481
Fine-tune [856/100000]  val_loss=-0.638014
Fine-tune [857/100000]  val_loss=-0.633456
Fine-tune [858/100000]  val_loss=-0.550470
Fine-tune [859/100000]  val_loss=-0.540256
Fine-tune [860/100000]  val_loss=-0.579699
Fine-tune [861/100000]  val_loss=-0.612239
Fine-tune [862/100000]  val_loss=-0.574186
Fine-tune [863/100000]  val_loss=-0.545465
Fine-tune [864/100000]  val_loss=-0.632174
Fine-tune [865/100000]  val_loss=-0.627657
Fine-tune [866/100000]  val_loss=-0.642333
Fine-tune [867/100000]  val_loss=-0.627796
Fine-tune [868/100000]  val_loss=-0.688774
Fine-tune [869/100000]  val_loss=-0.676873
Fine-tune [870/100000]  val_loss=-0.676115
Fine-tune [871/100000]  val_loss=-0.670399
Fine-tune [872/100000]  val_loss=-0.620640
Fine-tune [873/100000]  val_loss=-0.683531
Fine-tune [874/100000]  val_loss=-0.618322
Fine-tune [875/100000]  val_loss=-0.634656
Fine-tune [876/100000]  val_loss=-0.619664
Fine-tune [877/100000]  val_loss=-0.599035
Fine-tune [878/100000]  val_loss=-0.609582
Fine-tune [879/100000]  val_loss=-0.613835
Fine-tune [880/100000]  val_loss=-0.603768
Fine-tune [881/100000]  val_loss=-0.613502
Fine-tune [882/100000]  val_loss=-0.678324
Fine-tune [883/100000]  val_loss=-0.644035
Fine-tune [884/100000]  val_loss=-0.639849
Fine-tune [885/100000]  val_loss=-0.636100
Fine-tune [886/100000]  val_loss=-0.654381
Fine-tune [887/100000]  val_loss=-0.638015
Fine-tune [888/100000]  val_loss=-0.659788
Fine-tune [889/100000]  val_loss=-0.638884
Fine-tune [890/100000]  val_loss=-0.633119
Fine-tune [891/100000]  val_loss=-0.658573
Fine-tune [892/100000]  val_loss=-0.649893
Fine-tune [893/100000]  val_loss=-0.638607
Fine-tune [894/100000]  val_loss=-0.632678
Fine-tune [895/100000]  val_loss=-0.651566
Fine-tune [896/100000]  val_loss=-0.619426
Fine-tune [897/100000]  val_loss=-0.619501
Fine-tune [898/100000]  val_loss=-0.632874
Fine-tune [899/100000]  val_loss=-0.632534
Fine-tune [900/100000]  val_loss=-0.613033
Fine-tune [901/100000]  val_loss=-0.585240
Fine-tune [902/100000]  val_loss=-0.619759
Fine-tune [903/100000]  val_loss=-0.637851
Fine-tune [904/100000]  val_loss=-0.611381
Fine-tune [905/100000]  val_loss=-0.626980
Fine-tune [906/100000]  val_loss=-0.640144
Fine-tune [907/100000]  val_loss=-0.637104
Fine-tune [908/100000]  val_loss=-0.630876
Fine-tune [909/100000]  val_loss=-0.652147
Fine-tune [910/100000]  val_loss=-0.661331
Fine-tune [911/100000]  val_loss=-0.661358
Fine-tune [912/100000]  val_loss=-0.692979
Fine-tune [913/100000]  val_loss=-0.657833
Fine-tune [914/100000]  val_loss=-0.629582
Fine-tune [915/100000]  val_loss=-0.679732
Fine-tune [916/100000]  val_loss=-0.621897
Fine-tune [917/100000]  val_loss=-0.656908
Fine-tune [918/100000]  val_loss=-0.634178
Fine-tune [919/100000]  val_loss=-0.622129
Fine-tune [920/100000]  val_loss=-0.622321
Fine-tune [921/100000]  val_loss=-0.579170
Fine-tune [922/100000]  val_loss=-0.601251
Fine-tune [923/100000]  val_loss=-0.617418
Fine-tune [924/100000]  val_loss=-0.614785
Fine-tune [925/100000]  val_loss=-0.582883
Fine-tune [926/100000]  val_loss=-0.610347
Fine-tune [927/100000]  val_loss=-0.623536
Fine-tune [928/100000]  val_loss=-0.628613
Fine-tune [929/100000]  val_loss=-0.578084
Fine-tune [930/100000]  val_loss=-0.568108
Fine-tune [931/100000]  val_loss=-0.583828
Fine-tune [932/100000]  val_loss=-0.591315
Fine-tune [933/100000]  val_loss=-0.598784
Fine-tune [934/100000]  val_loss=-0.584570
Fine-tune [935/100000]  val_loss=-0.595064
Fine-tune [936/100000]  val_loss=-0.545218
Fine-tune [937/100000]  val_loss=-0.533271
Fine-tune [938/100000]  val_loss=-0.569243
Fine-tune [939/100000]  val_loss=-0.572036
Fine-tune [940/100000]  val_loss=-0.583224
Fine-tune [941/100000]  val_loss=-0.559617
Fine-tune [942/100000]  val_loss=-0.561793
Fine-tune [943/100000]  val_loss=-0.566662
Fine-tune [944/100000]  val_loss=-0.559850
Fine-tune [945/100000]  val_loss=-0.572579
Fine-tune [946/100000]  val_loss=-0.558902
Fine-tune [947/100000]  val_loss=-0.573559
Fine-tune [948/100000]  val_loss=-0.575151
Fine-tune [949/100000]  val_loss=-0.569486
Fine-tune [950/100000]  val_loss=-0.543586
Fine-tune [951/100000]  val_loss=-0.573648
Fine-tune [952/100000]  val_loss=-0.578305
Fine-tune [953/100000]  val_loss=-0.553956
Fine-tune [954/100000]  val_loss=-0.575182
Fine-tune [955/100000]  val_loss=-0.570700
Fine-tune [956/100000]  val_loss=-0.548098
Fine-tune [957/100000]  val_loss=-0.533285
Fine-tune [958/100000]  val_loss=-0.560790
Fine-tune [959/100000]  val_loss=-0.556957
Fine-tune [960/100000]  val_loss=-0.616538
Fine-tune [961/100000]  val_loss=-0.602445
Fine-tune [962/100000]  val_loss=-0.579686
Fine-tune [963/100000]  val_loss=-0.613905
Fine-tune [964/100000]  val_loss=-0.593409
Fine-tune [965/100000]  val_loss=-0.580481
Fine-tune [966/100000]  val_loss=-0.567789
Fine-tune [967/100000]  val_loss=-0.576345
Fine-tune [968/100000]  val_loss=-0.588975
Fine-tune [969/100000]  val_loss=-0.555288
Fine-tune [970/100000]  val_loss=-0.570747
Fine-tune [971/100000]  val_loss=-0.559375
Fine-tune [972/100000]  val_loss=-0.561412
Fine-tune [973/100000]  val_loss=-0.556943
Fine-tune [974/100000]  val_loss=-0.515923
Fine-tune [975/100000]  val_loss=-0.525567
Fine-tune [976/100000]  val_loss=-0.521456
Fine-tune [977/100000]  val_loss=-0.490592
Fine-tune [978/100000]  val_loss=-0.526892
Fine-tune [979/100000]  val_loss=-0.565359
Fine-tune [980/100000]  val_loss=-0.506419
Fine-tune [981/100000]  val_loss=-0.545778
Fine-tune [982/100000]  val_loss=-0.562325
Fine-tune [983/100000]  val_loss=-0.613439
Fine-tune [984/100000]  val_loss=-0.601555
Fine-tune [985/100000]  val_loss=-0.521619
Fine-tune [986/100000]  val_loss=-0.594241
Fine-tune [987/100000]  val_loss=-0.577895
Fine-tune [988/100000]  val_loss=-0.594802
Fine-tune [989/100000]  val_loss=-0.538235
Fine-tune [990/100000]  val_loss=-0.552658
Fine-tune [991/100000]  val_loss=-0.521387
Fine-tune [992/100000]  val_loss=-0.546064
Fine-tune [993/100000]  val_loss=-0.550205
Fine-tune [994/100000]  val_loss=-0.569796
Fine-tune [995/100000]  val_loss=-0.560637
Fine-tune [996/100000]  val_loss=-0.546401
Fine-tune [997/100000]  val_loss=-0.556699
Fine-tune [998/100000]  val_loss=-0.546655
Fine-tune [999/100000]  val_loss=-0.577110
Fine-tune [1000/100000]  val_loss=-0.608844
Fine-tune [1001/100000]  val_loss=-0.586230
Fine-tune [1002/100000]  val_loss=-0.566960
Fine-tune [1003/100000]  val_loss=-0.577846
Fine-tune [1004/100000]  val_loss=-0.599318
Fine-tune [1005/100000]  val_loss=-0.550019
Fine-tune [1006/100000]  val_loss=-0.567689
Fine-tune [1007/100000]  val_loss=-0.525712
Fine-tune [1008/100000]  val_loss=-0.520108
Fine-tune [1009/100000]  val_loss=-0.527633
Fine-tune [1010/100000]  val_loss=-0.515083
Fine-tune [1011/100000]  val_loss=-0.510060
Fine-tune [1012/100000]  val_loss=-0.479000
Fine-tune [1013/100000]  val_loss=-0.462816
Fine-tune [1014/100000]  val_loss=-0.490753
Fine-tune [1015/100000]  val_loss=-0.512911
Fine-tune [1016/100000]  val_loss=-0.537759
Fine-tune [1017/100000]  val_loss=-0.561701
Fine-tune [1018/100000]  val_loss=-0.569011
Fine-tune [1019/100000]  val_loss=-0.526502
Fine-tune [1020/100000]  val_loss=-0.507265
Fine-tune [1021/100000]  val_loss=-0.430392
Fine-tune [1022/100000]  val_loss=-0.457609
Fine-tune [1023/100000]  val_loss=-0.474796
Fine-tune [1024/100000]  val_loss=-0.510499
Fine-tune [1025/100000]  val_loss=-0.500195
Fine-tune [1026/100000]  val_loss=-0.555490
Fine-tune [1027/100000]  val_loss=-0.561830
Fine-tune [1028/100000]  val_loss=-0.518899
Fine-tune [1029/100000]  val_loss=-0.453249
Fine-tune [1030/100000]  val_loss=-0.471038
Fine-tune [1031/100000]  val_loss=-0.502683
Fine-tune [1032/100000]  val_loss=-0.546229
Fine-tune [1033/100000]  val_loss=-0.536104
Fine-tune [1034/100000]  val_loss=-0.536729
Fine-tune [1035/100000]  val_loss=-0.511561
Fine-tune [1036/100000]  val_loss=-0.513888
Fine-tune [1037/100000]  val_loss=-0.569282
Fine-tune [1038/100000]  val_loss=-0.570293
Fine-tune [1039/100000]  val_loss=-0.547081
Fine-tune [1040/100000]  val_loss=-0.515140
Fine-tune [1041/100000]  val_loss=-0.441908
Fine-tune [1042/100000]  val_loss=-0.488446
Fine-tune [1043/100000]  val_loss=-0.499262
Fine-tune [1044/100000]  val_loss=-0.512388
Fine-tune [1045/100000]  val_loss=-0.516228
Fine-tune [1046/100000]  val_loss=-0.495159
Fine-tune [1047/100000]  val_loss=-0.495164
Fine-tune [1048/100000]  val_loss=-0.510249
Fine-tune [1049/100000]  val_loss=-0.518969
Fine-tune [1050/100000]  val_loss=-0.513227
Fine-tune [1051/100000]  val_loss=-0.523352
Fine-tune [1052/100000]  val_loss=-0.526983
Fine-tune [1053/100000]  val_loss=-0.509197
Fine-tune [1054/100000]  val_loss=-0.526128
Fine-tune [1055/100000]  val_loss=-0.540373
Fine-tune [1056/100000]  val_loss=-0.549920
Fine-tune [1057/100000]  val_loss=-0.519682
Fine-tune [1058/100000]  val_loss=-0.464792
Fine-tune [1059/100000]  val_loss=-0.487814
Fine-tune [1060/100000]  val_loss=-0.506524
Fine-tune [1061/100000]  val_loss=-0.511750
Fine-tune [1062/100000]  val_loss=-0.506934
Fine-tune [1063/100000]  val_loss=-0.482447
Fine-tune [1064/100000]  val_loss=-0.495859
Fine-tune [1065/100000]  val_loss=-0.504565
Fine-tune [1066/100000]  val_loss=-0.447770
Fine-tune [1067/100000]  val_loss=-0.421739
Fine-tune [1068/100000]  val_loss=-0.509995
Fine-tune [1069/100000]  val_loss=-0.511414
Fine-tune [1070/100000]  val_loss=-0.490797
Fine-tune [1071/100000]  val_loss=-0.459765
Fine-tune [1072/100000]  val_loss=-0.493651
Fine-tune [1073/100000]  val_loss=-0.469062
Fine-tune [1074/100000]  val_loss=-0.438737
Fine-tune [1075/100000]  val_loss=-0.436665
Fine-tune [1076/100000]  val_loss=-0.462912
Fine-tune [1077/100000]  val_loss=-0.511887
Fine-tune [1078/100000]  val_loss=-0.508600
Fine-tune [1079/100000]  val_loss=-0.536636
Fine-tune [1080/100000]  val_loss=-0.499669
Fine-tune [1081/100000]  val_loss=-0.503954
Fine-tune [1082/100000]  val_loss=-0.463505
Fine-tune [1083/100000]  val_loss=-0.478682
Fine-tune [1084/100000]  val_loss=-0.501357
Fine-tune [1085/100000]  val_loss=-0.497322
Fine-tune [1086/100000]  val_loss=-0.487443
Fine-tune [1087/100000]  val_loss=-0.506219
Fine-tune [1088/100000]  val_loss=-0.499966
Fine-tune [1089/100000]  val_loss=-0.489639
Fine-tune [1090/100000]  val_loss=-0.505335
Fine-tune [1091/100000]  val_loss=-0.468282
Fine-tune [1092/100000]  val_loss=-0.463016
Fine-tune [1093/100000]  val_loss=-0.459249
Fine-tune [1094/100000]  val_loss=-0.477141
Fine-tune [1095/100000]  val_loss=-0.476943
Fine-tune [1096/100000]  val_loss=-0.495580
Fine-tune [1097/100000]  val_loss=-0.472088
Fine-tune [1098/100000]  val_loss=-0.481358
Fine-tune [1099/100000]  val_loss=-0.509831
Fine-tune [1100/100000]  val_loss=-0.517518
Fine-tune [1101/100000]  val_loss=-0.434604
Fine-tune [1102/100000]  val_loss=-0.423656
Fine-tune [1103/100000]  val_loss=-0.426100
Fine-tune [1104/100000]  val_loss=-0.481612
Fine-tune [1105/100000]  val_loss=-0.480714
Fine-tune [1106/100000]  val_loss=-0.463012
Fine-tune [1107/100000]  val_loss=-0.406091
Fine-tune [1108/100000]  val_loss=-0.430859
Fine-tune [1109/100000]  val_loss=-0.418019
Fine-tune [1110/100000]  val_loss=-0.450198
Fine-tune [1111/100000]  val_loss=-0.416469
Fine-tune [1112/100000]  val_loss=-0.450945
Fine-tune [1113/100000]  val_loss=-0.397200
Fine-tune [1114/100000]  val_loss=-0.499241
Fine-tune [1115/100000]  val_loss=-0.446711
Fine-tune [1116/100000]  val_loss=-0.457157
Fine-tune [1117/100000]  val_loss=-0.424504
Fine-tune [1118/100000]  val_loss=-0.432338
Fine-tune [1119/100000]  val_loss=-0.425444
Fine-tune [1120/100000]  val_loss=-0.456409
Fine-tune [1121/100000]  val_loss=-0.406623
Fine-tune [1122/100000]  val_loss=-0.382419
Fine-tune [1123/100000]  val_loss=-0.448782
Fine-tune [1124/100000]  val_loss=-0.453192
Fine-tune [1125/100000]  val_loss=-0.435868
Fine-tune [1126/100000]  val_loss=-0.454923
Fine-tune [1127/100000]  val_loss=-0.497684
Fine-tune [1128/100000]  val_loss=-0.476221
Fine-tune [1129/100000]  val_loss=-0.523047
Fine-tune [1130/100000]  val_loss=-0.484322
Fine-tune [1131/100000]  val_loss=-0.499907
Fine-tune [1132/100000]  val_loss=-0.466105
Fine-tune [1133/100000]  val_loss=-0.436704
Fine-tune [1134/100000]  val_loss=-0.462440
Fine-tune [1135/100000]  val_loss=-0.405671
Fine-tune [1136/100000]  val_loss=-0.404083
Fine-tune [1137/100000]  val_loss=-0.455081
Fine-tune [1138/100000]  val_loss=-0.444593
Fine-tune [1139/100000]  val_loss=-0.450251
Fine-tune [1140/100000]  val_loss=-0.446319
Fine-tune [1141/100000]  val_loss=-0.442710
Fine-tune [1142/100000]  val_loss=-0.403987
Fine-tune [1143/100000]  val_loss=-0.471045
Fine-tune [1144/100000]  val_loss=-0.510334
Fine-tune [1145/100000]  val_loss=-0.450621
Fine-tune [1146/100000]  val_loss=-0.447697
Fine-tune [1147/100000]  val_loss=-0.480762
Fine-tune [1148/100000]  val_loss=-0.492659
Fine-tune [1149/100000]  val_loss=-0.491931
Fine-tune [1150/100000]  val_loss=-0.425305
Fine-tune [1151/100000]  val_loss=-0.454329
Fine-tune [1152/100000]  val_loss=-0.458596
Fine-tune [1153/100000]  val_loss=-0.406781
Fine-tune [1154/100000]  val_loss=-0.376528
Fine-tune [1155/100000]  val_loss=-0.353356
Fine-tune [1156/100000]  val_loss=-0.374310
Fine-tune [1157/100000]  val_loss=-0.444033
Fine-tune [1158/100000]  val_loss=-0.407841
Fine-tune [1159/100000]  val_loss=-0.405858
Fine-tune [1160/100000]  val_loss=-0.442990
Fine-tune [1161/100000]  val_loss=-0.463663
Fine-tune [1162/100000]  val_loss=-0.442902
Fine-tune [1163/100000]  val_loss=-0.433535
Fine-tune [1164/100000]  val_loss=-0.390225
Fine-tune [1165/100000]  val_loss=-0.404817
Fine-tune [1166/100000]  val_loss=-0.462598
Fine-tune [1167/100000]  val_loss=-0.471427
Fine-tune [1168/100000]  val_loss=-0.497501
Fine-tune [1169/100000]  val_loss=-0.474363
Fine-tune [1170/100000]  val_loss=-0.452377
Fine-tune [1171/100000]  val_loss=-0.448414
Fine-tune [1172/100000]  val_loss=-0.499367
Fine-tune [1173/100000]  val_loss=-0.482275
Fine-tune [1174/100000]  val_loss=-0.455601
Fine-tune [1175/100000]  val_loss=-0.440306
Fine-tune [1176/100000]  val_loss=-0.396333
Fine-tune [1177/100000]  val_loss=-0.436153
Fine-tune [1178/100000]  val_loss=-0.477678
Fine-tune [1179/100000]  val_loss=-0.486883
Fine-tune [1180/100000]  val_loss=-0.466519
Fine-tune [1181/100000]  val_loss=-0.423833
Fine-tune [1182/100000]  val_loss=-0.415305
Fine-tune [1183/100000]  val_loss=-0.467953
Fine-tune [1184/100000]  val_loss=-0.505713
Fine-tune [1185/100000]  val_loss=-0.495851
Fine-tune [1186/100000]  val_loss=-0.455459
Fine-tune [1187/100000]  val_loss=-0.390315
Fine-tune [1188/100000]  val_loss=-0.384943
Fine-tune [1189/100000]  val_loss=-0.393011
Fine-tune [1190/100000]  val_loss=-0.444270
Fine-tune [1191/100000]  val_loss=-0.461461
Fine-tune [1192/100000]  val_loss=-0.461266
Fine-tune [1193/100000]  val_loss=-0.449622
Fine-tune [1194/100000]  val_loss=-0.462238
Fine-tune [1195/100000]  val_loss=-0.410814
Fine-tune [1196/100000]  val_loss=-0.477463
  -> 验证未改进 1000 次，早停。
[FINETUNE] 最佳验证损失=-1.046998 已保存。

--- 评估 [HD256_L3] ---

=== 本次试验参数 (Run Config) ===
opamp             : two_stage_opamp
hidden_dim        : 256
num_layers        : 3
lr_pretrain       : 0.003
epochs_pretrain   : 1000
patience_pretrain : 200
lr_finetune       : 0.0038
epochs_finetune   : 100000
patience_finetune : 1000
batch_a           : 128
batch_b           : 64
dropout_rate      : 0.2
alpha_r2          : 0.0
lambda_coral      : 0.1
seed              : 42
device            : cpu

--- [评估阶段] 开始计算指标 ---

=== 目标域验证集指标（物理单位）===
slewrate_pos    MSE=1.232e+14  MAE=8.061e+06  R2=0.7129
dc_gain         MSE=2.754e+07  MAE=1431  R2=0.2930
ugf             MSE=9.078e+13  MAE=6.179e+06  R2=0.7948
phase_margin    MSE=160.3  MAE=9.2  R2=0.8603
cmrr            MSE=8.448e+11  MAE=9.115e+04  R2=0.0247

Avg  (all dims)   MSE=4.296e+13  MAE=2.866e+06  R2=0.5371
[OK] HD256_L3 -> r2_avg=0.5371, mae_avg=2.866e+06, mse_avg=4.296e+13
===== [HD256_L3] 训练完成 =====

===== [HD256_L4] 训练开始 =====

--- [阶段一] Backbone 预训练 (source_train / source_val, HuberLoss) ---
Pretrain [1/1000]  train=0.244101  val=0.185868
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [2/1000]  train=0.182795  val=0.156737
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [3/1000]  train=0.155436  val=0.131980
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [4/1000]  train=0.145883  val=0.128383
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [5/1000]  train=0.142029  val=0.122786
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [6/1000]  train=0.130142  val=0.117843
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [7/1000]  train=0.129597  val=0.111365
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [8/1000]  train=0.121863  val=0.107957
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [9/1000]  train=0.117939  val=0.102116
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [10/1000]  train=0.115292  val=0.098464
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [11/1000]  train=0.112635  val=0.100181
Pretrain [12/1000]  train=0.108701  val=0.095035
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [13/1000]  train=0.106156  val=0.101557
Pretrain [14/1000]  train=0.102348  val=0.095864
Pretrain [15/1000]  train=0.104961  val=0.101226
Pretrain [16/1000]  train=0.101758  val=0.099566
Pretrain [17/1000]  train=0.101890  val=0.096753
Pretrain [18/1000]  train=0.100646  val=0.098589
Pretrain [19/1000]  train=0.097071  val=0.094970
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [20/1000]  train=0.096858  val=0.090745
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [21/1000]  train=0.098607  val=0.096476
Pretrain [22/1000]  train=0.097554  val=0.092918
Pretrain [23/1000]  train=0.095939  val=0.089196
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [24/1000]  train=0.090179  val=0.092606
Pretrain [25/1000]  train=0.095677  val=0.090225
Pretrain [26/1000]  train=0.092507  val=0.091413
Pretrain [27/1000]  train=0.089065  val=0.086849
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [28/1000]  train=0.087861  val=0.086561
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [29/1000]  train=0.089373  val=0.091741
Pretrain [30/1000]  train=0.086300  val=0.086782
Pretrain [31/1000]  train=0.091550  val=0.090064
Pretrain [32/1000]  train=0.085560  val=0.086679
Pretrain [33/1000]  train=0.083770  val=0.091732
Pretrain [34/1000]  train=0.083475  val=0.088115
Pretrain [35/1000]  train=0.087467  val=0.092716
Pretrain [36/1000]  train=0.084231  val=0.086956
Pretrain [37/1000]  train=0.081374  val=0.087138
Pretrain [38/1000]  train=0.078567  val=0.083835
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [39/1000]  train=0.079203  val=0.089031
Pretrain [40/1000]  train=0.080439  val=0.085797
Pretrain [41/1000]  train=0.079002  val=0.084774
Pretrain [42/1000]  train=0.078392  val=0.084301
Pretrain [43/1000]  train=0.076161  val=0.083347
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [44/1000]  train=0.079153  val=0.080095
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [45/1000]  train=0.077319  val=0.086047
Pretrain [46/1000]  train=0.077594  val=0.079917
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [47/1000]  train=0.073146  val=0.084487
Pretrain [48/1000]  train=0.075348  val=0.082938
Pretrain [49/1000]  train=0.074828  val=0.089721
Pretrain [50/1000]  train=0.072176  val=0.084886
Pretrain [51/1000]  train=0.074224  val=0.082048
Pretrain [52/1000]  train=0.072777  val=0.086018
Pretrain [53/1000]  train=0.072488  val=0.083049
Pretrain [54/1000]  train=0.071738  val=0.083202
Pretrain [55/1000]  train=0.072363  val=0.078356
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [56/1000]  train=0.069694  val=0.084479
Pretrain [57/1000]  train=0.070608  val=0.083686
Pretrain [58/1000]  train=0.071369  val=0.079423
Pretrain [59/1000]  train=0.066527  val=0.082273
Pretrain [60/1000]  train=0.066183  val=0.080382
Pretrain [61/1000]  train=0.066294  val=0.079962
Pretrain [62/1000]  train=0.065948  val=0.082053
Pretrain [63/1000]  train=0.069697  val=0.080145
Pretrain [64/1000]  train=0.070175  val=0.083684
Pretrain [65/1000]  train=0.064689  val=0.081095
Pretrain [66/1000]  train=0.063390  val=0.080246
Pretrain [67/1000]  train=0.065113  val=0.084083
Pretrain [68/1000]  train=0.065691  val=0.081593
Pretrain [69/1000]  train=0.061080  val=0.082109
Pretrain [70/1000]  train=0.061444  val=0.082546
Pretrain [71/1000]  train=0.062225  val=0.078015
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [72/1000]  train=0.059886  val=0.078549
Pretrain [73/1000]  train=0.060831  val=0.079918
Pretrain [74/1000]  train=0.057864  val=0.082963
Pretrain [75/1000]  train=0.061904  val=0.078289
Pretrain [76/1000]  train=0.058117  val=0.074623
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [77/1000]  train=0.058308  val=0.077433
Pretrain [78/1000]  train=0.059698  val=0.077566
Pretrain [79/1000]  train=0.060453  val=0.073728
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [80/1000]  train=0.057593  val=0.075750
Pretrain [81/1000]  train=0.058261  val=0.077197
Pretrain [82/1000]  train=0.056979  val=0.077866
Pretrain [83/1000]  train=0.057767  val=0.081313
Pretrain [84/1000]  train=0.057844  val=0.075983
Pretrain [85/1000]  train=0.058973  val=0.079457
Pretrain [86/1000]  train=0.057487  val=0.075596
Pretrain [87/1000]  train=0.056882  val=0.080272
Pretrain [88/1000]  train=0.056519  val=0.074896
Pretrain [89/1000]  train=0.055524  val=0.076304
Pretrain [90/1000]  train=0.055621  val=0.075311
Pretrain [91/1000]  train=0.054754  val=0.077623
Pretrain [92/1000]  train=0.053592  val=0.076082
Pretrain [93/1000]  train=0.052669  val=0.076727
Pretrain [94/1000]  train=0.052067  val=0.076623
Pretrain [95/1000]  train=0.053962  val=0.075092
Pretrain [96/1000]  train=0.052306  val=0.071687
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [97/1000]  train=0.051151  val=0.074929
Pretrain [98/1000]  train=0.049611  val=0.074815
Pretrain [99/1000]  train=0.051378  val=0.075225
Pretrain [100/1000]  train=0.050444  val=0.076209
Pretrain [101/1000]  train=0.047743  val=0.073851
Pretrain [102/1000]  train=0.051253  val=0.074763
Pretrain [103/1000]  train=0.048839  val=0.076965
Pretrain [104/1000]  train=0.049762  val=0.078419
Pretrain [105/1000]  train=0.048841  val=0.075372
Pretrain [106/1000]  train=0.048514  val=0.072145
Pretrain [107/1000]  train=0.048475  val=0.075992
Pretrain [108/1000]  train=0.046402  val=0.072796
Pretrain [109/1000]  train=0.045601  val=0.072428
Pretrain [110/1000]  train=0.046824  val=0.075057
Pretrain [111/1000]  train=0.047230  val=0.075461
Pretrain [112/1000]  train=0.048606  val=0.071817
Pretrain [113/1000]  train=0.047231  val=0.074171
Pretrain [114/1000]  train=0.046208  val=0.070027
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [115/1000]  train=0.045620  val=0.074281
Pretrain [116/1000]  train=0.045345  val=0.072846
Pretrain [117/1000]  train=0.045037  val=0.072325
Pretrain [118/1000]  train=0.044326  val=0.070900
Pretrain [119/1000]  train=0.042995  val=0.068209
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [120/1000]  train=0.043011  val=0.068901
Pretrain [121/1000]  train=0.042718  val=0.068914
Pretrain [122/1000]  train=0.043888  val=0.070531
Pretrain [123/1000]  train=0.041941  val=0.073313
Pretrain [124/1000]  train=0.042012  val=0.069465
Pretrain [125/1000]  train=0.042174  val=0.072566
Pretrain [126/1000]  train=0.043063  val=0.072366
Pretrain [127/1000]  train=0.040874  val=0.071172
Pretrain [128/1000]  train=0.040758  val=0.070648
Pretrain [129/1000]  train=0.042016  val=0.072482
Pretrain [130/1000]  train=0.041345  val=0.071784
Pretrain [131/1000]  train=0.041100  val=0.069742
Pretrain [132/1000]  train=0.040179  val=0.070108
Pretrain [133/1000]  train=0.039248  val=0.071363
Pretrain [134/1000]  train=0.039308  val=0.072272
Pretrain [135/1000]  train=0.039344  val=0.070563
Pretrain [136/1000]  train=0.038261  val=0.070783
Pretrain [137/1000]  train=0.039125  val=0.072072
Pretrain [138/1000]  train=0.039232  val=0.070980
Pretrain [139/1000]  train=0.041258  val=0.069303
Pretrain [140/1000]  train=0.038643  val=0.072402
Pretrain [141/1000]  train=0.037520  val=0.069612
Pretrain [142/1000]  train=0.038708  val=0.069826
Pretrain [143/1000]  train=0.037841  val=0.070185
Pretrain [144/1000]  train=0.037584  val=0.069651
Pretrain [145/1000]  train=0.037657  val=0.069120
Pretrain [146/1000]  train=0.037055  val=0.069469
Pretrain [147/1000]  train=0.038035  val=0.069319
Pretrain [148/1000]  train=0.037370  val=0.069295
Pretrain [149/1000]  train=0.036964  val=0.067970
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [150/1000]  train=0.037373  val=0.070384
Pretrain [151/1000]  train=0.036552  val=0.068066
Pretrain [152/1000]  train=0.036639  val=0.067449
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [153/1000]  train=0.036621  val=0.069304
Pretrain [154/1000]  train=0.036360  val=0.067363
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [155/1000]  train=0.036448  val=0.067215
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [156/1000]  train=0.036112  val=0.066335
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [157/1000]  train=0.036443  val=0.067110
Pretrain [158/1000]  train=0.035981  val=0.066752
Pretrain [159/1000]  train=0.036013  val=0.067379
Pretrain [160/1000]  train=0.035010  val=0.067792
Pretrain [161/1000]  train=0.036275  val=0.066781
Pretrain [162/1000]  train=0.034978  val=0.067480
Pretrain [163/1000]  train=0.034089  val=0.067364
Pretrain [164/1000]  train=0.036097  val=0.066728
Pretrain [165/1000]  train=0.035253  val=0.066159
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [166/1000]  train=0.034496  val=0.065373
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [167/1000]  train=0.034283  val=0.066255
Pretrain [168/1000]  train=0.034666  val=0.066005
Pretrain [169/1000]  train=0.034380  val=0.065290
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/pretrained.pth
Pretrain [170/1000]  train=0.033170  val=0.065618
Pretrain [171/1000]  train=0.034538  val=0.066469
Pretrain [172/1000]  train=0.033454  val=0.066077
Pretrain [173/1000]  train=0.033915  val=0.065333
Pretrain [174/1000]  train=0.034579  val=0.066015
Pretrain [175/1000]  train=0.034600  val=0.066639
Pretrain [176/1000]  train=0.033978  val=0.066324
Pretrain [177/1000]  train=0.032847  val=0.066396
Pretrain [178/1000]  train=0.033802  val=0.066484
Pretrain [179/1000]  train=0.033297  val=0.066627
Pretrain [180/1000]  train=0.032724  val=0.066351
Pretrain [181/1000]  train=0.032796  val=0.066922
Pretrain [182/1000]  train=0.032827  val=0.066573
Pretrain [183/1000]  train=0.032856  val=0.066541
Pretrain [184/1000]  train=0.033881  val=0.066631
Pretrain [185/1000]  train=0.033430  val=0.066607
Pretrain [186/1000]  train=0.032990  val=0.066701
Pretrain [187/1000]  train=0.034120  val=0.066634
Pretrain [188/1000]  train=0.034496  val=0.066548
Pretrain [189/1000]  train=0.032397  val=0.066541
Pretrain [190/1000]  train=0.033251  val=0.066639
Pretrain [191/1000]  train=0.033576  val=0.066650
Pretrain [192/1000]  train=0.032960  val=0.066548
Pretrain [193/1000]  train=0.032848  val=0.066544
Pretrain [194/1000]  train=0.032965  val=0.066487
Pretrain [195/1000]  train=0.034189  val=0.066505
Pretrain [196/1000]  train=0.033284  val=0.066464
Pretrain [197/1000]  train=0.034040  val=0.066480
Pretrain [198/1000]  train=0.033123  val=0.066472
Pretrain [199/1000]  train=0.031796  val=0.066479
Pretrain [200/1000]  train=0.033066  val=0.066485
Pretrain [201/1000]  train=0.049580  val=0.083842
Pretrain [202/1000]  train=0.063365  val=0.087770
Pretrain [203/1000]  train=0.076586  val=0.094176
Pretrain [204/1000]  train=0.076466  val=0.088231
Pretrain [205/1000]  train=0.071529  val=0.091592
Pretrain [206/1000]  train=0.075371  val=0.086629
Pretrain [207/1000]  train=0.067786  val=0.088074
Pretrain [208/1000]  train=0.067952  val=0.086088
Pretrain [209/1000]  train=0.072544  val=0.084979
Pretrain [210/1000]  train=0.067640  val=0.087058
Pretrain [211/1000]  train=0.063942  val=0.084271
Pretrain [212/1000]  train=0.064446  val=0.085139
Pretrain [213/1000]  train=0.066729  val=0.089787
Pretrain [214/1000]  train=0.065157  val=0.082347
Pretrain [215/1000]  train=0.068234  val=0.083444
Pretrain [216/1000]  train=0.064599  val=0.082248
Pretrain [217/1000]  train=0.062957  val=0.086005
Pretrain [218/1000]  train=0.061769  val=0.088413
Pretrain [219/1000]  train=0.058474  val=0.083537
Pretrain [220/1000]  train=0.058330  val=0.085308
Pretrain [221/1000]  train=0.061149  val=0.086409
Pretrain [222/1000]  train=0.062237  val=0.085328
Pretrain [223/1000]  train=0.061979  val=0.089623
Pretrain [224/1000]  train=0.062319  val=0.088498
Pretrain [225/1000]  train=0.060092  val=0.087896
Pretrain [226/1000]  train=0.059120  val=0.088759
Pretrain [227/1000]  train=0.061166  val=0.083774
Pretrain [228/1000]  train=0.058113  val=0.084264
Pretrain [229/1000]  train=0.060443  val=0.080177
Pretrain [230/1000]  train=0.058971  val=0.083002
Pretrain [231/1000]  train=0.058416  val=0.080563
Pretrain [232/1000]  train=0.059152  val=0.082296
Pretrain [233/1000]  train=0.058043  val=0.085305
Pretrain [234/1000]  train=0.057709  val=0.084133
Pretrain [235/1000]  train=0.057125  val=0.085516
Pretrain [236/1000]  train=0.052786  val=0.080941
Pretrain [237/1000]  train=0.054028  val=0.081814
Pretrain [238/1000]  train=0.057350  val=0.083089
Pretrain [239/1000]  train=0.058097  val=0.082773
Pretrain [240/1000]  train=0.054253  val=0.084113
Pretrain [241/1000]  train=0.054090  val=0.080571
Pretrain [242/1000]  train=0.055121  val=0.083326
Pretrain [243/1000]  train=0.055837  val=0.076739
Pretrain [244/1000]  train=0.054067  val=0.079964
Pretrain [245/1000]  train=0.052769  val=0.079177
Pretrain [246/1000]  train=0.051092  val=0.078776
Pretrain [247/1000]  train=0.054067  val=0.079274
Pretrain [248/1000]  train=0.052445  val=0.077858
Pretrain [249/1000]  train=0.056261  val=0.087316
Pretrain [250/1000]  train=0.057633  val=0.082466
Pretrain [251/1000]  train=0.051993  val=0.078883
Pretrain [252/1000]  train=0.051562  val=0.075270
Pretrain [253/1000]  train=0.051688  val=0.080826
Pretrain [254/1000]  train=0.049661  val=0.078563
Pretrain [255/1000]  train=0.049495  val=0.082102
Pretrain [256/1000]  train=0.052594  val=0.078952
Pretrain [257/1000]  train=0.048567  val=0.079318
Pretrain [258/1000]  train=0.050128  val=0.078341
Pretrain [259/1000]  train=0.051835  val=0.080522
Pretrain [260/1000]  train=0.050911  val=0.076908
Pretrain [261/1000]  train=0.046309  val=0.075982
Pretrain [262/1000]  train=0.050095  val=0.081139
Pretrain [263/1000]  train=0.048314  val=0.074007
Pretrain [264/1000]  train=0.046122  val=0.079146
Pretrain [265/1000]  train=0.048167  val=0.083281
Pretrain [266/1000]  train=0.050882  val=0.082601
Pretrain [267/1000]  train=0.047556  val=0.078760
Pretrain [268/1000]  train=0.049481  val=0.079798
Pretrain [269/1000]  train=0.048666  val=0.079525
Pretrain [270/1000]  train=0.048768  val=0.081852
Pretrain [271/1000]  train=0.047513  val=0.079192
Pretrain [272/1000]  train=0.045785  val=0.076677
Pretrain [273/1000]  train=0.046549  val=0.079752
Pretrain [274/1000]  train=0.048214  val=0.076319
Pretrain [275/1000]  train=0.045583  val=0.072740
Pretrain [276/1000]  train=0.046974  val=0.076241
Pretrain [277/1000]  train=0.046239  val=0.078579
Pretrain [278/1000]  train=0.045110  val=0.084686
Pretrain [279/1000]  train=0.045577  val=0.078008
Pretrain [280/1000]  train=0.043780  val=0.080676
Pretrain [281/1000]  train=0.043411  val=0.076854
Pretrain [282/1000]  train=0.043283  val=0.075220
Pretrain [283/1000]  train=0.044687  val=0.075814
Pretrain [284/1000]  train=0.045541  val=0.075907
Pretrain [285/1000]  train=0.045363  val=0.078447
Pretrain [286/1000]  train=0.043116  val=0.079038
Pretrain [287/1000]  train=0.042996  val=0.076792
Pretrain [288/1000]  train=0.043895  val=0.077855
Pretrain [289/1000]  train=0.043431  val=0.074767
Pretrain [290/1000]  train=0.042063  val=0.077149
Pretrain [291/1000]  train=0.043771  val=0.078030
Pretrain [292/1000]  train=0.042443  val=0.076246
Pretrain [293/1000]  train=0.041863  val=0.079011
Pretrain [294/1000]  train=0.039890  val=0.075228
Pretrain [295/1000]  train=0.040564  val=0.081912
Pretrain [296/1000]  train=0.041074  val=0.076957
Pretrain [297/1000]  train=0.041256  val=0.075398
Pretrain [298/1000]  train=0.041005  val=0.073988
Pretrain [299/1000]  train=0.040576  val=0.073939
Pretrain [300/1000]  train=0.041808  val=0.077110
Pretrain [301/1000]  train=0.041979  val=0.075098
Pretrain [302/1000]  train=0.039688  val=0.074156
Pretrain [303/1000]  train=0.041550  val=0.074391
Pretrain [304/1000]  train=0.039998  val=0.074289
Pretrain [305/1000]  train=0.038319  val=0.071412
Pretrain [306/1000]  train=0.037640  val=0.076131
Pretrain [307/1000]  train=0.038374  val=0.073571
Pretrain [308/1000]  train=0.036265  val=0.075250
Pretrain [309/1000]  train=0.037478  val=0.073572
Pretrain [310/1000]  train=0.035616  val=0.075650
Pretrain [311/1000]  train=0.037203  val=0.073733
Pretrain [312/1000]  train=0.038028  val=0.074367
Pretrain [313/1000]  train=0.036115  val=0.076309
Pretrain [314/1000]  train=0.037262  val=0.072092
Pretrain [315/1000]  train=0.036648  val=0.075913
Pretrain [316/1000]  train=0.036826  val=0.073169
Pretrain [317/1000]  train=0.034877  val=0.070647
Pretrain [318/1000]  train=0.035654  val=0.072578
Pretrain [319/1000]  train=0.035147  val=0.070497
Pretrain [320/1000]  train=0.035384  val=0.070010
Pretrain [321/1000]  train=0.034959  val=0.070760
Pretrain [322/1000]  train=0.034495  val=0.068937
Pretrain [323/1000]  train=0.034398  val=0.069719
Pretrain [324/1000]  train=0.034196  val=0.068883
Pretrain [325/1000]  train=0.034453  val=0.070608
Pretrain [326/1000]  train=0.032815  val=0.070076
Pretrain [327/1000]  train=0.033610  val=0.072631
Pretrain [328/1000]  train=0.033709  val=0.071202
Pretrain [329/1000]  train=0.033895  val=0.069638
Pretrain [330/1000]  train=0.033255  val=0.072050
Pretrain [331/1000]  train=0.033458  val=0.072908
Pretrain [332/1000]  train=0.032635  val=0.072577
Pretrain [333/1000]  train=0.033199  val=0.071551
Pretrain [334/1000]  train=0.033408  val=0.070913
Pretrain [335/1000]  train=0.032524  val=0.069826
Pretrain [336/1000]  train=0.032487  val=0.071313
Pretrain [337/1000]  train=0.031551  val=0.071704
Pretrain [338/1000]  train=0.031761  val=0.071015
Pretrain [339/1000]  train=0.032428  val=0.072555
Pretrain [340/1000]  train=0.032882  val=0.070459
Pretrain [341/1000]  train=0.031822  val=0.071855
Pretrain [342/1000]  train=0.030715  val=0.072586
Pretrain [343/1000]  train=0.030290  val=0.073320
Pretrain [344/1000]  train=0.032250  val=0.072279
Pretrain [345/1000]  train=0.030375  val=0.070333
Pretrain [346/1000]  train=0.030761  val=0.072306
Pretrain [347/1000]  train=0.030164  val=0.069319
Pretrain [348/1000]  train=0.030096  val=0.071596
Pretrain [349/1000]  train=0.030366  val=0.071386
Pretrain [350/1000]  train=0.029379  val=0.071165
Pretrain [351/1000]  train=0.030978  val=0.068599
Pretrain [352/1000]  train=0.030941  val=0.070447
Pretrain [353/1000]  train=0.030003  val=0.070295
Pretrain [354/1000]  train=0.029974  val=0.070579
Pretrain [355/1000]  train=0.030898  val=0.069693
Pretrain [356/1000]  train=0.029129  val=0.070044
Pretrain [357/1000]  train=0.028802  val=0.070795
Pretrain [358/1000]  train=0.030092  val=0.070011
Pretrain [359/1000]  train=0.029112  val=0.070906
Pretrain [360/1000]  train=0.029509  val=0.070248
Pretrain [361/1000]  train=0.029260  val=0.070352
Pretrain [362/1000]  train=0.028830  val=0.070631
Pretrain [363/1000]  train=0.029000  val=0.070244
Pretrain [364/1000]  train=0.029214  val=0.069951
Pretrain [365/1000]  train=0.028605  val=0.070148
Pretrain [366/1000]  train=0.027785  val=0.069566
Pretrain [367/1000]  train=0.029022  val=0.069798
Pretrain [368/1000]  train=0.029246  val=0.070381
Pretrain [369/1000]  train=0.029168  val=0.069370
  -> 验证未改进 200 次，早停。
[PRETRAIN] 最佳 val=0.065290 已保存。

--- [阶段二] 对齐微调 (NLL + α·(1−R2) + λ·CORAL) ---
Fine-tune [1/100000]  val_loss=0.256174
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [2/100000]  val_loss=0.099053
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [3/100000]  val_loss=-0.027331
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [4/100000]  val_loss=-0.128774
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [5/100000]  val_loss=-0.219187
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [6/100000]  val_loss=-0.295431
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [7/100000]  val_loss=-0.359122
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [8/100000]  val_loss=-0.425779
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [9/100000]  val_loss=-0.466604
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [10/100000]  val_loss=-0.526137
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [11/100000]  val_loss=-0.567705
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [12/100000]  val_loss=-0.602015
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [13/100000]  val_loss=-0.634732
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [14/100000]  val_loss=-0.639867
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [15/100000]  val_loss=-0.664442
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [16/100000]  val_loss=-0.672233
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [17/100000]  val_loss=-0.696354
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [18/100000]  val_loss=-0.705975
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [19/100000]  val_loss=-0.710332
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [20/100000]  val_loss=-0.730819
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [21/100000]  val_loss=-0.730800
Fine-tune [22/100000]  val_loss=-0.735190
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [23/100000]  val_loss=-0.745752
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [24/100000]  val_loss=-0.754071
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [25/100000]  val_loss=-0.758085
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [26/100000]  val_loss=-0.781636
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [27/100000]  val_loss=-0.778804
Fine-tune [28/100000]  val_loss=-0.791145
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [29/100000]  val_loss=-0.780564
Fine-tune [30/100000]  val_loss=-0.788681
Fine-tune [31/100000]  val_loss=-0.793906
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [32/100000]  val_loss=-0.816744
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [33/100000]  val_loss=-0.804471
Fine-tune [34/100000]  val_loss=-0.816711
Fine-tune [35/100000]  val_loss=-0.817520
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [36/100000]  val_loss=-0.835195
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [37/100000]  val_loss=-0.836771
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [38/100000]  val_loss=-0.833408
Fine-tune [39/100000]  val_loss=-0.843544
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [40/100000]  val_loss=-0.841085
Fine-tune [41/100000]  val_loss=-0.855999
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [42/100000]  val_loss=-0.861304
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [43/100000]  val_loss=-0.865134
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [44/100000]  val_loss=-0.860116
Fine-tune [45/100000]  val_loss=-0.867344
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [46/100000]  val_loss=-0.877143
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [47/100000]  val_loss=-0.882667
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [48/100000]  val_loss=-0.875800
Fine-tune [49/100000]  val_loss=-0.886312
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [50/100000]  val_loss=-0.890046
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [51/100000]  val_loss=-0.900879
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [52/100000]  val_loss=-0.894088
Fine-tune [53/100000]  val_loss=-0.907734
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [54/100000]  val_loss=-0.899961
Fine-tune [55/100000]  val_loss=-0.913689
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [56/100000]  val_loss=-0.916589
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [57/100000]  val_loss=-0.916479
Fine-tune [58/100000]  val_loss=-0.922995
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [59/100000]  val_loss=-0.929233
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [60/100000]  val_loss=-0.931856
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [61/100000]  val_loss=-0.926412
Fine-tune [62/100000]  val_loss=-0.932895
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [63/100000]  val_loss=-0.928127
Fine-tune [64/100000]  val_loss=-0.933612
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [65/100000]  val_loss=-0.930011
Fine-tune [66/100000]  val_loss=-0.933775
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [67/100000]  val_loss=-0.930519
Fine-tune [68/100000]  val_loss=-0.964912
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [69/100000]  val_loss=-0.961452
Fine-tune [70/100000]  val_loss=-0.963445
Fine-tune [71/100000]  val_loss=-0.957696
Fine-tune [72/100000]  val_loss=-0.959627
Fine-tune [73/100000]  val_loss=-0.958542
Fine-tune [74/100000]  val_loss=-0.971804
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [75/100000]  val_loss=-0.965570
Fine-tune [76/100000]  val_loss=-0.952458
Fine-tune [77/100000]  val_loss=-0.975758
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [78/100000]  val_loss=-0.977630
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [79/100000]  val_loss=-0.975305
Fine-tune [80/100000]  val_loss=-0.963243
Fine-tune [81/100000]  val_loss=-0.972976
Fine-tune [82/100000]  val_loss=-0.948955
Fine-tune [83/100000]  val_loss=-0.973965
Fine-tune [84/100000]  val_loss=-0.978444
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [85/100000]  val_loss=-0.993629
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [86/100000]  val_loss=-0.986577
Fine-tune [87/100000]  val_loss=-0.993655
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [88/100000]  val_loss=-0.998697
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [89/100000]  val_loss=-0.991873
Fine-tune [90/100000]  val_loss=-0.986193
Fine-tune [91/100000]  val_loss=-0.994329
Fine-tune [92/100000]  val_loss=-0.990739
Fine-tune [93/100000]  val_loss=-0.992735
Fine-tune [94/100000]  val_loss=-0.986041
Fine-tune [95/100000]  val_loss=-0.989953
Fine-tune [96/100000]  val_loss=-0.994086
Fine-tune [97/100000]  val_loss=-1.001750
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [98/100000]  val_loss=-0.993213
Fine-tune [99/100000]  val_loss=-0.998979
Fine-tune [100/100000]  val_loss=-0.982774
Fine-tune [101/100000]  val_loss=-0.994415
Fine-tune [102/100000]  val_loss=-1.000466
Fine-tune [103/100000]  val_loss=-1.003239
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [104/100000]  val_loss=-1.012061
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [105/100000]  val_loss=-0.996244
Fine-tune [106/100000]  val_loss=-0.985193
Fine-tune [107/100000]  val_loss=-0.969125
Fine-tune [108/100000]  val_loss=-0.973075
Fine-tune [109/100000]  val_loss=-0.988938
Fine-tune [110/100000]  val_loss=-0.989640
Fine-tune [111/100000]  val_loss=-0.997773
Fine-tune [112/100000]  val_loss=-1.003057
Fine-tune [113/100000]  val_loss=-1.009476
Fine-tune [114/100000]  val_loss=-1.000705
Fine-tune [115/100000]  val_loss=-1.000274
Fine-tune [116/100000]  val_loss=-1.008584
Fine-tune [117/100000]  val_loss=-0.995016
Fine-tune [118/100000]  val_loss=-0.992028
Fine-tune [119/100000]  val_loss=-1.015149
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [120/100000]  val_loss=-1.008956
Fine-tune [121/100000]  val_loss=-1.019152
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [122/100000]  val_loss=-1.015602
Fine-tune [123/100000]  val_loss=-1.002281
Fine-tune [124/100000]  val_loss=-1.001038
Fine-tune [125/100000]  val_loss=-1.001139
Fine-tune [126/100000]  val_loss=-0.996985
Fine-tune [127/100000]  val_loss=-0.993850
Fine-tune [128/100000]  val_loss=-1.009143
Fine-tune [129/100000]  val_loss=-1.025294
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [130/100000]  val_loss=-1.017313
Fine-tune [131/100000]  val_loss=-0.993915
Fine-tune [132/100000]  val_loss=-1.017732
Fine-tune [133/100000]  val_loss=-1.004447
Fine-tune [134/100000]  val_loss=-1.001500
Fine-tune [135/100000]  val_loss=-1.014164
Fine-tune [136/100000]  val_loss=-0.999554
Fine-tune [137/100000]  val_loss=-0.995207
Fine-tune [138/100000]  val_loss=-1.002458
Fine-tune [139/100000]  val_loss=-1.018959
Fine-tune [140/100000]  val_loss=-1.004824
Fine-tune [141/100000]  val_loss=-1.019349
Fine-tune [142/100000]  val_loss=-1.011140
Fine-tune [143/100000]  val_loss=-1.006041
Fine-tune [144/100000]  val_loss=-1.018034
Fine-tune [145/100000]  val_loss=-1.008181
Fine-tune [146/100000]  val_loss=-1.012217
Fine-tune [147/100000]  val_loss=-1.014340
Fine-tune [148/100000]  val_loss=-1.017375
Fine-tune [149/100000]  val_loss=-1.008028
Fine-tune [150/100000]  val_loss=-1.018091
Fine-tune [151/100000]  val_loss=-1.022247
Fine-tune [152/100000]  val_loss=-1.028361
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [153/100000]  val_loss=-1.029184
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [154/100000]  val_loss=-1.021590
Fine-tune [155/100000]  val_loss=-1.027553
Fine-tune [156/100000]  val_loss=-1.000641
Fine-tune [157/100000]  val_loss=-1.024762
Fine-tune [158/100000]  val_loss=-1.010452
Fine-tune [159/100000]  val_loss=-1.019730
Fine-tune [160/100000]  val_loss=-1.016701
Fine-tune [161/100000]  val_loss=-1.006154
Fine-tune [162/100000]  val_loss=-1.010709
Fine-tune [163/100000]  val_loss=-1.010768
Fine-tune [164/100000]  val_loss=-1.001069
Fine-tune [165/100000]  val_loss=-1.022337
Fine-tune [166/100000]  val_loss=-1.022992
Fine-tune [167/100000]  val_loss=-1.038649
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [168/100000]  val_loss=-1.037755
Fine-tune [169/100000]  val_loss=-1.036234
Fine-tune [170/100000]  val_loss=-1.036851
Fine-tune [171/100000]  val_loss=-1.025324
Fine-tune [172/100000]  val_loss=-1.030077
Fine-tune [173/100000]  val_loss=-1.047047
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [174/100000]  val_loss=-1.035175
Fine-tune [175/100000]  val_loss=-1.044503
Fine-tune [176/100000]  val_loss=-1.016321
Fine-tune [177/100000]  val_loss=-1.025633
Fine-tune [178/100000]  val_loss=-1.024739
Fine-tune [179/100000]  val_loss=-1.025652
Fine-tune [180/100000]  val_loss=-1.013609
Fine-tune [181/100000]  val_loss=-1.015440
Fine-tune [182/100000]  val_loss=-1.017620
Fine-tune [183/100000]  val_loss=-1.019358
Fine-tune [184/100000]  val_loss=-1.026759
Fine-tune [185/100000]  val_loss=-1.037461
Fine-tune [186/100000]  val_loss=-1.009780
Fine-tune [187/100000]  val_loss=-1.023562
Fine-tune [188/100000]  val_loss=-1.033402
Fine-tune [189/100000]  val_loss=-1.040534
Fine-tune [190/100000]  val_loss=-1.019462
Fine-tune [191/100000]  val_loss=-1.017516
Fine-tune [192/100000]  val_loss=-1.018145
Fine-tune [193/100000]  val_loss=-1.025556
Fine-tune [194/100000]  val_loss=-1.011475
Fine-tune [195/100000]  val_loss=-1.020697
Fine-tune [196/100000]  val_loss=-1.026165
Fine-tune [197/100000]  val_loss=-1.009499
Fine-tune [198/100000]  val_loss=-1.020048
Fine-tune [199/100000]  val_loss=-0.992563
Fine-tune [200/100000]  val_loss=-0.999230
Fine-tune [201/100000]  val_loss=-1.003449
Fine-tune [202/100000]  val_loss=-1.014013
Fine-tune [203/100000]  val_loss=-1.012613
Fine-tune [204/100000]  val_loss=-1.029598
Fine-tune [205/100000]  val_loss=-1.030651
Fine-tune [206/100000]  val_loss=-0.999201
Fine-tune [207/100000]  val_loss=-1.019289
Fine-tune [208/100000]  val_loss=-1.045693
Fine-tune [209/100000]  val_loss=-1.038243
Fine-tune [210/100000]  val_loss=-1.025504
Fine-tune [211/100000]  val_loss=-1.030556
Fine-tune [212/100000]  val_loss=-1.033501
Fine-tune [213/100000]  val_loss=-1.030882
Fine-tune [214/100000]  val_loss=-1.036102
Fine-tune [215/100000]  val_loss=-1.044531
Fine-tune [216/100000]  val_loss=-1.045598
Fine-tune [217/100000]  val_loss=-1.045923
Fine-tune [218/100000]  val_loss=-1.033972
Fine-tune [219/100000]  val_loss=-1.050216
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [220/100000]  val_loss=-1.051564
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD256_L4/finetuned.pth
Fine-tune [221/100000]  val_loss=-1.032123
Fine-tune [222/100000]  val_loss=-1.041656
Fine-tune [223/100000]  val_loss=-1.023482
Fine-tune [224/100000]  val_loss=-1.043657
Fine-tune [225/100000]  val_loss=-1.026188
Fine-tune [226/100000]  val_loss=-1.044966
Fine-tune [227/100000]  val_loss=-1.040158
Fine-tune [228/100000]  val_loss=-1.044365
Fine-tune [229/100000]  val_loss=-1.029713
Fine-tune [230/100000]  val_loss=-1.047862
Fine-tune [231/100000]  val_loss=-1.039906
Fine-tune [232/100000]  val_loss=-1.027796
Fine-tune [233/100000]  val_loss=-1.030674
Fine-tune [234/100000]  val_loss=-1.016777
Fine-tune [235/100000]  val_loss=-1.018978
Fine-tune [236/100000]  val_loss=-1.008479
Fine-tune [237/100000]  val_loss=-0.999368
Fine-tune [238/100000]  val_loss=-1.010842
Fine-tune [239/100000]  val_loss=-1.027281
Fine-tune [240/100000]  val_loss=-1.010883
Fine-tune [241/100000]  val_loss=-1.003387
Fine-tune [242/100000]  val_loss=-0.996933
Fine-tune [243/100000]  val_loss=-1.038695
Fine-tune [244/100000]  val_loss=-1.026217
Fine-tune [245/100000]  val_loss=-1.019736
Fine-tune [246/100000]  val_loss=-1.007182
Fine-tune [247/100000]  val_loss=-0.993301
Fine-tune [248/100000]  val_loss=-1.012000
Fine-tune [249/100000]  val_loss=-1.007718
Fine-tune [250/100000]  val_loss=-1.015253
Fine-tune [251/100000]  val_loss=-1.020419
Fine-tune [252/100000]  val_loss=-1.022566
Fine-tune [253/100000]  val_loss=-1.014440
Fine-tune [254/100000]  val_loss=-1.010025
Fine-tune [255/100000]  val_loss=-1.001140
Fine-tune [256/100000]  val_loss=-1.029588
Fine-tune [257/100000]  val_loss=-1.025766
Fine-tune [258/100000]  val_loss=-1.010770
Fine-tune [259/100000]  val_loss=-1.027408
Fine-tune [260/100000]  val_loss=-1.022005
Fine-tune [261/100000]  val_loss=-0.996257
Fine-tune [262/100000]  val_loss=-1.006201
Fine-tune [263/100000]  val_loss=-0.988538
Fine-tune [264/100000]  val_loss=-1.022701
Fine-tune [265/100000]  val_loss=-0.947908
Fine-tune [266/100000]  val_loss=-1.002056
Fine-tune [267/100000]  val_loss=-1.010970
Fine-tune [268/100000]  val_loss=-1.011769
Fine-tune [269/100000]  val_loss=-1.009303
Fine-tune [270/100000]  val_loss=-0.980723
Fine-tune [271/100000]  val_loss=-1.002388
Fine-tune [272/100000]  val_loss=-0.978757
Fine-tune [273/100000]  val_loss=-0.984197
Fine-tune [274/100000]  val_loss=-0.982615
Fine-tune [275/100000]  val_loss=-0.975529
Fine-tune [276/100000]  val_loss=-0.968880
Fine-tune [277/100000]  val_loss=-0.966998
Fine-tune [278/100000]  val_loss=-0.990128
Fine-tune [279/100000]  val_loss=-1.000118
Fine-tune [280/100000]  val_loss=-1.006058
Fine-tune [281/100000]  val_loss=-1.003098
Fine-tune [282/100000]  val_loss=-0.994341
Fine-tune [283/100000]  val_loss=-1.012433
Fine-tune [284/100000]  val_loss=-1.008592
Fine-tune [285/100000]  val_loss=-0.982702
Fine-tune [286/100000]  val_loss=-0.997850
Fine-tune [287/100000]  val_loss=-1.006222
Fine-tune [288/100000]  val_loss=-0.991683
Fine-tune [289/100000]  val_loss=-1.006482
Fine-tune [290/100000]  val_loss=-1.015049
Fine-tune [291/100000]  val_loss=-1.015697
Fine-tune [292/100000]  val_loss=-0.994069
Fine-tune [293/100000]  val_loss=-0.985203
Fine-tune [294/100000]  val_loss=-0.997369
Fine-tune [295/100000]  val_loss=-1.000481
Fine-tune [296/100000]  val_loss=-0.994056
Fine-tune [297/100000]  val_loss=-0.985756
Fine-tune [298/100000]  val_loss=-0.969283
Fine-tune [299/100000]  val_loss=-0.984251
Fine-tune [300/100000]  val_loss=-0.952625
Fine-tune [301/100000]  val_loss=-0.981493
Fine-tune [302/100000]  val_loss=-0.994523
Fine-tune [303/100000]  val_loss=-1.002150
Fine-tune [304/100000]  val_loss=-0.984091
Fine-tune [305/100000]  val_loss=-1.018200
Fine-tune [306/100000]  val_loss=-1.009809
Fine-tune [307/100000]  val_loss=-1.009397
Fine-tune [308/100000]  val_loss=-0.995310
Fine-tune [309/100000]  val_loss=-1.014534
Fine-tune [310/100000]  val_loss=-0.995327
Fine-tune [311/100000]  val_loss=-0.994796
Fine-tune [312/100000]  val_loss=-1.002985
Fine-tune [313/100000]  val_loss=-0.997625
Fine-tune [314/100000]  val_loss=-1.014170
Fine-tune [315/100000]  val_loss=-0.993296
Fine-tune [316/100000]  val_loss=-1.001652
Fine-tune [317/100000]  val_loss=-0.995543
Fine-tune [318/100000]  val_loss=-0.992051
Fine-tune [319/100000]  val_loss=-0.990960
Fine-tune [320/100000]  val_loss=-0.972026
Fine-tune [321/100000]  val_loss=-0.988951
Fine-tune [322/100000]  val_loss=-0.975170
Fine-tune [323/100000]  val_loss=-0.977466
Fine-tune [324/100000]  val_loss=-0.995837
Fine-tune [325/100000]  val_loss=-0.999062
Fine-tune [326/100000]  val_loss=-0.986825
Fine-tune [327/100000]  val_loss=-0.993566
Fine-tune [328/100000]  val_loss=-0.976548
Fine-tune [329/100000]  val_loss=-0.988359
Fine-tune [330/100000]  val_loss=-0.989333
Fine-tune [331/100000]  val_loss=-0.992206
Fine-tune [332/100000]  val_loss=-0.993494
Fine-tune [333/100000]  val_loss=-0.987260
Fine-tune [334/100000]  val_loss=-1.000223
Fine-tune [335/100000]  val_loss=-0.980467
Fine-tune [336/100000]  val_loss=-1.007703
Fine-tune [337/100000]  val_loss=-1.016372
Fine-tune [338/100000]  val_loss=-1.008198
Fine-tune [339/100000]  val_loss=-1.015141
Fine-tune [340/100000]  val_loss=-0.981391
Fine-tune [341/100000]  val_loss=-0.970272
Fine-tune [342/100000]  val_loss=-0.983463
Fine-tune [343/100000]  val_loss=-0.988755
Fine-tune [344/100000]  val_loss=-1.012622
Fine-tune [345/100000]  val_loss=-0.967646
Fine-tune [346/100000]  val_loss=-0.966408
Fine-tune [347/100000]  val_loss=-0.967754
Fine-tune [348/100000]  val_loss=-0.977310
Fine-tune [349/100000]  val_loss=-0.983354
Fine-tune [350/100000]  val_loss=-0.979651
Fine-tune [351/100000]  val_loss=-0.947047
Fine-tune [352/100000]  val_loss=-0.946977
Fine-tune [353/100000]  val_loss=-0.976321
Fine-tune [354/100000]  val_loss=-0.932854
Fine-tune [355/100000]  val_loss=-0.985199
Fine-tune [356/100000]  val_loss=-0.970524
Fine-tune [357/100000]  val_loss=-0.959561
Fine-tune [358/100000]  val_loss=-0.970884
Fine-tune [359/100000]  val_loss=-0.972774
Fine-tune [360/100000]  val_loss=-0.978268
Fine-tune [361/100000]  val_loss=-0.976998
Fine-tune [362/100000]  val_loss=-0.977156
Fine-tune [363/100000]  val_loss=-0.970083
Fine-tune [364/100000]  val_loss=-0.965907
Fine-tune [365/100000]  val_loss=-0.966935
Fine-tune [366/100000]  val_loss=-0.946522
Fine-tune [367/100000]  val_loss=-0.986394
Fine-tune [368/100000]  val_loss=-0.961322
Fine-tune [369/100000]  val_loss=-0.967851
Fine-tune [370/100000]  val_loss=-0.985821
Fine-tune [371/100000]  val_loss=-0.949538
Fine-tune [372/100000]  val_loss=-0.963758
Fine-tune [373/100000]  val_loss=-0.965811
Fine-tune [374/100000]  val_loss=-0.946458
Fine-tune [375/100000]  val_loss=-0.956274
Fine-tune [376/100000]  val_loss=-0.938594
Fine-tune [377/100000]  val_loss=-0.961451
Fine-tune [378/100000]  val_loss=-0.955962
Fine-tune [379/100000]  val_loss=-0.955115
Fine-tune [380/100000]  val_loss=-0.947094
Fine-tune [381/100000]  val_loss=-0.975474
Fine-tune [382/100000]  val_loss=-0.935899
Fine-tune [383/100000]  val_loss=-0.968050
Fine-tune [384/100000]  val_loss=-0.956950
Fine-tune [385/100000]  val_loss=-0.956790
Fine-tune [386/100000]  val_loss=-0.932561
Fine-tune [387/100000]  val_loss=-0.918156
Fine-tune [388/100000]  val_loss=-0.959170
Fine-tune [389/100000]  val_loss=-0.948016
Fine-tune [390/100000]  val_loss=-0.925478
Fine-tune [391/100000]  val_loss=-0.937155
Fine-tune [392/100000]  val_loss=-0.948681
Fine-tune [393/100000]  val_loss=-0.927687
Fine-tune [394/100000]  val_loss=-0.924667
Fine-tune [395/100000]  val_loss=-0.930087
Fine-tune [396/100000]  val_loss=-0.968257
Fine-tune [397/100000]  val_loss=-0.936531
Fine-tune [398/100000]  val_loss=-0.931217
Fine-tune [399/100000]  val_loss=-0.930591
Fine-tune [400/100000]  val_loss=-0.953704
Fine-tune [401/100000]  val_loss=-0.939503
Fine-tune [402/100000]  val_loss=-0.951917
Fine-tune [403/100000]  val_loss=-0.951781
Fine-tune [404/100000]  val_loss=-0.971406
Fine-tune [405/100000]  val_loss=-0.955772
Fine-tune [406/100000]  val_loss=-0.952695
Fine-tune [407/100000]  val_loss=-0.928315
Fine-tune [408/100000]  val_loss=-0.946549
Fine-tune [409/100000]  val_loss=-0.944349
Fine-tune [410/100000]  val_loss=-0.945252
Fine-tune [411/100000]  val_loss=-0.934052
Fine-tune [412/100000]  val_loss=-0.953108
Fine-tune [413/100000]  val_loss=-0.967136
Fine-tune [414/100000]  val_loss=-0.932441
Fine-tune [415/100000]  val_loss=-0.917528
Fine-tune [416/100000]  val_loss=-0.932700
Fine-tune [417/100000]  val_loss=-0.955930
Fine-tune [418/100000]  val_loss=-0.934393
Fine-tune [419/100000]  val_loss=-0.938456
Fine-tune [420/100000]  val_loss=-0.936888
Fine-tune [421/100000]  val_loss=-0.910922
Fine-tune [422/100000]  val_loss=-0.909636
Fine-tune [423/100000]  val_loss=-0.920255
Fine-tune [424/100000]  val_loss=-0.950949
Fine-tune [425/100000]  val_loss=-0.947459
Fine-tune [426/100000]  val_loss=-0.906343
Fine-tune [427/100000]  val_loss=-0.950841
Fine-tune [428/100000]  val_loss=-0.943904
Fine-tune [429/100000]  val_loss=-0.946060
Fine-tune [430/100000]  val_loss=-0.928050
Fine-tune [431/100000]  val_loss=-0.914345
Fine-tune [432/100000]  val_loss=-0.945174
Fine-tune [433/100000]  val_loss=-0.938711
Fine-tune [434/100000]  val_loss=-0.918394
Fine-tune [435/100000]  val_loss=-0.894170
Fine-tune [436/100000]  val_loss=-0.883942
Fine-tune [437/100000]  val_loss=-0.901073
Fine-tune [438/100000]  val_loss=-0.901941
Fine-tune [439/100000]  val_loss=-0.917818
Fine-tune [440/100000]  val_loss=-0.903852
Fine-tune [441/100000]  val_loss=-0.900967
Fine-tune [442/100000]  val_loss=-0.896534
Fine-tune [443/100000]  val_loss=-0.890469
Fine-tune [444/100000]  val_loss=-0.870137
Fine-tune [445/100000]  val_loss=-0.901143
Fine-tune [446/100000]  val_loss=-0.891622
Fine-tune [447/100000]  val_loss=-0.906070
Fine-tune [448/100000]  val_loss=-0.904326
Fine-tune [449/100000]  val_loss=-0.905060
Fine-tune [450/100000]  val_loss=-0.901614
Fine-tune [451/100000]  val_loss=-0.897678
Fine-tune [452/100000]  val_loss=-0.884150
Fine-tune [453/100000]  val_loss=-0.917678
Fine-tune [454/100000]  val_loss=-0.925119
Fine-tune [455/100000]  val_loss=-0.902852
Fine-tune [456/100000]  val_loss=-0.889709
Fine-tune [457/100000]  val_loss=-0.877049
Fine-tune [458/100000]  val_loss=-0.897540
Fine-tune [459/100000]  val_loss=-0.852160
Fine-tune [460/100000]  val_loss=-0.879348
Fine-tune [461/100000]  val_loss=-0.887500
Fine-tune [462/100000]  val_loss=-0.883512
Fine-tune [463/100000]  val_loss=-0.904572
Fine-tune [464/100000]  val_loss=-0.889654
Fine-tune [465/100000]  val_loss=-0.885458
Fine-tune [466/100000]  val_loss=-0.891127
Fine-tune [467/100000]  val_loss=-0.883785
Fine-tune [468/100000]  val_loss=-0.897954
Fine-tune [469/100000]  val_loss=-0.905186
Fine-tune [470/100000]  val_loss=-0.913263
Fine-tune [471/100000]  val_loss=-0.894116
Fine-tune [472/100000]  val_loss=-0.897241
Fine-tune [473/100000]  val_loss=-0.864683
Fine-tune [474/100000]  val_loss=-0.895062
Fine-tune [475/100000]  val_loss=-0.893133
Fine-tune [476/100000]  val_loss=-0.906644
Fine-tune [477/100000]  val_loss=-0.879297
Fine-tune [478/100000]  val_loss=-0.898844
Fine-tune [479/100000]  val_loss=-0.889373
Fine-tune [480/100000]  val_loss=-0.847331
Fine-tune [481/100000]  val_loss=-0.878707
Fine-tune [482/100000]  val_loss=-0.873942
Fine-tune [483/100000]  val_loss=-0.873824
Fine-tune [484/100000]  val_loss=-0.885679
Fine-tune [485/100000]  val_loss=-0.870515
Fine-tune [486/100000]  val_loss=-0.900887
Fine-tune [487/100000]  val_loss=-0.882041
Fine-tune [488/100000]  val_loss=-0.886357
Fine-tune [489/100000]  val_loss=-0.892751
Fine-tune [490/100000]  val_loss=-0.891697
Fine-tune [491/100000]  val_loss=-0.890862
Fine-tune [492/100000]  val_loss=-0.880027
Fine-tune [493/100000]  val_loss=-0.876277
Fine-tune [494/100000]  val_loss=-0.824304
Fine-tune [495/100000]  val_loss=-0.868829
Fine-tune [496/100000]  val_loss=-0.893138
Fine-tune [497/100000]  val_loss=-0.879687
Fine-tune [498/100000]  val_loss=-0.858051
Fine-tune [499/100000]  val_loss=-0.821129
Fine-tune [500/100000]  val_loss=-0.861064
Fine-tune [501/100000]  val_loss=-0.876576
Fine-tune [502/100000]  val_loss=-0.853894
Fine-tune [503/100000]  val_loss=-0.843774
Fine-tune [504/100000]  val_loss=-0.834326
Fine-tune [505/100000]  val_loss=-0.844459
Fine-tune [506/100000]  val_loss=-0.874970
Fine-tune [507/100000]  val_loss=-0.895032
Fine-tune [508/100000]  val_loss=-0.872981
Fine-tune [509/100000]  val_loss=-0.885299
Fine-tune [510/100000]  val_loss=-0.878653
Fine-tune [511/100000]  val_loss=-0.828823
Fine-tune [512/100000]  val_loss=-0.894276
Fine-tune [513/100000]  val_loss=-0.868033
Fine-tune [514/100000]  val_loss=-0.862943
Fine-tune [515/100000]  val_loss=-0.870571
Fine-tune [516/100000]  val_loss=-0.820845
Fine-tune [517/100000]  val_loss=-0.819219
Fine-tune [518/100000]  val_loss=-0.843840
Fine-tune [519/100000]  val_loss=-0.838435
Fine-tune [520/100000]  val_loss=-0.801232
Fine-tune [521/100000]  val_loss=-0.845107
Fine-tune [522/100000]  val_loss=-0.854393
Fine-tune [523/100000]  val_loss=-0.870499
Fine-tune [524/100000]  val_loss=-0.819149
Fine-tune [525/100000]  val_loss=-0.826175
Fine-tune [526/100000]  val_loss=-0.809927
Fine-tune [527/100000]  val_loss=-0.808579
Fine-tune [528/100000]  val_loss=-0.787356
Fine-tune [529/100000]  val_loss=-0.801924
Fine-tune [530/100000]  val_loss=-0.793796
Fine-tune [531/100000]  val_loss=-0.825413
Fine-tune [532/100000]  val_loss=-0.815002
Fine-tune [533/100000]  val_loss=-0.812673
Fine-tune [534/100000]  val_loss=-0.785474
Fine-tune [535/100000]  val_loss=-0.788507
Fine-tune [536/100000]  val_loss=-0.782716
Fine-tune [537/100000]  val_loss=-0.793940
Fine-tune [538/100000]  val_loss=-0.823392
Fine-tune [539/100000]  val_loss=-0.825157
Fine-tune [540/100000]  val_loss=-0.802058
Fine-tune [541/100000]  val_loss=-0.828880
Fine-tune [542/100000]  val_loss=-0.837169
Fine-tune [543/100000]  val_loss=-0.841305
Fine-tune [544/100000]  val_loss=-0.822007
Fine-tune [545/100000]  val_loss=-0.831194
Fine-tune [546/100000]  val_loss=-0.824088
Fine-tune [547/100000]  val_loss=-0.820075
Fine-tune [548/100000]  val_loss=-0.825281
Fine-tune [549/100000]  val_loss=-0.845458
Fine-tune [550/100000]  val_loss=-0.817319
Fine-tune [551/100000]  val_loss=-0.857462
Fine-tune [552/100000]  val_loss=-0.834636
Fine-tune [553/100000]  val_loss=-0.839490
Fine-tune [554/100000]  val_loss=-0.855179
Fine-tune [555/100000]  val_loss=-0.814468
Fine-tune [556/100000]  val_loss=-0.828166
Fine-tune [557/100000]  val_loss=-0.799912
Fine-tune [558/100000]  val_loss=-0.816010
Fine-tune [559/100000]  val_loss=-0.847386
Fine-tune [560/100000]  val_loss=-0.849276
Fine-tune [561/100000]  val_loss=-0.832820
Fine-tune [562/100000]  val_loss=-0.787419
Fine-tune [563/100000]  val_loss=-0.772228
Fine-tune [564/100000]  val_loss=-0.762948
Fine-tune [565/100000]  val_loss=-0.738983
Fine-tune [566/100000]  val_loss=-0.767773
Fine-tune [567/100000]  val_loss=-0.767219
Fine-tune [568/100000]  val_loss=-0.777277
Fine-tune [569/100000]  val_loss=-0.768487
Fine-tune [570/100000]  val_loss=-0.788599
Fine-tune [571/100000]  val_loss=-0.777699
Fine-tune [572/100000]  val_loss=-0.831195
Fine-tune [573/100000]  val_loss=-0.796122
Fine-tune [574/100000]  val_loss=-0.757108
Fine-tune [575/100000]  val_loss=-0.780206
Fine-tune [576/100000]  val_loss=-0.830011
Fine-tune [577/100000]  val_loss=-0.838991
Fine-tune [578/100000]  val_loss=-0.854740
Fine-tune [579/100000]  val_loss=-0.797922
Fine-tune [580/100000]  val_loss=-0.833020
Fine-tune [581/100000]  val_loss=-0.851591
Fine-tune [582/100000]  val_loss=-0.791931
Fine-tune [583/100000]  val_loss=-0.823209
Fine-tune [584/100000]  val_loss=-0.762222
Fine-tune [585/100000]  val_loss=-0.792070
Fine-tune [586/100000]  val_loss=-0.792034
Fine-tune [587/100000]  val_loss=-0.804387
Fine-tune [588/100000]  val_loss=-0.772585
Fine-tune [589/100000]  val_loss=-0.783399
Fine-tune [590/100000]  val_loss=-0.778267
Fine-tune [591/100000]  val_loss=-0.771964
Fine-tune [592/100000]  val_loss=-0.791888
Fine-tune [593/100000]  val_loss=-0.785275
Fine-tune [594/100000]  val_loss=-0.771945
Fine-tune [595/100000]  val_loss=-0.753124
Fine-tune [596/100000]  val_loss=-0.759570
Fine-tune [597/100000]  val_loss=-0.773720
Fine-tune [598/100000]  val_loss=-0.757048
Fine-tune [599/100000]  val_loss=-0.756928
Fine-tune [600/100000]  val_loss=-0.749114
Fine-tune [601/100000]  val_loss=-0.780912
Fine-tune [602/100000]  val_loss=-0.785663
Fine-tune [603/100000]  val_loss=-0.783116
Fine-tune [604/100000]  val_loss=-0.778621
Fine-tune [605/100000]  val_loss=-0.772845
Fine-tune [606/100000]  val_loss=-0.776872
Fine-tune [607/100000]  val_loss=-0.782925
Fine-tune [608/100000]  val_loss=-0.808489
Fine-tune [609/100000]  val_loss=-0.769497
Fine-tune [610/100000]  val_loss=-0.763134
Fine-tune [611/100000]  val_loss=-0.762699
Fine-tune [612/100000]  val_loss=-0.693818
Fine-tune [613/100000]  val_loss=-0.722239
Fine-tune [614/100000]  val_loss=-0.740578
Fine-tune [615/100000]  val_loss=-0.792585
Fine-tune [616/100000]  val_loss=-0.815633
Fine-tune [617/100000]  val_loss=-0.790688
Fine-tune [618/100000]  val_loss=-0.773613
Fine-tune [619/100000]  val_loss=-0.775002
Fine-tune [620/100000]  val_loss=-0.719461
Fine-tune [621/100000]  val_loss=-0.749548
Fine-tune [622/100000]  val_loss=-0.749764
Fine-tune [623/100000]  val_loss=-0.779319
Fine-tune [624/100000]  val_loss=-0.768664
Fine-tune [625/100000]  val_loss=-0.801768
Fine-tune [626/100000]  val_loss=-0.762567
Fine-tune [627/100000]  val_loss=-0.724769
Fine-tune [628/100000]  val_loss=-0.749857
Fine-tune [629/100000]  val_loss=-0.738413
Fine-tune [630/100000]  val_loss=-0.712610
Fine-tune [631/100000]  val_loss=-0.758428
Fine-tune [632/100000]  val_loss=-0.723641
Fine-tune [633/100000]  val_loss=-0.742302
Fine-tune [634/100000]  val_loss=-0.755364
Fine-tune [635/100000]  val_loss=-0.767781
Fine-tune [636/100000]  val_loss=-0.755030
Fine-tune [637/100000]  val_loss=-0.774229
Fine-tune [638/100000]  val_loss=-0.802505
Fine-tune [639/100000]  val_loss=-0.788305
Fine-tune [640/100000]  val_loss=-0.760936
Fine-tune [641/100000]  val_loss=-0.775941
Fine-tune [642/100000]  val_loss=-0.755043
Fine-tune [643/100000]  val_loss=-0.806301
Fine-tune [644/100000]  val_loss=-0.753743
Fine-tune [645/100000]  val_loss=-0.746957
Fine-tune [646/100000]  val_loss=-0.728117
Fine-tune [647/100000]  val_loss=-0.738486
Fine-tune [648/100000]  val_loss=-0.741363
Fine-tune [649/100000]  val_loss=-0.750464
Fine-tune [650/100000]  val_loss=-0.806033
Fine-tune [651/100000]  val_loss=-0.775288
Fine-tune [652/100000]  val_loss=-0.736278
Fine-tune [653/100000]  val_loss=-0.753211
Fine-tune [654/100000]  val_loss=-0.755791
Fine-tune [655/100000]  val_loss=-0.746359
Fine-tune [656/100000]  val_loss=-0.800573
Fine-tune [657/100000]  val_loss=-0.765946
Fine-tune [658/100000]  val_loss=-0.760050
Fine-tune [659/100000]  val_loss=-0.748175
Fine-tune [660/100000]  val_loss=-0.778437
Fine-tune [661/100000]  val_loss=-0.747023
Fine-tune [662/100000]  val_loss=-0.725893
Fine-tune [663/100000]  val_loss=-0.768026
Fine-tune [664/100000]  val_loss=-0.723288
Fine-tune [665/100000]  val_loss=-0.729078
Fine-tune [666/100000]  val_loss=-0.717200
Fine-tune [667/100000]  val_loss=-0.733395
Fine-tune [668/100000]  val_loss=-0.715485
Fine-tune [669/100000]  val_loss=-0.703868
Fine-tune [670/100000]  val_loss=-0.740384
Fine-tune [671/100000]  val_loss=-0.720274
Fine-tune [672/100000]  val_loss=-0.693683
Fine-tune [673/100000]  val_loss=-0.716376
Fine-tune [674/100000]  val_loss=-0.725858
Fine-tune [675/100000]  val_loss=-0.697527
Fine-tune [676/100000]  val_loss=-0.810512
Fine-tune [677/100000]  val_loss=-0.783098
Fine-tune [678/100000]  val_loss=-0.765709
Fine-tune [679/100000]  val_loss=-0.786689
Fine-tune [680/100000]  val_loss=-0.776737
Fine-tune [681/100000]  val_loss=-0.772739
Fine-tune [682/100000]  val_loss=-0.728334
Fine-tune [683/100000]  val_loss=-0.734267
Fine-tune [684/100000]  val_loss=-0.720688
Fine-tune [685/100000]  val_loss=-0.716365
Fine-tune [686/100000]  val_loss=-0.720004
Fine-tune [687/100000]  val_loss=-0.727302
Fine-tune [688/100000]  val_loss=-0.689961
Fine-tune [689/100000]  val_loss=-0.750524
Fine-tune [690/100000]  val_loss=-0.696841
Fine-tune [691/100000]  val_loss=-0.715941
Fine-tune [692/100000]  val_loss=-0.732040
Fine-tune [693/100000]  val_loss=-0.713110
Fine-tune [694/100000]  val_loss=-0.705464
Fine-tune [695/100000]  val_loss=-0.708243
Fine-tune [696/100000]  val_loss=-0.696525
Fine-tune [697/100000]  val_loss=-0.736928
Fine-tune [698/100000]  val_loss=-0.680973
Fine-tune [699/100000]  val_loss=-0.717494
Fine-tune [700/100000]  val_loss=-0.725571
Fine-tune [701/100000]  val_loss=-0.723232
Fine-tune [702/100000]  val_loss=-0.708252
Fine-tune [703/100000]  val_loss=-0.681670
Fine-tune [704/100000]  val_loss=-0.748702
Fine-tune [705/100000]  val_loss=-0.741978
Fine-tune [706/100000]  val_loss=-0.737010
Fine-tune [707/100000]  val_loss=-0.708576
Fine-tune [708/100000]  val_loss=-0.738609
Fine-tune [709/100000]  val_loss=-0.747203
Fine-tune [710/100000]  val_loss=-0.703298
Fine-tune [711/100000]  val_loss=-0.693459
Fine-tune [712/100000]  val_loss=-0.720171
Fine-tune [713/100000]  val_loss=-0.738819
Fine-tune [714/100000]  val_loss=-0.752929
Fine-tune [715/100000]  val_loss=-0.730895
Fine-tune [716/100000]  val_loss=-0.728557
Fine-tune [717/100000]  val_loss=-0.744269
Fine-tune [718/100000]  val_loss=-0.714381
Fine-tune [719/100000]  val_loss=-0.757991
Fine-tune [720/100000]  val_loss=-0.741462
Fine-tune [721/100000]  val_loss=-0.734184
Fine-tune [722/100000]  val_loss=-0.706100
Fine-tune [723/100000]  val_loss=-0.732025
Fine-tune [724/100000]  val_loss=-0.700858
Fine-tune [725/100000]  val_loss=-0.692275
Fine-tune [726/100000]  val_loss=-0.699605
Fine-tune [727/100000]  val_loss=-0.686883
Fine-tune [728/100000]  val_loss=-0.656752
Fine-tune [729/100000]  val_loss=-0.664039
Fine-tune [730/100000]  val_loss=-0.679191
Fine-tune [731/100000]  val_loss=-0.709992
Fine-tune [732/100000]  val_loss=-0.714223
Fine-tune [733/100000]  val_loss=-0.711878
Fine-tune [734/100000]  val_loss=-0.691925
Fine-tune [735/100000]  val_loss=-0.620855
Fine-tune [736/100000]  val_loss=-0.630013
Fine-tune [737/100000]  val_loss=-0.647464
Fine-tune [738/100000]  val_loss=-0.701403
Fine-tune [739/100000]  val_loss=-0.710324
Fine-tune [740/100000]  val_loss=-0.708297
Fine-tune [741/100000]  val_loss=-0.654859
Fine-tune [742/100000]  val_loss=-0.664809
Fine-tune [743/100000]  val_loss=-0.635493
Fine-tune [744/100000]  val_loss=-0.702309
Fine-tune [745/100000]  val_loss=-0.665802
Fine-tune [746/100000]  val_loss=-0.715993
Fine-tune [747/100000]  val_loss=-0.683588
Fine-tune [748/100000]  val_loss=-0.705019
Fine-tune [749/100000]  val_loss=-0.658454
Fine-tune [750/100000]  val_loss=-0.684479
Fine-tune [751/100000]  val_loss=-0.644954
Fine-tune [752/100000]  val_loss=-0.673957
Fine-tune [753/100000]  val_loss=-0.726315
Fine-tune [754/100000]  val_loss=-0.738425
Fine-tune [755/100000]  val_loss=-0.749386
Fine-tune [756/100000]  val_loss=-0.711245
Fine-tune [757/100000]  val_loss=-0.682308
Fine-tune [758/100000]  val_loss=-0.695641
Fine-tune [759/100000]  val_loss=-0.652392
Fine-tune [760/100000]  val_loss=-0.680923
Fine-tune [761/100000]  val_loss=-0.658553
Fine-tune [762/100000]  val_loss=-0.651116
Fine-tune [763/100000]  val_loss=-0.668299
Fine-tune [764/100000]  val_loss=-0.693141
Fine-tune [765/100000]  val_loss=-0.642469
Fine-tune [766/100000]  val_loss=-0.665286
Fine-tune [767/100000]  val_loss=-0.670447
Fine-tune [768/100000]  val_loss=-0.675055
Fine-tune [769/100000]  val_loss=-0.663995
Fine-tune [770/100000]  val_loss=-0.665443
Fine-tune [771/100000]  val_loss=-0.671496
Fine-tune [772/100000]  val_loss=-0.655920
Fine-tune [773/100000]  val_loss=-0.590143
Fine-tune [774/100000]  val_loss=-0.593486
Fine-tune [775/100000]  val_loss=-0.623541
Fine-tune [776/100000]  val_loss=-0.652441
Fine-tune [777/100000]  val_loss=-0.665974
Fine-tune [778/100000]  val_loss=-0.646226
Fine-tune [779/100000]  val_loss=-0.609802
Fine-tune [780/100000]  val_loss=-0.658042
Fine-tune [781/100000]  val_loss=-0.625793
Fine-tune [782/100000]  val_loss=-0.637317
Fine-tune [783/100000]  val_loss=-0.643622
Fine-tune [784/100000]  val_loss=-0.619547
Fine-tune [785/100000]  val_loss=-0.644512
Fine-tune [786/100000]  val_loss=-0.601241
Fine-tune [787/100000]  val_loss=-0.620609
Fine-tune [788/100000]  val_loss=-0.636665
Fine-tune [789/100000]  val_loss=-0.668273
Fine-tune [790/100000]  val_loss=-0.650557
Fine-tune [791/100000]  val_loss=-0.670533
Fine-tune [792/100000]  val_loss=-0.668141
Fine-tune [793/100000]  val_loss=-0.692002
Fine-tune [794/100000]  val_loss=-0.653770
Fine-tune [795/100000]  val_loss=-0.674702
Fine-tune [796/100000]  val_loss=-0.608797
Fine-tune [797/100000]  val_loss=-0.658344
Fine-tune [798/100000]  val_loss=-0.635908
Fine-tune [799/100000]  val_loss=-0.638731
Fine-tune [800/100000]  val_loss=-0.647799
Fine-tune [801/100000]  val_loss=-0.666755
Fine-tune [802/100000]  val_loss=-0.621091
Fine-tune [803/100000]  val_loss=-0.664344
Fine-tune [804/100000]  val_loss=-0.638303
Fine-tune [805/100000]  val_loss=-0.644850
Fine-tune [806/100000]  val_loss=-0.623237
Fine-tune [807/100000]  val_loss=-0.591167
Fine-tune [808/100000]  val_loss=-0.637556
Fine-tune [809/100000]  val_loss=-0.619698
Fine-tune [810/100000]  val_loss=-0.659652
Fine-tune [811/100000]  val_loss=-0.652491
Fine-tune [812/100000]  val_loss=-0.658839
Fine-tune [813/100000]  val_loss=-0.649859
Fine-tune [814/100000]  val_loss=-0.629312
Fine-tune [815/100000]  val_loss=-0.641404
Fine-tune [816/100000]  val_loss=-0.652516
Fine-tune [817/100000]  val_loss=-0.677131
Fine-tune [818/100000]  val_loss=-0.720404
Fine-tune [819/100000]  val_loss=-0.693606
Fine-tune [820/100000]  val_loss=-0.708734
Fine-tune [821/100000]  val_loss=-0.624272
Fine-tune [822/100000]  val_loss=-0.700697
Fine-tune [823/100000]  val_loss=-0.661591
Fine-tune [824/100000]  val_loss=-0.711534
Fine-tune [825/100000]  val_loss=-0.672311
Fine-tune [826/100000]  val_loss=-0.655941
Fine-tune [827/100000]  val_loss=-0.642059
Fine-tune [828/100000]  val_loss=-0.592108
Fine-tune [829/100000]  val_loss=-0.608473
Fine-tune [830/100000]  val_loss=-0.602176
Fine-tune [831/100000]  val_loss=-0.629189
Fine-tune [832/100000]  val_loss=-0.651639
Fine-tune [833/100000]  val_loss=-0.641407
Fine-tune [834/100000]  val_loss=-0.635741
Fine-tune [835/100000]  val_loss=-0.638289
Fine-tune [836/100000]  val_loss=-0.638586
Fine-tune [837/100000]  val_loss=-0.655654
Fine-tune [838/100000]  val_loss=-0.627598
Fine-tune [839/100000]  val_loss=-0.648280
Fine-tune [840/100000]  val_loss=-0.574696
Fine-tune [841/100000]  val_loss=-0.596550
Fine-tune [842/100000]  val_loss=-0.583812
Fine-tune [843/100000]  val_loss=-0.622372
Fine-tune [844/100000]  val_loss=-0.532531
Fine-tune [845/100000]  val_loss=-0.529652
Fine-tune [846/100000]  val_loss=-0.566980
Fine-tune [847/100000]  val_loss=-0.588937
Fine-tune [848/100000]  val_loss=-0.561107
Fine-tune [849/100000]  val_loss=-0.584210
Fine-tune [850/100000]  val_loss=-0.587489
Fine-tune [851/100000]  val_loss=-0.636090
Fine-tune [852/100000]  val_loss=-0.593704
Fine-tune [853/100000]  val_loss=-0.577194
Fine-tune [854/100000]  val_loss=-0.582851
Fine-tune [855/100000]  val_loss=-0.574059
Fine-tune [856/100000]  val_loss=-0.561432
Fine-tune [857/100000]  val_loss=-0.602768
Fine-tune [858/100000]  val_loss=-0.612550
Fine-tune [859/100000]  val_loss=-0.632335
Fine-tune [860/100000]  val_loss=-0.632268
Fine-tune [861/100000]  val_loss=-0.564200
Fine-tune [862/100000]  val_loss=-0.585152
Fine-tune [863/100000]  val_loss=-0.592062
Fine-tune [864/100000]  val_loss=-0.635275
Fine-tune [865/100000]  val_loss=-0.622186
Fine-tune [866/100000]  val_loss=-0.616842
Fine-tune [867/100000]  val_loss=-0.569017
Fine-tune [868/100000]  val_loss=-0.595604
Fine-tune [869/100000]  val_loss=-0.624490
Fine-tune [870/100000]  val_loss=-0.655479
Fine-tune [871/100000]  val_loss=-0.633225
Fine-tune [872/100000]  val_loss=-0.617490
Fine-tune [873/100000]  val_loss=-0.586048
Fine-tune [874/100000]  val_loss=-0.525262
Fine-tune [875/100000]  val_loss=-0.517553
Fine-tune [876/100000]  val_loss=-0.506852
Fine-tune [877/100000]  val_loss=-0.593829
Fine-tune [878/100000]  val_loss=-0.577335
Fine-tune [879/100000]  val_loss=-0.563582
Fine-tune [880/100000]  val_loss=-0.511692
Fine-tune [881/100000]  val_loss=-0.514817
Fine-tune [882/100000]  val_loss=-0.533358
Fine-tune [883/100000]  val_loss=-0.542416
Fine-tune [884/100000]  val_loss=-0.511587
Fine-tune [885/100000]  val_loss=-0.542725
Fine-tune [886/100000]  val_loss=-0.566785
Fine-tune [887/100000]  val_loss=-0.560335
Fine-tune [888/100000]  val_loss=-0.540476
Fine-tune [889/100000]  val_loss=-0.581126
Fine-tune [890/100000]  val_loss=-0.591673
Fine-tune [891/100000]  val_loss=-0.560059
Fine-tune [892/100000]  val_loss=-0.550978
Fine-tune [893/100000]  val_loss=-0.573870
Fine-tune [894/100000]  val_loss=-0.601393
Fine-tune [895/100000]  val_loss=-0.580224
Fine-tune [896/100000]  val_loss=-0.602503
Fine-tune [897/100000]  val_loss=-0.598330
Fine-tune [898/100000]  val_loss=-0.551164
Fine-tune [899/100000]  val_loss=-0.519962
Fine-tune [900/100000]  val_loss=-0.561087
Fine-tune [901/100000]  val_loss=-0.606491
Fine-tune [902/100000]  val_loss=-0.542576
Fine-tune [903/100000]  val_loss=-0.563658
Fine-tune [904/100000]  val_loss=-0.573773
Fine-tune [905/100000]  val_loss=-0.569730
Fine-tune [906/100000]  val_loss=-0.577099
Fine-tune [907/100000]  val_loss=-0.587473
Fine-tune [908/100000]  val_loss=-0.642815
Fine-tune [909/100000]  val_loss=-0.615657
Fine-tune [910/100000]  val_loss=-0.643895
Fine-tune [911/100000]  val_loss=-0.631313
Fine-tune [912/100000]  val_loss=-0.581333
Fine-tune [913/100000]  val_loss=-0.587180
Fine-tune [914/100000]  val_loss=-0.573100
Fine-tune [915/100000]  val_loss=-0.559631
Fine-tune [916/100000]  val_loss=-0.577914
Fine-tune [917/100000]  val_loss=-0.557454
Fine-tune [918/100000]  val_loss=-0.569534
Fine-tune [919/100000]  val_loss=-0.607979
Fine-tune [920/100000]  val_loss=-0.575435
Fine-tune [921/100000]  val_loss=-0.576264
Fine-tune [922/100000]  val_loss=-0.569564
Fine-tune [923/100000]  val_loss=-0.592480
Fine-tune [924/100000]  val_loss=-0.588246
Fine-tune [925/100000]  val_loss=-0.601782
Fine-tune [926/100000]  val_loss=-0.562026
Fine-tune [927/100000]  val_loss=-0.554991
Fine-tune [928/100000]  val_loss=-0.574489
Fine-tune [929/100000]  val_loss=-0.488588
Fine-tune [930/100000]  val_loss=-0.622605
Fine-tune [931/100000]  val_loss=-0.515976
Fine-tune [932/100000]  val_loss=-0.504898
Fine-tune [933/100000]  val_loss=-0.532850
Fine-tune [934/100000]  val_loss=-0.519573
Fine-tune [935/100000]  val_loss=-0.543160
Fine-tune [936/100000]  val_loss=-0.513520
Fine-tune [937/100000]  val_loss=-0.540010
Fine-tune [938/100000]  val_loss=-0.559229
Fine-tune [939/100000]  val_loss=-0.606878
Fine-tune [940/100000]  val_loss=-0.586764
Fine-tune [941/100000]  val_loss=-0.540742
Fine-tune [942/100000]  val_loss=-0.547375
Fine-tune [943/100000]  val_loss=-0.579208
Fine-tune [944/100000]  val_loss=-0.538315
Fine-tune [945/100000]  val_loss=-0.543890
Fine-tune [946/100000]  val_loss=-0.541058
Fine-tune [947/100000]  val_loss=-0.543599
Fine-tune [948/100000]  val_loss=-0.562627
Fine-tune [949/100000]  val_loss=-0.522560
Fine-tune [950/100000]  val_loss=-0.539390
Fine-tune [951/100000]  val_loss=-0.500567
Fine-tune [952/100000]  val_loss=-0.476825
Fine-tune [953/100000]  val_loss=-0.432749
Fine-tune [954/100000]  val_loss=-0.525015
Fine-tune [955/100000]  val_loss=-0.557376
Fine-tune [956/100000]  val_loss=-0.582305
Fine-tune [957/100000]  val_loss=-0.516688
Fine-tune [958/100000]  val_loss=-0.502958
Fine-tune [959/100000]  val_loss=-0.487161
Fine-tune [960/100000]  val_loss=-0.519307
Fine-tune [961/100000]  val_loss=-0.548190
Fine-tune [962/100000]  val_loss=-0.562341
Fine-tune [963/100000]  val_loss=-0.525418
Fine-tune [964/100000]  val_loss=-0.540352
Fine-tune [965/100000]  val_loss=-0.560454
Fine-tune [966/100000]  val_loss=-0.575365
Fine-tune [967/100000]  val_loss=-0.564898
Fine-tune [968/100000]  val_loss=-0.525442
Fine-tune [969/100000]  val_loss=-0.536521
Fine-tune [970/100000]  val_loss=-0.494610
Fine-tune [971/100000]  val_loss=-0.457454
Fine-tune [972/100000]  val_loss=-0.522281
Fine-tune [973/100000]  val_loss=-0.510825
Fine-tune [974/100000]  val_loss=-0.543744
Fine-tune [975/100000]  val_loss=-0.553425
Fine-tune [976/100000]  val_loss=-0.535412
Fine-tune [977/100000]  val_loss=-0.517189
Fine-tune [978/100000]  val_loss=-0.464606
Fine-tune [979/100000]  val_loss=-0.501371
Fine-tune [980/100000]  val_loss=-0.505570
Fine-tune [981/100000]  val_loss=-0.495662
Fine-tune [982/100000]  val_loss=-0.461083
Fine-tune [983/100000]  val_loss=-0.484864
Fine-tune [984/100000]  val_loss=-0.477600
Fine-tune [985/100000]  val_loss=-0.486955
Fine-tune [986/100000]  val_loss=-0.500045
Fine-tune [987/100000]  val_loss=-0.539698
Fine-tune [988/100000]  val_loss=-0.541098
Fine-tune [989/100000]  val_loss=-0.597490
Fine-tune [990/100000]  val_loss=-0.542592
Fine-tune [991/100000]  val_loss=-0.580303
Fine-tune [992/100000]  val_loss=-0.536718
Fine-tune [993/100000]  val_loss=-0.541751
Fine-tune [994/100000]  val_loss=-0.477898
Fine-tune [995/100000]  val_loss=-0.498130
Fine-tune [996/100000]  val_loss=-0.479242
Fine-tune [997/100000]  val_loss=-0.495409
Fine-tune [998/100000]  val_loss=-0.490639
Fine-tune [999/100000]  val_loss=-0.491896
Fine-tune [1000/100000]  val_loss=-0.520077
Fine-tune [1001/100000]  val_loss=-0.517184
Fine-tune [1002/100000]  val_loss=-0.499597
Fine-tune [1003/100000]  val_loss=-0.533582
Fine-tune [1004/100000]  val_loss=-0.470036
Fine-tune [1005/100000]  val_loss=-0.503184
Fine-tune [1006/100000]  val_loss=-0.500918
Fine-tune [1007/100000]  val_loss=-0.574624
Fine-tune [1008/100000]  val_loss=-0.573320
Fine-tune [1009/100000]  val_loss=-0.556776
Fine-tune [1010/100000]  val_loss=-0.539459
Fine-tune [1011/100000]  val_loss=-0.556329
Fine-tune [1012/100000]  val_loss=-0.479855
Fine-tune [1013/100000]  val_loss=-0.420074
Fine-tune [1014/100000]  val_loss=-0.488539
Fine-tune [1015/100000]  val_loss=-0.470719
Fine-tune [1016/100000]  val_loss=-0.448631
Fine-tune [1017/100000]  val_loss=-0.516667
Fine-tune [1018/100000]  val_loss=-0.540800
Fine-tune [1019/100000]  val_loss=-0.557146
Fine-tune [1020/100000]  val_loss=-0.476245
Fine-tune [1021/100000]  val_loss=-0.489775
Fine-tune [1022/100000]  val_loss=-0.477408
Fine-tune [1023/100000]  val_loss=-0.497159
Fine-tune [1024/100000]  val_loss=-0.512870
Fine-tune [1025/100000]  val_loss=-0.498425
Fine-tune [1026/100000]  val_loss=-0.488531
Fine-tune [1027/100000]  val_loss=-0.487720
Fine-tune [1028/100000]  val_loss=-0.500985
Fine-tune [1029/100000]  val_loss=-0.468469
Fine-tune [1030/100000]  val_loss=-0.478393
Fine-tune [1031/100000]  val_loss=-0.527012
Fine-tune [1032/100000]  val_loss=-0.520047
Fine-tune [1033/100000]  val_loss=-0.546945
Fine-tune [1034/100000]  val_loss=-0.513611
Fine-tune [1035/100000]  val_loss=-0.507084
Fine-tune [1036/100000]  val_loss=-0.517517
Fine-tune [1037/100000]  val_loss=-0.491955
Fine-tune [1038/100000]  val_loss=-0.396419
Fine-tune [1039/100000]  val_loss=-0.411956
Fine-tune [1040/100000]  val_loss=-0.429426
Fine-tune [1041/100000]  val_loss=-0.454799
Fine-tune [1042/100000]  val_loss=-0.522524
Fine-tune [1043/100000]  val_loss=-0.471383
Fine-tune [1044/100000]  val_loss=-0.419274
Fine-tune [1045/100000]  val_loss=-0.458936
Fine-tune [1046/100000]  val_loss=-0.462194
Fine-tune [1047/100000]  val_loss=-0.448720
Fine-tune [1048/100000]  val_loss=-0.465599
Fine-tune [1049/100000]  val_loss=-0.501077
Fine-tune [1050/100000]  val_loss=-0.473319
Fine-tune [1051/100000]  val_loss=-0.465074
Fine-tune [1052/100000]  val_loss=-0.479466
Fine-tune [1053/100000]  val_loss=-0.479994
Fine-tune [1054/100000]  val_loss=-0.520444
Fine-tune [1055/100000]  val_loss=-0.468707
Fine-tune [1056/100000]  val_loss=-0.526312
Fine-tune [1057/100000]  val_loss=-0.450851
Fine-tune [1058/100000]  val_loss=-0.504799
Fine-tune [1059/100000]  val_loss=-0.479176
Fine-tune [1060/100000]  val_loss=-0.516297
Fine-tune [1061/100000]  val_loss=-0.472596
Fine-tune [1062/100000]  val_loss=-0.444286
Fine-tune [1063/100000]  val_loss=-0.513603
Fine-tune [1064/100000]  val_loss=-0.483916
Fine-tune [1065/100000]  val_loss=-0.443438
Fine-tune [1066/100000]  val_loss=-0.441119
Fine-tune [1067/100000]  val_loss=-0.490754
Fine-tune [1068/100000]  val_loss=-0.452116
Fine-tune [1069/100000]  val_loss=-0.470474
Fine-tune [1070/100000]  val_loss=-0.501761
Fine-tune [1071/100000]  val_loss=-0.473786
Fine-tune [1072/100000]  val_loss=-0.468398
Fine-tune [1073/100000]  val_loss=-0.495499
Fine-tune [1074/100000]  val_loss=-0.494605
Fine-tune [1075/100000]  val_loss=-0.458269
Fine-tune [1076/100000]  val_loss=-0.493581
Fine-tune [1077/100000]  val_loss=-0.475573
Fine-tune [1078/100000]  val_loss=-0.500193
Fine-tune [1079/100000]  val_loss=-0.429820
Fine-tune [1080/100000]  val_loss=-0.455594
Fine-tune [1081/100000]  val_loss=-0.522000
Fine-tune [1082/100000]  val_loss=-0.483549
Fine-tune [1083/100000]  val_loss=-0.408833
Fine-tune [1084/100000]  val_loss=-0.433033
Fine-tune [1085/100000]  val_loss=-0.453843
Fine-tune [1086/100000]  val_loss=-0.460071
Fine-tune [1087/100000]  val_loss=-0.377452
Fine-tune [1088/100000]  val_loss=-0.470604
Fine-tune [1089/100000]  val_loss=-0.458146
Fine-tune [1090/100000]  val_loss=-0.476077
Fine-tune [1091/100000]  val_loss=-0.522858
Fine-tune [1092/100000]  val_loss=-0.514903
Fine-tune [1093/100000]  val_loss=-0.483983
Fine-tune [1094/100000]  val_loss=-0.469399
Fine-tune [1095/100000]  val_loss=-0.421546
Fine-tune [1096/100000]  val_loss=-0.452129
Fine-tune [1097/100000]  val_loss=-0.492101
Fine-tune [1098/100000]  val_loss=-0.515322
Fine-tune [1099/100000]  val_loss=-0.443678
Fine-tune [1100/100000]  val_loss=-0.449350
Fine-tune [1101/100000]  val_loss=-0.424108
Fine-tune [1102/100000]  val_loss=-0.451395
Fine-tune [1103/100000]  val_loss=-0.402161
Fine-tune [1104/100000]  val_loss=-0.426078
Fine-tune [1105/100000]  val_loss=-0.454340
Fine-tune [1106/100000]  val_loss=-0.441257
Fine-tune [1107/100000]  val_loss=-0.448330
Fine-tune [1108/100000]  val_loss=-0.461223
Fine-tune [1109/100000]  val_loss=-0.399759
Fine-tune [1110/100000]  val_loss=-0.421501
Fine-tune [1111/100000]  val_loss=-0.371492
Fine-tune [1112/100000]  val_loss=-0.427386
Fine-tune [1113/100000]  val_loss=-0.438847
Fine-tune [1114/100000]  val_loss=-0.465911
Fine-tune [1115/100000]  val_loss=-0.485998
Fine-tune [1116/100000]  val_loss=-0.448615
Fine-tune [1117/100000]  val_loss=-0.433351
Fine-tune [1118/100000]  val_loss=-0.432359
Fine-tune [1119/100000]  val_loss=-0.476360
Fine-tune [1120/100000]  val_loss=-0.464270
Fine-tune [1121/100000]  val_loss=-0.481636
Fine-tune [1122/100000]  val_loss=-0.468600
Fine-tune [1123/100000]  val_loss=-0.455687
Fine-tune [1124/100000]  val_loss=-0.420489
Fine-tune [1125/100000]  val_loss=-0.429793
Fine-tune [1126/100000]  val_loss=-0.478530
Fine-tune [1127/100000]  val_loss=-0.463981
Fine-tune [1128/100000]  val_loss=-0.447328
Fine-tune [1129/100000]  val_loss=-0.414301
Fine-tune [1130/100000]  val_loss=-0.381834
Fine-tune [1131/100000]  val_loss=-0.415685
Fine-tune [1132/100000]  val_loss=-0.508086
Fine-tune [1133/100000]  val_loss=-0.493879
Fine-tune [1134/100000]  val_loss=-0.467294
Fine-tune [1135/100000]  val_loss=-0.496897
Fine-tune [1136/100000]  val_loss=-0.467550
Fine-tune [1137/100000]  val_loss=-0.445579
Fine-tune [1138/100000]  val_loss=-0.430242
Fine-tune [1139/100000]  val_loss=-0.444534
Fine-tune [1140/100000]  val_loss=-0.429305
Fine-tune [1141/100000]  val_loss=-0.452509
Fine-tune [1142/100000]  val_loss=-0.439711
Fine-tune [1143/100000]  val_loss=-0.458370
Fine-tune [1144/100000]  val_loss=-0.521101
Fine-tune [1145/100000]  val_loss=-0.513737
Fine-tune [1146/100000]  val_loss=-0.536484
Fine-tune [1147/100000]  val_loss=-0.515864
Fine-tune [1148/100000]  val_loss=-0.554048
Fine-tune [1149/100000]  val_loss=-0.500669
Fine-tune [1150/100000]  val_loss=-0.436840
Fine-tune [1151/100000]  val_loss=-0.453426
Fine-tune [1152/100000]  val_loss=-0.410845
Fine-tune [1153/100000]  val_loss=-0.424363
Fine-tune [1154/100000]  val_loss=-0.443022
Fine-tune [1155/100000]  val_loss=-0.468708
Fine-tune [1156/100000]  val_loss=-0.488921
Fine-tune [1157/100000]  val_loss=-0.481681
Fine-tune [1158/100000]  val_loss=-0.469911
Fine-tune [1159/100000]  val_loss=-0.365919
Fine-tune [1160/100000]  val_loss=-0.418967
Fine-tune [1161/100000]  val_loss=-0.415992
Fine-tune [1162/100000]  val_loss=-0.436196
Fine-tune [1163/100000]  val_loss=-0.439393
Fine-tune [1164/100000]  val_loss=-0.449898
Fine-tune [1165/100000]  val_loss=-0.393564
Fine-tune [1166/100000]  val_loss=-0.412548
Fine-tune [1167/100000]  val_loss=-0.441024
Fine-tune [1168/100000]  val_loss=-0.409647
Fine-tune [1169/100000]  val_loss=-0.412105
Fine-tune [1170/100000]  val_loss=-0.419311
Fine-tune [1171/100000]  val_loss=-0.443154
Fine-tune [1172/100000]  val_loss=-0.438957
Fine-tune [1173/100000]  val_loss=-0.454987
Fine-tune [1174/100000]  val_loss=-0.404857
Fine-tune [1175/100000]  val_loss=-0.489514
Fine-tune [1176/100000]  val_loss=-0.462975
Fine-tune [1177/100000]  val_loss=-0.434281
Fine-tune [1178/100000]  val_loss=-0.342818
Fine-tune [1179/100000]  val_loss=-0.445866
Fine-tune [1180/100000]  val_loss=-0.372727
Fine-tune [1181/100000]  val_loss=-0.377932
Fine-tune [1182/100000]  val_loss=-0.422458
Fine-tune [1183/100000]  val_loss=-0.451641
Fine-tune [1184/100000]  val_loss=-0.514676
Fine-tune [1185/100000]  val_loss=-0.489132
Fine-tune [1186/100000]  val_loss=-0.485552
Fine-tune [1187/100000]  val_loss=-0.432913
Fine-tune [1188/100000]  val_loss=-0.412796
Fine-tune [1189/100000]  val_loss=-0.371371
Fine-tune [1190/100000]  val_loss=-0.392513
Fine-tune [1191/100000]  val_loss=-0.446235
Fine-tune [1192/100000]  val_loss=-0.442299
Fine-tune [1193/100000]  val_loss=-0.442006
Fine-tune [1194/100000]  val_loss=-0.517508
Fine-tune [1195/100000]  val_loss=-0.492308
Fine-tune [1196/100000]  val_loss=-0.524989
Fine-tune [1197/100000]  val_loss=-0.484278
Fine-tune [1198/100000]  val_loss=-0.419659
Fine-tune [1199/100000]  val_loss=-0.470383
Fine-tune [1200/100000]  val_loss=-0.467947
Fine-tune [1201/100000]  val_loss=-0.471771
Fine-tune [1202/100000]  val_loss=-0.416714
Fine-tune [1203/100000]  val_loss=-0.429897
Fine-tune [1204/100000]  val_loss=-0.438365
Fine-tune [1205/100000]  val_loss=-0.384221
Fine-tune [1206/100000]  val_loss=-0.419440
Fine-tune [1207/100000]  val_loss=-0.466399
Fine-tune [1208/100000]  val_loss=-0.435512
Fine-tune [1209/100000]  val_loss=-0.489530
Fine-tune [1210/100000]  val_loss=-0.419338
Fine-tune [1211/100000]  val_loss=-0.457420
Fine-tune [1212/100000]  val_loss=-0.450883
Fine-tune [1213/100000]  val_loss=-0.433001
Fine-tune [1214/100000]  val_loss=-0.449094
Fine-tune [1215/100000]  val_loss=-0.444425
Fine-tune [1216/100000]  val_loss=-0.411416
Fine-tune [1217/100000]  val_loss=-0.368762
Fine-tune [1218/100000]  val_loss=-0.342784
Fine-tune [1219/100000]  val_loss=-0.348565
Fine-tune [1220/100000]  val_loss=-0.392454
  -> 验证未改进 1000 次，早停。
[FINETUNE] 最佳验证损失=-1.051564 已保存。

--- 评估 [HD256_L4] ---

=== 本次试验参数 (Run Config) ===
opamp             : two_stage_opamp
hidden_dim        : 256
num_layers        : 4
lr_pretrain       : 0.003
epochs_pretrain   : 1000
patience_pretrain : 200
lr_finetune       : 0.0038
epochs_finetune   : 100000
patience_finetune : 1000
batch_a           : 128
batch_b           : 64
dropout_rate      : 0.2
alpha_r2          : 0.0
lambda_coral      : 0.1
seed              : 42
device            : cpu

--- [评估阶段] 开始计算指标 ---

=== 目标域验证集指标（物理单位）===
slewrate_pos    MSE=1.17e+14  MAE=8.186e+06  R2=0.7272
dc_gain         MSE=2.682e+07  MAE=1505  R2=0.3114
ugf             MSE=8.956e+13  MAE=6.26e+06  R2=0.7976
phase_margin    MSE=159.9  MAE=9.013  R2=0.8607
cmrr            MSE=8.29e+11  MAE=8.877e+04  R2=0.0429

Avg  (all dims)   MSE=4.148e+13  MAE=2.907e+06  R2=0.5480
[OK] HD256_L4 -> r2_avg=0.5480, mae_avg=2.907e+06, mse_avg=4.148e+13
===== [HD256_L4] 训练完成 =====

===== [HD512_L2] 训练开始 =====

--- [阶段一] Backbone 预训练 (source_train / source_val, HuberLoss) ---
Pretrain [1/1000]  train=0.234664  val=0.195727
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [2/1000]  train=0.178793  val=0.166938
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [3/1000]  train=0.157413  val=0.151914
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [4/1000]  train=0.148109  val=0.139508
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [5/1000]  train=0.139425  val=0.127525
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [6/1000]  train=0.130084  val=0.124691
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [7/1000]  train=0.124748  val=0.121432
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [8/1000]  train=0.121076  val=0.121295
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [9/1000]  train=0.117100  val=0.116848
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [10/1000]  train=0.113428  val=0.115311
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [11/1000]  train=0.110896  val=0.110440
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [12/1000]  train=0.107542  val=0.111272
Pretrain [13/1000]  train=0.107959  val=0.112443
Pretrain [14/1000]  train=0.103620  val=0.107435
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [15/1000]  train=0.103156  val=0.109001
Pretrain [16/1000]  train=0.099866  val=0.104708
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [17/1000]  train=0.098671  val=0.103569
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [18/1000]  train=0.097726  val=0.100475
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [19/1000]  train=0.093860  val=0.102904
Pretrain [20/1000]  train=0.095165  val=0.101490
Pretrain [21/1000]  train=0.092237  val=0.101386
Pretrain [22/1000]  train=0.093216  val=0.096403
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [23/1000]  train=0.090202  val=0.099976
Pretrain [24/1000]  train=0.089642  val=0.099261
Pretrain [25/1000]  train=0.086336  val=0.099130
Pretrain [26/1000]  train=0.087925  val=0.099786
Pretrain [27/1000]  train=0.085855  val=0.096609
Pretrain [28/1000]  train=0.084793  val=0.099815
Pretrain [29/1000]  train=0.084110  val=0.100095
Pretrain [30/1000]  train=0.083035  val=0.099820
Pretrain [31/1000]  train=0.083789  val=0.096014
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [32/1000]  train=0.081498  val=0.096924
Pretrain [33/1000]  train=0.081592  val=0.095937
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [34/1000]  train=0.079565  val=0.098074
Pretrain [35/1000]  train=0.078648  val=0.098633
Pretrain [36/1000]  train=0.079092  val=0.097156
Pretrain [37/1000]  train=0.075864  val=0.093976
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [38/1000]  train=0.077810  val=0.100380
Pretrain [39/1000]  train=0.075236  val=0.094435
Pretrain [40/1000]  train=0.074985  val=0.097929
Pretrain [41/1000]  train=0.073614  val=0.094805
Pretrain [42/1000]  train=0.074006  val=0.098760
Pretrain [43/1000]  train=0.075190  val=0.098393
Pretrain [44/1000]  train=0.071154  val=0.095125
Pretrain [45/1000]  train=0.072541  val=0.093498
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [46/1000]  train=0.070482  val=0.094736
Pretrain [47/1000]  train=0.072250  val=0.096438
Pretrain [48/1000]  train=0.070040  val=0.098194
Pretrain [49/1000]  train=0.069433  val=0.098420
Pretrain [50/1000]  train=0.069726  val=0.092875
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [51/1000]  train=0.069320  val=0.094471
Pretrain [52/1000]  train=0.067317  val=0.097037
Pretrain [53/1000]  train=0.068243  val=0.097252
Pretrain [54/1000]  train=0.066839  val=0.097893
Pretrain [55/1000]  train=0.067983  val=0.094805
Pretrain [56/1000]  train=0.066954  val=0.096752
Pretrain [57/1000]  train=0.064110  val=0.097440
Pretrain [58/1000]  train=0.066061  val=0.094426
Pretrain [59/1000]  train=0.062002  val=0.094123
Pretrain [60/1000]  train=0.062845  val=0.096099
Pretrain [61/1000]  train=0.063143  val=0.100640
Pretrain [62/1000]  train=0.061421  val=0.095392
Pretrain [63/1000]  train=0.061417  val=0.094939
Pretrain [64/1000]  train=0.059773  val=0.096106
Pretrain [65/1000]  train=0.060398  val=0.094880
Pretrain [66/1000]  train=0.060395  val=0.094261
Pretrain [67/1000]  train=0.061035  val=0.090867
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/pretrained.pth
Pretrain [68/1000]  train=0.058932  val=0.095767
Pretrain [69/1000]  train=0.059982  val=0.094548
Pretrain [70/1000]  train=0.060166  val=0.095733
Pretrain [71/1000]  train=0.057895  val=0.094757
Pretrain [72/1000]  train=0.057052  val=0.097227
Pretrain [73/1000]  train=0.057145  val=0.097404
Pretrain [74/1000]  train=0.058092  val=0.094287
Pretrain [75/1000]  train=0.058242  val=0.095717
Pretrain [76/1000]  train=0.055387  val=0.096224
Pretrain [77/1000]  train=0.056169  val=0.096412
Pretrain [78/1000]  train=0.057209  val=0.095647
Pretrain [79/1000]  train=0.055467  val=0.097224
Pretrain [80/1000]  train=0.054001  val=0.094831
Pretrain [81/1000]  train=0.054312  val=0.097572
Pretrain [82/1000]  train=0.054850  val=0.097638
Pretrain [83/1000]  train=0.053689  val=0.095783
Pretrain [84/1000]  train=0.051999  val=0.094161
Pretrain [85/1000]  train=0.054061  val=0.095470
Pretrain [86/1000]  train=0.052865  val=0.096309
Pretrain [87/1000]  train=0.053381  val=0.093585
Pretrain [88/1000]  train=0.052552  val=0.094826
Pretrain [89/1000]  train=0.052496  val=0.095236
Pretrain [90/1000]  train=0.052999  val=0.094651
Pretrain [91/1000]  train=0.051691  val=0.095428
Pretrain [92/1000]  train=0.051452  val=0.097218
Pretrain [93/1000]  train=0.050289  val=0.095335
Pretrain [94/1000]  train=0.050097  val=0.094636
Pretrain [95/1000]  train=0.048149  val=0.096549
Pretrain [96/1000]  train=0.049009  val=0.095803
Pretrain [97/1000]  train=0.049952  val=0.094361
Pretrain [98/1000]  train=0.049257  val=0.094447
Pretrain [99/1000]  train=0.048376  val=0.095552
Pretrain [100/1000]  train=0.048611  val=0.094447
Pretrain [101/1000]  train=0.047336  val=0.093700
Pretrain [102/1000]  train=0.045447  val=0.097396
Pretrain [103/1000]  train=0.047346  val=0.097025
Pretrain [104/1000]  train=0.046890  val=0.095051
Pretrain [105/1000]  train=0.046487  val=0.096763
Pretrain [106/1000]  train=0.046635  val=0.094247
Pretrain [107/1000]  train=0.045192  val=0.095511
Pretrain [108/1000]  train=0.046425  val=0.093162
Pretrain [109/1000]  train=0.045192  val=0.091971
Pretrain [110/1000]  train=0.044342  val=0.093763
Pretrain [111/1000]  train=0.045757  val=0.095458
Pretrain [112/1000]  train=0.045115  val=0.094659
Pretrain [113/1000]  train=0.044071  val=0.094441
Pretrain [114/1000]  train=0.045031  val=0.094123
Pretrain [115/1000]  train=0.043111  val=0.093304
Pretrain [116/1000]  train=0.044289  val=0.093456
Pretrain [117/1000]  train=0.044184  val=0.094476
Pretrain [118/1000]  train=0.043654  val=0.095224
Pretrain [119/1000]  train=0.042100  val=0.093208
Pretrain [120/1000]  train=0.042106  val=0.095544
Pretrain [121/1000]  train=0.043377  val=0.096389
Pretrain [122/1000]  train=0.042089  val=0.096537
Pretrain [123/1000]  train=0.042554  val=0.096172
Pretrain [124/1000]  train=0.042728  val=0.095755
Pretrain [125/1000]  train=0.042298  val=0.094011
Pretrain [126/1000]  train=0.041032  val=0.095444
Pretrain [127/1000]  train=0.041075  val=0.095049
Pretrain [128/1000]  train=0.041223  val=0.094918
Pretrain [129/1000]  train=0.041359  val=0.094191
Pretrain [130/1000]  train=0.040487  val=0.094966
Pretrain [131/1000]  train=0.040831  val=0.094301
Pretrain [132/1000]  train=0.040296  val=0.092791
Pretrain [133/1000]  train=0.039474  val=0.093522
Pretrain [134/1000]  train=0.040106  val=0.094645
Pretrain [135/1000]  train=0.041223  val=0.094051
Pretrain [136/1000]  train=0.040634  val=0.094023
Pretrain [137/1000]  train=0.039898  val=0.094050
Pretrain [138/1000]  train=0.038966  val=0.094071
Pretrain [139/1000]  train=0.038739  val=0.093357
Pretrain [140/1000]  train=0.038514  val=0.094094
Pretrain [141/1000]  train=0.038729  val=0.094658
Pretrain [142/1000]  train=0.039114  val=0.093178
Pretrain [143/1000]  train=0.039014  val=0.092807
Pretrain [144/1000]  train=0.038448  val=0.095042
Pretrain [145/1000]  train=0.039596  val=0.093932
Pretrain [146/1000]  train=0.037523  val=0.095503
Pretrain [147/1000]  train=0.037514  val=0.093373
Pretrain [148/1000]  train=0.037763  val=0.094496
Pretrain [149/1000]  train=0.037537  val=0.094087
Pretrain [150/1000]  train=0.038161  val=0.093923
Pretrain [151/1000]  train=0.037267  val=0.093926
Pretrain [152/1000]  train=0.035533  val=0.094490
Pretrain [153/1000]  train=0.036788  val=0.094339
Pretrain [154/1000]  train=0.037069  val=0.093538
Pretrain [155/1000]  train=0.036623  val=0.093566
Pretrain [156/1000]  train=0.037765  val=0.094057
Pretrain [157/1000]  train=0.036873  val=0.094757
Pretrain [158/1000]  train=0.035678  val=0.094024
Pretrain [159/1000]  train=0.036151  val=0.092968
Pretrain [160/1000]  train=0.036291  val=0.094890
Pretrain [161/1000]  train=0.036503  val=0.093990
Pretrain [162/1000]  train=0.036598  val=0.093514
Pretrain [163/1000]  train=0.035554  val=0.092882
Pretrain [164/1000]  train=0.035491  val=0.093100
Pretrain [165/1000]  train=0.036633  val=0.093021
Pretrain [166/1000]  train=0.035417  val=0.093375
Pretrain [167/1000]  train=0.035983  val=0.093080
Pretrain [168/1000]  train=0.035385  val=0.092799
Pretrain [169/1000]  train=0.033854  val=0.092775
Pretrain [170/1000]  train=0.035346  val=0.093553
Pretrain [171/1000]  train=0.033688  val=0.093362
Pretrain [172/1000]  train=0.034964  val=0.092788
Pretrain [173/1000]  train=0.034584  val=0.093338
Pretrain [174/1000]  train=0.034377  val=0.093616
Pretrain [175/1000]  train=0.035254  val=0.093580
Pretrain [176/1000]  train=0.035308  val=0.092682
Pretrain [177/1000]  train=0.034037  val=0.093367
Pretrain [178/1000]  train=0.033920  val=0.093117
Pretrain [179/1000]  train=0.034612  val=0.093088
Pretrain [180/1000]  train=0.033437  val=0.092936
Pretrain [181/1000]  train=0.034461  val=0.093098
Pretrain [182/1000]  train=0.034654  val=0.093031
Pretrain [183/1000]  train=0.034447  val=0.092851
Pretrain [184/1000]  train=0.033374  val=0.093124
Pretrain [185/1000]  train=0.034184  val=0.093134
Pretrain [186/1000]  train=0.034254  val=0.093197
Pretrain [187/1000]  train=0.034538  val=0.093023
Pretrain [188/1000]  train=0.034992  val=0.093090
Pretrain [189/1000]  train=0.034797  val=0.093245
Pretrain [190/1000]  train=0.033628  val=0.093422
Pretrain [191/1000]  train=0.034357  val=0.093267
Pretrain [192/1000]  train=0.035197  val=0.093316
Pretrain [193/1000]  train=0.033646  val=0.093309
Pretrain [194/1000]  train=0.034317  val=0.093314
Pretrain [195/1000]  train=0.034228  val=0.093289
Pretrain [196/1000]  train=0.034915  val=0.093263
Pretrain [197/1000]  train=0.034310  val=0.093250
Pretrain [198/1000]  train=0.034818  val=0.093257
Pretrain [199/1000]  train=0.033671  val=0.093241
Pretrain [200/1000]  train=0.035675  val=0.093229
Pretrain [201/1000]  train=0.049852  val=0.105197
Pretrain [202/1000]  train=0.059764  val=0.101240
Pretrain [203/1000]  train=0.061085  val=0.102524
Pretrain [204/1000]  train=0.060270  val=0.102262
Pretrain [205/1000]  train=0.057031  val=0.104287
Pretrain [206/1000]  train=0.059424  val=0.103730
Pretrain [207/1000]  train=0.058247  val=0.103317
Pretrain [208/1000]  train=0.057043  val=0.100521
Pretrain [209/1000]  train=0.055573  val=0.100493
Pretrain [210/1000]  train=0.056335  val=0.103701
Pretrain [211/1000]  train=0.056385  val=0.101011
Pretrain [212/1000]  train=0.053677  val=0.097716
Pretrain [213/1000]  train=0.056422  val=0.101445
Pretrain [214/1000]  train=0.056041  val=0.104616
Pretrain [215/1000]  train=0.056370  val=0.101303
Pretrain [216/1000]  train=0.055202  val=0.097574
Pretrain [217/1000]  train=0.054698  val=0.101224
Pretrain [218/1000]  train=0.054230  val=0.099780
Pretrain [219/1000]  train=0.053964  val=0.099840
Pretrain [220/1000]  train=0.050081  val=0.098689
Pretrain [221/1000]  train=0.052962  val=0.100351
Pretrain [222/1000]  train=0.052210  val=0.100094
Pretrain [223/1000]  train=0.050901  val=0.098395
Pretrain [224/1000]  train=0.050722  val=0.099119
Pretrain [225/1000]  train=0.051672  val=0.097003
Pretrain [226/1000]  train=0.053714  val=0.097734
Pretrain [227/1000]  train=0.050677  val=0.098384
Pretrain [228/1000]  train=0.052408  val=0.100979
Pretrain [229/1000]  train=0.050426  val=0.098795
Pretrain [230/1000]  train=0.047432  val=0.099273
Pretrain [231/1000]  train=0.048631  val=0.098285
Pretrain [232/1000]  train=0.049689  val=0.098354
Pretrain [233/1000]  train=0.050504  val=0.098073
Pretrain [234/1000]  train=0.050483  val=0.102965
Pretrain [235/1000]  train=0.050423  val=0.099848
Pretrain [236/1000]  train=0.049622  val=0.097968
Pretrain [237/1000]  train=0.051000  val=0.101217
Pretrain [238/1000]  train=0.048599  val=0.097041
Pretrain [239/1000]  train=0.047311  val=0.096486
Pretrain [240/1000]  train=0.049786  val=0.097515
Pretrain [241/1000]  train=0.047257  val=0.098877
Pretrain [242/1000]  train=0.047373  val=0.099569
Pretrain [243/1000]  train=0.047133  val=0.098117
Pretrain [244/1000]  train=0.045920  val=0.098784
Pretrain [245/1000]  train=0.047949  val=0.095683
Pretrain [246/1000]  train=0.046806  val=0.100722
Pretrain [247/1000]  train=0.046566  val=0.099584
Pretrain [248/1000]  train=0.046561  val=0.096486
Pretrain [249/1000]  train=0.044901  val=0.096693
Pretrain [250/1000]  train=0.046740  val=0.099550
Pretrain [251/1000]  train=0.045075  val=0.099311
Pretrain [252/1000]  train=0.046832  val=0.098533
Pretrain [253/1000]  train=0.046792  val=0.098323
Pretrain [254/1000]  train=0.047860  val=0.098446
Pretrain [255/1000]  train=0.046655  val=0.099468
Pretrain [256/1000]  train=0.046141  val=0.100293
Pretrain [257/1000]  train=0.044825  val=0.098582
Pretrain [258/1000]  train=0.044966  val=0.099184
Pretrain [259/1000]  train=0.044641  val=0.100961
Pretrain [260/1000]  train=0.043982  val=0.099986
Pretrain [261/1000]  train=0.044240  val=0.096941
Pretrain [262/1000]  train=0.043422  val=0.098715
Pretrain [263/1000]  train=0.044414  val=0.096075
Pretrain [264/1000]  train=0.044195  val=0.096312
Pretrain [265/1000]  train=0.041686  val=0.095190
Pretrain [266/1000]  train=0.044571  val=0.098975
Pretrain [267/1000]  train=0.043674  val=0.097592
  -> 验证未改进 200 次，早停。
[PRETRAIN] 最佳 val=0.090867 已保存。

--- [阶段二] 对齐微调 (NLL + α·(1−R2) + λ·CORAL) ---
Fine-tune [1/100000]  val_loss=0.304974
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [2/100000]  val_loss=0.186440
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [3/100000]  val_loss=0.077807
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [4/100000]  val_loss=-0.027004
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [5/100000]  val_loss=-0.116086
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [6/100000]  val_loss=-0.199720
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [7/100000]  val_loss=-0.261227
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [8/100000]  val_loss=-0.326379
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [9/100000]  val_loss=-0.375539
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [10/100000]  val_loss=-0.423538
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [11/100000]  val_loss=-0.458062
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [12/100000]  val_loss=-0.507910
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [13/100000]  val_loss=-0.530940
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [14/100000]  val_loss=-0.559185
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [15/100000]  val_loss=-0.586883
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [16/100000]  val_loss=-0.606735
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [17/100000]  val_loss=-0.624461
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [18/100000]  val_loss=-0.634633
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [19/100000]  val_loss=-0.649241
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [20/100000]  val_loss=-0.659955
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [21/100000]  val_loss=-0.673637
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [22/100000]  val_loss=-0.692839
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [23/100000]  val_loss=-0.690703
Fine-tune [24/100000]  val_loss=-0.707534
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [25/100000]  val_loss=-0.714425
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [26/100000]  val_loss=-0.729964
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [27/100000]  val_loss=-0.715344
Fine-tune [28/100000]  val_loss=-0.736745
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [29/100000]  val_loss=-0.743453
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [30/100000]  val_loss=-0.745111
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [31/100000]  val_loss=-0.759218
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [32/100000]  val_loss=-0.751402
Fine-tune [33/100000]  val_loss=-0.748852
Fine-tune [34/100000]  val_loss=-0.767409
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [35/100000]  val_loss=-0.778854
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [36/100000]  val_loss=-0.785165
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [37/100000]  val_loss=-0.781355
Fine-tune [38/100000]  val_loss=-0.795776
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [39/100000]  val_loss=-0.787580
Fine-tune [40/100000]  val_loss=-0.804649
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [41/100000]  val_loss=-0.817304
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [42/100000]  val_loss=-0.817600
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [43/100000]  val_loss=-0.820767
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [44/100000]  val_loss=-0.813950
Fine-tune [45/100000]  val_loss=-0.825245
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [46/100000]  val_loss=-0.839970
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [47/100000]  val_loss=-0.830523
Fine-tune [48/100000]  val_loss=-0.834351
Fine-tune [49/100000]  val_loss=-0.845558
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [50/100000]  val_loss=-0.838236
Fine-tune [51/100000]  val_loss=-0.834435
Fine-tune [52/100000]  val_loss=-0.846818
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [53/100000]  val_loss=-0.851091
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [54/100000]  val_loss=-0.853347
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [55/100000]  val_loss=-0.865017
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [56/100000]  val_loss=-0.853401
Fine-tune [57/100000]  val_loss=-0.858157
Fine-tune [58/100000]  val_loss=-0.875984
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [59/100000]  val_loss=-0.882230
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [60/100000]  val_loss=-0.871474
Fine-tune [61/100000]  val_loss=-0.867453
Fine-tune [62/100000]  val_loss=-0.869619
Fine-tune [63/100000]  val_loss=-0.871719
Fine-tune [64/100000]  val_loss=-0.851748
Fine-tune [65/100000]  val_loss=-0.854670
Fine-tune [66/100000]  val_loss=-0.876494
Fine-tune [67/100000]  val_loss=-0.879156
Fine-tune [68/100000]  val_loss=-0.890708
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [69/100000]  val_loss=-0.881702
Fine-tune [70/100000]  val_loss=-0.882187
Fine-tune [71/100000]  val_loss=-0.897699
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [72/100000]  val_loss=-0.900355
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [73/100000]  val_loss=-0.893742
Fine-tune [74/100000]  val_loss=-0.879405
Fine-tune [75/100000]  val_loss=-0.902367
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [76/100000]  val_loss=-0.913778
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [77/100000]  val_loss=-0.895147
Fine-tune [78/100000]  val_loss=-0.901570
Fine-tune [79/100000]  val_loss=-0.910799
Fine-tune [80/100000]  val_loss=-0.912953
Fine-tune [81/100000]  val_loss=-0.920120
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [82/100000]  val_loss=-0.908234
Fine-tune [83/100000]  val_loss=-0.913038
Fine-tune [84/100000]  val_loss=-0.914587
Fine-tune [85/100000]  val_loss=-0.916760
Fine-tune [86/100000]  val_loss=-0.906246
Fine-tune [87/100000]  val_loss=-0.913890
Fine-tune [88/100000]  val_loss=-0.909040
Fine-tune [89/100000]  val_loss=-0.924177
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [90/100000]  val_loss=-0.927235
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [91/100000]  val_loss=-0.929853
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [92/100000]  val_loss=-0.918372
Fine-tune [93/100000]  val_loss=-0.904282
Fine-tune [94/100000]  val_loss=-0.921514
Fine-tune [95/100000]  val_loss=-0.927954
Fine-tune [96/100000]  val_loss=-0.920639
Fine-tune [97/100000]  val_loss=-0.922016
Fine-tune [98/100000]  val_loss=-0.936009
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [99/100000]  val_loss=-0.928527
Fine-tune [100/100000]  val_loss=-0.924635
Fine-tune [101/100000]  val_loss=-0.928595
Fine-tune [102/100000]  val_loss=-0.925609
Fine-tune [103/100000]  val_loss=-0.922683
Fine-tune [104/100000]  val_loss=-0.938864
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [105/100000]  val_loss=-0.936665
Fine-tune [106/100000]  val_loss=-0.934865
Fine-tune [107/100000]  val_loss=-0.927488
Fine-tune [108/100000]  val_loss=-0.950681
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [109/100000]  val_loss=-0.926210
Fine-tune [110/100000]  val_loss=-0.923096
Fine-tune [111/100000]  val_loss=-0.932781
Fine-tune [112/100000]  val_loss=-0.934790
Fine-tune [113/100000]  val_loss=-0.932441
Fine-tune [114/100000]  val_loss=-0.948479
Fine-tune [115/100000]  val_loss=-0.954737
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [116/100000]  val_loss=-0.965390
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L2/finetuned.pth
Fine-tune [117/100000]  val_loss=-0.946992
Fine-tune [118/100000]  val_loss=-0.941817
Fine-tune [119/100000]  val_loss=-0.944498
Fine-tune [120/100000]  val_loss=-0.936328
Fine-tune [121/100000]  val_loss=-0.920347
Fine-tune [122/100000]  val_loss=-0.934946
Fine-tune [123/100000]  val_loss=-0.925175
Fine-tune [124/100000]  val_loss=-0.927599
Fine-tune [125/100000]  val_loss=-0.917032
Fine-tune [126/100000]  val_loss=-0.925562
Fine-tune [127/100000]  val_loss=-0.926724
Fine-tune [128/100000]  val_loss=-0.910885
Fine-tune [129/100000]  val_loss=-0.915945
Fine-tune [130/100000]  val_loss=-0.937916
Fine-tune [131/100000]  val_loss=-0.943670
Fine-tune [132/100000]  val_loss=-0.950761
Fine-tune [133/100000]  val_loss=-0.929483
Fine-tune [134/100000]  val_loss=-0.945409
Fine-tune [135/100000]  val_loss=-0.943803
Fine-tune [136/100000]  val_loss=-0.953102
Fine-tune [137/100000]  val_loss=-0.926943
Fine-tune [138/100000]  val_loss=-0.937759
Fine-tune [139/100000]  val_loss=-0.913044
Fine-tune [140/100000]  val_loss=-0.944058
Fine-tune [141/100000]  val_loss=-0.918373
Fine-tune [142/100000]  val_loss=-0.928306
Fine-tune [143/100000]  val_loss=-0.946974
Fine-tune [144/100000]  val_loss=-0.927299
Fine-tune [145/100000]  val_loss=-0.935358
Fine-tune [146/100000]  val_loss=-0.937379
Fine-tune [147/100000]  val_loss=-0.922098
Fine-tune [148/100000]  val_loss=-0.928360
Fine-tune [149/100000]  val_loss=-0.920999
Fine-tune [150/100000]  val_loss=-0.942063
Fine-tune [151/100000]  val_loss=-0.940195
Fine-tune [152/100000]  val_loss=-0.933853
Fine-tune [153/100000]  val_loss=-0.937004
Fine-tune [154/100000]  val_loss=-0.933742
Fine-tune [155/100000]  val_loss=-0.935037
Fine-tune [156/100000]  val_loss=-0.951457
Fine-tune [157/100000]  val_loss=-0.927643
Fine-tune [158/100000]  val_loss=-0.942426
Fine-tune [159/100000]  val_loss=-0.954806
Fine-tune [160/100000]  val_loss=-0.940551
Fine-tune [161/100000]  val_loss=-0.925537
Fine-tune [162/100000]  val_loss=-0.945060
Fine-tune [163/100000]  val_loss=-0.943295
Fine-tune [164/100000]  val_loss=-0.942221
Fine-tune [165/100000]  val_loss=-0.946653
Fine-tune [166/100000]  val_loss=-0.950005
Fine-tune [167/100000]  val_loss=-0.938010
Fine-tune [168/100000]  val_loss=-0.942911
Fine-tune [169/100000]  val_loss=-0.929700
Fine-tune [170/100000]  val_loss=-0.939281
Fine-tune [171/100000]  val_loss=-0.937927
Fine-tune [172/100000]  val_loss=-0.922842
Fine-tune [173/100000]  val_loss=-0.930055
Fine-tune [174/100000]  val_loss=-0.915138
Fine-tune [175/100000]  val_loss=-0.927836
Fine-tune [176/100000]  val_loss=-0.910929
Fine-tune [177/100000]  val_loss=-0.932736
Fine-tune [178/100000]  val_loss=-0.920967
Fine-tune [179/100000]  val_loss=-0.872729
Fine-tune [180/100000]  val_loss=-0.908752
Fine-tune [181/100000]  val_loss=-0.903974
Fine-tune [182/100000]  val_loss=-0.940262
Fine-tune [183/100000]  val_loss=-0.939958
Fine-tune [184/100000]  val_loss=-0.954792
Fine-tune [185/100000]  val_loss=-0.937545
Fine-tune [186/100000]  val_loss=-0.917349
Fine-tune [187/100000]  val_loss=-0.932603
Fine-tune [188/100000]  val_loss=-0.916947
Fine-tune [189/100000]  val_loss=-0.928016
Fine-tune [190/100000]  val_loss=-0.913017
Fine-tune [191/100000]  val_loss=-0.917927
Fine-tune [192/100000]  val_loss=-0.901966
Fine-tune [193/100000]  val_loss=-0.894850
Fine-tune [194/100000]  val_loss=-0.914082
Fine-tune [195/100000]  val_loss=-0.920866
Fine-tune [196/100000]  val_loss=-0.929336
Fine-tune [197/100000]  val_loss=-0.926046
Fine-tune [198/100000]  val_loss=-0.891304
Fine-tune [199/100000]  val_loss=-0.917079
Fine-tune [200/100000]  val_loss=-0.932369
Fine-tune [201/100000]  val_loss=-0.919704
Fine-tune [202/100000]  val_loss=-0.908983
Fine-tune [203/100000]  val_loss=-0.904084
Fine-tune [204/100000]  val_loss=-0.905846
Fine-tune [205/100000]  val_loss=-0.902116
Fine-tune [206/100000]  val_loss=-0.904056
Fine-tune [207/100000]  val_loss=-0.911385
Fine-tune [208/100000]  val_loss=-0.902758
Fine-tune [209/100000]  val_loss=-0.882027
Fine-tune [210/100000]  val_loss=-0.895234
Fine-tune [211/100000]  val_loss=-0.911894
Fine-tune [212/100000]  val_loss=-0.887584
Fine-tune [213/100000]  val_loss=-0.883646
Fine-tune [214/100000]  val_loss=-0.867264
Fine-tune [215/100000]  val_loss=-0.875680
Fine-tune [216/100000]  val_loss=-0.893971
Fine-tune [217/100000]  val_loss=-0.885194
Fine-tune [218/100000]  val_loss=-0.900613
Fine-tune [219/100000]  val_loss=-0.904386
Fine-tune [220/100000]  val_loss=-0.908452
Fine-tune [221/100000]  val_loss=-0.920634
Fine-tune [222/100000]  val_loss=-0.913277
Fine-tune [223/100000]  val_loss=-0.899025
Fine-tune [224/100000]  val_loss=-0.898110
Fine-tune [225/100000]  val_loss=-0.893585
Fine-tune [226/100000]  val_loss=-0.903133
Fine-tune [227/100000]  val_loss=-0.916991
Fine-tune [228/100000]  val_loss=-0.920025
Fine-tune [229/100000]  val_loss=-0.929213
Fine-tune [230/100000]  val_loss=-0.909072
Fine-tune [231/100000]  val_loss=-0.870863
Fine-tune [232/100000]  val_loss=-0.887753
Fine-tune [233/100000]  val_loss=-0.916944
Fine-tune [234/100000]  val_loss=-0.888091
Fine-tune [235/100000]  val_loss=-0.918393
Fine-tune [236/100000]  val_loss=-0.902245
Fine-tune [237/100000]  val_loss=-0.921903
Fine-tune [238/100000]  val_loss=-0.908660
Fine-tune [239/100000]  val_loss=-0.920535
Fine-tune [240/100000]  val_loss=-0.895872
Fine-tune [241/100000]  val_loss=-0.915497
Fine-tune [242/100000]  val_loss=-0.899329
Fine-tune [243/100000]  val_loss=-0.921532
Fine-tune [244/100000]  val_loss=-0.913869
Fine-tune [245/100000]  val_loss=-0.910822
Fine-tune [246/100000]  val_loss=-0.896223
Fine-tune [247/100000]  val_loss=-0.921413
Fine-tune [248/100000]  val_loss=-0.891106
Fine-tune [249/100000]  val_loss=-0.870596
Fine-tune [250/100000]  val_loss=-0.900810
Fine-tune [251/100000]  val_loss=-0.861798
Fine-tune [252/100000]  val_loss=-0.906014
Fine-tune [253/100000]  val_loss=-0.904478
Fine-tune [254/100000]  val_loss=-0.880597
Fine-tune [255/100000]  val_loss=-0.911657
Fine-tune [256/100000]  val_loss=-0.893090
Fine-tune [257/100000]  val_loss=-0.891570
Fine-tune [258/100000]  val_loss=-0.921773
Fine-tune [259/100000]  val_loss=-0.889782
Fine-tune [260/100000]  val_loss=-0.915174
Fine-tune [261/100000]  val_loss=-0.890106
Fine-tune [262/100000]  val_loss=-0.902444
Fine-tune [263/100000]  val_loss=-0.911939
Fine-tune [264/100000]  val_loss=-0.904180
Fine-tune [265/100000]  val_loss=-0.861394
Fine-tune [266/100000]  val_loss=-0.886460
Fine-tune [267/100000]  val_loss=-0.904395
Fine-tune [268/100000]  val_loss=-0.895294
Fine-tune [269/100000]  val_loss=-0.885324
Fine-tune [270/100000]  val_loss=-0.872684
Fine-tune [271/100000]  val_loss=-0.852826
Fine-tune [272/100000]  val_loss=-0.893304
Fine-tune [273/100000]  val_loss=-0.865426
Fine-tune [274/100000]  val_loss=-0.872240
Fine-tune [275/100000]  val_loss=-0.867874
Fine-tune [276/100000]  val_loss=-0.865631
Fine-tune [277/100000]  val_loss=-0.855865
Fine-tune [278/100000]  val_loss=-0.878244
Fine-tune [279/100000]  val_loss=-0.853768
Fine-tune [280/100000]  val_loss=-0.860919
Fine-tune [281/100000]  val_loss=-0.887812
Fine-tune [282/100000]  val_loss=-0.891754
Fine-tune [283/100000]  val_loss=-0.844220
Fine-tune [284/100000]  val_loss=-0.863139
Fine-tune [285/100000]  val_loss=-0.874792
Fine-tune [286/100000]  val_loss=-0.893054
Fine-tune [287/100000]  val_loss=-0.855602
Fine-tune [288/100000]  val_loss=-0.881434
Fine-tune [289/100000]  val_loss=-0.868278
Fine-tune [290/100000]  val_loss=-0.840361
Fine-tune [291/100000]  val_loss=-0.867291
Fine-tune [292/100000]  val_loss=-0.865504
Fine-tune [293/100000]  val_loss=-0.861224
Fine-tune [294/100000]  val_loss=-0.883351
Fine-tune [295/100000]  val_loss=-0.874952
Fine-tune [296/100000]  val_loss=-0.872637
Fine-tune [297/100000]  val_loss=-0.861581
Fine-tune [298/100000]  val_loss=-0.861369
Fine-tune [299/100000]  val_loss=-0.875951
Fine-tune [300/100000]  val_loss=-0.873528
Fine-tune [301/100000]  val_loss=-0.871354
Fine-tune [302/100000]  val_loss=-0.865507
Fine-tune [303/100000]  val_loss=-0.867852
Fine-tune [304/100000]  val_loss=-0.869405
Fine-tune [305/100000]  val_loss=-0.873293
Fine-tune [306/100000]  val_loss=-0.815354
Fine-tune [307/100000]  val_loss=-0.824788
Fine-tune [308/100000]  val_loss=-0.880311
Fine-tune [309/100000]  val_loss=-0.869798
Fine-tune [310/100000]  val_loss=-0.850663
Fine-tune [311/100000]  val_loss=-0.840422
Fine-tune [312/100000]  val_loss=-0.841951
Fine-tune [313/100000]  val_loss=-0.845423
Fine-tune [314/100000]  val_loss=-0.806917
Fine-tune [315/100000]  val_loss=-0.831952
Fine-tune [316/100000]  val_loss=-0.851908
Fine-tune [317/100000]  val_loss=-0.855994
Fine-tune [318/100000]  val_loss=-0.849318
Fine-tune [319/100000]  val_loss=-0.839843
Fine-tune [320/100000]  val_loss=-0.835870
Fine-tune [321/100000]  val_loss=-0.830488
Fine-tune [322/100000]  val_loss=-0.818700
Fine-tune [323/100000]  val_loss=-0.849449
Fine-tune [324/100000]  val_loss=-0.832736
Fine-tune [325/100000]  val_loss=-0.820422
Fine-tune [326/100000]  val_loss=-0.790359
Fine-tune [327/100000]  val_loss=-0.827020
Fine-tune [328/100000]  val_loss=-0.842829
Fine-tune [329/100000]  val_loss=-0.827449
Fine-tune [330/100000]  val_loss=-0.832235
Fine-tune [331/100000]  val_loss=-0.846605
Fine-tune [332/100000]  val_loss=-0.825463
Fine-tune [333/100000]  val_loss=-0.871078
Fine-tune [334/100000]  val_loss=-0.841717
Fine-tune [335/100000]  val_loss=-0.854129
Fine-tune [336/100000]  val_loss=-0.842678
Fine-tune [337/100000]  val_loss=-0.811880
Fine-tune [338/100000]  val_loss=-0.813402
Fine-tune [339/100000]  val_loss=-0.817625
Fine-tune [340/100000]  val_loss=-0.792870
Fine-tune [341/100000]  val_loss=-0.810275
Fine-tune [342/100000]  val_loss=-0.827767
Fine-tune [343/100000]  val_loss=-0.847498
Fine-tune [344/100000]  val_loss=-0.823911
Fine-tune [345/100000]  val_loss=-0.842418
Fine-tune [346/100000]  val_loss=-0.833641
Fine-tune [347/100000]  val_loss=-0.846648
Fine-tune [348/100000]  val_loss=-0.823294
Fine-tune [349/100000]  val_loss=-0.845085
Fine-tune [350/100000]  val_loss=-0.820639
Fine-tune [351/100000]  val_loss=-0.827994
Fine-tune [352/100000]  val_loss=-0.795822
Fine-tune [353/100000]  val_loss=-0.820979
Fine-tune [354/100000]  val_loss=-0.829437
Fine-tune [355/100000]  val_loss=-0.817886
Fine-tune [356/100000]  val_loss=-0.775710
Fine-tune [357/100000]  val_loss=-0.843002
Fine-tune [358/100000]  val_loss=-0.809012
Fine-tune [359/100000]  val_loss=-0.828754
Fine-tune [360/100000]  val_loss=-0.829218
Fine-tune [361/100000]  val_loss=-0.838939
Fine-tune [362/100000]  val_loss=-0.758369
Fine-tune [363/100000]  val_loss=-0.790198
Fine-tune [364/100000]  val_loss=-0.805286
Fine-tune [365/100000]  val_loss=-0.826783
Fine-tune [366/100000]  val_loss=-0.808089
Fine-tune [367/100000]  val_loss=-0.810286
Fine-tune [368/100000]  val_loss=-0.793344
Fine-tune [369/100000]  val_loss=-0.773553
Fine-tune [370/100000]  val_loss=-0.813628
Fine-tune [371/100000]  val_loss=-0.824102
Fine-tune [372/100000]  val_loss=-0.790415
Fine-tune [373/100000]  val_loss=-0.795756
Fine-tune [374/100000]  val_loss=-0.803291
Fine-tune [375/100000]  val_loss=-0.784343
Fine-tune [376/100000]  val_loss=-0.767680
Fine-tune [377/100000]  val_loss=-0.784954
Fine-tune [378/100000]  val_loss=-0.759356
Fine-tune [379/100000]  val_loss=-0.799528
Fine-tune [380/100000]  val_loss=-0.772699
Fine-tune [381/100000]  val_loss=-0.780020
Fine-tune [382/100000]  val_loss=-0.731643
Fine-tune [383/100000]  val_loss=-0.746224
Fine-tune [384/100000]  val_loss=-0.775545
Fine-tune [385/100000]  val_loss=-0.763479
Fine-tune [386/100000]  val_loss=-0.795349
Fine-tune [387/100000]  val_loss=-0.787929
Fine-tune [388/100000]  val_loss=-0.770090
Fine-tune [389/100000]  val_loss=-0.742942
Fine-tune [390/100000]  val_loss=-0.770772
Fine-tune [391/100000]  val_loss=-0.785331
Fine-tune [392/100000]  val_loss=-0.780226
Fine-tune [393/100000]  val_loss=-0.796260
Fine-tune [394/100000]  val_loss=-0.774724
Fine-tune [395/100000]  val_loss=-0.816209
Fine-tune [396/100000]  val_loss=-0.774319
Fine-tune [397/100000]  val_loss=-0.786687
Fine-tune [398/100000]  val_loss=-0.750384
Fine-tune [399/100000]  val_loss=-0.744055
Fine-tune [400/100000]  val_loss=-0.755663
Fine-tune [401/100000]  val_loss=-0.790334
Fine-tune [402/100000]  val_loss=-0.803006
Fine-tune [403/100000]  val_loss=-0.753429
Fine-tune [404/100000]  val_loss=-0.775561
Fine-tune [405/100000]  val_loss=-0.774279
Fine-tune [406/100000]  val_loss=-0.759228
Fine-tune [407/100000]  val_loss=-0.773912
Fine-tune [408/100000]  val_loss=-0.758479
Fine-tune [409/100000]  val_loss=-0.712378
Fine-tune [410/100000]  val_loss=-0.745280
Fine-tune [411/100000]  val_loss=-0.742295
Fine-tune [412/100000]  val_loss=-0.744152
Fine-tune [413/100000]  val_loss=-0.776307
Fine-tune [414/100000]  val_loss=-0.768976
Fine-tune [415/100000]  val_loss=-0.749863
Fine-tune [416/100000]  val_loss=-0.728372
Fine-tune [417/100000]  val_loss=-0.757898
Fine-tune [418/100000]  val_loss=-0.770447
Fine-tune [419/100000]  val_loss=-0.769591
Fine-tune [420/100000]  val_loss=-0.771311
Fine-tune [421/100000]  val_loss=-0.777125
Fine-tune [422/100000]  val_loss=-0.771039
Fine-tune [423/100000]  val_loss=-0.752186
Fine-tune [424/100000]  val_loss=-0.733880
Fine-tune [425/100000]  val_loss=-0.791848
Fine-tune [426/100000]  val_loss=-0.806271
Fine-tune [427/100000]  val_loss=-0.774285
Fine-tune [428/100000]  val_loss=-0.765763
Fine-tune [429/100000]  val_loss=-0.772699
Fine-tune [430/100000]  val_loss=-0.744966
Fine-tune [431/100000]  val_loss=-0.762804
Fine-tune [432/100000]  val_loss=-0.759465
Fine-tune [433/100000]  val_loss=-0.746642
Fine-tune [434/100000]  val_loss=-0.721215
Fine-tune [435/100000]  val_loss=-0.721189
Fine-tune [436/100000]  val_loss=-0.723651
Fine-tune [437/100000]  val_loss=-0.759464
Fine-tune [438/100000]  val_loss=-0.764352
Fine-tune [439/100000]  val_loss=-0.739226
Fine-tune [440/100000]  val_loss=-0.734789
Fine-tune [441/100000]  val_loss=-0.729702
Fine-tune [442/100000]  val_loss=-0.751400
Fine-tune [443/100000]  val_loss=-0.729912
Fine-tune [444/100000]  val_loss=-0.708079
Fine-tune [445/100000]  val_loss=-0.714999
Fine-tune [446/100000]  val_loss=-0.705872
Fine-tune [447/100000]  val_loss=-0.728844
Fine-tune [448/100000]  val_loss=-0.739949
Fine-tune [449/100000]  val_loss=-0.754478
Fine-tune [450/100000]  val_loss=-0.766480
Fine-tune [451/100000]  val_loss=-0.729507
Fine-tune [452/100000]  val_loss=-0.745446
Fine-tune [453/100000]  val_loss=-0.741889
Fine-tune [454/100000]  val_loss=-0.749724
Fine-tune [455/100000]  val_loss=-0.737772
Fine-tune [456/100000]  val_loss=-0.720203
Fine-tune [457/100000]  val_loss=-0.746256
Fine-tune [458/100000]  val_loss=-0.715917
Fine-tune [459/100000]  val_loss=-0.709447
Fine-tune [460/100000]  val_loss=-0.702872
Fine-tune [461/100000]  val_loss=-0.689112
Fine-tune [462/100000]  val_loss=-0.736326
Fine-tune [463/100000]  val_loss=-0.698377
Fine-tune [464/100000]  val_loss=-0.728561
Fine-tune [465/100000]  val_loss=-0.715322
Fine-tune [466/100000]  val_loss=-0.727185
Fine-tune [467/100000]  val_loss=-0.727961
Fine-tune [468/100000]  val_loss=-0.724253
Fine-tune [469/100000]  val_loss=-0.754931
Fine-tune [470/100000]  val_loss=-0.747155
Fine-tune [471/100000]  val_loss=-0.756049
Fine-tune [472/100000]  val_loss=-0.730952
Fine-tune [473/100000]  val_loss=-0.731938
Fine-tune [474/100000]  val_loss=-0.707455
Fine-tune [475/100000]  val_loss=-0.692649
Fine-tune [476/100000]  val_loss=-0.723999
Fine-tune [477/100000]  val_loss=-0.684186
Fine-tune [478/100000]  val_loss=-0.682832
Fine-tune [479/100000]  val_loss=-0.685446
Fine-tune [480/100000]  val_loss=-0.656137
Fine-tune [481/100000]  val_loss=-0.695965
Fine-tune [482/100000]  val_loss=-0.709466
Fine-tune [483/100000]  val_loss=-0.722060
Fine-tune [484/100000]  val_loss=-0.726580
Fine-tune [485/100000]  val_loss=-0.682257
Fine-tune [486/100000]  val_loss=-0.681223
Fine-tune [487/100000]  val_loss=-0.707466
Fine-tune [488/100000]  val_loss=-0.742577
Fine-tune [489/100000]  val_loss=-0.733954
Fine-tune [490/100000]  val_loss=-0.680676
Fine-tune [491/100000]  val_loss=-0.633799
Fine-tune [492/100000]  val_loss=-0.705313
Fine-tune [493/100000]  val_loss=-0.697972
Fine-tune [494/100000]  val_loss=-0.689736
Fine-tune [495/100000]  val_loss=-0.693928
Fine-tune [496/100000]  val_loss=-0.690734
Fine-tune [497/100000]  val_loss=-0.660635
Fine-tune [498/100000]  val_loss=-0.679743
Fine-tune [499/100000]  val_loss=-0.688784
Fine-tune [500/100000]  val_loss=-0.712753
Fine-tune [501/100000]  val_loss=-0.641920
Fine-tune [502/100000]  val_loss=-0.651082
Fine-tune [503/100000]  val_loss=-0.690618
Fine-tune [504/100000]  val_loss=-0.728655
Fine-tune [505/100000]  val_loss=-0.713299
Fine-tune [506/100000]  val_loss=-0.666462
Fine-tune [507/100000]  val_loss=-0.691212
Fine-tune [508/100000]  val_loss=-0.659953
Fine-tune [509/100000]  val_loss=-0.671516
Fine-tune [510/100000]  val_loss=-0.642506
Fine-tune [511/100000]  val_loss=-0.656799
Fine-tune [512/100000]  val_loss=-0.655963
Fine-tune [513/100000]  val_loss=-0.681223
Fine-tune [514/100000]  val_loss=-0.663406
Fine-tune [515/100000]  val_loss=-0.636080
Fine-tune [516/100000]  val_loss=-0.636268
Fine-tune [517/100000]  val_loss=-0.623566
Fine-tune [518/100000]  val_loss=-0.738719
Fine-tune [519/100000]  val_loss=-0.725072
Fine-tune [520/100000]  val_loss=-0.707499
Fine-tune [521/100000]  val_loss=-0.669685
Fine-tune [522/100000]  val_loss=-0.640911
Fine-tune [523/100000]  val_loss=-0.661924
Fine-tune [524/100000]  val_loss=-0.680213
Fine-tune [525/100000]  val_loss=-0.682764
Fine-tune [526/100000]  val_loss=-0.689752
Fine-tune [527/100000]  val_loss=-0.672475
Fine-tune [528/100000]  val_loss=-0.653816
Fine-tune [529/100000]  val_loss=-0.610994
Fine-tune [530/100000]  val_loss=-0.684995
Fine-tune [531/100000]  val_loss=-0.678935
Fine-tune [532/100000]  val_loss=-0.667964
Fine-tune [533/100000]  val_loss=-0.641033
Fine-tune [534/100000]  val_loss=-0.615618
Fine-tune [535/100000]  val_loss=-0.663033
Fine-tune [536/100000]  val_loss=-0.684648
Fine-tune [537/100000]  val_loss=-0.678448
Fine-tune [538/100000]  val_loss=-0.666375
Fine-tune [539/100000]  val_loss=-0.712861
Fine-tune [540/100000]  val_loss=-0.714020
Fine-tune [541/100000]  val_loss=-0.695669
Fine-tune [542/100000]  val_loss=-0.697917
Fine-tune [543/100000]  val_loss=-0.643423
Fine-tune [544/100000]  val_loss=-0.669379
Fine-tune [545/100000]  val_loss=-0.683754
Fine-tune [546/100000]  val_loss=-0.715534
Fine-tune [547/100000]  val_loss=-0.708647
Fine-tune [548/100000]  val_loss=-0.693304
Fine-tune [549/100000]  val_loss=-0.665753
Fine-tune [550/100000]  val_loss=-0.685809
Fine-tune [551/100000]  val_loss=-0.690641
Fine-tune [552/100000]  val_loss=-0.681968
Fine-tune [553/100000]  val_loss=-0.629680
Fine-tune [554/100000]  val_loss=-0.638707
Fine-tune [555/100000]  val_loss=-0.668126
Fine-tune [556/100000]  val_loss=-0.641505
Fine-tune [557/100000]  val_loss=-0.650397
Fine-tune [558/100000]  val_loss=-0.671958
Fine-tune [559/100000]  val_loss=-0.679305
Fine-tune [560/100000]  val_loss=-0.609428
Fine-tune [561/100000]  val_loss=-0.689794
Fine-tune [562/100000]  val_loss=-0.656077
Fine-tune [563/100000]  val_loss=-0.605603
Fine-tune [564/100000]  val_loss=-0.667470
Fine-tune [565/100000]  val_loss=-0.647645
Fine-tune [566/100000]  val_loss=-0.622528
Fine-tune [567/100000]  val_loss=-0.637682
Fine-tune [568/100000]  val_loss=-0.664207
Fine-tune [569/100000]  val_loss=-0.661695
Fine-tune [570/100000]  val_loss=-0.638898
Fine-tune [571/100000]  val_loss=-0.643798
Fine-tune [572/100000]  val_loss=-0.576395
Fine-tune [573/100000]  val_loss=-0.596832
Fine-tune [574/100000]  val_loss=-0.571513
Fine-tune [575/100000]  val_loss=-0.617306
Fine-tune [576/100000]  val_loss=-0.650749
Fine-tune [577/100000]  val_loss=-0.588696
Fine-tune [578/100000]  val_loss=-0.614699
Fine-tune [579/100000]  val_loss=-0.582645
Fine-tune [580/100000]  val_loss=-0.599566
Fine-tune [581/100000]  val_loss=-0.594753
Fine-tune [582/100000]  val_loss=-0.673586
Fine-tune [583/100000]  val_loss=-0.620916
Fine-tune [584/100000]  val_loss=-0.610654
Fine-tune [585/100000]  val_loss=-0.615153
Fine-tune [586/100000]  val_loss=-0.613853
Fine-tune [587/100000]  val_loss=-0.630957
Fine-tune [588/100000]  val_loss=-0.575709
Fine-tune [589/100000]  val_loss=-0.632574
Fine-tune [590/100000]  val_loss=-0.610023
Fine-tune [591/100000]  val_loss=-0.615272
Fine-tune [592/100000]  val_loss=-0.610427
Fine-tune [593/100000]  val_loss=-0.572686
Fine-tune [594/100000]  val_loss=-0.582118
Fine-tune [595/100000]  val_loss=-0.602046
Fine-tune [596/100000]  val_loss=-0.575014
Fine-tune [597/100000]  val_loss=-0.635269
Fine-tune [598/100000]  val_loss=-0.645175
Fine-tune [599/100000]  val_loss=-0.615749
Fine-tune [600/100000]  val_loss=-0.624115
Fine-tune [601/100000]  val_loss=-0.555074
Fine-tune [602/100000]  val_loss=-0.555783
Fine-tune [603/100000]  val_loss=-0.544799
Fine-tune [604/100000]  val_loss=-0.532721
Fine-tune [605/100000]  val_loss=-0.591587
Fine-tune [606/100000]  val_loss=-0.597301
Fine-tune [607/100000]  val_loss=-0.583083
Fine-tune [608/100000]  val_loss=-0.597806
Fine-tune [609/100000]  val_loss=-0.571849
Fine-tune [610/100000]  val_loss=-0.519823
Fine-tune [611/100000]  val_loss=-0.552818
Fine-tune [612/100000]  val_loss=-0.586403
Fine-tune [613/100000]  val_loss=-0.596875
Fine-tune [614/100000]  val_loss=-0.579237
Fine-tune [615/100000]  val_loss=-0.592496
Fine-tune [616/100000]  val_loss=-0.579729
Fine-tune [617/100000]  val_loss=-0.585441
Fine-tune [618/100000]  val_loss=-0.545606
Fine-tune [619/100000]  val_loss=-0.544207
Fine-tune [620/100000]  val_loss=-0.566396
Fine-tune [621/100000]  val_loss=-0.535490
Fine-tune [622/100000]  val_loss=-0.529858
Fine-tune [623/100000]  val_loss=-0.565201
Fine-tune [624/100000]  val_loss=-0.601912
Fine-tune [625/100000]  val_loss=-0.601769
Fine-tune [626/100000]  val_loss=-0.624346
Fine-tune [627/100000]  val_loss=-0.586101
Fine-tune [628/100000]  val_loss=-0.510693
Fine-tune [629/100000]  val_loss=-0.544719
Fine-tune [630/100000]  val_loss=-0.575174
Fine-tune [631/100000]  val_loss=-0.592582
Fine-tune [632/100000]  val_loss=-0.593014
Fine-tune [633/100000]  val_loss=-0.592128
Fine-tune [634/100000]  val_loss=-0.566634
Fine-tune [635/100000]  val_loss=-0.572207
Fine-tune [636/100000]  val_loss=-0.565319
Fine-tune [637/100000]  val_loss=-0.607149
Fine-tune [638/100000]  val_loss=-0.589872
Fine-tune [639/100000]  val_loss=-0.610134
Fine-tune [640/100000]  val_loss=-0.582973
Fine-tune [641/100000]  val_loss=-0.542097
Fine-tune [642/100000]  val_loss=-0.540866
Fine-tune [643/100000]  val_loss=-0.546317
Fine-tune [644/100000]  val_loss=-0.559965
Fine-tune [645/100000]  val_loss=-0.538211
Fine-tune [646/100000]  val_loss=-0.556539
Fine-tune [647/100000]  val_loss=-0.562153
Fine-tune [648/100000]  val_loss=-0.545298
Fine-tune [649/100000]  val_loss=-0.507315
Fine-tune [650/100000]  val_loss=-0.548197
Fine-tune [651/100000]  val_loss=-0.497599
Fine-tune [652/100000]  val_loss=-0.577773
Fine-tune [653/100000]  val_loss=-0.558991
Fine-tune [654/100000]  val_loss=-0.540939
Fine-tune [655/100000]  val_loss=-0.506532
Fine-tune [656/100000]  val_loss=-0.499140
Fine-tune [657/100000]  val_loss=-0.493642
Fine-tune [658/100000]  val_loss=-0.524970
Fine-tune [659/100000]  val_loss=-0.488002
Fine-tune [660/100000]  val_loss=-0.594673
Fine-tune [661/100000]  val_loss=-0.607376
Fine-tune [662/100000]  val_loss=-0.589843
Fine-tune [663/100000]  val_loss=-0.586538
Fine-tune [664/100000]  val_loss=-0.579279
Fine-tune [665/100000]  val_loss=-0.580104
Fine-tune [666/100000]  val_loss=-0.581052
Fine-tune [667/100000]  val_loss=-0.548650
Fine-tune [668/100000]  val_loss=-0.561450
Fine-tune [669/100000]  val_loss=-0.538631
Fine-tune [670/100000]  val_loss=-0.515429
Fine-tune [671/100000]  val_loss=-0.516498
Fine-tune [672/100000]  val_loss=-0.539943
Fine-tune [673/100000]  val_loss=-0.548917
Fine-tune [674/100000]  val_loss=-0.534111
Fine-tune [675/100000]  val_loss=-0.475822
Fine-tune [676/100000]  val_loss=-0.497176
Fine-tune [677/100000]  val_loss=-0.540983
Fine-tune [678/100000]  val_loss=-0.544766
Fine-tune [679/100000]  val_loss=-0.541989
Fine-tune [680/100000]  val_loss=-0.540604
Fine-tune [681/100000]  val_loss=-0.508411
Fine-tune [682/100000]  val_loss=-0.507799
Fine-tune [683/100000]  val_loss=-0.537392
Fine-tune [684/100000]  val_loss=-0.533263
Fine-tune [685/100000]  val_loss=-0.539300
Fine-tune [686/100000]  val_loss=-0.549352
Fine-tune [687/100000]  val_loss=-0.553111
Fine-tune [688/100000]  val_loss=-0.542594
Fine-tune [689/100000]  val_loss=-0.525651
Fine-tune [690/100000]  val_loss=-0.509108
Fine-tune [691/100000]  val_loss=-0.519688
Fine-tune [692/100000]  val_loss=-0.488532
Fine-tune [693/100000]  val_loss=-0.528684
Fine-tune [694/100000]  val_loss=-0.494717
Fine-tune [695/100000]  val_loss=-0.500277
Fine-tune [696/100000]  val_loss=-0.538980
Fine-tune [697/100000]  val_loss=-0.470828
Fine-tune [698/100000]  val_loss=-0.514421
Fine-tune [699/100000]  val_loss=-0.446800
Fine-tune [700/100000]  val_loss=-0.528587
Fine-tune [701/100000]  val_loss=-0.498489
Fine-tune [702/100000]  val_loss=-0.514667
Fine-tune [703/100000]  val_loss=-0.511532
Fine-tune [704/100000]  val_loss=-0.481655
Fine-tune [705/100000]  val_loss=-0.527855
Fine-tune [706/100000]  val_loss=-0.465559
Fine-tune [707/100000]  val_loss=-0.489223
Fine-tune [708/100000]  val_loss=-0.432933
Fine-tune [709/100000]  val_loss=-0.467523
Fine-tune [710/100000]  val_loss=-0.426910
Fine-tune [711/100000]  val_loss=-0.462031
Fine-tune [712/100000]  val_loss=-0.468801
Fine-tune [713/100000]  val_loss=-0.507068
Fine-tune [714/100000]  val_loss=-0.492916
Fine-tune [715/100000]  val_loss=-0.481775
Fine-tune [716/100000]  val_loss=-0.490864
Fine-tune [717/100000]  val_loss=-0.509418
Fine-tune [718/100000]  val_loss=-0.488688
Fine-tune [719/100000]  val_loss=-0.474135
Fine-tune [720/100000]  val_loss=-0.536343
Fine-tune [721/100000]  val_loss=-0.529726
Fine-tune [722/100000]  val_loss=-0.551488
Fine-tune [723/100000]  val_loss=-0.508650
Fine-tune [724/100000]  val_loss=-0.480184
Fine-tune [725/100000]  val_loss=-0.477458
Fine-tune [726/100000]  val_loss=-0.534304
Fine-tune [727/100000]  val_loss=-0.522236
Fine-tune [728/100000]  val_loss=-0.517354
Fine-tune [729/100000]  val_loss=-0.492821
Fine-tune [730/100000]  val_loss=-0.456762
Fine-tune [731/100000]  val_loss=-0.495889
Fine-tune [732/100000]  val_loss=-0.481910
Fine-tune [733/100000]  val_loss=-0.512208
Fine-tune [734/100000]  val_loss=-0.483150
Fine-tune [735/100000]  val_loss=-0.532743
Fine-tune [736/100000]  val_loss=-0.532943
Fine-tune [737/100000]  val_loss=-0.470038
Fine-tune [738/100000]  val_loss=-0.491115
Fine-tune [739/100000]  val_loss=-0.502304
Fine-tune [740/100000]  val_loss=-0.530897
Fine-tune [741/100000]  val_loss=-0.504422
Fine-tune [742/100000]  val_loss=-0.508927
Fine-tune [743/100000]  val_loss=-0.478917
Fine-tune [744/100000]  val_loss=-0.465432
Fine-tune [745/100000]  val_loss=-0.533494
Fine-tune [746/100000]  val_loss=-0.507749
Fine-tune [747/100000]  val_loss=-0.508936
Fine-tune [748/100000]  val_loss=-0.500461
Fine-tune [749/100000]  val_loss=-0.489282
Fine-tune [750/100000]  val_loss=-0.453609
Fine-tune [751/100000]  val_loss=-0.483975
Fine-tune [752/100000]  val_loss=-0.481758
Fine-tune [753/100000]  val_loss=-0.457659
Fine-tune [754/100000]  val_loss=-0.525527
Fine-tune [755/100000]  val_loss=-0.446796
Fine-tune [756/100000]  val_loss=-0.481065
Fine-tune [757/100000]  val_loss=-0.402142
Fine-tune [758/100000]  val_loss=-0.397866
Fine-tune [759/100000]  val_loss=-0.438445
Fine-tune [760/100000]  val_loss=-0.437343
Fine-tune [761/100000]  val_loss=-0.456575
Fine-tune [762/100000]  val_loss=-0.438334
Fine-tune [763/100000]  val_loss=-0.427390
Fine-tune [764/100000]  val_loss=-0.456265
Fine-tune [765/100000]  val_loss=-0.424150
Fine-tune [766/100000]  val_loss=-0.459292
Fine-tune [767/100000]  val_loss=-0.440270
Fine-tune [768/100000]  val_loss=-0.447250
Fine-tune [769/100000]  val_loss=-0.455209
Fine-tune [770/100000]  val_loss=-0.447916
Fine-tune [771/100000]  val_loss=-0.489090
Fine-tune [772/100000]  val_loss=-0.446146
Fine-tune [773/100000]  val_loss=-0.482214
Fine-tune [774/100000]  val_loss=-0.448088
Fine-tune [775/100000]  val_loss=-0.483667
Fine-tune [776/100000]  val_loss=-0.454145
Fine-tune [777/100000]  val_loss=-0.529964
Fine-tune [778/100000]  val_loss=-0.475125
Fine-tune [779/100000]  val_loss=-0.471958
Fine-tune [780/100000]  val_loss=-0.470018
Fine-tune [781/100000]  val_loss=-0.491063
Fine-tune [782/100000]  val_loss=-0.448901
Fine-tune [783/100000]  val_loss=-0.457944
Fine-tune [784/100000]  val_loss=-0.430853
Fine-tune [785/100000]  val_loss=-0.436977
Fine-tune [786/100000]  val_loss=-0.387279
Fine-tune [787/100000]  val_loss=-0.430240
Fine-tune [788/100000]  val_loss=-0.439403
Fine-tune [789/100000]  val_loss=-0.414333
Fine-tune [790/100000]  val_loss=-0.445587
Fine-tune [791/100000]  val_loss=-0.421727
Fine-tune [792/100000]  val_loss=-0.427231
Fine-tune [793/100000]  val_loss=-0.423788
Fine-tune [794/100000]  val_loss=-0.459128
Fine-tune [795/100000]  val_loss=-0.393231
Fine-tune [796/100000]  val_loss=-0.449935
Fine-tune [797/100000]  val_loss=-0.347949
Fine-tune [798/100000]  val_loss=-0.360548
Fine-tune [799/100000]  val_loss=-0.359450
Fine-tune [800/100000]  val_loss=-0.369764
Fine-tune [801/100000]  val_loss=-0.469109
Fine-tune [802/100000]  val_loss=-0.419195
Fine-tune [803/100000]  val_loss=-0.443079
Fine-tune [804/100000]  val_loss=-0.426117
Fine-tune [805/100000]  val_loss=-0.418595
Fine-tune [806/100000]  val_loss=-0.453054
Fine-tune [807/100000]  val_loss=-0.410638
Fine-tune [808/100000]  val_loss=-0.389420
Fine-tune [809/100000]  val_loss=-0.385428
Fine-tune [810/100000]  val_loss=-0.408819
Fine-tune [811/100000]  val_loss=-0.403934
Fine-tune [812/100000]  val_loss=-0.363050
Fine-tune [813/100000]  val_loss=-0.419820
Fine-tune [814/100000]  val_loss=-0.391805
Fine-tune [815/100000]  val_loss=-0.405508
Fine-tune [816/100000]  val_loss=-0.383719
Fine-tune [817/100000]  val_loss=-0.395883
Fine-tune [818/100000]  val_loss=-0.430963
Fine-tune [819/100000]  val_loss=-0.349555
Fine-tune [820/100000]  val_loss=-0.373257
Fine-tune [821/100000]  val_loss=-0.381451
Fine-tune [822/100000]  val_loss=-0.376864
Fine-tune [823/100000]  val_loss=-0.374576
Fine-tune [824/100000]  val_loss=-0.377278
Fine-tune [825/100000]  val_loss=-0.402570
Fine-tune [826/100000]  val_loss=-0.308320
Fine-tune [827/100000]  val_loss=-0.342203
Fine-tune [828/100000]  val_loss=-0.404312
Fine-tune [829/100000]  val_loss=-0.375935
Fine-tune [830/100000]  val_loss=-0.377424
Fine-tune [831/100000]  val_loss=-0.433443
Fine-tune [832/100000]  val_loss=-0.371987
Fine-tune [833/100000]  val_loss=-0.342596
Fine-tune [834/100000]  val_loss=-0.397537
Fine-tune [835/100000]  val_loss=-0.360338
Fine-tune [836/100000]  val_loss=-0.388995
Fine-tune [837/100000]  val_loss=-0.357478
Fine-tune [838/100000]  val_loss=-0.345574
Fine-tune [839/100000]  val_loss=-0.449310
Fine-tune [840/100000]  val_loss=-0.411377
Fine-tune [841/100000]  val_loss=-0.371444
Fine-tune [842/100000]  val_loss=-0.384871
Fine-tune [843/100000]  val_loss=-0.418157
Fine-tune [844/100000]  val_loss=-0.339938
Fine-tune [845/100000]  val_loss=-0.310172
Fine-tune [846/100000]  val_loss=-0.352528
Fine-tune [847/100000]  val_loss=-0.329379
Fine-tune [848/100000]  val_loss=-0.366044
Fine-tune [849/100000]  val_loss=-0.364611
Fine-tune [850/100000]  val_loss=-0.351947
Fine-tune [851/100000]  val_loss=-0.334915
Fine-tune [852/100000]  val_loss=-0.376316
Fine-tune [853/100000]  val_loss=-0.361718
Fine-tune [854/100000]  val_loss=-0.411545
Fine-tune [855/100000]  val_loss=-0.412349
Fine-tune [856/100000]  val_loss=-0.418491
Fine-tune [857/100000]  val_loss=-0.388223
Fine-tune [858/100000]  val_loss=-0.378243
Fine-tune [859/100000]  val_loss=-0.383122
Fine-tune [860/100000]  val_loss=-0.405475
Fine-tune [861/100000]  val_loss=-0.386642
Fine-tune [862/100000]  val_loss=-0.418736
Fine-tune [863/100000]  val_loss=-0.404290
Fine-tune [864/100000]  val_loss=-0.343345
Fine-tune [865/100000]  val_loss=-0.357527
Fine-tune [866/100000]  val_loss=-0.384406
Fine-tune [867/100000]  val_loss=-0.394680
Fine-tune [868/100000]  val_loss=-0.357590
Fine-tune [869/100000]  val_loss=-0.329773
Fine-tune [870/100000]  val_loss=-0.265501
Fine-tune [871/100000]  val_loss=-0.276313
Fine-tune [872/100000]  val_loss=-0.353032
Fine-tune [873/100000]  val_loss=-0.339852
Fine-tune [874/100000]  val_loss=-0.354795
Fine-tune [875/100000]  val_loss=-0.347177
Fine-tune [876/100000]  val_loss=-0.344204
Fine-tune [877/100000]  val_loss=-0.352471
Fine-tune [878/100000]  val_loss=-0.396856
Fine-tune [879/100000]  val_loss=-0.373717
Fine-tune [880/100000]  val_loss=-0.391126
Fine-tune [881/100000]  val_loss=-0.337984
Fine-tune [882/100000]  val_loss=-0.287139
Fine-tune [883/100000]  val_loss=-0.314293
Fine-tune [884/100000]  val_loss=-0.318952
Fine-tune [885/100000]  val_loss=-0.312299
Fine-tune [886/100000]  val_loss=-0.365706
Fine-tune [887/100000]  val_loss=-0.372989
Fine-tune [888/100000]  val_loss=-0.361898
Fine-tune [889/100000]  val_loss=-0.276012
Fine-tune [890/100000]  val_loss=-0.262619
Fine-tune [891/100000]  val_loss=-0.284272
Fine-tune [892/100000]  val_loss=-0.305230
Fine-tune [893/100000]  val_loss=-0.312637
Fine-tune [894/100000]  val_loss=-0.238746
Fine-tune [895/100000]  val_loss=-0.319619
Fine-tune [896/100000]  val_loss=-0.335794
Fine-tune [897/100000]  val_loss=-0.352934
Fine-tune [898/100000]  val_loss=-0.298240
Fine-tune [899/100000]  val_loss=-0.358378
Fine-tune [900/100000]  val_loss=-0.360748
Fine-tune [901/100000]  val_loss=-0.290873
Fine-tune [902/100000]  val_loss=-0.312745
Fine-tune [903/100000]  val_loss=-0.357171
Fine-tune [904/100000]  val_loss=-0.314441
Fine-tune [905/100000]  val_loss=-0.325168
Fine-tune [906/100000]  val_loss=-0.343166
Fine-tune [907/100000]  val_loss=-0.348674
Fine-tune [908/100000]  val_loss=-0.355564
Fine-tune [909/100000]  val_loss=-0.316020
Fine-tune [910/100000]  val_loss=-0.301820
Fine-tune [911/100000]  val_loss=-0.326426
Fine-tune [912/100000]  val_loss=-0.327955
Fine-tune [913/100000]  val_loss=-0.390416
Fine-tune [914/100000]  val_loss=-0.337001
Fine-tune [915/100000]  val_loss=-0.351851
Fine-tune [916/100000]  val_loss=-0.279842
Fine-tune [917/100000]  val_loss=-0.294071
Fine-tune [918/100000]  val_loss=-0.382098
Fine-tune [919/100000]  val_loss=-0.341241
Fine-tune [920/100000]  val_loss=-0.406396
Fine-tune [921/100000]  val_loss=-0.328732
Fine-tune [922/100000]  val_loss=-0.309865
Fine-tune [923/100000]  val_loss=-0.365920
Fine-tune [924/100000]  val_loss=-0.334357
Fine-tune [925/100000]  val_loss=-0.311979
Fine-tune [926/100000]  val_loss=-0.307990
Fine-tune [927/100000]  val_loss=-0.281072
Fine-tune [928/100000]  val_loss=-0.291253
Fine-tune [929/100000]  val_loss=-0.282336
Fine-tune [930/100000]  val_loss=-0.298010
Fine-tune [931/100000]  val_loss=-0.343596
Fine-tune [932/100000]  val_loss=-0.250118
Fine-tune [933/100000]  val_loss=-0.243915
Fine-tune [934/100000]  val_loss=-0.268781
Fine-tune [935/100000]  val_loss=-0.307510
Fine-tune [936/100000]  val_loss=-0.347576
Fine-tune [937/100000]  val_loss=-0.345620
Fine-tune [938/100000]  val_loss=-0.275770
Fine-tune [939/100000]  val_loss=-0.221471
Fine-tune [940/100000]  val_loss=-0.279616
Fine-tune [941/100000]  val_loss=-0.328862
Fine-tune [942/100000]  val_loss=-0.276655
Fine-tune [943/100000]  val_loss=-0.279245
Fine-tune [944/100000]  val_loss=-0.249207
Fine-tune [945/100000]  val_loss=-0.279647
Fine-tune [946/100000]  val_loss=-0.355780
Fine-tune [947/100000]  val_loss=-0.351776
Fine-tune [948/100000]  val_loss=-0.326245
Fine-tune [949/100000]  val_loss=-0.333029
Fine-tune [950/100000]  val_loss=-0.307663
Fine-tune [951/100000]  val_loss=-0.307078
Fine-tune [952/100000]  val_loss=-0.180618
Fine-tune [953/100000]  val_loss=-0.241525
Fine-tune [954/100000]  val_loss=-0.240638
Fine-tune [955/100000]  val_loss=-0.228421
Fine-tune [956/100000]  val_loss=-0.266650
Fine-tune [957/100000]  val_loss=-0.301067
Fine-tune [958/100000]  val_loss=-0.341273
Fine-tune [959/100000]  val_loss=-0.346357
Fine-tune [960/100000]  val_loss=-0.311062
Fine-tune [961/100000]  val_loss=-0.290565
Fine-tune [962/100000]  val_loss=-0.269396
Fine-tune [963/100000]  val_loss=-0.271830
Fine-tune [964/100000]  val_loss=-0.289654
Fine-tune [965/100000]  val_loss=-0.309805
Fine-tune [966/100000]  val_loss=-0.332395
Fine-tune [967/100000]  val_loss=-0.202981
Fine-tune [968/100000]  val_loss=-0.237200
Fine-tune [969/100000]  val_loss=-0.256193
Fine-tune [970/100000]  val_loss=-0.322595
Fine-tune [971/100000]  val_loss=-0.281883
Fine-tune [972/100000]  val_loss=-0.254153
Fine-tune [973/100000]  val_loss=-0.268725
Fine-tune [974/100000]  val_loss=-0.297414
Fine-tune [975/100000]  val_loss=-0.260447
Fine-tune [976/100000]  val_loss=-0.256031
Fine-tune [977/100000]  val_loss=-0.279724
Fine-tune [978/100000]  val_loss=-0.287988
Fine-tune [979/100000]  val_loss=-0.228965
Fine-tune [980/100000]  val_loss=-0.258328
Fine-tune [981/100000]  val_loss=-0.248882
Fine-tune [982/100000]  val_loss=-0.305373
Fine-tune [983/100000]  val_loss=-0.223638
Fine-tune [984/100000]  val_loss=-0.247358
Fine-tune [985/100000]  val_loss=-0.250565
Fine-tune [986/100000]  val_loss=-0.266755
Fine-tune [987/100000]  val_loss=-0.290901
Fine-tune [988/100000]  val_loss=-0.250540
Fine-tune [989/100000]  val_loss=-0.275925
Fine-tune [990/100000]  val_loss=-0.226730
Fine-tune [991/100000]  val_loss=-0.246995
Fine-tune [992/100000]  val_loss=-0.224066
Fine-tune [993/100000]  val_loss=-0.206602
Fine-tune [994/100000]  val_loss=-0.265708
Fine-tune [995/100000]  val_loss=-0.305306
Fine-tune [996/100000]  val_loss=-0.282403
Fine-tune [997/100000]  val_loss=-0.300557
Fine-tune [998/100000]  val_loss=-0.247862
Fine-tune [999/100000]  val_loss=-0.288645
Fine-tune [1000/100000]  val_loss=-0.295109
Fine-tune [1001/100000]  val_loss=-0.229756
Fine-tune [1002/100000]  val_loss=-0.253672
Fine-tune [1003/100000]  val_loss=-0.224782
Fine-tune [1004/100000]  val_loss=-0.211371
Fine-tune [1005/100000]  val_loss=-0.253304
Fine-tune [1006/100000]  val_loss=-0.277078
Fine-tune [1007/100000]  val_loss=-0.261572
Fine-tune [1008/100000]  val_loss=-0.290845
Fine-tune [1009/100000]  val_loss=-0.306052
Fine-tune [1010/100000]  val_loss=-0.285336
Fine-tune [1011/100000]  val_loss=-0.238092
Fine-tune [1012/100000]  val_loss=-0.211807
Fine-tune [1013/100000]  val_loss=-0.235259
Fine-tune [1014/100000]  val_loss=-0.275005
Fine-tune [1015/100000]  val_loss=-0.225850
Fine-tune [1016/100000]  val_loss=-0.196405
Fine-tune [1017/100000]  val_loss=-0.205984
Fine-tune [1018/100000]  val_loss=-0.250678
Fine-tune [1019/100000]  val_loss=-0.235699
Fine-tune [1020/100000]  val_loss=-0.241386
Fine-tune [1021/100000]  val_loss=-0.271831
Fine-tune [1022/100000]  val_loss=-0.222721
Fine-tune [1023/100000]  val_loss=-0.237768
Fine-tune [1024/100000]  val_loss=-0.135526
Fine-tune [1025/100000]  val_loss=-0.212878
Fine-tune [1026/100000]  val_loss=-0.244103
Fine-tune [1027/100000]  val_loss=-0.227217
Fine-tune [1028/100000]  val_loss=-0.169170
Fine-tune [1029/100000]  val_loss=-0.142345
Fine-tune [1030/100000]  val_loss=-0.258112
Fine-tune [1031/100000]  val_loss=-0.313429
Fine-tune [1032/100000]  val_loss=-0.247987
Fine-tune [1033/100000]  val_loss=-0.196253
Fine-tune [1034/100000]  val_loss=-0.251169
Fine-tune [1035/100000]  val_loss=-0.216585
Fine-tune [1036/100000]  val_loss=-0.227198
Fine-tune [1037/100000]  val_loss=-0.233508
Fine-tune [1038/100000]  val_loss=-0.219011
Fine-tune [1039/100000]  val_loss=-0.231583
Fine-tune [1040/100000]  val_loss=-0.258868
Fine-tune [1041/100000]  val_loss=-0.220345
Fine-tune [1042/100000]  val_loss=-0.258029
Fine-tune [1043/100000]  val_loss=-0.266246
Fine-tune [1044/100000]  val_loss=-0.276397
Fine-tune [1045/100000]  val_loss=-0.251877
Fine-tune [1046/100000]  val_loss=-0.209832
Fine-tune [1047/100000]  val_loss=-0.216165
Fine-tune [1048/100000]  val_loss=-0.210602
Fine-tune [1049/100000]  val_loss=-0.245944
Fine-tune [1050/100000]  val_loss=-0.199815
Fine-tune [1051/100000]  val_loss=-0.208685
Fine-tune [1052/100000]  val_loss=-0.196078
Fine-tune [1053/100000]  val_loss=-0.243367
Fine-tune [1054/100000]  val_loss=-0.179730
Fine-tune [1055/100000]  val_loss=-0.171928
Fine-tune [1056/100000]  val_loss=-0.175603
Fine-tune [1057/100000]  val_loss=-0.222157
Fine-tune [1058/100000]  val_loss=-0.202221
Fine-tune [1059/100000]  val_loss=-0.240982
Fine-tune [1060/100000]  val_loss=-0.214915
Fine-tune [1061/100000]  val_loss=-0.184083
Fine-tune [1062/100000]  val_loss=-0.259957
Fine-tune [1063/100000]  val_loss=-0.253719
Fine-tune [1064/100000]  val_loss=-0.294219
Fine-tune [1065/100000]  val_loss=-0.227719
Fine-tune [1066/100000]  val_loss=-0.224109
Fine-tune [1067/100000]  val_loss=-0.163674
Fine-tune [1068/100000]  val_loss=-0.185329
Fine-tune [1069/100000]  val_loss=-0.228583
Fine-tune [1070/100000]  val_loss=-0.211076
Fine-tune [1071/100000]  val_loss=-0.226635
Fine-tune [1072/100000]  val_loss=-0.231155
Fine-tune [1073/100000]  val_loss=-0.211843
Fine-tune [1074/100000]  val_loss=-0.193487
Fine-tune [1075/100000]  val_loss=-0.176176
Fine-tune [1076/100000]  val_loss=-0.173039
Fine-tune [1077/100000]  val_loss=-0.192989
Fine-tune [1078/100000]  val_loss=-0.204451
Fine-tune [1079/100000]  val_loss=-0.151450
Fine-tune [1080/100000]  val_loss=-0.195138
Fine-tune [1081/100000]  val_loss=-0.277226
Fine-tune [1082/100000]  val_loss=-0.229327
Fine-tune [1083/100000]  val_loss=-0.227389
Fine-tune [1084/100000]  val_loss=-0.177999
Fine-tune [1085/100000]  val_loss=-0.131747
Fine-tune [1086/100000]  val_loss=-0.210071
Fine-tune [1087/100000]  val_loss=-0.199992
Fine-tune [1088/100000]  val_loss=-0.220317
Fine-tune [1089/100000]  val_loss=-0.123703
Fine-tune [1090/100000]  val_loss=-0.207554
Fine-tune [1091/100000]  val_loss=-0.163526
Fine-tune [1092/100000]  val_loss=-0.139017
Fine-tune [1093/100000]  val_loss=-0.122028
Fine-tune [1094/100000]  val_loss=-0.067268
Fine-tune [1095/100000]  val_loss=-0.143903
Fine-tune [1096/100000]  val_loss=-0.150272
Fine-tune [1097/100000]  val_loss=-0.134026
Fine-tune [1098/100000]  val_loss=-0.107712
Fine-tune [1099/100000]  val_loss=-0.194443
Fine-tune [1100/100000]  val_loss=-0.148916
Fine-tune [1101/100000]  val_loss=-0.209702
Fine-tune [1102/100000]  val_loss=-0.167994
Fine-tune [1103/100000]  val_loss=-0.142240
Fine-tune [1104/100000]  val_loss=-0.151315
Fine-tune [1105/100000]  val_loss=-0.101467
Fine-tune [1106/100000]  val_loss=-0.117906
Fine-tune [1107/100000]  val_loss=-0.126963
Fine-tune [1108/100000]  val_loss=-0.168815
Fine-tune [1109/100000]  val_loss=-0.161449
Fine-tune [1110/100000]  val_loss=-0.194208
Fine-tune [1111/100000]  val_loss=-0.195751
Fine-tune [1112/100000]  val_loss=-0.189139
Fine-tune [1113/100000]  val_loss=-0.220730
Fine-tune [1114/100000]  val_loss=-0.225094
Fine-tune [1115/100000]  val_loss=-0.180911
Fine-tune [1116/100000]  val_loss=-0.175915
  -> 验证未改进 1000 次，早停。
[FINETUNE] 最佳验证损失=-0.965390 已保存。

--- 评估 [HD512_L2] ---

=== 本次试验参数 (Run Config) ===
opamp             : two_stage_opamp
hidden_dim        : 512
num_layers        : 2
lr_pretrain       : 0.003
epochs_pretrain   : 1000
patience_pretrain : 200
lr_finetune       : 0.0038
epochs_finetune   : 100000
patience_finetune : 1000
batch_a           : 128
batch_b           : 64
dropout_rate      : 0.2
alpha_r2          : 0.0
lambda_coral      : 0.1
seed              : 42
device            : cpu

--- [评估阶段] 开始计算指标 ---

=== 目标域验证集指标（物理单位）===
slewrate_pos    MSE=1.109e+14  MAE=8.086e+06  R2=0.7414
dc_gain         MSE=2.897e+07  MAE=1465  R2=0.2563
ugf             MSE=1.284e+14  MAE=6.975e+06  R2=0.7097
phase_margin    MSE=171.9  MAE=9.899  R2=0.8502
cmrr            MSE=8.604e+11  MAE=9.747e+04  R2=0.0067

Avg  (all dims)   MSE=4.804e+13  MAE=3.032e+06  R2=0.5128
[OK] HD512_L2 -> r2_avg=0.5128, mae_avg=3.032e+06, mse_avg=4.804e+13
===== [HD512_L2] 训练完成 =====

===== [HD512_L3] 训练开始 =====

--- [阶段一] Backbone 预训练 (source_train / source_val, HuberLoss) ---
Pretrain [1/1000]  train=0.234135  val=0.194811
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [2/1000]  train=0.168214  val=0.147872
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [3/1000]  train=0.148608  val=0.127793
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [4/1000]  train=0.133642  val=0.126259
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [5/1000]  train=0.127141  val=0.116977
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [6/1000]  train=0.122223  val=0.111169
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [7/1000]  train=0.115692  val=0.108218
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [8/1000]  train=0.111005  val=0.101919
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [9/1000]  train=0.107329  val=0.100112
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [10/1000]  train=0.104839  val=0.099967
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [11/1000]  train=0.102574  val=0.097968
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [12/1000]  train=0.101475  val=0.099376
Pretrain [13/1000]  train=0.099530  val=0.091239
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [14/1000]  train=0.097401  val=0.091233
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [15/1000]  train=0.094746  val=0.092069
Pretrain [16/1000]  train=0.093447  val=0.089189
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [17/1000]  train=0.088855  val=0.096409
Pretrain [18/1000]  train=0.091653  val=0.096511
Pretrain [19/1000]  train=0.086831  val=0.088923
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [20/1000]  train=0.088352  val=0.093399
Pretrain [21/1000]  train=0.085640  val=0.088571
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [22/1000]  train=0.084755  val=0.085102
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [23/1000]  train=0.083583  val=0.091074
Pretrain [24/1000]  train=0.083124  val=0.105510
Pretrain [25/1000]  train=0.084508  val=0.091277
Pretrain [26/1000]  train=0.081301  val=0.089716
Pretrain [27/1000]  train=0.080282  val=0.083374
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [28/1000]  train=0.077573  val=0.085385
Pretrain [29/1000]  train=0.077252  val=0.085844
Pretrain [30/1000]  train=0.075099  val=0.084574
Pretrain [31/1000]  train=0.077066  val=0.083000
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [32/1000]  train=0.073750  val=0.080995
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [33/1000]  train=0.073714  val=0.081780
Pretrain [34/1000]  train=0.073519  val=0.081370
Pretrain [35/1000]  train=0.072717  val=0.083424
Pretrain [36/1000]  train=0.073527  val=0.080397
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [37/1000]  train=0.071999  val=0.082074
Pretrain [38/1000]  train=0.075130  val=0.085026
Pretrain [39/1000]  train=0.071010  val=0.079510
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [40/1000]  train=0.067953  val=0.083012
Pretrain [41/1000]  train=0.066048  val=0.084176
Pretrain [42/1000]  train=0.066515  val=0.078932
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [43/1000]  train=0.065618  val=0.080011
Pretrain [44/1000]  train=0.065851  val=0.084377
Pretrain [45/1000]  train=0.066733  val=0.084079
Pretrain [46/1000]  train=0.064571  val=0.080727
Pretrain [47/1000]  train=0.064444  val=0.084971
Pretrain [48/1000]  train=0.063170  val=0.079020
Pretrain [49/1000]  train=0.062163  val=0.081821
Pretrain [50/1000]  train=0.060833  val=0.083155
Pretrain [51/1000]  train=0.061634  val=0.084559
Pretrain [52/1000]  train=0.061167  val=0.080226
Pretrain [53/1000]  train=0.058724  val=0.080801
Pretrain [54/1000]  train=0.058342  val=0.078230
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [55/1000]  train=0.058148  val=0.083827
Pretrain [56/1000]  train=0.058655  val=0.076587
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [57/1000]  train=0.059436  val=0.081240
Pretrain [58/1000]  train=0.056788  val=0.080351
Pretrain [59/1000]  train=0.055232  val=0.080483
Pretrain [60/1000]  train=0.058278  val=0.083259
Pretrain [61/1000]  train=0.055483  val=0.084175
Pretrain [62/1000]  train=0.055124  val=0.081977
Pretrain [63/1000]  train=0.055089  val=0.080083
Pretrain [64/1000]  train=0.053045  val=0.077874
Pretrain [65/1000]  train=0.053895  val=0.076814
Pretrain [66/1000]  train=0.053546  val=0.081633
Pretrain [67/1000]  train=0.052490  val=0.077138
Pretrain [68/1000]  train=0.052007  val=0.074248
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [69/1000]  train=0.051942  val=0.078616
Pretrain [70/1000]  train=0.051144  val=0.082413
Pretrain [71/1000]  train=0.052272  val=0.076535
Pretrain [72/1000]  train=0.052223  val=0.072250
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [73/1000]  train=0.049119  val=0.077039
Pretrain [74/1000]  train=0.048280  val=0.075412
Pretrain [75/1000]  train=0.047185  val=0.078904
Pretrain [76/1000]  train=0.048484  val=0.077653
Pretrain [77/1000]  train=0.048278  val=0.081392
Pretrain [78/1000]  train=0.048603  val=0.078500
Pretrain [79/1000]  train=0.045596  val=0.080372
Pretrain [80/1000]  train=0.047069  val=0.076526
Pretrain [81/1000]  train=0.048062  val=0.077802
Pretrain [82/1000]  train=0.047820  val=0.076618
Pretrain [83/1000]  train=0.047059  val=0.074730
Pretrain [84/1000]  train=0.043705  val=0.079446
Pretrain [85/1000]  train=0.044183  val=0.077362
Pretrain [86/1000]  train=0.044089  val=0.075888
Pretrain [87/1000]  train=0.041706  val=0.076148
Pretrain [88/1000]  train=0.042893  val=0.075558
Pretrain [89/1000]  train=0.044847  val=0.077800
Pretrain [90/1000]  train=0.043267  val=0.075592
Pretrain [91/1000]  train=0.042988  val=0.076274
Pretrain [92/1000]  train=0.041946  val=0.071897
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [93/1000]  train=0.041151  val=0.076712
Pretrain [94/1000]  train=0.043959  val=0.076725
Pretrain [95/1000]  train=0.041889  val=0.074805
Pretrain [96/1000]  train=0.040866  val=0.073661
Pretrain [97/1000]  train=0.040502  val=0.077584
Pretrain [98/1000]  train=0.039212  val=0.075098
Pretrain [99/1000]  train=0.039939  val=0.075485
Pretrain [100/1000]  train=0.041265  val=0.075887
Pretrain [101/1000]  train=0.040604  val=0.076507
Pretrain [102/1000]  train=0.039857  val=0.076188
Pretrain [103/1000]  train=0.039539  val=0.077042
Pretrain [104/1000]  train=0.038055  val=0.074004
Pretrain [105/1000]  train=0.039307  val=0.073291
Pretrain [106/1000]  train=0.038527  val=0.072041
Pretrain [107/1000]  train=0.038237  val=0.072392
Pretrain [108/1000]  train=0.036393  val=0.072715
Pretrain [109/1000]  train=0.037609  val=0.072227
Pretrain [110/1000]  train=0.036837  val=0.070021
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [111/1000]  train=0.035541  val=0.071765
Pretrain [112/1000]  train=0.035368  val=0.073765
Pretrain [113/1000]  train=0.034875  val=0.073128
Pretrain [114/1000]  train=0.035027  val=0.069978
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [115/1000]  train=0.035308  val=0.071319
Pretrain [116/1000]  train=0.035166  val=0.072479
Pretrain [117/1000]  train=0.035278  val=0.073575
Pretrain [118/1000]  train=0.035346  val=0.070799
Pretrain [119/1000]  train=0.034304  val=0.070835
Pretrain [120/1000]  train=0.033522  val=0.072374
Pretrain [121/1000]  train=0.032289  val=0.070610
Pretrain [122/1000]  train=0.032559  val=0.069705
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [123/1000]  train=0.032286  val=0.071188
Pretrain [124/1000]  train=0.034137  val=0.072030
Pretrain [125/1000]  train=0.032564  val=0.071834
Pretrain [126/1000]  train=0.032838  val=0.071930
Pretrain [127/1000]  train=0.031146  val=0.071010
Pretrain [128/1000]  train=0.031001  val=0.071505
Pretrain [129/1000]  train=0.032657  val=0.069442
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [130/1000]  train=0.032254  val=0.069354
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [131/1000]  train=0.031149  val=0.069005
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [132/1000]  train=0.032023  val=0.070265
Pretrain [133/1000]  train=0.032082  val=0.068990
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [134/1000]  train=0.032781  val=0.069291
Pretrain [135/1000]  train=0.031011  val=0.069041
Pretrain [136/1000]  train=0.030092  val=0.067819
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [137/1000]  train=0.030568  val=0.069517
Pretrain [138/1000]  train=0.030085  val=0.070150
Pretrain [139/1000]  train=0.029696  val=0.069162
Pretrain [140/1000]  train=0.028769  val=0.069647
Pretrain [141/1000]  train=0.030345  val=0.068675
Pretrain [142/1000]  train=0.028782  val=0.069258
Pretrain [143/1000]  train=0.028568  val=0.069652
Pretrain [144/1000]  train=0.029486  val=0.069361
Pretrain [145/1000]  train=0.029640  val=0.068250
Pretrain [146/1000]  train=0.029064  val=0.070557
Pretrain [147/1000]  train=0.029414  val=0.067632
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [148/1000]  train=0.029152  val=0.067754
Pretrain [149/1000]  train=0.028304  val=0.069088
Pretrain [150/1000]  train=0.028070  val=0.067707
Pretrain [151/1000]  train=0.028029  val=0.068052
Pretrain [152/1000]  train=0.026992  val=0.067272
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [153/1000]  train=0.027168  val=0.067608
Pretrain [154/1000]  train=0.027599  val=0.067989
Pretrain [155/1000]  train=0.026937  val=0.068167
Pretrain [156/1000]  train=0.027715  val=0.067924
Pretrain [157/1000]  train=0.027180  val=0.069001
Pretrain [158/1000]  train=0.028872  val=0.068505
Pretrain [159/1000]  train=0.027415  val=0.067491
Pretrain [160/1000]  train=0.025953  val=0.066105
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/pretrained.pth
Pretrain [161/1000]  train=0.026238  val=0.067439
Pretrain [162/1000]  train=0.026662  val=0.066315
Pretrain [163/1000]  train=0.027318  val=0.067447
Pretrain [164/1000]  train=0.025937  val=0.068370
Pretrain [165/1000]  train=0.025662  val=0.067233
Pretrain [166/1000]  train=0.026705  val=0.066890
Pretrain [167/1000]  train=0.026427  val=0.067623
Pretrain [168/1000]  train=0.026804  val=0.066269
Pretrain [169/1000]  train=0.025770  val=0.067191
Pretrain [170/1000]  train=0.026844  val=0.067273
Pretrain [171/1000]  train=0.027255  val=0.067105
Pretrain [172/1000]  train=0.025948  val=0.066427
Pretrain [173/1000]  train=0.026478  val=0.067279
Pretrain [174/1000]  train=0.025742  val=0.067463
Pretrain [175/1000]  train=0.024922  val=0.067502
Pretrain [176/1000]  train=0.025381  val=0.066212
Pretrain [177/1000]  train=0.025076  val=0.066448
Pretrain [178/1000]  train=0.025244  val=0.067159
Pretrain [179/1000]  train=0.025372  val=0.067070
Pretrain [180/1000]  train=0.025577  val=0.067042
Pretrain [181/1000]  train=0.026216  val=0.066724
Pretrain [182/1000]  train=0.025284  val=0.066953
Pretrain [183/1000]  train=0.025147  val=0.066762
Pretrain [184/1000]  train=0.025846  val=0.067076
Pretrain [185/1000]  train=0.025668  val=0.066409
Pretrain [186/1000]  train=0.025909  val=0.066394
Pretrain [187/1000]  train=0.026636  val=0.066341
Pretrain [188/1000]  train=0.025667  val=0.066355
Pretrain [189/1000]  train=0.025117  val=0.066527
Pretrain [190/1000]  train=0.024788  val=0.066472
Pretrain [191/1000]  train=0.025237  val=0.066524
Pretrain [192/1000]  train=0.025336  val=0.066595
Pretrain [193/1000]  train=0.025063  val=0.066518
Pretrain [194/1000]  train=0.024634  val=0.066353
Pretrain [195/1000]  train=0.025300  val=0.066422
Pretrain [196/1000]  train=0.025341  val=0.066430
Pretrain [197/1000]  train=0.025226  val=0.066457
Pretrain [198/1000]  train=0.025983  val=0.066428
Pretrain [199/1000]  train=0.024602  val=0.066417
Pretrain [200/1000]  train=0.025111  val=0.066429
Pretrain [201/1000]  train=0.043147  val=0.083309
Pretrain [202/1000]  train=0.069830  val=0.094939
Pretrain [203/1000]  train=0.068542  val=0.089493
Pretrain [204/1000]  train=0.064607  val=0.082990
Pretrain [205/1000]  train=0.064312  val=0.090156
Pretrain [206/1000]  train=0.061682  val=0.084276
Pretrain [207/1000]  train=0.056999  val=0.080362
Pretrain [208/1000]  train=0.059394  val=0.080438
Pretrain [209/1000]  train=0.059321  val=0.084244
Pretrain [210/1000]  train=0.058446  val=0.082141
Pretrain [211/1000]  train=0.056269  val=0.081851
Pretrain [212/1000]  train=0.053293  val=0.083465
Pretrain [213/1000]  train=0.055676  val=0.083725
Pretrain [214/1000]  train=0.055128  val=0.079497
Pretrain [215/1000]  train=0.051598  val=0.082706
Pretrain [216/1000]  train=0.051051  val=0.083935
Pretrain [217/1000]  train=0.049254  val=0.085896
Pretrain [218/1000]  train=0.051374  val=0.086338
Pretrain [219/1000]  train=0.052450  val=0.084249
Pretrain [220/1000]  train=0.050678  val=0.077365
Pretrain [221/1000]  train=0.047972  val=0.080459
Pretrain [222/1000]  train=0.048323  val=0.079863
Pretrain [223/1000]  train=0.046957  val=0.082012
Pretrain [224/1000]  train=0.048406  val=0.077788
Pretrain [225/1000]  train=0.046805  val=0.076149
Pretrain [226/1000]  train=0.049801  val=0.076222
Pretrain [227/1000]  train=0.047719  val=0.079559
Pretrain [228/1000]  train=0.045139  val=0.076412
Pretrain [229/1000]  train=0.045813  val=0.077919
Pretrain [230/1000]  train=0.048209  val=0.077441
Pretrain [231/1000]  train=0.047891  val=0.078270
Pretrain [232/1000]  train=0.045975  val=0.079194
Pretrain [233/1000]  train=0.045425  val=0.079155
Pretrain [234/1000]  train=0.046235  val=0.079807
Pretrain [235/1000]  train=0.045283  val=0.079093
Pretrain [236/1000]  train=0.044333  val=0.083253
Pretrain [237/1000]  train=0.047115  val=0.081278
Pretrain [238/1000]  train=0.043498  val=0.081755
Pretrain [239/1000]  train=0.043009  val=0.080552
Pretrain [240/1000]  train=0.044055  val=0.081804
Pretrain [241/1000]  train=0.042104  val=0.080119
Pretrain [242/1000]  train=0.043085  val=0.080325
Pretrain [243/1000]  train=0.043352  val=0.077106
Pretrain [244/1000]  train=0.041439  val=0.079200
Pretrain [245/1000]  train=0.041758  val=0.075962
Pretrain [246/1000]  train=0.040453  val=0.080409
Pretrain [247/1000]  train=0.042005  val=0.080902
Pretrain [248/1000]  train=0.040716  val=0.080250
Pretrain [249/1000]  train=0.040461  val=0.080848
Pretrain [250/1000]  train=0.041789  val=0.079151
Pretrain [251/1000]  train=0.040336  val=0.075475
Pretrain [252/1000]  train=0.040975  val=0.080871
Pretrain [253/1000]  train=0.038616  val=0.077904
Pretrain [254/1000]  train=0.040758  val=0.077797
Pretrain [255/1000]  train=0.039836  val=0.076544
Pretrain [256/1000]  train=0.038044  val=0.080325
Pretrain [257/1000]  train=0.039410  val=0.080632
Pretrain [258/1000]  train=0.039075  val=0.079584
Pretrain [259/1000]  train=0.037083  val=0.079201
Pretrain [260/1000]  train=0.036721  val=0.077859
Pretrain [261/1000]  train=0.036285  val=0.078192
Pretrain [262/1000]  train=0.037340  val=0.078824
Pretrain [263/1000]  train=0.037793  val=0.076703
Pretrain [264/1000]  train=0.037548  val=0.080187
Pretrain [265/1000]  train=0.039712  val=0.075675
Pretrain [266/1000]  train=0.037809  val=0.077353
Pretrain [267/1000]  train=0.035647  val=0.074687
Pretrain [268/1000]  train=0.037929  val=0.077855
Pretrain [269/1000]  train=0.037441  val=0.076472
Pretrain [270/1000]  train=0.036487  val=0.078878
Pretrain [271/1000]  train=0.037214  val=0.076397
Pretrain [272/1000]  train=0.035448  val=0.076940
Pretrain [273/1000]  train=0.037606  val=0.073847
Pretrain [274/1000]  train=0.035577  val=0.074152
Pretrain [275/1000]  train=0.033927  val=0.073801
Pretrain [276/1000]  train=0.034731  val=0.074521
Pretrain [277/1000]  train=0.036089  val=0.075447
Pretrain [278/1000]  train=0.033605  val=0.075439
Pretrain [279/1000]  train=0.032795  val=0.076536
Pretrain [280/1000]  train=0.035163  val=0.072515
Pretrain [281/1000]  train=0.034043  val=0.072706
Pretrain [282/1000]  train=0.033639  val=0.078133
Pretrain [283/1000]  train=0.033351  val=0.078238
Pretrain [284/1000]  train=0.033782  val=0.076152
Pretrain [285/1000]  train=0.032499  val=0.079310
Pretrain [286/1000]  train=0.031284  val=0.074627
Pretrain [287/1000]  train=0.031548  val=0.074142
Pretrain [288/1000]  train=0.031960  val=0.072147
Pretrain [289/1000]  train=0.032209  val=0.075446
Pretrain [290/1000]  train=0.031759  val=0.072235
Pretrain [291/1000]  train=0.031512  val=0.075925
Pretrain [292/1000]  train=0.032385  val=0.075279
Pretrain [293/1000]  train=0.032217  val=0.075520
Pretrain [294/1000]  train=0.031290  val=0.074417
Pretrain [295/1000]  train=0.030825  val=0.075385
Pretrain [296/1000]  train=0.030607  val=0.075101
Pretrain [297/1000]  train=0.030863  val=0.075715
Pretrain [298/1000]  train=0.030424  val=0.073758
Pretrain [299/1000]  train=0.029382  val=0.073125
Pretrain [300/1000]  train=0.029218  val=0.076808
Pretrain [301/1000]  train=0.029182  val=0.077160
Pretrain [302/1000]  train=0.029196  val=0.074522
Pretrain [303/1000]  train=0.028870  val=0.074551
Pretrain [304/1000]  train=0.028966  val=0.073813
Pretrain [305/1000]  train=0.028399  val=0.075711
Pretrain [306/1000]  train=0.031312  val=0.074222
Pretrain [307/1000]  train=0.029143  val=0.072856
Pretrain [308/1000]  train=0.029118  val=0.072698
Pretrain [309/1000]  train=0.027408  val=0.071865
Pretrain [310/1000]  train=0.028230  val=0.071891
Pretrain [311/1000]  train=0.029214  val=0.071941
Pretrain [312/1000]  train=0.027207  val=0.073411
Pretrain [313/1000]  train=0.028344  val=0.072244
Pretrain [314/1000]  train=0.026872  val=0.072085
Pretrain [315/1000]  train=0.027617  val=0.072949
Pretrain [316/1000]  train=0.026650  val=0.072227
Pretrain [317/1000]  train=0.026603  val=0.072508
Pretrain [318/1000]  train=0.026508  val=0.072361
Pretrain [319/1000]  train=0.026803  val=0.071187
Pretrain [320/1000]  train=0.025711  val=0.071313
Pretrain [321/1000]  train=0.027109  val=0.071061
Pretrain [322/1000]  train=0.025982  val=0.072034
Pretrain [323/1000]  train=0.026031  val=0.073490
Pretrain [324/1000]  train=0.026103  val=0.072997
Pretrain [325/1000]  train=0.024254  val=0.073173
Pretrain [326/1000]  train=0.024043  val=0.071855
Pretrain [327/1000]  train=0.024812  val=0.071910
Pretrain [328/1000]  train=0.024970  val=0.071247
Pretrain [329/1000]  train=0.024070  val=0.071481
Pretrain [330/1000]  train=0.025481  val=0.070594
Pretrain [331/1000]  train=0.024873  val=0.070661
Pretrain [332/1000]  train=0.024250  val=0.071463
Pretrain [333/1000]  train=0.025317  val=0.071637
Pretrain [334/1000]  train=0.023556  val=0.072015
Pretrain [335/1000]  train=0.023443  val=0.070273
Pretrain [336/1000]  train=0.023411  val=0.069119
Pretrain [337/1000]  train=0.023184  val=0.069533
Pretrain [338/1000]  train=0.023699  val=0.069032
Pretrain [339/1000]  train=0.023094  val=0.068066
Pretrain [340/1000]  train=0.023423  val=0.068421
Pretrain [341/1000]  train=0.023055  val=0.067782
Pretrain [342/1000]  train=0.023414  val=0.069080
Pretrain [343/1000]  train=0.022816  val=0.069259
Pretrain [344/1000]  train=0.021888  val=0.068063
Pretrain [345/1000]  train=0.021908  val=0.067601
Pretrain [346/1000]  train=0.022526  val=0.067838
Pretrain [347/1000]  train=0.022374  val=0.069101
Pretrain [348/1000]  train=0.022381  val=0.068031
Pretrain [349/1000]  train=0.022711  val=0.068996
Pretrain [350/1000]  train=0.022320  val=0.068601
Pretrain [351/1000]  train=0.023389  val=0.067990
Pretrain [352/1000]  train=0.020818  val=0.068611
Pretrain [353/1000]  train=0.020961  val=0.068560
Pretrain [354/1000]  train=0.021325  val=0.068349
Pretrain [355/1000]  train=0.022443  val=0.068533
Pretrain [356/1000]  train=0.022062  val=0.068282
Pretrain [357/1000]  train=0.022009  val=0.067614
Pretrain [358/1000]  train=0.021062  val=0.068149
Pretrain [359/1000]  train=0.021624  val=0.067316
Pretrain [360/1000]  train=0.021494  val=0.067935
  -> 验证未改进 200 次，早停。
[PRETRAIN] 最佳 val=0.066105 已保存。

--- [阶段二] 对齐微调 (NLL + α·(1−R2) + λ·CORAL) ---
Fine-tune [1/100000]  val_loss=0.334490
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [2/100000]  val_loss=0.194969
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [3/100000]  val_loss=0.059955
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [4/100000]  val_loss=-0.062814
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [5/100000]  val_loss=-0.151846
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [6/100000]  val_loss=-0.230504
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [7/100000]  val_loss=-0.296466
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [8/100000]  val_loss=-0.358194
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [9/100000]  val_loss=-0.411967
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [10/100000]  val_loss=-0.460932
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [11/100000]  val_loss=-0.508753
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [12/100000]  val_loss=-0.534936
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [13/100000]  val_loss=-0.574264
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [14/100000]  val_loss=-0.595878
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [15/100000]  val_loss=-0.628646
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [16/100000]  val_loss=-0.647403
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [17/100000]  val_loss=-0.657003
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [18/100000]  val_loss=-0.681824
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [19/100000]  val_loss=-0.705866
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [20/100000]  val_loss=-0.706401
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [21/100000]  val_loss=-0.723570
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [22/100000]  val_loss=-0.729255
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [23/100000]  val_loss=-0.731729
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [24/100000]  val_loss=-0.739028
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [25/100000]  val_loss=-0.749336
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [26/100000]  val_loss=-0.766218
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [27/100000]  val_loss=-0.766928
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [28/100000]  val_loss=-0.794186
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [29/100000]  val_loss=-0.778659
Fine-tune [30/100000]  val_loss=-0.783558
Fine-tune [31/100000]  val_loss=-0.791269
Fine-tune [32/100000]  val_loss=-0.817050
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [33/100000]  val_loss=-0.809925
Fine-tune [34/100000]  val_loss=-0.813873
Fine-tune [35/100000]  val_loss=-0.814283
Fine-tune [36/100000]  val_loss=-0.832592
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [37/100000]  val_loss=-0.834294
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [38/100000]  val_loss=-0.835501
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [39/100000]  val_loss=-0.839583
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [40/100000]  val_loss=-0.861987
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [41/100000]  val_loss=-0.852871
Fine-tune [42/100000]  val_loss=-0.860497
Fine-tune [43/100000]  val_loss=-0.857401
Fine-tune [44/100000]  val_loss=-0.858285
Fine-tune [45/100000]  val_loss=-0.859324
Fine-tune [46/100000]  val_loss=-0.858964
Fine-tune [47/100000]  val_loss=-0.858686
Fine-tune [48/100000]  val_loss=-0.861547
Fine-tune [49/100000]  val_loss=-0.881098
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [50/100000]  val_loss=-0.882578
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [51/100000]  val_loss=-0.870702
Fine-tune [52/100000]  val_loss=-0.897323
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [53/100000]  val_loss=-0.880346
Fine-tune [54/100000]  val_loss=-0.861790
Fine-tune [55/100000]  val_loss=-0.891074
Fine-tune [56/100000]  val_loss=-0.888906
Fine-tune [57/100000]  val_loss=-0.903343
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [58/100000]  val_loss=-0.908703
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [59/100000]  val_loss=-0.903135
Fine-tune [60/100000]  val_loss=-0.915582
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [61/100000]  val_loss=-0.896824
Fine-tune [62/100000]  val_loss=-0.903315
Fine-tune [63/100000]  val_loss=-0.889654
Fine-tune [64/100000]  val_loss=-0.897391
Fine-tune [65/100000]  val_loss=-0.919483
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [66/100000]  val_loss=-0.924698
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [67/100000]  val_loss=-0.906962
Fine-tune [68/100000]  val_loss=-0.921534
Fine-tune [69/100000]  val_loss=-0.923923
Fine-tune [70/100000]  val_loss=-0.926538
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [71/100000]  val_loss=-0.925405
Fine-tune [72/100000]  val_loss=-0.925365
Fine-tune [73/100000]  val_loss=-0.922314
Fine-tune [74/100000]  val_loss=-0.935179
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [75/100000]  val_loss=-0.931633
Fine-tune [76/100000]  val_loss=-0.939203
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [77/100000]  val_loss=-0.945597
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [78/100000]  val_loss=-0.947777
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [79/100000]  val_loss=-0.915432
Fine-tune [80/100000]  val_loss=-0.950956
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [81/100000]  val_loss=-0.924267
Fine-tune [82/100000]  val_loss=-0.948699
Fine-tune [83/100000]  val_loss=-0.938384
Fine-tune [84/100000]  val_loss=-0.930947
Fine-tune [85/100000]  val_loss=-0.942775
Fine-tune [86/100000]  val_loss=-0.930661
Fine-tune [87/100000]  val_loss=-0.933491
Fine-tune [88/100000]  val_loss=-0.943610
Fine-tune [89/100000]  val_loss=-0.930249
Fine-tune [90/100000]  val_loss=-0.931327
Fine-tune [91/100000]  val_loss=-0.943991
Fine-tune [92/100000]  val_loss=-0.952584
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [93/100000]  val_loss=-0.952660
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [94/100000]  val_loss=-0.961586
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [95/100000]  val_loss=-0.951438
Fine-tune [96/100000]  val_loss=-0.939543
Fine-tune [97/100000]  val_loss=-0.959341
Fine-tune [98/100000]  val_loss=-0.943901
Fine-tune [99/100000]  val_loss=-0.954760
Fine-tune [100/100000]  val_loss=-0.937851
Fine-tune [101/100000]  val_loss=-0.975736
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [102/100000]  val_loss=-0.977301
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [103/100000]  val_loss=-0.952725
Fine-tune [104/100000]  val_loss=-0.956213
Fine-tune [105/100000]  val_loss=-0.936392
Fine-tune [106/100000]  val_loss=-0.941931
Fine-tune [107/100000]  val_loss=-0.939252
Fine-tune [108/100000]  val_loss=-0.935904
Fine-tune [109/100000]  val_loss=-0.959590
Fine-tune [110/100000]  val_loss=-0.958179
Fine-tune [111/100000]  val_loss=-0.957611
Fine-tune [112/100000]  val_loss=-0.962692
Fine-tune [113/100000]  val_loss=-0.964334
Fine-tune [114/100000]  val_loss=-0.947886
Fine-tune [115/100000]  val_loss=-0.975166
Fine-tune [116/100000]  val_loss=-0.968550
Fine-tune [117/100000]  val_loss=-0.983178
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [118/100000]  val_loss=-0.963127
Fine-tune [119/100000]  val_loss=-0.956485
Fine-tune [120/100000]  val_loss=-0.954616
Fine-tune [121/100000]  val_loss=-0.950654
Fine-tune [122/100000]  val_loss=-0.964347
Fine-tune [123/100000]  val_loss=-0.955615
Fine-tune [124/100000]  val_loss=-0.958134
Fine-tune [125/100000]  val_loss=-0.982625
Fine-tune [126/100000]  val_loss=-0.960604
Fine-tune [127/100000]  val_loss=-0.952985
Fine-tune [128/100000]  val_loss=-0.951409
Fine-tune [129/100000]  val_loss=-0.953568
Fine-tune [130/100000]  val_loss=-0.968844
Fine-tune [131/100000]  val_loss=-0.966395
Fine-tune [132/100000]  val_loss=-0.995118
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [133/100000]  val_loss=-0.983154
Fine-tune [134/100000]  val_loss=-0.974178
Fine-tune [135/100000]  val_loss=-0.972918
Fine-tune [136/100000]  val_loss=-0.960521
Fine-tune [137/100000]  val_loss=-0.967981
Fine-tune [138/100000]  val_loss=-0.970698
Fine-tune [139/100000]  val_loss=-0.957171
Fine-tune [140/100000]  val_loss=-0.967692
Fine-tune [141/100000]  val_loss=-0.969007
Fine-tune [142/100000]  val_loss=-0.954772
Fine-tune [143/100000]  val_loss=-0.956761
Fine-tune [144/100000]  val_loss=-0.956164
Fine-tune [145/100000]  val_loss=-0.964646
Fine-tune [146/100000]  val_loss=-0.946010
Fine-tune [147/100000]  val_loss=-0.958817
Fine-tune [148/100000]  val_loss=-0.980134
Fine-tune [149/100000]  val_loss=-0.978027
Fine-tune [150/100000]  val_loss=-0.962032
Fine-tune [151/100000]  val_loss=-0.974212
Fine-tune [152/100000]  val_loss=-0.954749
Fine-tune [153/100000]  val_loss=-0.972772
Fine-tune [154/100000]  val_loss=-0.951358
Fine-tune [155/100000]  val_loss=-0.975894
Fine-tune [156/100000]  val_loss=-0.958920
Fine-tune [157/100000]  val_loss=-0.981014
Fine-tune [158/100000]  val_loss=-0.953373
Fine-tune [159/100000]  val_loss=-0.963595
Fine-tune [160/100000]  val_loss=-0.957685
Fine-tune [161/100000]  val_loss=-0.969906
Fine-tune [162/100000]  val_loss=-0.958262
Fine-tune [163/100000]  val_loss=-0.951918
Fine-tune [164/100000]  val_loss=-0.935649
Fine-tune [165/100000]  val_loss=-0.954209
Fine-tune [166/100000]  val_loss=-0.968357
Fine-tune [167/100000]  val_loss=-0.976349
Fine-tune [168/100000]  val_loss=-0.984231
Fine-tune [169/100000]  val_loss=-0.944188
Fine-tune [170/100000]  val_loss=-0.963536
Fine-tune [171/100000]  val_loss=-0.978149
Fine-tune [172/100000]  val_loss=-0.981918
Fine-tune [173/100000]  val_loss=-0.933875
Fine-tune [174/100000]  val_loss=-0.964192
Fine-tune [175/100000]  val_loss=-0.954967
Fine-tune [176/100000]  val_loss=-0.976879
Fine-tune [177/100000]  val_loss=-0.948943
Fine-tune [178/100000]  val_loss=-0.956012
Fine-tune [179/100000]  val_loss=-0.972114
Fine-tune [180/100000]  val_loss=-0.952981
Fine-tune [181/100000]  val_loss=-0.974869
Fine-tune [182/100000]  val_loss=-0.946386
Fine-tune [183/100000]  val_loss=-0.963640
Fine-tune [184/100000]  val_loss=-0.957443
Fine-tune [185/100000]  val_loss=-0.984125
Fine-tune [186/100000]  val_loss=-0.964964
Fine-tune [187/100000]  val_loss=-0.939191
Fine-tune [188/100000]  val_loss=-0.944085
Fine-tune [189/100000]  val_loss=-0.943725
Fine-tune [190/100000]  val_loss=-0.947773
Fine-tune [191/100000]  val_loss=-0.938157
Fine-tune [192/100000]  val_loss=-0.948273
Fine-tune [193/100000]  val_loss=-0.948327
Fine-tune [194/100000]  val_loss=-0.937842
Fine-tune [195/100000]  val_loss=-0.942167
Fine-tune [196/100000]  val_loss=-0.935575
Fine-tune [197/100000]  val_loss=-0.952176
Fine-tune [198/100000]  val_loss=-0.938374
Fine-tune [199/100000]  val_loss=-0.944218
Fine-tune [200/100000]  val_loss=-0.935089
Fine-tune [201/100000]  val_loss=-0.946042
Fine-tune [202/100000]  val_loss=-0.926901
Fine-tune [203/100000]  val_loss=-0.946318
Fine-tune [204/100000]  val_loss=-0.935722
Fine-tune [205/100000]  val_loss=-0.943650
Fine-tune [206/100000]  val_loss=-0.931994
Fine-tune [207/100000]  val_loss=-0.933255
Fine-tune [208/100000]  val_loss=-0.950902
Fine-tune [209/100000]  val_loss=-0.951725
Fine-tune [210/100000]  val_loss=-0.945177
Fine-tune [211/100000]  val_loss=-0.941328
Fine-tune [212/100000]  val_loss=-0.946528
Fine-tune [213/100000]  val_loss=-0.952566
Fine-tune [214/100000]  val_loss=-0.940165
Fine-tune [215/100000]  val_loss=-0.945154
Fine-tune [216/100000]  val_loss=-0.940043
Fine-tune [217/100000]  val_loss=-0.979694
Fine-tune [218/100000]  val_loss=-0.958634
Fine-tune [219/100000]  val_loss=-0.941525
Fine-tune [220/100000]  val_loss=-0.947623
Fine-tune [221/100000]  val_loss=-0.950900
Fine-tune [222/100000]  val_loss=-0.926793
Fine-tune [223/100000]  val_loss=-0.954619
Fine-tune [224/100000]  val_loss=-0.953882
Fine-tune [225/100000]  val_loss=-0.973757
Fine-tune [226/100000]  val_loss=-0.952558
Fine-tune [227/100000]  val_loss=-0.965904
Fine-tune [228/100000]  val_loss=-0.964322
Fine-tune [229/100000]  val_loss=-0.943529
Fine-tune [230/100000]  val_loss=-0.954978
Fine-tune [231/100000]  val_loss=-0.923800
Fine-tune [232/100000]  val_loss=-0.957220
Fine-tune [233/100000]  val_loss=-0.939946
Fine-tune [234/100000]  val_loss=-0.956770
Fine-tune [235/100000]  val_loss=-0.960423
Fine-tune [236/100000]  val_loss=-0.937203
Fine-tune [237/100000]  val_loss=-0.935113
Fine-tune [238/100000]  val_loss=-0.921282
Fine-tune [239/100000]  val_loss=-0.943578
Fine-tune [240/100000]  val_loss=-0.951910
Fine-tune [241/100000]  val_loss=-0.971173
Fine-tune [242/100000]  val_loss=-0.953808
Fine-tune [243/100000]  val_loss=-0.956651
Fine-tune [244/100000]  val_loss=-0.971982
Fine-tune [245/100000]  val_loss=-0.954917
Fine-tune [246/100000]  val_loss=-0.936162
Fine-tune [247/100000]  val_loss=-0.942859
Fine-tune [248/100000]  val_loss=-0.958670
Fine-tune [249/100000]  val_loss=-0.958394
Fine-tune [250/100000]  val_loss=-0.952001
Fine-tune [251/100000]  val_loss=-0.961947
Fine-tune [252/100000]  val_loss=-0.935143
Fine-tune [253/100000]  val_loss=-0.945168
Fine-tune [254/100000]  val_loss=-0.934361
Fine-tune [255/100000]  val_loss=-0.955616
Fine-tune [256/100000]  val_loss=-0.917805
Fine-tune [257/100000]  val_loss=-0.934709
Fine-tune [258/100000]  val_loss=-0.955336
Fine-tune [259/100000]  val_loss=-0.949997
Fine-tune [260/100000]  val_loss=-0.948535
Fine-tune [261/100000]  val_loss=-0.995746
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L3/finetuned.pth
Fine-tune [262/100000]  val_loss=-0.987084
Fine-tune [263/100000]  val_loss=-0.975552
Fine-tune [264/100000]  val_loss=-0.968423
Fine-tune [265/100000]  val_loss=-0.975492
Fine-tune [266/100000]  val_loss=-0.978765
Fine-tune [267/100000]  val_loss=-0.959269
Fine-tune [268/100000]  val_loss=-0.959197
Fine-tune [269/100000]  val_loss=-0.929663
Fine-tune [270/100000]  val_loss=-0.937752
Fine-tune [271/100000]  val_loss=-0.926654
Fine-tune [272/100000]  val_loss=-0.938133
Fine-tune [273/100000]  val_loss=-0.907109
Fine-tune [274/100000]  val_loss=-0.965396
Fine-tune [275/100000]  val_loss=-0.897235
Fine-tune [276/100000]  val_loss=-0.954276
Fine-tune [277/100000]  val_loss=-0.943515
Fine-tune [278/100000]  val_loss=-0.956416
Fine-tune [279/100000]  val_loss=-0.943407
Fine-tune [280/100000]  val_loss=-0.970682
Fine-tune [281/100000]  val_loss=-0.957539
Fine-tune [282/100000]  val_loss=-0.949434
Fine-tune [283/100000]  val_loss=-0.962549
Fine-tune [284/100000]  val_loss=-0.949245
Fine-tune [285/100000]  val_loss=-0.929341
Fine-tune [286/100000]  val_loss=-0.917326
Fine-tune [287/100000]  val_loss=-0.960420
Fine-tune [288/100000]  val_loss=-0.927589
Fine-tune [289/100000]  val_loss=-0.927279
Fine-tune [290/100000]  val_loss=-0.941676
Fine-tune [291/100000]  val_loss=-0.929319
Fine-tune [292/100000]  val_loss=-0.941100
Fine-tune [293/100000]  val_loss=-0.913477
Fine-tune [294/100000]  val_loss=-0.909218
Fine-tune [295/100000]  val_loss=-0.877027
Fine-tune [296/100000]  val_loss=-0.932896
Fine-tune [297/100000]  val_loss=-0.951931
Fine-tune [298/100000]  val_loss=-0.927960
Fine-tune [299/100000]  val_loss=-0.921288
Fine-tune [300/100000]  val_loss=-0.918789
Fine-tune [301/100000]  val_loss=-0.885299
Fine-tune [302/100000]  val_loss=-0.928855
Fine-tune [303/100000]  val_loss=-0.914969
Fine-tune [304/100000]  val_loss=-0.913247
Fine-tune [305/100000]  val_loss=-0.913771
Fine-tune [306/100000]  val_loss=-0.929928
Fine-tune [307/100000]  val_loss=-0.917334
Fine-tune [308/100000]  val_loss=-0.917869
Fine-tune [309/100000]  val_loss=-0.925229
Fine-tune [310/100000]  val_loss=-0.924076
Fine-tune [311/100000]  val_loss=-0.910767
Fine-tune [312/100000]  val_loss=-0.932118
Fine-tune [313/100000]  val_loss=-0.897959
Fine-tune [314/100000]  val_loss=-0.928197
Fine-tune [315/100000]  val_loss=-0.918772
Fine-tune [316/100000]  val_loss=-0.910116
Fine-tune [317/100000]  val_loss=-0.872425
Fine-tune [318/100000]  val_loss=-0.897107
Fine-tune [319/100000]  val_loss=-0.920784
Fine-tune [320/100000]  val_loss=-0.922173
Fine-tune [321/100000]  val_loss=-0.925395
Fine-tune [322/100000]  val_loss=-0.924005
Fine-tune [323/100000]  val_loss=-0.906330
Fine-tune [324/100000]  val_loss=-0.933546
Fine-tune [325/100000]  val_loss=-0.892394
Fine-tune [326/100000]  val_loss=-0.925510
Fine-tune [327/100000]  val_loss=-0.905205
Fine-tune [328/100000]  val_loss=-0.891805
Fine-tune [329/100000]  val_loss=-0.910387
Fine-tune [330/100000]  val_loss=-0.895185
Fine-tune [331/100000]  val_loss=-0.909984
Fine-tune [332/100000]  val_loss=-0.922938
Fine-tune [333/100000]  val_loss=-0.906141
Fine-tune [334/100000]  val_loss=-0.919734
Fine-tune [335/100000]  val_loss=-0.871358
Fine-tune [336/100000]  val_loss=-0.902930
Fine-tune [337/100000]  val_loss=-0.883115
Fine-tune [338/100000]  val_loss=-0.882931
Fine-tune [339/100000]  val_loss=-0.873481
Fine-tune [340/100000]  val_loss=-0.899391
Fine-tune [341/100000]  val_loss=-0.906367
Fine-tune [342/100000]  val_loss=-0.917314
Fine-tune [343/100000]  val_loss=-0.910526
Fine-tune [344/100000]  val_loss=-0.898511
Fine-tune [345/100000]  val_loss=-0.920757
Fine-tune [346/100000]  val_loss=-0.920842
Fine-tune [347/100000]  val_loss=-0.913132
Fine-tune [348/100000]  val_loss=-0.915412
Fine-tune [349/100000]  val_loss=-0.907037
Fine-tune [350/100000]  val_loss=-0.908771
Fine-tune [351/100000]  val_loss=-0.871683
Fine-tune [352/100000]  val_loss=-0.862344
Fine-tune [353/100000]  val_loss=-0.868700
Fine-tune [354/100000]  val_loss=-0.878518
Fine-tune [355/100000]  val_loss=-0.878716
Fine-tune [356/100000]  val_loss=-0.884890
Fine-tune [357/100000]  val_loss=-0.920107
Fine-tune [358/100000]  val_loss=-0.928695
Fine-tune [359/100000]  val_loss=-0.924127
Fine-tune [360/100000]  val_loss=-0.917757
Fine-tune [361/100000]  val_loss=-0.859574
Fine-tune [362/100000]  val_loss=-0.818811
Fine-tune [363/100000]  val_loss=-0.863603
Fine-tune [364/100000]  val_loss=-0.878177
Fine-tune [365/100000]  val_loss=-0.821968
Fine-tune [366/100000]  val_loss=-0.872010
Fine-tune [367/100000]  val_loss=-0.866295
Fine-tune [368/100000]  val_loss=-0.898054
Fine-tune [369/100000]  val_loss=-0.853497
Fine-tune [370/100000]  val_loss=-0.834789
Fine-tune [371/100000]  val_loss=-0.842543
Fine-tune [372/100000]  val_loss=-0.864605
Fine-tune [373/100000]  val_loss=-0.869022
Fine-tune [374/100000]  val_loss=-0.858172
Fine-tune [375/100000]  val_loss=-0.933702
Fine-tune [376/100000]  val_loss=-0.898124
Fine-tune [377/100000]  val_loss=-0.900594
Fine-tune [378/100000]  val_loss=-0.895593
Fine-tune [379/100000]  val_loss=-0.848807
Fine-tune [380/100000]  val_loss=-0.877854
Fine-tune [381/100000]  val_loss=-0.853784
Fine-tune [382/100000]  val_loss=-0.845711
Fine-tune [383/100000]  val_loss=-0.838836
Fine-tune [384/100000]  val_loss=-0.875238
Fine-tune [385/100000]  val_loss=-0.862498
Fine-tune [386/100000]  val_loss=-0.880331
Fine-tune [387/100000]  val_loss=-0.846830
Fine-tune [388/100000]  val_loss=-0.826539
Fine-tune [389/100000]  val_loss=-0.851638
Fine-tune [390/100000]  val_loss=-0.875308
Fine-tune [391/100000]  val_loss=-0.854080
Fine-tune [392/100000]  val_loss=-0.874306
Fine-tune [393/100000]  val_loss=-0.898924
Fine-tune [394/100000]  val_loss=-0.861984
Fine-tune [395/100000]  val_loss=-0.880356
Fine-tune [396/100000]  val_loss=-0.849282
Fine-tune [397/100000]  val_loss=-0.869650
Fine-tune [398/100000]  val_loss=-0.831789
Fine-tune [399/100000]  val_loss=-0.864678
Fine-tune [400/100000]  val_loss=-0.869340
Fine-tune [401/100000]  val_loss=-0.855562
Fine-tune [402/100000]  val_loss=-0.865870
Fine-tune [403/100000]  val_loss=-0.845215
Fine-tune [404/100000]  val_loss=-0.838534
Fine-tune [405/100000]  val_loss=-0.839630
Fine-tune [406/100000]  val_loss=-0.830583
Fine-tune [407/100000]  val_loss=-0.784248
Fine-tune [408/100000]  val_loss=-0.869827
Fine-tune [409/100000]  val_loss=-0.827306
Fine-tune [410/100000]  val_loss=-0.856498
Fine-tune [411/100000]  val_loss=-0.874276
Fine-tune [412/100000]  val_loss=-0.887861
Fine-tune [413/100000]  val_loss=-0.845963
Fine-tune [414/100000]  val_loss=-0.874945
Fine-tune [415/100000]  val_loss=-0.847696
Fine-tune [416/100000]  val_loss=-0.832304
Fine-tune [417/100000]  val_loss=-0.835654
Fine-tune [418/100000]  val_loss=-0.852766
Fine-tune [419/100000]  val_loss=-0.848866
Fine-tune [420/100000]  val_loss=-0.866121
Fine-tune [421/100000]  val_loss=-0.843117
Fine-tune [422/100000]  val_loss=-0.801577
Fine-tune [423/100000]  val_loss=-0.820111
Fine-tune [424/100000]  val_loss=-0.851228
Fine-tune [425/100000]  val_loss=-0.815682
Fine-tune [426/100000]  val_loss=-0.853118
Fine-tune [427/100000]  val_loss=-0.850124
Fine-tune [428/100000]  val_loss=-0.839707
Fine-tune [429/100000]  val_loss=-0.863809
Fine-tune [430/100000]  val_loss=-0.841385
Fine-tune [431/100000]  val_loss=-0.785105
Fine-tune [432/100000]  val_loss=-0.805971
Fine-tune [433/100000]  val_loss=-0.768633
Fine-tune [434/100000]  val_loss=-0.782617
Fine-tune [435/100000]  val_loss=-0.763778
Fine-tune [436/100000]  val_loss=-0.817333
Fine-tune [437/100000]  val_loss=-0.817878
Fine-tune [438/100000]  val_loss=-0.799585
Fine-tune [439/100000]  val_loss=-0.774623
Fine-tune [440/100000]  val_loss=-0.801682
Fine-tune [441/100000]  val_loss=-0.795505
Fine-tune [442/100000]  val_loss=-0.786285
Fine-tune [443/100000]  val_loss=-0.794445
Fine-tune [444/100000]  val_loss=-0.813779
Fine-tune [445/100000]  val_loss=-0.791683
Fine-tune [446/100000]  val_loss=-0.798078
Fine-tune [447/100000]  val_loss=-0.788884
Fine-tune [448/100000]  val_loss=-0.780979
Fine-tune [449/100000]  val_loss=-0.796845
Fine-tune [450/100000]  val_loss=-0.837043
Fine-tune [451/100000]  val_loss=-0.801663
Fine-tune [452/100000]  val_loss=-0.810677
Fine-tune [453/100000]  val_loss=-0.790603
Fine-tune [454/100000]  val_loss=-0.831142
Fine-tune [455/100000]  val_loss=-0.788697
Fine-tune [456/100000]  val_loss=-0.797223
Fine-tune [457/100000]  val_loss=-0.823364
Fine-tune [458/100000]  val_loss=-0.824242
Fine-tune [459/100000]  val_loss=-0.819023
Fine-tune [460/100000]  val_loss=-0.824101
Fine-tune [461/100000]  val_loss=-0.797071
Fine-tune [462/100000]  val_loss=-0.774366
Fine-tune [463/100000]  val_loss=-0.788430
Fine-tune [464/100000]  val_loss=-0.799285
Fine-tune [465/100000]  val_loss=-0.738817
Fine-tune [466/100000]  val_loss=-0.798648
Fine-tune [467/100000]  val_loss=-0.817733
Fine-tune [468/100000]  val_loss=-0.796287
Fine-tune [469/100000]  val_loss=-0.763535
Fine-tune [470/100000]  val_loss=-0.723670
Fine-tune [471/100000]  val_loss=-0.762920
Fine-tune [472/100000]  val_loss=-0.763478
Fine-tune [473/100000]  val_loss=-0.702271
Fine-tune [474/100000]  val_loss=-0.726966
Fine-tune [475/100000]  val_loss=-0.771695
Fine-tune [476/100000]  val_loss=-0.740713
Fine-tune [477/100000]  val_loss=-0.782203
Fine-tune [478/100000]  val_loss=-0.755139
Fine-tune [479/100000]  val_loss=-0.762959
Fine-tune [480/100000]  val_loss=-0.761294
Fine-tune [481/100000]  val_loss=-0.756878
Fine-tune [482/100000]  val_loss=-0.764708
Fine-tune [483/100000]  val_loss=-0.775490
Fine-tune [484/100000]  val_loss=-0.764649
Fine-tune [485/100000]  val_loss=-0.732948
Fine-tune [486/100000]  val_loss=-0.705748
Fine-tune [487/100000]  val_loss=-0.738787
Fine-tune [488/100000]  val_loss=-0.740790
Fine-tune [489/100000]  val_loss=-0.762764
Fine-tune [490/100000]  val_loss=-0.723727
Fine-tune [491/100000]  val_loss=-0.764311
Fine-tune [492/100000]  val_loss=-0.734447
Fine-tune [493/100000]  val_loss=-0.772755
Fine-tune [494/100000]  val_loss=-0.757115
Fine-tune [495/100000]  val_loss=-0.755827
Fine-tune [496/100000]  val_loss=-0.731492
Fine-tune [497/100000]  val_loss=-0.750225
Fine-tune [498/100000]  val_loss=-0.749290
Fine-tune [499/100000]  val_loss=-0.788849
Fine-tune [500/100000]  val_loss=-0.775962
Fine-tune [501/100000]  val_loss=-0.750527
Fine-tune [502/100000]  val_loss=-0.769902
Fine-tune [503/100000]  val_loss=-0.775161
Fine-tune [504/100000]  val_loss=-0.776434
Fine-tune [505/100000]  val_loss=-0.784011
Fine-tune [506/100000]  val_loss=-0.795380
Fine-tune [507/100000]  val_loss=-0.787860
Fine-tune [508/100000]  val_loss=-0.774899
Fine-tune [509/100000]  val_loss=-0.763890
Fine-tune [510/100000]  val_loss=-0.789432
Fine-tune [511/100000]  val_loss=-0.776983
Fine-tune [512/100000]  val_loss=-0.799956
Fine-tune [513/100000]  val_loss=-0.768943
Fine-tune [514/100000]  val_loss=-0.747361
Fine-tune [515/100000]  val_loss=-0.752420
Fine-tune [516/100000]  val_loss=-0.710172
Fine-tune [517/100000]  val_loss=-0.732750
Fine-tune [518/100000]  val_loss=-0.748720
Fine-tune [519/100000]  val_loss=-0.797747
Fine-tune [520/100000]  val_loss=-0.801289
Fine-tune [521/100000]  val_loss=-0.778135
Fine-tune [522/100000]  val_loss=-0.792495
Fine-tune [523/100000]  val_loss=-0.739445
Fine-tune [524/100000]  val_loss=-0.764294
Fine-tune [525/100000]  val_loss=-0.743420
Fine-tune [526/100000]  val_loss=-0.747191
Fine-tune [527/100000]  val_loss=-0.778973
Fine-tune [528/100000]  val_loss=-0.750261
Fine-tune [529/100000]  val_loss=-0.761210
Fine-tune [530/100000]  val_loss=-0.743401
Fine-tune [531/100000]  val_loss=-0.716021
Fine-tune [532/100000]  val_loss=-0.739520
Fine-tune [533/100000]  val_loss=-0.723525
Fine-tune [534/100000]  val_loss=-0.726319
Fine-tune [535/100000]  val_loss=-0.730297
Fine-tune [536/100000]  val_loss=-0.745651
Fine-tune [537/100000]  val_loss=-0.700163
Fine-tune [538/100000]  val_loss=-0.700479
Fine-tune [539/100000]  val_loss=-0.734268
Fine-tune [540/100000]  val_loss=-0.767053
Fine-tune [541/100000]  val_loss=-0.744224
Fine-tune [542/100000]  val_loss=-0.711441
Fine-tune [543/100000]  val_loss=-0.750816
Fine-tune [544/100000]  val_loss=-0.713162
Fine-tune [545/100000]  val_loss=-0.734182
Fine-tune [546/100000]  val_loss=-0.720415
Fine-tune [547/100000]  val_loss=-0.745713
Fine-tune [548/100000]  val_loss=-0.740090
Fine-tune [549/100000]  val_loss=-0.706798
Fine-tune [550/100000]  val_loss=-0.746695
Fine-tune [551/100000]  val_loss=-0.752351
Fine-tune [552/100000]  val_loss=-0.712072
Fine-tune [553/100000]  val_loss=-0.690286
Fine-tune [554/100000]  val_loss=-0.688884
Fine-tune [555/100000]  val_loss=-0.647572
Fine-tune [556/100000]  val_loss=-0.656196
Fine-tune [557/100000]  val_loss=-0.678029
Fine-tune [558/100000]  val_loss=-0.652334
Fine-tune [559/100000]  val_loss=-0.671123
Fine-tune [560/100000]  val_loss=-0.675689
Fine-tune [561/100000]  val_loss=-0.690895
Fine-tune [562/100000]  val_loss=-0.681634
Fine-tune [563/100000]  val_loss=-0.669089
Fine-tune [564/100000]  val_loss=-0.671654
Fine-tune [565/100000]  val_loss=-0.686729
Fine-tune [566/100000]  val_loss=-0.674706
Fine-tune [567/100000]  val_loss=-0.679447
Fine-tune [568/100000]  val_loss=-0.685257
Fine-tune [569/100000]  val_loss=-0.672426
Fine-tune [570/100000]  val_loss=-0.687266
Fine-tune [571/100000]  val_loss=-0.637288
Fine-tune [572/100000]  val_loss=-0.637195
Fine-tune [573/100000]  val_loss=-0.681141
Fine-tune [574/100000]  val_loss=-0.703476
Fine-tune [575/100000]  val_loss=-0.695437
Fine-tune [576/100000]  val_loss=-0.698545
Fine-tune [577/100000]  val_loss=-0.747699
Fine-tune [578/100000]  val_loss=-0.678502
Fine-tune [579/100000]  val_loss=-0.659822
Fine-tune [580/100000]  val_loss=-0.680998
Fine-tune [581/100000]  val_loss=-0.681916
Fine-tune [582/100000]  val_loss=-0.672637
Fine-tune [583/100000]  val_loss=-0.647665
Fine-tune [584/100000]  val_loss=-0.684609
Fine-tune [585/100000]  val_loss=-0.704347
Fine-tune [586/100000]  val_loss=-0.740745
Fine-tune [587/100000]  val_loss=-0.728496
Fine-tune [588/100000]  val_loss=-0.688827
Fine-tune [589/100000]  val_loss=-0.704804
Fine-tune [590/100000]  val_loss=-0.676805
Fine-tune [591/100000]  val_loss=-0.656241
Fine-tune [592/100000]  val_loss=-0.641059
Fine-tune [593/100000]  val_loss=-0.647001
Fine-tune [594/100000]  val_loss=-0.674049
Fine-tune [595/100000]  val_loss=-0.692004
Fine-tune [596/100000]  val_loss=-0.688866
Fine-tune [597/100000]  val_loss=-0.667995
Fine-tune [598/100000]  val_loss=-0.661839
Fine-tune [599/100000]  val_loss=-0.655308
Fine-tune [600/100000]  val_loss=-0.641747
Fine-tune [601/100000]  val_loss=-0.615354
Fine-tune [602/100000]  val_loss=-0.593277
Fine-tune [603/100000]  val_loss=-0.607003
Fine-tune [604/100000]  val_loss=-0.669870
Fine-tune [605/100000]  val_loss=-0.655241
Fine-tune [606/100000]  val_loss=-0.609883
Fine-tune [607/100000]  val_loss=-0.657806
Fine-tune [608/100000]  val_loss=-0.611789
Fine-tune [609/100000]  val_loss=-0.647624
Fine-tune [610/100000]  val_loss=-0.601651
Fine-tune [611/100000]  val_loss=-0.561394
Fine-tune [612/100000]  val_loss=-0.647582
Fine-tune [613/100000]  val_loss=-0.650079
Fine-tune [614/100000]  val_loss=-0.653295
Fine-tune [615/100000]  val_loss=-0.646518
Fine-tune [616/100000]  val_loss=-0.651231
Fine-tune [617/100000]  val_loss=-0.656693
Fine-tune [618/100000]  val_loss=-0.662382
Fine-tune [619/100000]  val_loss=-0.645092
Fine-tune [620/100000]  val_loss=-0.639284
Fine-tune [621/100000]  val_loss=-0.655613
Fine-tune [622/100000]  val_loss=-0.665179
Fine-tune [623/100000]  val_loss=-0.662127
Fine-tune [624/100000]  val_loss=-0.637232
Fine-tune [625/100000]  val_loss=-0.662980
Fine-tune [626/100000]  val_loss=-0.619175
Fine-tune [627/100000]  val_loss=-0.653467
Fine-tune [628/100000]  val_loss=-0.596289
Fine-tune [629/100000]  val_loss=-0.625483
Fine-tune [630/100000]  val_loss=-0.617203
Fine-tune [631/100000]  val_loss=-0.615752
Fine-tune [632/100000]  val_loss=-0.585634
Fine-tune [633/100000]  val_loss=-0.589442
Fine-tune [634/100000]  val_loss=-0.581759
Fine-tune [635/100000]  val_loss=-0.537034
Fine-tune [636/100000]  val_loss=-0.585016
Fine-tune [637/100000]  val_loss=-0.618073
Fine-tune [638/100000]  val_loss=-0.606509
Fine-tune [639/100000]  val_loss=-0.629787
Fine-tune [640/100000]  val_loss=-0.639819
Fine-tune [641/100000]  val_loss=-0.596827
Fine-tune [642/100000]  val_loss=-0.544751
Fine-tune [643/100000]  val_loss=-0.594023
Fine-tune [644/100000]  val_loss=-0.570193
Fine-tune [645/100000]  val_loss=-0.579870
Fine-tune [646/100000]  val_loss=-0.605370
Fine-tune [647/100000]  val_loss=-0.597377
Fine-tune [648/100000]  val_loss=-0.616661
Fine-tune [649/100000]  val_loss=-0.624055
Fine-tune [650/100000]  val_loss=-0.575498
Fine-tune [651/100000]  val_loss=-0.587920
Fine-tune [652/100000]  val_loss=-0.491647
Fine-tune [653/100000]  val_loss=-0.602744
Fine-tune [654/100000]  val_loss=-0.604621
Fine-tune [655/100000]  val_loss=-0.583210
Fine-tune [656/100000]  val_loss=-0.554162
Fine-tune [657/100000]  val_loss=-0.583776
Fine-tune [658/100000]  val_loss=-0.573438
Fine-tune [659/100000]  val_loss=-0.605314
Fine-tune [660/100000]  val_loss=-0.589565
Fine-tune [661/100000]  val_loss=-0.572587
Fine-tune [662/100000]  val_loss=-0.642760
Fine-tune [663/100000]  val_loss=-0.616457
Fine-tune [664/100000]  val_loss=-0.608618
Fine-tune [665/100000]  val_loss=-0.555967
Fine-tune [666/100000]  val_loss=-0.554410
Fine-tune [667/100000]  val_loss=-0.555675
Fine-tune [668/100000]  val_loss=-0.561454
Fine-tune [669/100000]  val_loss=-0.615650
Fine-tune [670/100000]  val_loss=-0.595807
Fine-tune [671/100000]  val_loss=-0.627211
Fine-tune [672/100000]  val_loss=-0.629512
Fine-tune [673/100000]  val_loss=-0.622298
Fine-tune [674/100000]  val_loss=-0.586876
Fine-tune [675/100000]  val_loss=-0.563415
Fine-tune [676/100000]  val_loss=-0.534278
Fine-tune [677/100000]  val_loss=-0.575745
Fine-tune [678/100000]  val_loss=-0.527295
Fine-tune [679/100000]  val_loss=-0.560492
Fine-tune [680/100000]  val_loss=-0.532868
Fine-tune [681/100000]  val_loss=-0.486533
Fine-tune [682/100000]  val_loss=-0.534994
Fine-tune [683/100000]  val_loss=-0.530529
Fine-tune [684/100000]  val_loss=-0.588295
Fine-tune [685/100000]  val_loss=-0.562347
Fine-tune [686/100000]  val_loss=-0.552135
Fine-tune [687/100000]  val_loss=-0.587883
Fine-tune [688/100000]  val_loss=-0.583864
Fine-tune [689/100000]  val_loss=-0.591841
Fine-tune [690/100000]  val_loss=-0.567400
Fine-tune [691/100000]  val_loss=-0.518473
Fine-tune [692/100000]  val_loss=-0.542305
Fine-tune [693/100000]  val_loss=-0.590677
Fine-tune [694/100000]  val_loss=-0.612545
Fine-tune [695/100000]  val_loss=-0.603901
Fine-tune [696/100000]  val_loss=-0.550466
Fine-tune [697/100000]  val_loss=-0.495822
Fine-tune [698/100000]  val_loss=-0.575499
Fine-tune [699/100000]  val_loss=-0.566576
Fine-tune [700/100000]  val_loss=-0.533467
Fine-tune [701/100000]  val_loss=-0.574944
Fine-tune [702/100000]  val_loss=-0.564161
Fine-tune [703/100000]  val_loss=-0.566548
Fine-tune [704/100000]  val_loss=-0.568865
Fine-tune [705/100000]  val_loss=-0.556355
Fine-tune [706/100000]  val_loss=-0.546612
Fine-tune [707/100000]  val_loss=-0.552589
Fine-tune [708/100000]  val_loss=-0.557925
Fine-tune [709/100000]  val_loss=-0.598334
Fine-tune [710/100000]  val_loss=-0.585399
Fine-tune [711/100000]  val_loss=-0.565183
Fine-tune [712/100000]  val_loss=-0.558064
Fine-tune [713/100000]  val_loss=-0.523578
Fine-tune [714/100000]  val_loss=-0.610730
Fine-tune [715/100000]  val_loss=-0.574771
Fine-tune [716/100000]  val_loss=-0.602948
Fine-tune [717/100000]  val_loss=-0.501174
Fine-tune [718/100000]  val_loss=-0.540073
Fine-tune [719/100000]  val_loss=-0.536136
Fine-tune [720/100000]  val_loss=-0.605087
Fine-tune [721/100000]  val_loss=-0.531908
Fine-tune [722/100000]  val_loss=-0.572393
Fine-tune [723/100000]  val_loss=-0.482204
Fine-tune [724/100000]  val_loss=-0.556684
Fine-tune [725/100000]  val_loss=-0.533099
Fine-tune [726/100000]  val_loss=-0.507771
Fine-tune [727/100000]  val_loss=-0.521307
Fine-tune [728/100000]  val_loss=-0.489147
Fine-tune [729/100000]  val_loss=-0.485376
Fine-tune [730/100000]  val_loss=-0.485363
Fine-tune [731/100000]  val_loss=-0.513181
Fine-tune [732/100000]  val_loss=-0.493572
Fine-tune [733/100000]  val_loss=-0.485579
Fine-tune [734/100000]  val_loss=-0.489925
Fine-tune [735/100000]  val_loss=-0.456641
Fine-tune [736/100000]  val_loss=-0.493837
Fine-tune [737/100000]  val_loss=-0.474427
Fine-tune [738/100000]  val_loss=-0.514982
Fine-tune [739/100000]  val_loss=-0.475914
Fine-tune [740/100000]  val_loss=-0.551190
Fine-tune [741/100000]  val_loss=-0.490361
Fine-tune [742/100000]  val_loss=-0.495959
Fine-tune [743/100000]  val_loss=-0.492344
Fine-tune [744/100000]  val_loss=-0.480129
Fine-tune [745/100000]  val_loss=-0.540548
Fine-tune [746/100000]  val_loss=-0.472287
Fine-tune [747/100000]  val_loss=-0.526383
Fine-tune [748/100000]  val_loss=-0.526536
Fine-tune [749/100000]  val_loss=-0.582714
Fine-tune [750/100000]  val_loss=-0.566325
Fine-tune [751/100000]  val_loss=-0.572664
Fine-tune [752/100000]  val_loss=-0.544262
Fine-tune [753/100000]  val_loss=-0.527339
Fine-tune [754/100000]  val_loss=-0.539519
Fine-tune [755/100000]  val_loss=-0.536807
Fine-tune [756/100000]  val_loss=-0.549490
Fine-tune [757/100000]  val_loss=-0.499002
Fine-tune [758/100000]  val_loss=-0.451776
Fine-tune [759/100000]  val_loss=-0.457851
Fine-tune [760/100000]  val_loss=-0.455770
Fine-tune [761/100000]  val_loss=-0.504942
Fine-tune [762/100000]  val_loss=-0.452112
Fine-tune [763/100000]  val_loss=-0.525816
Fine-tune [764/100000]  val_loss=-0.496910
Fine-tune [765/100000]  val_loss=-0.480589
Fine-tune [766/100000]  val_loss=-0.495055
Fine-tune [767/100000]  val_loss=-0.493209
Fine-tune [768/100000]  val_loss=-0.470405
Fine-tune [769/100000]  val_loss=-0.511581
Fine-tune [770/100000]  val_loss=-0.521347
Fine-tune [771/100000]  val_loss=-0.474792
Fine-tune [772/100000]  val_loss=-0.499606
Fine-tune [773/100000]  val_loss=-0.517969
Fine-tune [774/100000]  val_loss=-0.510979
Fine-tune [775/100000]  val_loss=-0.457068
Fine-tune [776/100000]  val_loss=-0.436107
Fine-tune [777/100000]  val_loss=-0.469062
Fine-tune [778/100000]  val_loss=-0.467822
Fine-tune [779/100000]  val_loss=-0.474441
Fine-tune [780/100000]  val_loss=-0.481064
Fine-tune [781/100000]  val_loss=-0.464728
Fine-tune [782/100000]  val_loss=-0.492785
Fine-tune [783/100000]  val_loss=-0.453799
Fine-tune [784/100000]  val_loss=-0.505903
Fine-tune [785/100000]  val_loss=-0.490151
Fine-tune [786/100000]  val_loss=-0.469101
Fine-tune [787/100000]  val_loss=-0.437521
Fine-tune [788/100000]  val_loss=-0.475551
Fine-tune [789/100000]  val_loss=-0.440636
Fine-tune [790/100000]  val_loss=-0.431053
Fine-tune [791/100000]  val_loss=-0.424484
Fine-tune [792/100000]  val_loss=-0.467282
Fine-tune [793/100000]  val_loss=-0.451278
Fine-tune [794/100000]  val_loss=-0.455944
Fine-tune [795/100000]  val_loss=-0.473196
Fine-tune [796/100000]  val_loss=-0.446595
Fine-tune [797/100000]  val_loss=-0.423343
Fine-tune [798/100000]  val_loss=-0.418063
Fine-tune [799/100000]  val_loss=-0.410804
Fine-tune [800/100000]  val_loss=-0.420346
Fine-tune [801/100000]  val_loss=-0.431956
Fine-tune [802/100000]  val_loss=-0.418048
Fine-tune [803/100000]  val_loss=-0.438701
Fine-tune [804/100000]  val_loss=-0.420525
Fine-tune [805/100000]  val_loss=-0.423841
Fine-tune [806/100000]  val_loss=-0.427391
Fine-tune [807/100000]  val_loss=-0.488076
Fine-tune [808/100000]  val_loss=-0.476013
Fine-tune [809/100000]  val_loss=-0.474968
Fine-tune [810/100000]  val_loss=-0.399570
Fine-tune [811/100000]  val_loss=-0.415747
Fine-tune [812/100000]  val_loss=-0.421677
Fine-tune [813/100000]  val_loss=-0.405705
Fine-tune [814/100000]  val_loss=-0.452619
Fine-tune [815/100000]  val_loss=-0.379055
Fine-tune [816/100000]  val_loss=-0.395794
Fine-tune [817/100000]  val_loss=-0.420726
Fine-tune [818/100000]  val_loss=-0.390358
Fine-tune [819/100000]  val_loss=-0.331564
Fine-tune [820/100000]  val_loss=-0.401533
Fine-tune [821/100000]  val_loss=-0.413566
Fine-tune [822/100000]  val_loss=-0.375701
Fine-tune [823/100000]  val_loss=-0.391251
Fine-tune [824/100000]  val_loss=-0.400364
Fine-tune [825/100000]  val_loss=-0.434912
Fine-tune [826/100000]  val_loss=-0.432943
Fine-tune [827/100000]  val_loss=-0.391332
Fine-tune [828/100000]  val_loss=-0.488333
Fine-tune [829/100000]  val_loss=-0.443056
Fine-tune [830/100000]  val_loss=-0.370724
Fine-tune [831/100000]  val_loss=-0.393422
Fine-tune [832/100000]  val_loss=-0.389780
Fine-tune [833/100000]  val_loss=-0.429225
Fine-tune [834/100000]  val_loss=-0.428132
Fine-tune [835/100000]  val_loss=-0.410828
Fine-tune [836/100000]  val_loss=-0.477651
Fine-tune [837/100000]  val_loss=-0.480250
Fine-tune [838/100000]  val_loss=-0.424810
Fine-tune [839/100000]  val_loss=-0.440238
Fine-tune [840/100000]  val_loss=-0.476934
Fine-tune [841/100000]  val_loss=-0.453180
Fine-tune [842/100000]  val_loss=-0.453328
Fine-tune [843/100000]  val_loss=-0.399585
Fine-tune [844/100000]  val_loss=-0.413397
Fine-tune [845/100000]  val_loss=-0.355602
Fine-tune [846/100000]  val_loss=-0.389940
Fine-tune [847/100000]  val_loss=-0.432347
Fine-tune [848/100000]  val_loss=-0.413018
Fine-tune [849/100000]  val_loss=-0.451145
Fine-tune [850/100000]  val_loss=-0.381174
Fine-tune [851/100000]  val_loss=-0.355510
Fine-tune [852/100000]  val_loss=-0.396227
Fine-tune [853/100000]  val_loss=-0.388383
Fine-tune [854/100000]  val_loss=-0.392552
Fine-tune [855/100000]  val_loss=-0.348313
Fine-tune [856/100000]  val_loss=-0.402425
Fine-tune [857/100000]  val_loss=-0.409532
Fine-tune [858/100000]  val_loss=-0.377970
Fine-tune [859/100000]  val_loss=-0.400575
Fine-tune [860/100000]  val_loss=-0.348518
Fine-tune [861/100000]  val_loss=-0.405355
Fine-tune [862/100000]  val_loss=-0.424569
Fine-tune [863/100000]  val_loss=-0.357597
Fine-tune [864/100000]  val_loss=-0.365033
Fine-tune [865/100000]  val_loss=-0.337046
Fine-tune [866/100000]  val_loss=-0.289810
Fine-tune [867/100000]  val_loss=-0.371010
Fine-tune [868/100000]  val_loss=-0.342809
Fine-tune [869/100000]  val_loss=-0.329985
Fine-tune [870/100000]  val_loss=-0.398120
Fine-tune [871/100000]  val_loss=-0.397259
Fine-tune [872/100000]  val_loss=-0.382799
Fine-tune [873/100000]  val_loss=-0.343011
Fine-tune [874/100000]  val_loss=-0.284442
Fine-tune [875/100000]  val_loss=-0.360093
Fine-tune [876/100000]  val_loss=-0.353093
Fine-tune [877/100000]  val_loss=-0.401574
Fine-tune [878/100000]  val_loss=-0.374412
Fine-tune [879/100000]  val_loss=-0.386259
Fine-tune [880/100000]  val_loss=-0.378978
Fine-tune [881/100000]  val_loss=-0.431900
Fine-tune [882/100000]  val_loss=-0.386226
Fine-tune [883/100000]  val_loss=-0.313322
Fine-tune [884/100000]  val_loss=-0.380000
Fine-tune [885/100000]  val_loss=-0.353275
Fine-tune [886/100000]  val_loss=-0.407468
Fine-tune [887/100000]  val_loss=-0.387581
Fine-tune [888/100000]  val_loss=-0.316984
Fine-tune [889/100000]  val_loss=-0.409285
Fine-tune [890/100000]  val_loss=-0.371732
Fine-tune [891/100000]  val_loss=-0.373136
Fine-tune [892/100000]  val_loss=-0.388537
Fine-tune [893/100000]  val_loss=-0.434405
Fine-tune [894/100000]  val_loss=-0.415334
Fine-tune [895/100000]  val_loss=-0.403359
Fine-tune [896/100000]  val_loss=-0.374964
Fine-tune [897/100000]  val_loss=-0.449054
Fine-tune [898/100000]  val_loss=-0.364211
Fine-tune [899/100000]  val_loss=-0.368865
Fine-tune [900/100000]  val_loss=-0.386125
Fine-tune [901/100000]  val_loss=-0.478358
Fine-tune [902/100000]  val_loss=-0.435072
Fine-tune [903/100000]  val_loss=-0.366149
Fine-tune [904/100000]  val_loss=-0.346565
Fine-tune [905/100000]  val_loss=-0.372451
Fine-tune [906/100000]  val_loss=-0.401885
Fine-tune [907/100000]  val_loss=-0.372565
Fine-tune [908/100000]  val_loss=-0.378403
Fine-tune [909/100000]  val_loss=-0.374761
Fine-tune [910/100000]  val_loss=-0.401989
Fine-tune [911/100000]  val_loss=-0.396228
Fine-tune [912/100000]  val_loss=-0.421223
Fine-tune [913/100000]  val_loss=-0.317252
Fine-tune [914/100000]  val_loss=-0.369491
Fine-tune [915/100000]  val_loss=-0.407578
Fine-tune [916/100000]  val_loss=-0.393855
Fine-tune [917/100000]  val_loss=-0.410235
Fine-tune [918/100000]  val_loss=-0.424442
Fine-tune [919/100000]  val_loss=-0.468013
Fine-tune [920/100000]  val_loss=-0.464267
Fine-tune [921/100000]  val_loss=-0.435597
Fine-tune [922/100000]  val_loss=-0.424246
Fine-tune [923/100000]  val_loss=-0.400989
Fine-tune [924/100000]  val_loss=-0.436122
Fine-tune [925/100000]  val_loss=-0.413064
Fine-tune [926/100000]  val_loss=-0.403408
Fine-tune [927/100000]  val_loss=-0.361209
Fine-tune [928/100000]  val_loss=-0.384839
Fine-tune [929/100000]  val_loss=-0.433127
Fine-tune [930/100000]  val_loss=-0.427535
Fine-tune [931/100000]  val_loss=-0.425283
Fine-tune [932/100000]  val_loss=-0.339626
Fine-tune [933/100000]  val_loss=-0.349781
Fine-tune [934/100000]  val_loss=-0.349746
Fine-tune [935/100000]  val_loss=-0.324383
Fine-tune [936/100000]  val_loss=-0.409087
Fine-tune [937/100000]  val_loss=-0.459848
Fine-tune [938/100000]  val_loss=-0.415649
Fine-tune [939/100000]  val_loss=-0.389615
Fine-tune [940/100000]  val_loss=-0.360400
Fine-tune [941/100000]  val_loss=-0.385404
Fine-tune [942/100000]  val_loss=-0.386737
Fine-tune [943/100000]  val_loss=-0.343310
Fine-tune [944/100000]  val_loss=-0.362899
Fine-tune [945/100000]  val_loss=-0.346568
Fine-tune [946/100000]  val_loss=-0.388153
Fine-tune [947/100000]  val_loss=-0.374912
Fine-tune [948/100000]  val_loss=-0.375254
Fine-tune [949/100000]  val_loss=-0.407222
Fine-tune [950/100000]  val_loss=-0.345043
Fine-tune [951/100000]  val_loss=-0.387296
Fine-tune [952/100000]  val_loss=-0.422033
Fine-tune [953/100000]  val_loss=-0.372194
Fine-tune [954/100000]  val_loss=-0.377516
Fine-tune [955/100000]  val_loss=-0.331773
Fine-tune [956/100000]  val_loss=-0.375599
Fine-tune [957/100000]  val_loss=-0.383237
Fine-tune [958/100000]  val_loss=-0.411818
Fine-tune [959/100000]  val_loss=-0.383217
Fine-tune [960/100000]  val_loss=-0.456590
Fine-tune [961/100000]  val_loss=-0.411381
Fine-tune [962/100000]  val_loss=-0.391984
Fine-tune [963/100000]  val_loss=-0.318488
Fine-tune [964/100000]  val_loss=-0.343485
Fine-tune [965/100000]  val_loss=-0.320684
Fine-tune [966/100000]  val_loss=-0.347282
Fine-tune [967/100000]  val_loss=-0.358482
Fine-tune [968/100000]  val_loss=-0.322133
Fine-tune [969/100000]  val_loss=-0.317001
Fine-tune [970/100000]  val_loss=-0.388330
Fine-tune [971/100000]  val_loss=-0.377023
Fine-tune [972/100000]  val_loss=-0.402712
Fine-tune [973/100000]  val_loss=-0.384983
Fine-tune [974/100000]  val_loss=-0.304859
Fine-tune [975/100000]  val_loss=-0.392430
Fine-tune [976/100000]  val_loss=-0.314564
Fine-tune [977/100000]  val_loss=-0.293744
Fine-tune [978/100000]  val_loss=-0.336990
Fine-tune [979/100000]  val_loss=-0.341428
Fine-tune [980/100000]  val_loss=-0.325300
Fine-tune [981/100000]  val_loss=-0.301783
Fine-tune [982/100000]  val_loss=-0.367296
Fine-tune [983/100000]  val_loss=-0.268532
Fine-tune [984/100000]  val_loss=-0.253049
Fine-tune [985/100000]  val_loss=-0.349044
Fine-tune [986/100000]  val_loss=-0.360579
Fine-tune [987/100000]  val_loss=-0.352073
Fine-tune [988/100000]  val_loss=-0.327383
Fine-tune [989/100000]  val_loss=-0.359478
Fine-tune [990/100000]  val_loss=-0.317371
Fine-tune [991/100000]  val_loss=-0.380406
Fine-tune [992/100000]  val_loss=-0.413520
Fine-tune [993/100000]  val_loss=-0.380653
Fine-tune [994/100000]  val_loss=-0.315569
Fine-tune [995/100000]  val_loss=-0.292520
Fine-tune [996/100000]  val_loss=-0.333352
Fine-tune [997/100000]  val_loss=-0.310084
Fine-tune [998/100000]  val_loss=-0.323464
Fine-tune [999/100000]  val_loss=-0.403282
Fine-tune [1000/100000]  val_loss=-0.318518
Fine-tune [1001/100000]  val_loss=-0.408531
Fine-tune [1002/100000]  val_loss=-0.359393
Fine-tune [1003/100000]  val_loss=-0.338620
Fine-tune [1004/100000]  val_loss=-0.311251
Fine-tune [1005/100000]  val_loss=-0.355287
Fine-tune [1006/100000]  val_loss=-0.334008
Fine-tune [1007/100000]  val_loss=-0.357083
Fine-tune [1008/100000]  val_loss=-0.380149
Fine-tune [1009/100000]  val_loss=-0.384644
Fine-tune [1010/100000]  val_loss=-0.399372
Fine-tune [1011/100000]  val_loss=-0.328604
Fine-tune [1012/100000]  val_loss=-0.318130
Fine-tune [1013/100000]  val_loss=-0.410056
Fine-tune [1014/100000]  val_loss=-0.388812
Fine-tune [1015/100000]  val_loss=-0.313118
Fine-tune [1016/100000]  val_loss=-0.326635
Fine-tune [1017/100000]  val_loss=-0.289078
Fine-tune [1018/100000]  val_loss=-0.322063
Fine-tune [1019/100000]  val_loss=-0.246402
Fine-tune [1020/100000]  val_loss=-0.313526
Fine-tune [1021/100000]  val_loss=-0.301087
Fine-tune [1022/100000]  val_loss=-0.298152
Fine-tune [1023/100000]  val_loss=-0.285385
Fine-tune [1024/100000]  val_loss=-0.320851
Fine-tune [1025/100000]  val_loss=-0.309753
Fine-tune [1026/100000]  val_loss=-0.221227
Fine-tune [1027/100000]  val_loss=-0.279188
Fine-tune [1028/100000]  val_loss=-0.270003
Fine-tune [1029/100000]  val_loss=-0.322437
Fine-tune [1030/100000]  val_loss=-0.322096
Fine-tune [1031/100000]  val_loss=-0.287186
Fine-tune [1032/100000]  val_loss=-0.274537
Fine-tune [1033/100000]  val_loss=-0.285399
Fine-tune [1034/100000]  val_loss=-0.345411
Fine-tune [1035/100000]  val_loss=-0.294859
Fine-tune [1036/100000]  val_loss=-0.309763
Fine-tune [1037/100000]  val_loss=-0.323988
Fine-tune [1038/100000]  val_loss=-0.242289
Fine-tune [1039/100000]  val_loss=-0.308260
Fine-tune [1040/100000]  val_loss=-0.276421
Fine-tune [1041/100000]  val_loss=-0.352311
Fine-tune [1042/100000]  val_loss=-0.308922
Fine-tune [1043/100000]  val_loss=-0.348833
Fine-tune [1044/100000]  val_loss=-0.324763
Fine-tune [1045/100000]  val_loss=-0.315304
Fine-tune [1046/100000]  val_loss=-0.326901
Fine-tune [1047/100000]  val_loss=-0.219257
Fine-tune [1048/100000]  val_loss=-0.276314
Fine-tune [1049/100000]  val_loss=-0.267866
Fine-tune [1050/100000]  val_loss=-0.203043
Fine-tune [1051/100000]  val_loss=-0.206022
Fine-tune [1052/100000]  val_loss=-0.244872
Fine-tune [1053/100000]  val_loss=-0.250686
Fine-tune [1054/100000]  val_loss=-0.267809
Fine-tune [1055/100000]  val_loss=-0.218355
Fine-tune [1056/100000]  val_loss=-0.237235
Fine-tune [1057/100000]  val_loss=-0.261894
Fine-tune [1058/100000]  val_loss=-0.287332
Fine-tune [1059/100000]  val_loss=-0.292051
Fine-tune [1060/100000]  val_loss=-0.301736
Fine-tune [1061/100000]  val_loss=-0.250343
Fine-tune [1062/100000]  val_loss=-0.246534
Fine-tune [1063/100000]  val_loss=-0.175069
Fine-tune [1064/100000]  val_loss=-0.272377
Fine-tune [1065/100000]  val_loss=-0.321995
Fine-tune [1066/100000]  val_loss=-0.307762
Fine-tune [1067/100000]  val_loss=-0.331803
Fine-tune [1068/100000]  val_loss=-0.285049
Fine-tune [1069/100000]  val_loss=-0.368870
Fine-tune [1070/100000]  val_loss=-0.365605
Fine-tune [1071/100000]  val_loss=-0.369922
Fine-tune [1072/100000]  val_loss=-0.257256
Fine-tune [1073/100000]  val_loss=-0.252493
Fine-tune [1074/100000]  val_loss=-0.259155
Fine-tune [1075/100000]  val_loss=-0.170716
Fine-tune [1076/100000]  val_loss=-0.284714
Fine-tune [1077/100000]  val_loss=-0.282184
Fine-tune [1078/100000]  val_loss=-0.331824
Fine-tune [1079/100000]  val_loss=-0.315251
Fine-tune [1080/100000]  val_loss=-0.360600
Fine-tune [1081/100000]  val_loss=-0.350475
Fine-tune [1082/100000]  val_loss=-0.260262
Fine-tune [1083/100000]  val_loss=-0.288049
Fine-tune [1084/100000]  val_loss=-0.284983
Fine-tune [1085/100000]  val_loss=-0.254421
Fine-tune [1086/100000]  val_loss=-0.303237
Fine-tune [1087/100000]  val_loss=-0.324926
Fine-tune [1088/100000]  val_loss=-0.303095
Fine-tune [1089/100000]  val_loss=-0.242756
Fine-tune [1090/100000]  val_loss=-0.204034
Fine-tune [1091/100000]  val_loss=-0.288493
Fine-tune [1092/100000]  val_loss=-0.315477
Fine-tune [1093/100000]  val_loss=-0.316867
Fine-tune [1094/100000]  val_loss=-0.287022
Fine-tune [1095/100000]  val_loss=-0.241445
Fine-tune [1096/100000]  val_loss=-0.287163
Fine-tune [1097/100000]  val_loss=-0.217591
Fine-tune [1098/100000]  val_loss=-0.198177
Fine-tune [1099/100000]  val_loss=-0.227632
Fine-tune [1100/100000]  val_loss=-0.291395
Fine-tune [1101/100000]  val_loss=-0.286667
Fine-tune [1102/100000]  val_loss=-0.261187
Fine-tune [1103/100000]  val_loss=-0.259601
Fine-tune [1104/100000]  val_loss=-0.271068
Fine-tune [1105/100000]  val_loss=-0.270623
Fine-tune [1106/100000]  val_loss=-0.252587
Fine-tune [1107/100000]  val_loss=-0.215681
Fine-tune [1108/100000]  val_loss=-0.243666
Fine-tune [1109/100000]  val_loss=-0.234148
Fine-tune [1110/100000]  val_loss=-0.264153
Fine-tune [1111/100000]  val_loss=-0.274022
Fine-tune [1112/100000]  val_loss=-0.274572
Fine-tune [1113/100000]  val_loss=-0.262700
Fine-tune [1114/100000]  val_loss=-0.281359
Fine-tune [1115/100000]  val_loss=-0.229504
Fine-tune [1116/100000]  val_loss=-0.156903
Fine-tune [1117/100000]  val_loss=-0.175980
Fine-tune [1118/100000]  val_loss=-0.235910
Fine-tune [1119/100000]  val_loss=-0.224614
Fine-tune [1120/100000]  val_loss=-0.237145
Fine-tune [1121/100000]  val_loss=-0.226541
Fine-tune [1122/100000]  val_loss=-0.217206
Fine-tune [1123/100000]  val_loss=-0.274485
Fine-tune [1124/100000]  val_loss=-0.196050
Fine-tune [1125/100000]  val_loss=-0.196834
Fine-tune [1126/100000]  val_loss=-0.207702
Fine-tune [1127/100000]  val_loss=-0.301119
Fine-tune [1128/100000]  val_loss=-0.272398
Fine-tune [1129/100000]  val_loss=-0.250958
Fine-tune [1130/100000]  val_loss=-0.224386
Fine-tune [1131/100000]  val_loss=-0.247690
Fine-tune [1132/100000]  val_loss=-0.205965
Fine-tune [1133/100000]  val_loss=-0.168049
Fine-tune [1134/100000]  val_loss=-0.265377
Fine-tune [1135/100000]  val_loss=-0.261952
Fine-tune [1136/100000]  val_loss=-0.176703
Fine-tune [1137/100000]  val_loss=-0.162826
Fine-tune [1138/100000]  val_loss=-0.126853
Fine-tune [1139/100000]  val_loss=-0.153711
Fine-tune [1140/100000]  val_loss=-0.170468
Fine-tune [1141/100000]  val_loss=-0.170648
Fine-tune [1142/100000]  val_loss=-0.176962
Fine-tune [1143/100000]  val_loss=-0.201944
Fine-tune [1144/100000]  val_loss=-0.135724
Fine-tune [1145/100000]  val_loss=-0.216171
Fine-tune [1146/100000]  val_loss=-0.217655
Fine-tune [1147/100000]  val_loss=-0.241298
Fine-tune [1148/100000]  val_loss=-0.218250
Fine-tune [1149/100000]  val_loss=-0.262986
Fine-tune [1150/100000]  val_loss=-0.133794
Fine-tune [1151/100000]  val_loss=-0.124386
Fine-tune [1152/100000]  val_loss=-0.168290
Fine-tune [1153/100000]  val_loss=-0.170111
Fine-tune [1154/100000]  val_loss=-0.199304
Fine-tune [1155/100000]  val_loss=-0.221435
Fine-tune [1156/100000]  val_loss=-0.267588
Fine-tune [1157/100000]  val_loss=-0.235353
Fine-tune [1158/100000]  val_loss=-0.206325
Fine-tune [1159/100000]  val_loss=-0.239262
Fine-tune [1160/100000]  val_loss=-0.240887
Fine-tune [1161/100000]  val_loss=-0.165822
Fine-tune [1162/100000]  val_loss=-0.170285
Fine-tune [1163/100000]  val_loss=-0.195130
Fine-tune [1164/100000]  val_loss=-0.171258
Fine-tune [1165/100000]  val_loss=-0.242815
Fine-tune [1166/100000]  val_loss=-0.213071
Fine-tune [1167/100000]  val_loss=-0.174033
Fine-tune [1168/100000]  val_loss=-0.140187
Fine-tune [1169/100000]  val_loss=-0.141277
Fine-tune [1170/100000]  val_loss=-0.096631
Fine-tune [1171/100000]  val_loss=-0.167541
Fine-tune [1172/100000]  val_loss=-0.132383
Fine-tune [1173/100000]  val_loss=-0.130289
Fine-tune [1174/100000]  val_loss=-0.207924
Fine-tune [1175/100000]  val_loss=-0.205876
Fine-tune [1176/100000]  val_loss=-0.266410
Fine-tune [1177/100000]  val_loss=-0.231610
Fine-tune [1178/100000]  val_loss=-0.145336
Fine-tune [1179/100000]  val_loss=-0.207044
Fine-tune [1180/100000]  val_loss=-0.125410
Fine-tune [1181/100000]  val_loss=-0.153260
Fine-tune [1182/100000]  val_loss=-0.174906
Fine-tune [1183/100000]  val_loss=-0.115963
Fine-tune [1184/100000]  val_loss=-0.120753
Fine-tune [1185/100000]  val_loss=-0.131043
Fine-tune [1186/100000]  val_loss=-0.155429
Fine-tune [1187/100000]  val_loss=-0.094041
Fine-tune [1188/100000]  val_loss=-0.068337
Fine-tune [1189/100000]  val_loss=-0.019085
Fine-tune [1190/100000]  val_loss=-0.009759
Fine-tune [1191/100000]  val_loss=-0.082231
Fine-tune [1192/100000]  val_loss=-0.054788
Fine-tune [1193/100000]  val_loss=-0.131392
Fine-tune [1194/100000]  val_loss=-0.116487
Fine-tune [1195/100000]  val_loss=-0.028994
Fine-tune [1196/100000]  val_loss=-0.155485
Fine-tune [1197/100000]  val_loss=-0.068458
Fine-tune [1198/100000]  val_loss=-0.136360
Fine-tune [1199/100000]  val_loss=-0.149387
Fine-tune [1200/100000]  val_loss=-0.170229
Fine-tune [1201/100000]  val_loss=-0.197987
Fine-tune [1202/100000]  val_loss=-0.121190
Fine-tune [1203/100000]  val_loss=-0.153218
Fine-tune [1204/100000]  val_loss=-0.132470
Fine-tune [1205/100000]  val_loss=-0.149700
Fine-tune [1206/100000]  val_loss=-0.145882
Fine-tune [1207/100000]  val_loss=-0.206191
Fine-tune [1208/100000]  val_loss=-0.219464
Fine-tune [1209/100000]  val_loss=-0.132215
Fine-tune [1210/100000]  val_loss=-0.109549
Fine-tune [1211/100000]  val_loss=-0.115693
Fine-tune [1212/100000]  val_loss=-0.174558
Fine-tune [1213/100000]  val_loss=-0.145420
Fine-tune [1214/100000]  val_loss=-0.209319
Fine-tune [1215/100000]  val_loss=-0.154526
Fine-tune [1216/100000]  val_loss=-0.133865
Fine-tune [1217/100000]  val_loss=-0.134351
Fine-tune [1218/100000]  val_loss=-0.048975
Fine-tune [1219/100000]  val_loss=-0.112869
Fine-tune [1220/100000]  val_loss=-0.075724
Fine-tune [1221/100000]  val_loss=-0.067166
Fine-tune [1222/100000]  val_loss=-0.054200
Fine-tune [1223/100000]  val_loss=-0.079844
Fine-tune [1224/100000]  val_loss=-0.142873
Fine-tune [1225/100000]  val_loss=-0.132211
Fine-tune [1226/100000]  val_loss=-0.161408
Fine-tune [1227/100000]  val_loss=-0.141474
Fine-tune [1228/100000]  val_loss=-0.190271
Fine-tune [1229/100000]  val_loss=-0.167857
Fine-tune [1230/100000]  val_loss=-0.217974
Fine-tune [1231/100000]  val_loss=-0.231254
Fine-tune [1232/100000]  val_loss=-0.167595
Fine-tune [1233/100000]  val_loss=-0.130791
Fine-tune [1234/100000]  val_loss=-0.155166
Fine-tune [1235/100000]  val_loss=-0.154511
Fine-tune [1236/100000]  val_loss=-0.120980
Fine-tune [1237/100000]  val_loss=-0.135809
Fine-tune [1238/100000]  val_loss=-0.060404
Fine-tune [1239/100000]  val_loss=-0.065132
Fine-tune [1240/100000]  val_loss=-0.144404
Fine-tune [1241/100000]  val_loss=-0.182012
Fine-tune [1242/100000]  val_loss=-0.172680
Fine-tune [1243/100000]  val_loss=-0.200829
Fine-tune [1244/100000]  val_loss=-0.167458
Fine-tune [1245/100000]  val_loss=-0.241411
Fine-tune [1246/100000]  val_loss=-0.127829
Fine-tune [1247/100000]  val_loss=-0.143398
Fine-tune [1248/100000]  val_loss=-0.194916
Fine-tune [1249/100000]  val_loss=-0.127938
Fine-tune [1250/100000]  val_loss=-0.113608
Fine-tune [1251/100000]  val_loss=-0.145236
Fine-tune [1252/100000]  val_loss=-0.118733
Fine-tune [1253/100000]  val_loss=-0.100008
Fine-tune [1254/100000]  val_loss=-0.203408
Fine-tune [1255/100000]  val_loss=-0.214135
Fine-tune [1256/100000]  val_loss=-0.080747
Fine-tune [1257/100000]  val_loss=-0.098804
Fine-tune [1258/100000]  val_loss=-0.138372
Fine-tune [1259/100000]  val_loss=-0.083913
Fine-tune [1260/100000]  val_loss=-0.045389
Fine-tune [1261/100000]  val_loss=-0.130666
  -> 验证未改进 1000 次，早停。
[FINETUNE] 最佳验证损失=-0.995746 已保存。

--- 评估 [HD512_L3] ---

=== 本次试验参数 (Run Config) ===
opamp             : two_stage_opamp
hidden_dim        : 512
num_layers        : 3
lr_pretrain       : 0.003
epochs_pretrain   : 1000
patience_pretrain : 200
lr_finetune       : 0.0038
epochs_finetune   : 100000
patience_finetune : 1000
batch_a           : 128
batch_b           : 64
dropout_rate      : 0.2
alpha_r2          : 0.0
lambda_coral      : 0.1
seed              : 42
device            : cpu

--- [评估阶段] 开始计算指标 ---

=== 目标域验证集指标（物理单位）===
slewrate_pos    MSE=1.134e+14  MAE=7.706e+06  R2=0.7357
dc_gain         MSE=1.94e+07  MAE=1250  R2=0.5019
ugf             MSE=8.148e+13  MAE=5.49e+06  R2=0.8158
phase_margin    MSE=145.5  MAE=8.57  R2=0.8732
cmrr            MSE=8.442e+11  MAE=9.235e+04  R2=0.0253

Avg  (all dims)   MSE=3.914e+13  MAE=2.658e+06  R2=0.5904
[OK] HD512_L3 -> r2_avg=0.5904, mae_avg=2.658e+06, mse_avg=3.914e+13
===== [HD512_L3] 训练完成 =====

===== [HD512_L4] 训练开始 =====

--- [阶段一] Backbone 预训练 (source_train / source_val, HuberLoss) ---
Pretrain [1/1000]  train=0.243356  val=0.183124
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [2/1000]  train=0.174842  val=0.151314
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [3/1000]  train=0.157090  val=0.127200
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [4/1000]  train=0.143401  val=0.123503
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [5/1000]  train=0.136229  val=0.124683
Pretrain [6/1000]  train=0.131096  val=0.113669
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [7/1000]  train=0.124848  val=0.111307
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [8/1000]  train=0.119845  val=0.110785
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [9/1000]  train=0.115504  val=0.106030
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [10/1000]  train=0.110361  val=0.110810
Pretrain [11/1000]  train=0.112251  val=0.102615
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [12/1000]  train=0.108560  val=0.098645
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [13/1000]  train=0.105705  val=0.097301
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [14/1000]  train=0.102246  val=0.098581
Pretrain [15/1000]  train=0.100814  val=0.091549
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [16/1000]  train=0.098574  val=0.092310
Pretrain [17/1000]  train=0.099231  val=0.098730
Pretrain [18/1000]  train=0.097247  val=0.088196
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [19/1000]  train=0.097801  val=0.097284
Pretrain [20/1000]  train=0.095104  val=0.093778
Pretrain [21/1000]  train=0.092039  val=0.095207
Pretrain [22/1000]  train=0.091079  val=0.095071
Pretrain [23/1000]  train=0.093317  val=0.092528
Pretrain [24/1000]  train=0.091706  val=0.092209
Pretrain [25/1000]  train=0.088374  val=0.088293
Pretrain [26/1000]  train=0.089763  val=0.087256
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [27/1000]  train=0.089324  val=0.088806
Pretrain [28/1000]  train=0.092662  val=0.092269
Pretrain [29/1000]  train=0.089025  val=0.091501
Pretrain [30/1000]  train=0.086791  val=0.085840
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [31/1000]  train=0.082856  val=0.089227
Pretrain [32/1000]  train=0.079733  val=0.084890
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [33/1000]  train=0.081790  val=0.086039
Pretrain [34/1000]  train=0.083474  val=0.085611
Pretrain [35/1000]  train=0.080332  val=0.086494
Pretrain [36/1000]  train=0.078248  val=0.088047
Pretrain [37/1000]  train=0.083435  val=0.090191
Pretrain [38/1000]  train=0.081559  val=0.085545
Pretrain [39/1000]  train=0.077115  val=0.089043
Pretrain [40/1000]  train=0.078541  val=0.084114
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [41/1000]  train=0.076784  val=0.086485
Pretrain [42/1000]  train=0.077633  val=0.087432
Pretrain [43/1000]  train=0.077504  val=0.086087
Pretrain [44/1000]  train=0.077654  val=0.091012
Pretrain [45/1000]  train=0.073461  val=0.082930
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [46/1000]  train=0.071744  val=0.085063
Pretrain [47/1000]  train=0.072998  val=0.090393
Pretrain [48/1000]  train=0.072899  val=0.084195
Pretrain [49/1000]  train=0.073151  val=0.084171
Pretrain [50/1000]  train=0.075556  val=0.090096
Pretrain [51/1000]  train=0.072154  val=0.085350
Pretrain [52/1000]  train=0.069902  val=0.083503
Pretrain [53/1000]  train=0.071169  val=0.086581
Pretrain [54/1000]  train=0.072317  val=0.084249
Pretrain [55/1000]  train=0.070099  val=0.081271
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [56/1000]  train=0.068248  val=0.087942
Pretrain [57/1000]  train=0.067357  val=0.082198
Pretrain [58/1000]  train=0.068652  val=0.080011
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [59/1000]  train=0.064137  val=0.084081
Pretrain [60/1000]  train=0.065651  val=0.088295
Pretrain [61/1000]  train=0.064865  val=0.089570
Pretrain [62/1000]  train=0.068563  val=0.085393
Pretrain [63/1000]  train=0.063240  val=0.084811
Pretrain [64/1000]  train=0.061575  val=0.086773
Pretrain [65/1000]  train=0.062231  val=0.083576
Pretrain [66/1000]  train=0.063789  val=0.081493
Pretrain [67/1000]  train=0.065999  val=0.079573
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [68/1000]  train=0.065038  val=0.082211
Pretrain [69/1000]  train=0.059754  val=0.082098
Pretrain [70/1000]  train=0.062129  val=0.086532
Pretrain [71/1000]  train=0.061616  val=0.081336
Pretrain [72/1000]  train=0.058913  val=0.081432
Pretrain [73/1000]  train=0.059808  val=0.081431
Pretrain [74/1000]  train=0.058477  val=0.083202
Pretrain [75/1000]  train=0.058723  val=0.083721
Pretrain [76/1000]  train=0.056015  val=0.080922
Pretrain [77/1000]  train=0.058771  val=0.082901
Pretrain [78/1000]  train=0.057629  val=0.083602
Pretrain [79/1000]  train=0.056703  val=0.078019
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [80/1000]  train=0.054196  val=0.079945
Pretrain [81/1000]  train=0.054676  val=0.079793
Pretrain [82/1000]  train=0.053733  val=0.081006
Pretrain [83/1000]  train=0.051244  val=0.080296
Pretrain [84/1000]  train=0.053230  val=0.084661
Pretrain [85/1000]  train=0.052310  val=0.079160
Pretrain [86/1000]  train=0.051821  val=0.078341
Pretrain [87/1000]  train=0.052847  val=0.080661
Pretrain [88/1000]  train=0.051546  val=0.079828
Pretrain [89/1000]  train=0.052115  val=0.078927
Pretrain [90/1000]  train=0.052583  val=0.081908
Pretrain [91/1000]  train=0.053043  val=0.082838
Pretrain [92/1000]  train=0.051196  val=0.080228
Pretrain [93/1000]  train=0.049689  val=0.083901
Pretrain [94/1000]  train=0.048443  val=0.079753
Pretrain [95/1000]  train=0.049166  val=0.083883
Pretrain [96/1000]  train=0.047633  val=0.082305
Pretrain [97/1000]  train=0.048154  val=0.079525
Pretrain [98/1000]  train=0.048213  val=0.077913
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [99/1000]  train=0.048559  val=0.077091
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [100/1000]  train=0.047134  val=0.080382
Pretrain [101/1000]  train=0.046232  val=0.072704
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [102/1000]  train=0.044345  val=0.073304
Pretrain [103/1000]  train=0.045732  val=0.077375
Pretrain [104/1000]  train=0.043797  val=0.074121
Pretrain [105/1000]  train=0.045790  val=0.078853
Pretrain [106/1000]  train=0.046539  val=0.081651
Pretrain [107/1000]  train=0.044177  val=0.079715
Pretrain [108/1000]  train=0.041883  val=0.076771
Pretrain [109/1000]  train=0.043739  val=0.077674
Pretrain [110/1000]  train=0.042448  val=0.076760
Pretrain [111/1000]  train=0.043242  val=0.077925
Pretrain [112/1000]  train=0.041474  val=0.081056
Pretrain [113/1000]  train=0.043358  val=0.071515
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [114/1000]  train=0.043116  val=0.075580
Pretrain [115/1000]  train=0.041034  val=0.075150
Pretrain [116/1000]  train=0.041882  val=0.075531
Pretrain [117/1000]  train=0.040566  val=0.071912
Pretrain [118/1000]  train=0.040182  val=0.073526
Pretrain [119/1000]  train=0.038750  val=0.074703
Pretrain [120/1000]  train=0.038893  val=0.080832
Pretrain [121/1000]  train=0.039275  val=0.077615
Pretrain [122/1000]  train=0.039090  val=0.074359
Pretrain [123/1000]  train=0.037952  val=0.073751
Pretrain [124/1000]  train=0.038565  val=0.076794
Pretrain [125/1000]  train=0.036445  val=0.074819
Pretrain [126/1000]  train=0.037231  val=0.075365
Pretrain [127/1000]  train=0.038296  val=0.075290
Pretrain [128/1000]  train=0.037520  val=0.077341
Pretrain [129/1000]  train=0.036779  val=0.076996
Pretrain [130/1000]  train=0.036906  val=0.074774
Pretrain [131/1000]  train=0.035730  val=0.074234
Pretrain [132/1000]  train=0.035043  val=0.072508
Pretrain [133/1000]  train=0.035194  val=0.073382
Pretrain [134/1000]  train=0.035936  val=0.074590
Pretrain [135/1000]  train=0.035588  val=0.074091
Pretrain [136/1000]  train=0.034061  val=0.074176
Pretrain [137/1000]  train=0.034956  val=0.074859
Pretrain [138/1000]  train=0.035731  val=0.075306
Pretrain [139/1000]  train=0.034411  val=0.074248
Pretrain [140/1000]  train=0.034002  val=0.074937
Pretrain [141/1000]  train=0.033344  val=0.072192
Pretrain [142/1000]  train=0.033551  val=0.072825
Pretrain [143/1000]  train=0.032852  val=0.073081
Pretrain [144/1000]  train=0.033192  val=0.075702
Pretrain [145/1000]  train=0.032422  val=0.071937
Pretrain [146/1000]  train=0.031947  val=0.071811
Pretrain [147/1000]  train=0.033793  val=0.074753
Pretrain [148/1000]  train=0.032046  val=0.076880
Pretrain [149/1000]  train=0.031240  val=0.074651
Pretrain [150/1000]  train=0.032271  val=0.073792
Pretrain [151/1000]  train=0.031175  val=0.072495
Pretrain [152/1000]  train=0.030480  val=0.073582
Pretrain [153/1000]  train=0.032757  val=0.076216
Pretrain [154/1000]  train=0.031917  val=0.075589
Pretrain [155/1000]  train=0.030832  val=0.074525
Pretrain [156/1000]  train=0.030723  val=0.073888
Pretrain [157/1000]  train=0.030346  val=0.072992
Pretrain [158/1000]  train=0.030303  val=0.074188
Pretrain [159/1000]  train=0.030982  val=0.072559
Pretrain [160/1000]  train=0.030186  val=0.071135
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [161/1000]  train=0.030059  val=0.071616
Pretrain [162/1000]  train=0.030376  val=0.071889
Pretrain [163/1000]  train=0.031231  val=0.071710
Pretrain [164/1000]  train=0.029655  val=0.070785
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [165/1000]  train=0.029315  val=0.072137
Pretrain [166/1000]  train=0.029260  val=0.072140
Pretrain [167/1000]  train=0.030605  val=0.071925
Pretrain [168/1000]  train=0.029984  val=0.072619
Pretrain [169/1000]  train=0.027953  val=0.071702
Pretrain [170/1000]  train=0.028960  val=0.072862
Pretrain [171/1000]  train=0.028343  val=0.071844
Pretrain [172/1000]  train=0.029166  val=0.072082
Pretrain [173/1000]  train=0.029247  val=0.072963
Pretrain [174/1000]  train=0.027739  val=0.072429
Pretrain [175/1000]  train=0.028489  val=0.072521
Pretrain [176/1000]  train=0.027806  val=0.074217
Pretrain [177/1000]  train=0.028638  val=0.073502
Pretrain [178/1000]  train=0.027827  val=0.074095
Pretrain [179/1000]  train=0.028035  val=0.073207
Pretrain [180/1000]  train=0.028187  val=0.073531
Pretrain [181/1000]  train=0.027841  val=0.073488
Pretrain [182/1000]  train=0.027689  val=0.073786
Pretrain [183/1000]  train=0.027817  val=0.073758
Pretrain [184/1000]  train=0.028137  val=0.073579
Pretrain [185/1000]  train=0.027817  val=0.073105
Pretrain [186/1000]  train=0.027904  val=0.072787
Pretrain [187/1000]  train=0.028293  val=0.072430
Pretrain [188/1000]  train=0.028631  val=0.072353
Pretrain [189/1000]  train=0.028071  val=0.072286
Pretrain [190/1000]  train=0.027889  val=0.072448
Pretrain [191/1000]  train=0.028221  val=0.072577
Pretrain [192/1000]  train=0.028143  val=0.072632
Pretrain [193/1000]  train=0.027514  val=0.072625
Pretrain [194/1000]  train=0.027964  val=0.072755
Pretrain [195/1000]  train=0.028687  val=0.072691
Pretrain [196/1000]  train=0.027904  val=0.072662
Pretrain [197/1000]  train=0.028132  val=0.072659
Pretrain [198/1000]  train=0.027949  val=0.072684
Pretrain [199/1000]  train=0.027870  val=0.072672
Pretrain [200/1000]  train=0.027267  val=0.072665
Pretrain [201/1000]  train=0.048443  val=0.087251
Pretrain [202/1000]  train=0.074163  val=0.097438
Pretrain [203/1000]  train=0.076042  val=0.094024
Pretrain [204/1000]  train=0.081150  val=0.092731
Pretrain [205/1000]  train=0.080970  val=0.095378
Pretrain [206/1000]  train=0.074743  val=0.092925
Pretrain [207/1000]  train=0.073472  val=0.090918
Pretrain [208/1000]  train=0.072400  val=0.088695
Pretrain [209/1000]  train=0.071875  val=0.092541
Pretrain [210/1000]  train=0.072109  val=0.091925
Pretrain [211/1000]  train=0.069281  val=0.094996
Pretrain [212/1000]  train=0.067005  val=0.092535
Pretrain [213/1000]  train=0.069013  val=0.090551
Pretrain [214/1000]  train=0.067012  val=0.086046
Pretrain [215/1000]  train=0.063063  val=0.088480
Pretrain [216/1000]  train=0.064022  val=0.088035
Pretrain [217/1000]  train=0.063332  val=0.090317
Pretrain [218/1000]  train=0.061553  val=0.085009
Pretrain [219/1000]  train=0.059400  val=0.084775
Pretrain [220/1000]  train=0.059750  val=0.086377
Pretrain [221/1000]  train=0.058921  val=0.083225
Pretrain [222/1000]  train=0.057935  val=0.085790
Pretrain [223/1000]  train=0.061465  val=0.083110
Pretrain [224/1000]  train=0.061784  val=0.093232
Pretrain [225/1000]  train=0.061386  val=0.085649
Pretrain [226/1000]  train=0.063192  val=0.092252
Pretrain [227/1000]  train=0.062096  val=0.087295
Pretrain [228/1000]  train=0.056721  val=0.090426
Pretrain [229/1000]  train=0.057689  val=0.085197
Pretrain [230/1000]  train=0.056790  val=0.085931
Pretrain [231/1000]  train=0.056838  val=0.084850
Pretrain [232/1000]  train=0.053013  val=0.087357
Pretrain [233/1000]  train=0.051309  val=0.085907
Pretrain [234/1000]  train=0.055170  val=0.086696
Pretrain [235/1000]  train=0.053704  val=0.087456
Pretrain [236/1000]  train=0.059651  val=0.086196
Pretrain [237/1000]  train=0.055474  val=0.085637
Pretrain [238/1000]  train=0.052145  val=0.088793
Pretrain [239/1000]  train=0.055585  val=0.090609
Pretrain [240/1000]  train=0.051496  val=0.086445
Pretrain [241/1000]  train=0.051199  val=0.086284
Pretrain [242/1000]  train=0.052648  val=0.082324
Pretrain [243/1000]  train=0.050802  val=0.079646
Pretrain [244/1000]  train=0.051453  val=0.083416
Pretrain [245/1000]  train=0.054339  val=0.081006
Pretrain [246/1000]  train=0.051646  val=0.087141
Pretrain [247/1000]  train=0.048500  val=0.086232
Pretrain [248/1000]  train=0.051796  val=0.084045
Pretrain [249/1000]  train=0.049296  val=0.088378
Pretrain [250/1000]  train=0.053341  val=0.089214
Pretrain [251/1000]  train=0.047295  val=0.087525
Pretrain [252/1000]  train=0.047322  val=0.087728
Pretrain [253/1000]  train=0.049016  val=0.086286
Pretrain [254/1000]  train=0.045880  val=0.082748
Pretrain [255/1000]  train=0.051919  val=0.085519
Pretrain [256/1000]  train=0.049951  val=0.082918
Pretrain [257/1000]  train=0.046251  val=0.089158
Pretrain [258/1000]  train=0.046176  val=0.089680
Pretrain [259/1000]  train=0.047525  val=0.086616
Pretrain [260/1000]  train=0.047864  val=0.088006
Pretrain [261/1000]  train=0.047712  val=0.083519
Pretrain [262/1000]  train=0.046282  val=0.086191
Pretrain [263/1000]  train=0.050243  val=0.082569
Pretrain [264/1000]  train=0.045617  val=0.084992
Pretrain [265/1000]  train=0.045109  val=0.085636
Pretrain [266/1000]  train=0.047117  val=0.085159
Pretrain [267/1000]  train=0.045135  val=0.080657
Pretrain [268/1000]  train=0.046320  val=0.083299
Pretrain [269/1000]  train=0.042767  val=0.083922
Pretrain [270/1000]  train=0.043724  val=0.081949
Pretrain [271/1000]  train=0.041066  val=0.078982
Pretrain [272/1000]  train=0.042733  val=0.084347
Pretrain [273/1000]  train=0.042372  val=0.084869
Pretrain [274/1000]  train=0.043059  val=0.079949
Pretrain [275/1000]  train=0.042518  val=0.084626
Pretrain [276/1000]  train=0.041374  val=0.081928
Pretrain [277/1000]  train=0.042981  val=0.081192
Pretrain [278/1000]  train=0.041335  val=0.082935
Pretrain [279/1000]  train=0.040338  val=0.082773
Pretrain [280/1000]  train=0.039791  val=0.082887
Pretrain [281/1000]  train=0.040583  val=0.081429
Pretrain [282/1000]  train=0.040455  val=0.087516
Pretrain [283/1000]  train=0.042195  val=0.084893
Pretrain [284/1000]  train=0.039405  val=0.080148
Pretrain [285/1000]  train=0.041446  val=0.085310
Pretrain [286/1000]  train=0.038292  val=0.078187
Pretrain [287/1000]  train=0.038004  val=0.079640
Pretrain [288/1000]  train=0.038311  val=0.080074
Pretrain [289/1000]  train=0.039551  val=0.076971
Pretrain [290/1000]  train=0.037311  val=0.081561
Pretrain [291/1000]  train=0.038290  val=0.080670
Pretrain [292/1000]  train=0.036350  val=0.080906
Pretrain [293/1000]  train=0.036210  val=0.084676
Pretrain [294/1000]  train=0.035458  val=0.082366
Pretrain [295/1000]  train=0.035752  val=0.083092
Pretrain [296/1000]  train=0.036705  val=0.079852
Pretrain [297/1000]  train=0.034987  val=0.079215
Pretrain [298/1000]  train=0.036497  val=0.078925
Pretrain [299/1000]  train=0.034504  val=0.076407
Pretrain [300/1000]  train=0.036395  val=0.079427
Pretrain [301/1000]  train=0.032450  val=0.080050
Pretrain [302/1000]  train=0.034313  val=0.074335
Pretrain [303/1000]  train=0.032575  val=0.076656
Pretrain [304/1000]  train=0.032946  val=0.077121
Pretrain [305/1000]  train=0.033011  val=0.078108
Pretrain [306/1000]  train=0.033288  val=0.077030
Pretrain [307/1000]  train=0.033142  val=0.075911
Pretrain [308/1000]  train=0.034019  val=0.077821
Pretrain [309/1000]  train=0.031976  val=0.076016
Pretrain [310/1000]  train=0.030739  val=0.076090
Pretrain [311/1000]  train=0.030870  val=0.077838
Pretrain [312/1000]  train=0.029592  val=0.078158
Pretrain [313/1000]  train=0.030408  val=0.074177
Pretrain [314/1000]  train=0.032086  val=0.076965
Pretrain [315/1000]  train=0.029770  val=0.075080
Pretrain [316/1000]  train=0.030246  val=0.079623
Pretrain [317/1000]  train=0.029877  val=0.077595
Pretrain [318/1000]  train=0.028909  val=0.076791
Pretrain [319/1000]  train=0.029357  val=0.076274
Pretrain [320/1000]  train=0.029253  val=0.081199
Pretrain [321/1000]  train=0.028793  val=0.074790
Pretrain [322/1000]  train=0.028011  val=0.075547
Pretrain [323/1000]  train=0.028263  val=0.074525
Pretrain [324/1000]  train=0.027881  val=0.077172
Pretrain [325/1000]  train=0.027975  val=0.077053
Pretrain [326/1000]  train=0.028407  val=0.076253
Pretrain [327/1000]  train=0.027395  val=0.076370
Pretrain [328/1000]  train=0.027015  val=0.077364
Pretrain [329/1000]  train=0.027200  val=0.075218
Pretrain [330/1000]  train=0.028938  val=0.076557
Pretrain [331/1000]  train=0.027760  val=0.075466
Pretrain [332/1000]  train=0.027132  val=0.074260
Pretrain [333/1000]  train=0.027854  val=0.076253
Pretrain [334/1000]  train=0.026873  val=0.076361
Pretrain [335/1000]  train=0.027308  val=0.074908
Pretrain [336/1000]  train=0.026802  val=0.074205
Pretrain [337/1000]  train=0.026296  val=0.071422
Pretrain [338/1000]  train=0.026303  val=0.071386
Pretrain [339/1000]  train=0.025683  val=0.072936
Pretrain [340/1000]  train=0.025977  val=0.072989
Pretrain [341/1000]  train=0.026340  val=0.071220
Pretrain [342/1000]  train=0.025665  val=0.071340
Pretrain [343/1000]  train=0.025966  val=0.072460
Pretrain [344/1000]  train=0.025326  val=0.072937
Pretrain [345/1000]  train=0.024671  val=0.072447
Pretrain [346/1000]  train=0.024026  val=0.072392
Pretrain [347/1000]  train=0.024246  val=0.071374
Pretrain [348/1000]  train=0.024664  val=0.070623
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [349/1000]  train=0.024341  val=0.071478
Pretrain [350/1000]  train=0.024053  val=0.073327
Pretrain [351/1000]  train=0.023791  val=0.072611
Pretrain [352/1000]  train=0.023754  val=0.071873
Pretrain [353/1000]  train=0.023849  val=0.072794
Pretrain [354/1000]  train=0.025110  val=0.071898
Pretrain [355/1000]  train=0.024996  val=0.073350
Pretrain [356/1000]  train=0.024210  val=0.073955
Pretrain [357/1000]  train=0.023720  val=0.073126
Pretrain [358/1000]  train=0.024204  val=0.074700
Pretrain [359/1000]  train=0.023860  val=0.073003
Pretrain [360/1000]  train=0.023223  val=0.073087
Pretrain [361/1000]  train=0.023421  val=0.073052
Pretrain [362/1000]  train=0.023669  val=0.073822
Pretrain [363/1000]  train=0.023431  val=0.073143
Pretrain [364/1000]  train=0.022991  val=0.072517
Pretrain [365/1000]  train=0.022521  val=0.071963
Pretrain [366/1000]  train=0.022601  val=0.071736
Pretrain [367/1000]  train=0.022603  val=0.073401
Pretrain [368/1000]  train=0.022875  val=0.072879
Pretrain [369/1000]  train=0.022799  val=0.073274
Pretrain [370/1000]  train=0.022570  val=0.072786
Pretrain [371/1000]  train=0.023414  val=0.071622
Pretrain [372/1000]  train=0.022617  val=0.070074
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [373/1000]  train=0.022668  val=0.070802
Pretrain [374/1000]  train=0.021354  val=0.070105
Pretrain [375/1000]  train=0.021997  val=0.070687
Pretrain [376/1000]  train=0.022429  val=0.070781
Pretrain [377/1000]  train=0.022574  val=0.070115
Pretrain [378/1000]  train=0.022333  val=0.069895
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [379/1000]  train=0.022899  val=0.069872
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [380/1000]  train=0.021885  val=0.070456
Pretrain [381/1000]  train=0.022141  val=0.070823
Pretrain [382/1000]  train=0.021676  val=0.069992
Pretrain [383/1000]  train=0.022136  val=0.070272
Pretrain [384/1000]  train=0.022442  val=0.070707
Pretrain [385/1000]  train=0.022574  val=0.070369
Pretrain [386/1000]  train=0.022496  val=0.070166
Pretrain [387/1000]  train=0.021381  val=0.070235
Pretrain [388/1000]  train=0.021671  val=0.069984
Pretrain [389/1000]  train=0.021487  val=0.069768
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [390/1000]  train=0.021980  val=0.069538
  -> 预训练验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/pretrained.pth
Pretrain [391/1000]  train=0.022077  val=0.069658
Pretrain [392/1000]  train=0.022161  val=0.069675
Pretrain [393/1000]  train=0.022593  val=0.069808
Pretrain [394/1000]  train=0.022120  val=0.069820
Pretrain [395/1000]  train=0.021887  val=0.069813
Pretrain [396/1000]  train=0.022324  val=0.069778
Pretrain [397/1000]  train=0.021841  val=0.069742
Pretrain [398/1000]  train=0.021938  val=0.069743
Pretrain [399/1000]  train=0.022118  val=0.069753
Pretrain [400/1000]  train=0.021633  val=0.069739
Pretrain [401/1000]  train=0.036612  val=0.094326
Pretrain [402/1000]  train=0.063635  val=0.093751
Pretrain [403/1000]  train=0.077545  val=0.101813
Pretrain [404/1000]  train=0.086718  val=0.105281
Pretrain [405/1000]  train=0.079744  val=0.098712
Pretrain [406/1000]  train=0.075755  val=0.095202
Pretrain [407/1000]  train=0.069175  val=0.091576
Pretrain [408/1000]  train=0.067912  val=0.090610
Pretrain [409/1000]  train=0.070794  val=0.094707
Pretrain [410/1000]  train=0.067123  val=0.095054
Pretrain [411/1000]  train=0.066906  val=0.102058
Pretrain [412/1000]  train=0.068602  val=0.086864
Pretrain [413/1000]  train=0.063588  val=0.087545
Pretrain [414/1000]  train=0.063834  val=0.093674
Pretrain [415/1000]  train=0.057891  val=0.087238
Pretrain [416/1000]  train=0.060212  val=0.092225
Pretrain [417/1000]  train=0.055964  val=0.083335
Pretrain [418/1000]  train=0.057567  val=0.085051
Pretrain [419/1000]  train=0.056290  val=0.086239
Pretrain [420/1000]  train=0.052452  val=0.092558
Pretrain [421/1000]  train=0.056193  val=0.085796
Pretrain [422/1000]  train=0.053980  val=0.082625
Pretrain [423/1000]  train=0.057568  val=0.086733
Pretrain [424/1000]  train=0.055105  val=0.085991
Pretrain [425/1000]  train=0.051301  val=0.084754
Pretrain [426/1000]  train=0.052544  val=0.089021
Pretrain [427/1000]  train=0.049117  val=0.085056
Pretrain [428/1000]  train=0.049404  val=0.084708
Pretrain [429/1000]  train=0.048137  val=0.087201
Pretrain [430/1000]  train=0.048320  val=0.084625
Pretrain [431/1000]  train=0.046997  val=0.085464
Pretrain [432/1000]  train=0.047394  val=0.087773
Pretrain [433/1000]  train=0.045762  val=0.079260
Pretrain [434/1000]  train=0.043463  val=0.090480
Pretrain [435/1000]  train=0.049195  val=0.089189
Pretrain [436/1000]  train=0.050260  val=0.086084
Pretrain [437/1000]  train=0.051425  val=0.087556
Pretrain [438/1000]  train=0.046798  val=0.087032
Pretrain [439/1000]  train=0.047040  val=0.086628
Pretrain [440/1000]  train=0.049909  val=0.086624
Pretrain [441/1000]  train=0.046289  val=0.086220
Pretrain [442/1000]  train=0.047386  val=0.084697
Pretrain [443/1000]  train=0.046356  val=0.086428
Pretrain [444/1000]  train=0.049132  val=0.088910
Pretrain [445/1000]  train=0.046954  val=0.088069
Pretrain [446/1000]  train=0.050104  val=0.087680
Pretrain [447/1000]  train=0.046448  val=0.086419
Pretrain [448/1000]  train=0.044698  val=0.086447
Pretrain [449/1000]  train=0.046539  val=0.087965
Pretrain [450/1000]  train=0.043868  val=0.083221
Pretrain [451/1000]  train=0.042535  val=0.083772
Pretrain [452/1000]  train=0.042422  val=0.084511
Pretrain [453/1000]  train=0.042189  val=0.080841
Pretrain [454/1000]  train=0.043800  val=0.090519
Pretrain [455/1000]  train=0.042679  val=0.087878
Pretrain [456/1000]  train=0.040422  val=0.085675
Pretrain [457/1000]  train=0.044553  val=0.085942
Pretrain [458/1000]  train=0.041635  val=0.081182
Pretrain [459/1000]  train=0.042899  val=0.081779
Pretrain [460/1000]  train=0.039345  val=0.089788
Pretrain [461/1000]  train=0.037894  val=0.087120
Pretrain [462/1000]  train=0.039333  val=0.084791
Pretrain [463/1000]  train=0.039497  val=0.082979
Pretrain [464/1000]  train=0.041494  val=0.084686
Pretrain [465/1000]  train=0.043054  val=0.088979
Pretrain [466/1000]  train=0.039473  val=0.080075
Pretrain [467/1000]  train=0.038154  val=0.080819
Pretrain [468/1000]  train=0.039220  val=0.085959
Pretrain [469/1000]  train=0.038755  val=0.085926
Pretrain [470/1000]  train=0.039877  val=0.084385
Pretrain [471/1000]  train=0.039438  val=0.084850
Pretrain [472/1000]  train=0.039496  val=0.080092
Pretrain [473/1000]  train=0.039534  val=0.084604
Pretrain [474/1000]  train=0.038785  val=0.086563
Pretrain [475/1000]  train=0.038434  val=0.081395
Pretrain [476/1000]  train=0.038444  val=0.079400
Pretrain [477/1000]  train=0.037526  val=0.083871
Pretrain [478/1000]  train=0.035434  val=0.082847
Pretrain [479/1000]  train=0.035406  val=0.080079
Pretrain [480/1000]  train=0.036236  val=0.087098
Pretrain [481/1000]  train=0.036491  val=0.081842
Pretrain [482/1000]  train=0.035002  val=0.082252
Pretrain [483/1000]  train=0.034116  val=0.084086
Pretrain [484/1000]  train=0.032939  val=0.077873
Pretrain [485/1000]  train=0.032241  val=0.080241
Pretrain [486/1000]  train=0.034623  val=0.080550
Pretrain [487/1000]  train=0.032794  val=0.079162
Pretrain [488/1000]  train=0.034514  val=0.077728
Pretrain [489/1000]  train=0.034147  val=0.078780
Pretrain [490/1000]  train=0.034635  val=0.086596
Pretrain [491/1000]  train=0.032906  val=0.082452
Pretrain [492/1000]  train=0.032844  val=0.083949
Pretrain [493/1000]  train=0.033057  val=0.084114
Pretrain [494/1000]  train=0.032219  val=0.079601
Pretrain [495/1000]  train=0.033116  val=0.081222
Pretrain [496/1000]  train=0.032767  val=0.077179
Pretrain [497/1000]  train=0.032946  val=0.075513
Pretrain [498/1000]  train=0.031850  val=0.076768
Pretrain [499/1000]  train=0.031370  val=0.076368
Pretrain [500/1000]  train=0.031135  val=0.076591
Pretrain [501/1000]  train=0.031146  val=0.083165
Pretrain [502/1000]  train=0.031170  val=0.081526
Pretrain [503/1000]  train=0.029902  val=0.083857
Pretrain [504/1000]  train=0.029610  val=0.079556
Pretrain [505/1000]  train=0.030682  val=0.077526
Pretrain [506/1000]  train=0.030495  val=0.076961
Pretrain [507/1000]  train=0.030711  val=0.076727
Pretrain [508/1000]  train=0.029887  val=0.077777
Pretrain [509/1000]  train=0.029690  val=0.079772
Pretrain [510/1000]  train=0.028514  val=0.077964
Pretrain [511/1000]  train=0.029553  val=0.078262
Pretrain [512/1000]  train=0.028412  val=0.076858
Pretrain [513/1000]  train=0.027782  val=0.075548
Pretrain [514/1000]  train=0.028548  val=0.075646
Pretrain [515/1000]  train=0.027691  val=0.078494
Pretrain [516/1000]  train=0.027293  val=0.078787
Pretrain [517/1000]  train=0.027425  val=0.076815
Pretrain [518/1000]  train=0.027044  val=0.079423
Pretrain [519/1000]  train=0.026155  val=0.079200
Pretrain [520/1000]  train=0.027404  val=0.080147
Pretrain [521/1000]  train=0.027347  val=0.078155
Pretrain [522/1000]  train=0.025429  val=0.077167
Pretrain [523/1000]  train=0.025760  val=0.077863
Pretrain [524/1000]  train=0.026282  val=0.076117
Pretrain [525/1000]  train=0.026300  val=0.079351
Pretrain [526/1000]  train=0.025572  val=0.076262
Pretrain [527/1000]  train=0.025214  val=0.077377
Pretrain [528/1000]  train=0.025853  val=0.078023
Pretrain [529/1000]  train=0.025133  val=0.075452
Pretrain [530/1000]  train=0.024909  val=0.079840
Pretrain [531/1000]  train=0.024255  val=0.080045
Pretrain [532/1000]  train=0.024288  val=0.079775
Pretrain [533/1000]  train=0.024748  val=0.081526
Pretrain [534/1000]  train=0.024453  val=0.080224
Pretrain [535/1000]  train=0.023743  val=0.077035
Pretrain [536/1000]  train=0.024418  val=0.076041
Pretrain [537/1000]  train=0.023807  val=0.075679
Pretrain [538/1000]  train=0.024293  val=0.076352
Pretrain [539/1000]  train=0.024045  val=0.076068
Pretrain [540/1000]  train=0.023509  val=0.076143
Pretrain [541/1000]  train=0.023408  val=0.078539
Pretrain [542/1000]  train=0.023840  val=0.076005
Pretrain [543/1000]  train=0.023686  val=0.076378
Pretrain [544/1000]  train=0.023573  val=0.076479
Pretrain [545/1000]  train=0.023995  val=0.077274
Pretrain [546/1000]  train=0.023993  val=0.075410
Pretrain [547/1000]  train=0.022853  val=0.075118
Pretrain [548/1000]  train=0.022425  val=0.077569
Pretrain [549/1000]  train=0.023197  val=0.074691
Pretrain [550/1000]  train=0.023017  val=0.075366
Pretrain [551/1000]  train=0.022105  val=0.074745
Pretrain [552/1000]  train=0.022491  val=0.075512
Pretrain [553/1000]  train=0.022065  val=0.075571
Pretrain [554/1000]  train=0.022212  val=0.076364
Pretrain [555/1000]  train=0.022369  val=0.077037
Pretrain [556/1000]  train=0.021341  val=0.075952
Pretrain [557/1000]  train=0.021206  val=0.076175
Pretrain [558/1000]  train=0.021599  val=0.075498
Pretrain [559/1000]  train=0.021448  val=0.076543
Pretrain [560/1000]  train=0.021286  val=0.077265
Pretrain [561/1000]  train=0.020973  val=0.075978
Pretrain [562/1000]  train=0.020916  val=0.075083
Pretrain [563/1000]  train=0.021229  val=0.075176
Pretrain [564/1000]  train=0.020667  val=0.076745
Pretrain [565/1000]  train=0.022105  val=0.076343
Pretrain [566/1000]  train=0.021356  val=0.076266
Pretrain [567/1000]  train=0.021120  val=0.075693
Pretrain [568/1000]  train=0.020761  val=0.075344
Pretrain [569/1000]  train=0.020803  val=0.075018
Pretrain [570/1000]  train=0.020608  val=0.075468
Pretrain [571/1000]  train=0.021677  val=0.074295
Pretrain [572/1000]  train=0.020835  val=0.074725
Pretrain [573/1000]  train=0.021247  val=0.074500
Pretrain [574/1000]  train=0.020421  val=0.073910
Pretrain [575/1000]  train=0.020786  val=0.073589
Pretrain [576/1000]  train=0.020692  val=0.074087
Pretrain [577/1000]  train=0.020574  val=0.073320
Pretrain [578/1000]  train=0.021387  val=0.073316
Pretrain [579/1000]  train=0.020703  val=0.073816
Pretrain [580/1000]  train=0.020708  val=0.073232
Pretrain [581/1000]  train=0.021238  val=0.073061
Pretrain [582/1000]  train=0.020800  val=0.073318
Pretrain [583/1000]  train=0.020513  val=0.073340
Pretrain [584/1000]  train=0.020099  val=0.072987
Pretrain [585/1000]  train=0.020878  val=0.073015
Pretrain [586/1000]  train=0.019934  val=0.072730
Pretrain [587/1000]  train=0.019832  val=0.072737
Pretrain [588/1000]  train=0.020421  val=0.072790
Pretrain [589/1000]  train=0.019618  val=0.072895
Pretrain [590/1000]  train=0.020805  val=0.072688
  -> 验证未改进 200 次，早停。
[PRETRAIN] 最佳 val=0.069538 已保存。

--- [阶段二] 对齐微调 (NLL + α·(1−R2) + λ·CORAL) ---
Fine-tune [1/100000]  val_loss=0.230797
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [2/100000]  val_loss=0.122144
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [3/100000]  val_loss=0.019124
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [4/100000]  val_loss=-0.089459
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [5/100000]  val_loss=-0.179631
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [6/100000]  val_loss=-0.258576
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [7/100000]  val_loss=-0.321624
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [8/100000]  val_loss=-0.387862
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [9/100000]  val_loss=-0.429146
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [10/100000]  val_loss=-0.498202
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [11/100000]  val_loss=-0.531808
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [12/100000]  val_loss=-0.569400
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [13/100000]  val_loss=-0.600814
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [14/100000]  val_loss=-0.614330
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [15/100000]  val_loss=-0.620438
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [16/100000]  val_loss=-0.632030
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [17/100000]  val_loss=-0.654941
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [18/100000]  val_loss=-0.665168
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [19/100000]  val_loss=-0.676233
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [20/100000]  val_loss=-0.695051
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [21/100000]  val_loss=-0.719366
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [22/100000]  val_loss=-0.709735
Fine-tune [23/100000]  val_loss=-0.722552
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [24/100000]  val_loss=-0.728407
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [25/100000]  val_loss=-0.733801
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [26/100000]  val_loss=-0.748611
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [27/100000]  val_loss=-0.745580
Fine-tune [28/100000]  val_loss=-0.746949
Fine-tune [29/100000]  val_loss=-0.764650
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [30/100000]  val_loss=-0.766403
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [31/100000]  val_loss=-0.778457
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [32/100000]  val_loss=-0.768110
Fine-tune [33/100000]  val_loss=-0.792374
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [34/100000]  val_loss=-0.785782
Fine-tune [35/100000]  val_loss=-0.800736
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [36/100000]  val_loss=-0.774497
Fine-tune [37/100000]  val_loss=-0.791333
Fine-tune [38/100000]  val_loss=-0.825058
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [39/100000]  val_loss=-0.800430
Fine-tune [40/100000]  val_loss=-0.827137
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [41/100000]  val_loss=-0.827968
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [42/100000]  val_loss=-0.839800
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [43/100000]  val_loss=-0.833273
Fine-tune [44/100000]  val_loss=-0.827870
Fine-tune [45/100000]  val_loss=-0.817283
Fine-tune [46/100000]  val_loss=-0.831261
Fine-tune [47/100000]  val_loss=-0.838030
Fine-tune [48/100000]  val_loss=-0.865671
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [49/100000]  val_loss=-0.858238
Fine-tune [50/100000]  val_loss=-0.850131
Fine-tune [51/100000]  val_loss=-0.867733
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [52/100000]  val_loss=-0.871775
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [53/100000]  val_loss=-0.871183
Fine-tune [54/100000]  val_loss=-0.845512
Fine-tune [55/100000]  val_loss=-0.870661
Fine-tune [56/100000]  val_loss=-0.878212
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [57/100000]  val_loss=-0.872784
Fine-tune [58/100000]  val_loss=-0.883837
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [59/100000]  val_loss=-0.872441
Fine-tune [60/100000]  val_loss=-0.876985
Fine-tune [61/100000]  val_loss=-0.873406
Fine-tune [62/100000]  val_loss=-0.887162
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [63/100000]  val_loss=-0.862470
Fine-tune [64/100000]  val_loss=-0.897867
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [65/100000]  val_loss=-0.892313
Fine-tune [66/100000]  val_loss=-0.887165
Fine-tune [67/100000]  val_loss=-0.913733
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [68/100000]  val_loss=-0.895983
Fine-tune [69/100000]  val_loss=-0.907801
Fine-tune [70/100000]  val_loss=-0.946419
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [71/100000]  val_loss=-0.911287
Fine-tune [72/100000]  val_loss=-0.939797
Fine-tune [73/100000]  val_loss=-0.926639
Fine-tune [74/100000]  val_loss=-0.928791
Fine-tune [75/100000]  val_loss=-0.909364
Fine-tune [76/100000]  val_loss=-0.920875
Fine-tune [77/100000]  val_loss=-0.928095
Fine-tune [78/100000]  val_loss=-0.922592
Fine-tune [79/100000]  val_loss=-0.933533
Fine-tune [80/100000]  val_loss=-0.935434
Fine-tune [81/100000]  val_loss=-0.927421
Fine-tune [82/100000]  val_loss=-0.947652
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [83/100000]  val_loss=-0.937993
Fine-tune [84/100000]  val_loss=-0.934246
Fine-tune [85/100000]  val_loss=-0.930998
Fine-tune [86/100000]  val_loss=-0.937809
Fine-tune [87/100000]  val_loss=-0.952558
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [88/100000]  val_loss=-0.943446
Fine-tune [89/100000]  val_loss=-0.930914
Fine-tune [90/100000]  val_loss=-0.932474
Fine-tune [91/100000]  val_loss=-0.941837
Fine-tune [92/100000]  val_loss=-0.925515
Fine-tune [93/100000]  val_loss=-0.942798
Fine-tune [94/100000]  val_loss=-0.936556
Fine-tune [95/100000]  val_loss=-0.933881
Fine-tune [96/100000]  val_loss=-0.933945
Fine-tune [97/100000]  val_loss=-0.946106
Fine-tune [98/100000]  val_loss=-0.947511
Fine-tune [99/100000]  val_loss=-0.933157
Fine-tune [100/100000]  val_loss=-0.930943
Fine-tune [101/100000]  val_loss=-0.926525
Fine-tune [102/100000]  val_loss=-0.934251
Fine-tune [103/100000]  val_loss=-0.954404
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [104/100000]  val_loss=-0.950076
Fine-tune [105/100000]  val_loss=-0.975966
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [106/100000]  val_loss=-0.976028
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [107/100000]  val_loss=-0.958283
Fine-tune [108/100000]  val_loss=-0.950292
Fine-tune [109/100000]  val_loss=-0.966725
Fine-tune [110/100000]  val_loss=-0.943913
Fine-tune [111/100000]  val_loss=-0.953369
Fine-tune [112/100000]  val_loss=-0.920400
Fine-tune [113/100000]  val_loss=-0.945068
Fine-tune [114/100000]  val_loss=-0.931667
Fine-tune [115/100000]  val_loss=-0.948601
Fine-tune [116/100000]  val_loss=-0.915578
Fine-tune [117/100000]  val_loss=-0.949556
Fine-tune [118/100000]  val_loss=-0.951856
Fine-tune [119/100000]  val_loss=-0.930754
Fine-tune [120/100000]  val_loss=-0.933141
Fine-tune [121/100000]  val_loss=-0.949519
Fine-tune [122/100000]  val_loss=-0.918785
Fine-tune [123/100000]  val_loss=-0.955779
Fine-tune [124/100000]  val_loss=-0.937167
Fine-tune [125/100000]  val_loss=-0.955015
Fine-tune [126/100000]  val_loss=-0.932750
Fine-tune [127/100000]  val_loss=-0.967174
Fine-tune [128/100000]  val_loss=-0.944913
Fine-tune [129/100000]  val_loss=-0.942284
Fine-tune [130/100000]  val_loss=-0.962352
Fine-tune [131/100000]  val_loss=-0.950673
Fine-tune [132/100000]  val_loss=-0.949334
Fine-tune [133/100000]  val_loss=-0.956765
Fine-tune [134/100000]  val_loss=-0.950658
Fine-tune [135/100000]  val_loss=-0.952678
Fine-tune [136/100000]  val_loss=-0.965954
Fine-tune [137/100000]  val_loss=-0.904905
Fine-tune [138/100000]  val_loss=-0.943899
Fine-tune [139/100000]  val_loss=-0.933795
Fine-tune [140/100000]  val_loss=-0.925673
Fine-tune [141/100000]  val_loss=-0.945992
Fine-tune [142/100000]  val_loss=-0.968543
Fine-tune [143/100000]  val_loss=-0.984921
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [144/100000]  val_loss=-0.948163
Fine-tune [145/100000]  val_loss=-0.983467
Fine-tune [146/100000]  val_loss=-0.935458
Fine-tune [147/100000]  val_loss=-0.930131
Fine-tune [148/100000]  val_loss=-0.950008
Fine-tune [149/100000]  val_loss=-0.978541
Fine-tune [150/100000]  val_loss=-0.952229
Fine-tune [151/100000]  val_loss=-0.934922
Fine-tune [152/100000]  val_loss=-0.945346
Fine-tune [153/100000]  val_loss=-0.979837
Fine-tune [154/100000]  val_loss=-0.977630
Fine-tune [155/100000]  val_loss=-0.975282
Fine-tune [156/100000]  val_loss=-0.980391
Fine-tune [157/100000]  val_loss=-0.959934
Fine-tune [158/100000]  val_loss=-0.985778
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [159/100000]  val_loss=-0.967222
Fine-tune [160/100000]  val_loss=-0.963798
Fine-tune [161/100000]  val_loss=-0.987371
  -> 验证改进，保存 /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/HD512_L4/finetuned.pth
Fine-tune [162/100000]  val_loss=-0.959891
Fine-tune [163/100000]  val_loss=-0.954549
Fine-tune [164/100000]  val_loss=-0.945391
Fine-tune [165/100000]  val_loss=-0.911782
Fine-tune [166/100000]  val_loss=-0.983584
Fine-tune [167/100000]  val_loss=-0.956673
Fine-tune [168/100000]  val_loss=-0.945479
Fine-tune [169/100000]  val_loss=-0.936541
Fine-tune [170/100000]  val_loss=-0.956138
Fine-tune [171/100000]  val_loss=-0.950520
Fine-tune [172/100000]  val_loss=-0.976968
Fine-tune [173/100000]  val_loss=-0.960039
Fine-tune [174/100000]  val_loss=-0.951936
Fine-tune [175/100000]  val_loss=-0.949405
Fine-tune [176/100000]  val_loss=-0.943845
Fine-tune [177/100000]  val_loss=-0.937477
Fine-tune [178/100000]  val_loss=-0.936947
Fine-tune [179/100000]  val_loss=-0.911890
Fine-tune [180/100000]  val_loss=-0.919477
Fine-tune [181/100000]  val_loss=-0.942818
Fine-tune [182/100000]  val_loss=-0.940169
Fine-tune [183/100000]  val_loss=-0.930222
Fine-tune [184/100000]  val_loss=-0.923464
Fine-tune [185/100000]  val_loss=-0.933706
Fine-tune [186/100000]  val_loss=-0.936903
Fine-tune [187/100000]  val_loss=-0.956592
Fine-tune [188/100000]  val_loss=-0.912822
Fine-tune [189/100000]  val_loss=-0.933705
Fine-tune [190/100000]  val_loss=-0.936295
Fine-tune [191/100000]  val_loss=-0.933377
Fine-tune [192/100000]  val_loss=-0.923452
Fine-tune [193/100000]  val_loss=-0.908599
Fine-tune [194/100000]  val_loss=-0.888382
Fine-tune [195/100000]  val_loss=-0.882986
Fine-tune [196/100000]  val_loss=-0.891606
Fine-tune [197/100000]  val_loss=-0.894672
Fine-tune [198/100000]  val_loss=-0.924933
Fine-tune [199/100000]  val_loss=-0.911399
Fine-tune [200/100000]  val_loss=-0.890111
Fine-tune [201/100000]  val_loss=-0.869106
Fine-tune [202/100000]  val_loss=-0.901102
Fine-tune [203/100000]  val_loss=-0.878459
Fine-tune [204/100000]  val_loss=-0.875538
Fine-tune [205/100000]  val_loss=-0.937269
Fine-tune [206/100000]  val_loss=-0.898863
Fine-tune [207/100000]  val_loss=-0.915057
Fine-tune [208/100000]  val_loss=-0.930653
Fine-tune [209/100000]  val_loss=-0.929847
Fine-tune [210/100000]  val_loss=-0.901442
Fine-tune [211/100000]  val_loss=-0.908523
Fine-tune [212/100000]  val_loss=-0.883358
Fine-tune [213/100000]  val_loss=-0.923413
Fine-tune [214/100000]  val_loss=-0.870719
Fine-tune [215/100000]  val_loss=-0.909267
Fine-tune [216/100000]  val_loss=-0.921829
Fine-tune [217/100000]  val_loss=-0.893399
Fine-tune [218/100000]  val_loss=-0.896874
Fine-tune [219/100000]  val_loss=-0.883219
Fine-tune [220/100000]  val_loss=-0.902811
Fine-tune [221/100000]  val_loss=-0.848220
Fine-tune [222/100000]  val_loss=-0.885762
Fine-tune [223/100000]  val_loss=-0.887695
Fine-tune [224/100000]  val_loss=-0.916198
Fine-tune [225/100000]  val_loss=-0.898367
Fine-tune [226/100000]  val_loss=-0.890986
Fine-tune [227/100000]  val_loss=-0.907282
Fine-tune [228/100000]  val_loss=-0.918369
Fine-tune [229/100000]  val_loss=-0.921860
Fine-tune [230/100000]  val_loss=-0.943067
Fine-tune [231/100000]  val_loss=-0.904781
Fine-tune [232/100000]  val_loss=-0.905129
Fine-tune [233/100000]  val_loss=-0.911448
Fine-tune [234/100000]  val_loss=-0.899312
Fine-tune [235/100000]  val_loss=-0.882939
Fine-tune [236/100000]  val_loss=-0.879275
Fine-tune [237/100000]  val_loss=-0.878202
Fine-tune [238/100000]  val_loss=-0.885827
Fine-tune [239/100000]  val_loss=-0.887890
Fine-tune [240/100000]  val_loss=-0.882839
Fine-tune [241/100000]  val_loss=-0.903046
Fine-tune [242/100000]  val_loss=-0.859723
Fine-tune [243/100000]  val_loss=-0.906024
Fine-tune [244/100000]  val_loss=-0.868441
Fine-tune [245/100000]  val_loss=-0.892580
Fine-tune [246/100000]  val_loss=-0.910511
Fine-tune [247/100000]  val_loss=-0.854988
Fine-tune [248/100000]  val_loss=-0.849021
Fine-tune [249/100000]  val_loss=-0.901381
Fine-tune [250/100000]  val_loss=-0.857056
Fine-tune [251/100000]  val_loss=-0.904763
Fine-tune [252/100000]  val_loss=-0.867320
Fine-tune [253/100000]  val_loss=-0.910114
Fine-tune [254/100000]  val_loss=-0.878132
Fine-tune [255/100000]  val_loss=-0.908312
Fine-tune [256/100000]  val_loss=-0.871654
Fine-tune [257/100000]  val_loss=-0.894799
Fine-tune [258/100000]  val_loss=-0.874406
Fine-tune [259/100000]  val_loss=-0.860466
Fine-tune [260/100000]  val_loss=-0.901548
Fine-tune [261/100000]  val_loss=-0.888987
Fine-tune [262/100000]  val_loss=-0.886081
Fine-tune [263/100000]  val_loss=-0.888917
Fine-tune [264/100000]  val_loss=-0.877204
Fine-tune [265/100000]  val_loss=-0.900925
Fine-tune [266/100000]  val_loss=-0.876327
Fine-tune [267/100000]  val_loss=-0.868392
Fine-tune [268/100000]  val_loss=-0.855776
Fine-tune [269/100000]  val_loss=-0.857673
Fine-tune [270/100000]  val_loss=-0.860682
Fine-tune [271/100000]  val_loss=-0.899431
Fine-tune [272/100000]  val_loss=-0.867134
Fine-tune [273/100000]  val_loss=-0.896394
Fine-tune [274/100000]  val_loss=-0.894414
Fine-tune [275/100000]  val_loss=-0.885922
Fine-tune [276/100000]  val_loss=-0.844360
Fine-tune [277/100000]  val_loss=-0.887177
Fine-tune [278/100000]  val_loss=-0.854721
Fine-tune [279/100000]  val_loss=-0.865843
Fine-tune [280/100000]  val_loss=-0.857592
Fine-tune [281/100000]  val_loss=-0.868649
Fine-tune [282/100000]  val_loss=-0.880298
Fine-tune [283/100000]  val_loss=-0.853243
Fine-tune [284/100000]  val_loss=-0.867111
Fine-tune [285/100000]  val_loss=-0.872916
Fine-tune [286/100000]  val_loss=-0.873164
Fine-tune [287/100000]  val_loss=-0.876348
Fine-tune [288/100000]  val_loss=-0.883881
Fine-tune [289/100000]  val_loss=-0.887010
Fine-tune [290/100000]  val_loss=-0.850334
Fine-tune [291/100000]  val_loss=-0.868405
Fine-tune [292/100000]  val_loss=-0.836817
Fine-tune [293/100000]  val_loss=-0.906257
Fine-tune [294/100000]  val_loss=-0.846823
Fine-tune [295/100000]  val_loss=-0.882111
Fine-tune [296/100000]  val_loss=-0.860475
Fine-tune [297/100000]  val_loss=-0.859975
Fine-tune [298/100000]  val_loss=-0.854564
Fine-tune [299/100000]  val_loss=-0.886520
Fine-tune [300/100000]  val_loss=-0.869144
Fine-tune [301/100000]  val_loss=-0.867965
Fine-tune [302/100000]  val_loss=-0.859493
Fine-tune [303/100000]  val_loss=-0.872350
Fine-tune [304/100000]  val_loss=-0.874696
Fine-tune [305/100000]  val_loss=-0.868482
Fine-tune [306/100000]  val_loss=-0.845558
Fine-tune [307/100000]  val_loss=-0.857356
Fine-tune [308/100000]  val_loss=-0.810239
Fine-tune [309/100000]  val_loss=-0.854508
Fine-tune [310/100000]  val_loss=-0.756808
Fine-tune [311/100000]  val_loss=-0.825712
Fine-tune [312/100000]  val_loss=-0.885067
Fine-tune [313/100000]  val_loss=-0.827887
Fine-tune [314/100000]  val_loss=-0.846312
Fine-tune [315/100000]  val_loss=-0.871341
Fine-tune [316/100000]  val_loss=-0.859772
Fine-tune [317/100000]  val_loss=-0.840502
Fine-tune [318/100000]  val_loss=-0.871837
Fine-tune [319/100000]  val_loss=-0.795930
Fine-tune [320/100000]  val_loss=-0.844442
Fine-tune [321/100000]  val_loss=-0.856788
Fine-tune [322/100000]  val_loss=-0.849049
Fine-tune [323/100000]  val_loss=-0.819039
Fine-tune [324/100000]  val_loss=-0.838894
Fine-tune [325/100000]  val_loss=-0.868674
Fine-tune [326/100000]  val_loss=-0.850238
Fine-tune [327/100000]  val_loss=-0.856883
Fine-tune [328/100000]  val_loss=-0.870064
Fine-tune [329/100000]  val_loss=-0.849099
Fine-tune [330/100000]  val_loss=-0.828149
Fine-tune [331/100000]  val_loss=-0.868326
Fine-tune [332/100000]  val_loss=-0.849595
Fine-tune [333/100000]  val_loss=-0.820918
Fine-tune [334/100000]  val_loss=-0.825698
Fine-tune [335/100000]  val_loss=-0.848285
Fine-tune [336/100000]  val_loss=-0.865335
Fine-tune [337/100000]  val_loss=-0.869699
Fine-tune [338/100000]  val_loss=-0.849848
Fine-tune [339/100000]  val_loss=-0.831894
Fine-tune [340/100000]  val_loss=-0.831099
Fine-tune [341/100000]  val_loss=-0.816135
Fine-tune [342/100000]  val_loss=-0.811722
Fine-tune [343/100000]  val_loss=-0.807688
Fine-tune [344/100000]  val_loss=-0.798535
Fine-tune [345/100000]  val_loss=-0.833598
Fine-tune [346/100000]  val_loss=-0.852498
Fine-tune [347/100000]  val_loss=-0.783993
Fine-tune [348/100000]  val_loss=-0.844118
Fine-tune [349/100000]  val_loss=-0.829028
Fine-tune [350/100000]  val_loss=-0.867778
Fine-tune [351/100000]  val_loss=-0.839651
Fine-tune [352/100000]  val_loss=-0.829568
Fine-tune [353/100000]  val_loss=-0.838186
Fine-tune [354/100000]  val_loss=-0.813652
Fine-tune [355/100000]  val_loss=-0.825998
Fine-tune [356/100000]  val_loss=-0.846299
Fine-tune [357/100000]  val_loss=-0.808421
Fine-tune [358/100000]  val_loss=-0.780533
Fine-tune [359/100000]  val_loss=-0.808746
Fine-tune [360/100000]  val_loss=-0.822762
Fine-tune [361/100000]  val_loss=-0.828476
Fine-tune [362/100000]  val_loss=-0.801459
Fine-tune [363/100000]  val_loss=-0.777415
Fine-tune [364/100000]  val_loss=-0.824362
Fine-tune [365/100000]  val_loss=-0.803147
Fine-tune [366/100000]  val_loss=-0.808201
Fine-tune [367/100000]  val_loss=-0.826918
Fine-tune [368/100000]  val_loss=-0.800979
Fine-tune [369/100000]  val_loss=-0.797473
Fine-tune [370/100000]  val_loss=-0.791678
Fine-tune [371/100000]  val_loss=-0.809052
Fine-tune [372/100000]  val_loss=-0.834107
Fine-tune [373/100000]  val_loss=-0.814368
Fine-tune [374/100000]  val_loss=-0.840165
Fine-tune [375/100000]  val_loss=-0.809657
Fine-tune [376/100000]  val_loss=-0.842922
Fine-tune [377/100000]  val_loss=-0.826844
Fine-tune [378/100000]  val_loss=-0.823024
Fine-tune [379/100000]  val_loss=-0.832654
Fine-tune [380/100000]  val_loss=-0.847874
Fine-tune [381/100000]  val_loss=-0.852616
Fine-tune [382/100000]  val_loss=-0.795989
Fine-tune [383/100000]  val_loss=-0.833642
Fine-tune [384/100000]  val_loss=-0.861016
Fine-tune [385/100000]  val_loss=-0.834275
Fine-tune [386/100000]  val_loss=-0.810661
Fine-tune [387/100000]  val_loss=-0.799269
Fine-tune [388/100000]  val_loss=-0.766578
Fine-tune [389/100000]  val_loss=-0.840357
Fine-tune [390/100000]  val_loss=-0.788605
Fine-tune [391/100000]  val_loss=-0.823384
Fine-tune [392/100000]  val_loss=-0.788260
Fine-tune [393/100000]  val_loss=-0.806136
Fine-tune [394/100000]  val_loss=-0.829768
Fine-tune [395/100000]  val_loss=-0.785029
Fine-tune [396/100000]  val_loss=-0.842871
Fine-tune [397/100000]  val_loss=-0.747349
Fine-tune [398/100000]  val_loss=-0.770225
Fine-tune [399/100000]  val_loss=-0.747420
Fine-tune [400/100000]  val_loss=-0.777804
Fine-tune [401/100000]  val_loss=-0.811799
Fine-tune [402/100000]  val_loss=-0.772209
Fine-tune [403/100000]  val_loss=-0.756536
Fine-tune [404/100000]  val_loss=-0.768377
Fine-tune [405/100000]  val_loss=-0.757628
Fine-tune [406/100000]  val_loss=-0.735966
Fine-tune [407/100000]  val_loss=-0.781916
Fine-tune [408/100000]  val_loss=-0.751433
Fine-tune [409/100000]  val_loss=-0.726504
Fine-tune [410/100000]  val_loss=-0.779247
Fine-tune [411/100000]  val_loss=-0.768008
Fine-tune [412/100000]  val_loss=-0.765508
Fine-tune [413/100000]  val_loss=-0.779068
Fine-tune [414/100000]  val_loss=-0.720922
Fine-tune [415/100000]  val_loss=-0.775864
Fine-tune [416/100000]  val_loss=-0.815064
Fine-tune [417/100000]  val_loss=-0.764841
Fine-tune [418/100000]  val_loss=-0.774558
Fine-tune [419/100000]  val_loss=-0.798212
Fine-tune [420/100000]  val_loss=-0.792017
Fine-tune [421/100000]  val_loss=-0.752996
Fine-tune [422/100000]  val_loss=-0.807205
Fine-tune [423/100000]  val_loss=-0.844509
Fine-tune [424/100000]  val_loss=-0.775496
Fine-tune [425/100000]  val_loss=-0.756924
Fine-tune [426/100000]  val_loss=-0.725379
Fine-tune [427/100000]  val_loss=-0.738393
Fine-tune [428/100000]  val_loss=-0.719612
Fine-tune [429/100000]  val_loss=-0.757606
Fine-tune [430/100000]  val_loss=-0.747645
Fine-tune [431/100000]  val_loss=-0.760827
Fine-tune [432/100000]  val_loss=-0.773125
Fine-tune [433/100000]  val_loss=-0.765882
Fine-tune [434/100000]  val_loss=-0.763959
Fine-tune [435/100000]  val_loss=-0.766196
Fine-tune [436/100000]  val_loss=-0.746231
Fine-tune [437/100000]  val_loss=-0.798271
Fine-tune [438/100000]  val_loss=-0.762659
Fine-tune [439/100000]  val_loss=-0.796365
Fine-tune [440/100000]  val_loss=-0.741588
Fine-tune [441/100000]  val_loss=-0.799371
Fine-tune [442/100000]  val_loss=-0.747677
Fine-tune [443/100000]  val_loss=-0.799980
Fine-tune [444/100000]  val_loss=-0.755933
Fine-tune [445/100000]  val_loss=-0.706363
Fine-tune [446/100000]  val_loss=-0.780531
Fine-tune [447/100000]  val_loss=-0.769928
Fine-tune [448/100000]  val_loss=-0.802275
Fine-tune [449/100000]  val_loss=-0.756854
Fine-tune [450/100000]  val_loss=-0.764850
Fine-tune [451/100000]  val_loss=-0.722626
Fine-tune [452/100000]  val_loss=-0.786566
Fine-tune [453/100000]  val_loss=-0.744270
Fine-tune [454/100000]  val_loss=-0.731387
Fine-tune [455/100000]  val_loss=-0.749271
Fine-tune [456/100000]  val_loss=-0.731197
Fine-tune [457/100000]  val_loss=-0.696150
Fine-tune [458/100000]  val_loss=-0.670864
Fine-tune [459/100000]  val_loss=-0.756680
Fine-tune [460/100000]  val_loss=-0.728135
Fine-tune [461/100000]  val_loss=-0.762428
Fine-tune [462/100000]  val_loss=-0.698707
Fine-tune [463/100000]  val_loss=-0.709109
Fine-tune [464/100000]  val_loss=-0.700792
Fine-tune [465/100000]  val_loss=-0.722861
Fine-tune [466/100000]  val_loss=-0.639948
Fine-tune [467/100000]  val_loss=-0.699449
Fine-tune [468/100000]  val_loss=-0.735845
Fine-tune [469/100000]  val_loss=-0.729607
Fine-tune [470/100000]  val_loss=-0.740549
Fine-tune [471/100000]  val_loss=-0.735029
Fine-tune [472/100000]  val_loss=-0.737801
Fine-tune [473/100000]  val_loss=-0.710469
Fine-tune [474/100000]  val_loss=-0.713750
Fine-tune [475/100000]  val_loss=-0.692732
Fine-tune [476/100000]  val_loss=-0.748411
Fine-tune [477/100000]  val_loss=-0.693462
Fine-tune [478/100000]  val_loss=-0.735971
Fine-tune [479/100000]  val_loss=-0.724362
Fine-tune [480/100000]  val_loss=-0.700948
Fine-tune [481/100000]  val_loss=-0.741228
Fine-tune [482/100000]  val_loss=-0.745341
Fine-tune [483/100000]  val_loss=-0.733720
Fine-tune [484/100000]  val_loss=-0.725539
Fine-tune [485/100000]  val_loss=-0.731008
Fine-tune [486/100000]  val_loss=-0.751490
Fine-tune [487/100000]  val_loss=-0.745724
Fine-tune [488/100000]  val_loss=-0.712314
Fine-tune [489/100000]  val_loss=-0.728872
Fine-tune [490/100000]  val_loss=-0.725879
Fine-tune [491/100000]  val_loss=-0.733734
Fine-tune [492/100000]  val_loss=-0.742057
Fine-tune [493/100000]  val_loss=-0.693678
Fine-tune [494/100000]  val_loss=-0.699591
Fine-tune [495/100000]  val_loss=-0.732405
Fine-tune [496/100000]  val_loss=-0.743470
Fine-tune [497/100000]  val_loss=-0.697250
Fine-tune [498/100000]  val_loss=-0.751976
Fine-tune [499/100000]  val_loss=-0.699637
Fine-tune [500/100000]  val_loss=-0.739703
Fine-tune [501/100000]  val_loss=-0.699324
Fine-tune [502/100000]  val_loss=-0.738867
Fine-tune [503/100000]  val_loss=-0.699813
Fine-tune [504/100000]  val_loss=-0.678076
Fine-tune [505/100000]  val_loss=-0.692298
Fine-tune [506/100000]  val_loss=-0.721452
Fine-tune [507/100000]  val_loss=-0.729340
Fine-tune [508/100000]  val_loss=-0.703092
Fine-tune [509/100000]  val_loss=-0.715418
Fine-tune [510/100000]  val_loss=-0.773381
Fine-tune [511/100000]  val_loss=-0.726581
Fine-tune [512/100000]  val_loss=-0.709026
Fine-tune [513/100000]  val_loss=-0.648002
Fine-tune [514/100000]  val_loss=-0.708963
Fine-tune [515/100000]  val_loss=-0.693981
Fine-tune [516/100000]  val_loss=-0.723506
Fine-tune [517/100000]  val_loss=-0.701099
Fine-tune [518/100000]  val_loss=-0.637584
Fine-tune [519/100000]  val_loss=-0.689192
Fine-tune [520/100000]  val_loss=-0.664905
Fine-tune [521/100000]  val_loss=-0.650347
Fine-tune [522/100000]  val_loss=-0.686974
Fine-tune [523/100000]  val_loss=-0.654214
Fine-tune [524/100000]  val_loss=-0.715656
Fine-tune [525/100000]  val_loss=-0.712677
Fine-tune [526/100000]  val_loss=-0.660825
Fine-tune [527/100000]  val_loss=-0.681814
Fine-tune [528/100000]  val_loss=-0.658969
Fine-tune [529/100000]  val_loss=-0.641678
Fine-tune [530/100000]  val_loss=-0.704645
Fine-tune [531/100000]  val_loss=-0.681020
Fine-tune [532/100000]  val_loss=-0.645757
Fine-tune [533/100000]  val_loss=-0.665041
Fine-tune [534/100000]  val_loss=-0.687965
Fine-tune [535/100000]  val_loss=-0.723256
Fine-tune [536/100000]  val_loss=-0.736842
Fine-tune [537/100000]  val_loss=-0.661829
Fine-tune [538/100000]  val_loss=-0.721448
Fine-tune [539/100000]  val_loss=-0.743599
Fine-tune [540/100000]  val_loss=-0.715590
Fine-tune [541/100000]  val_loss=-0.686683
Fine-tune [542/100000]  val_loss=-0.700048
Fine-tune [543/100000]  val_loss=-0.661807
Fine-tune [544/100000]  val_loss=-0.689487
Fine-tune [545/100000]  val_loss=-0.686599
Fine-tune [546/100000]  val_loss=-0.683320
Fine-tune [547/100000]  val_loss=-0.709115
Fine-tune [548/100000]  val_loss=-0.719959
Fine-tune [549/100000]  val_loss=-0.719304
Fine-tune [550/100000]  val_loss=-0.728061
Fine-tune [551/100000]  val_loss=-0.713003
Fine-tune [552/100000]  val_loss=-0.683671
Fine-tune [553/100000]  val_loss=-0.711040
Fine-tune [554/100000]  val_loss=-0.667267
Fine-tune [555/100000]  val_loss=-0.645277
Fine-tune [556/100000]  val_loss=-0.680523
Fine-tune [557/100000]  val_loss=-0.699718
Fine-tune [558/100000]  val_loss=-0.708541
Fine-tune [559/100000]  val_loss=-0.679561
Fine-tune [560/100000]  val_loss=-0.652968
Fine-tune [561/100000]  val_loss=-0.657362
Fine-tune [562/100000]  val_loss=-0.722671
Fine-tune [563/100000]  val_loss=-0.720523
Fine-tune [564/100000]  val_loss=-0.745721
Fine-tune [565/100000]  val_loss=-0.704787
Fine-tune [566/100000]  val_loss=-0.685504
Fine-tune [567/100000]  val_loss=-0.718545
Fine-tune [568/100000]  val_loss=-0.711059
Fine-tune [569/100000]  val_loss=-0.692922
Fine-tune [570/100000]  val_loss=-0.717993
Fine-tune [571/100000]  val_loss=-0.700845
Fine-tune [572/100000]  val_loss=-0.735990
Fine-tune [573/100000]  val_loss=-0.696265
Fine-tune [574/100000]  val_loss=-0.679459
Fine-tune [575/100000]  val_loss=-0.651355
Fine-tune [576/100000]  val_loss=-0.654609
Fine-tune [577/100000]  val_loss=-0.626246
Fine-tune [578/100000]  val_loss=-0.625506
Fine-tune [579/100000]  val_loss=-0.647559
Fine-tune [580/100000]  val_loss=-0.662942
Fine-tune [581/100000]  val_loss=-0.692310
Fine-tune [582/100000]  val_loss=-0.696712
Fine-tune [583/100000]  val_loss=-0.706748
Fine-tune [584/100000]  val_loss=-0.700192
Fine-tune [585/100000]  val_loss=-0.674838
Fine-tune [586/100000]  val_loss=-0.638278
Fine-tune [587/100000]  val_loss=-0.669012
Fine-tune [588/100000]  val_loss=-0.668670
Fine-tune [589/100000]  val_loss=-0.694146
Fine-tune [590/100000]  val_loss=-0.646093
Fine-tune [591/100000]  val_loss=-0.633374
Fine-tune [592/100000]  val_loss=-0.630018
Fine-tune [593/100000]  val_loss=-0.654085
Fine-tune [594/100000]  val_loss=-0.636502
Fine-tune [595/100000]  val_loss=-0.672183
Fine-tune [596/100000]  val_loss=-0.646389
Fine-tune [597/100000]  val_loss=-0.653462
Fine-tune [598/100000]  val_loss=-0.693405
Fine-tune [599/100000]  val_loss=-0.666581
Fine-tune [600/100000]  val_loss=-0.659229
Fine-tune [601/100000]  val_loss=-0.681528
Fine-tune [602/100000]  val_loss=-0.698515
Fine-tune [603/100000]  val_loss=-0.672974
Fine-tune [604/100000]  val_loss=-0.696756
Fine-tune [605/100000]  val_loss=-0.608221
Fine-tune [606/100000]  val_loss=-0.676292
Fine-tune [607/100000]  val_loss=-0.624147
Fine-tune [608/100000]  val_loss=-0.665956
Fine-tune [609/100000]  val_loss=-0.706384
Fine-tune [610/100000]  val_loss=-0.648152
Fine-tune [611/100000]  val_loss=-0.614618
Fine-tune [612/100000]  val_loss=-0.623997
Fine-tune [613/100000]  val_loss=-0.611728
Fine-tune [614/100000]  val_loss=-0.666255
Fine-tune [615/100000]  val_loss=-0.635549
Fine-tune [616/100000]  val_loss=-0.638582
Fine-tune [617/100000]  val_loss=-0.660796
Fine-tune [618/100000]  val_loss=-0.662225
Fine-tune [619/100000]  val_loss=-0.695400
Fine-tune [620/100000]  val_loss=-0.617168
Fine-tune [621/100000]  val_loss=-0.632769
Fine-tune [622/100000]  val_loss=-0.637576
Fine-tune [623/100000]  val_loss=-0.648093
Fine-tune [624/100000]  val_loss=-0.663333
Fine-tune [625/100000]  val_loss=-0.654883
Fine-tune [626/100000]  val_loss=-0.642555
Fine-tune [627/100000]  val_loss=-0.656792
Fine-tune [628/100000]  val_loss=-0.674694
Fine-tune [629/100000]  val_loss=-0.638829
Fine-tune [630/100000]  val_loss=-0.643348
Fine-tune [631/100000]  val_loss=-0.686599
Fine-tune [632/100000]  val_loss=-0.667894
Fine-tune [633/100000]  val_loss=-0.620565
Fine-tune [634/100000]  val_loss=-0.632405
Fine-tune [635/100000]  val_loss=-0.605214
Fine-tune [636/100000]  val_loss=-0.573486
Fine-tune [637/100000]  val_loss=-0.627078
Fine-tune [638/100000]  val_loss=-0.657353
Fine-tune [639/100000]  val_loss=-0.609222
Fine-tune [640/100000]  val_loss=-0.670247
Fine-tune [641/100000]  val_loss=-0.647322
Fine-tune [642/100000]  val_loss=-0.611380
Fine-tune [643/100000]  val_loss=-0.634857
Fine-tune [644/100000]  val_loss=-0.627925
Fine-tune [645/100000]  val_loss=-0.682118
Fine-tune [646/100000]  val_loss=-0.631258
Fine-tune [647/100000]  val_loss=-0.567998
Fine-tune [648/100000]  val_loss=-0.632718
Fine-tune [649/100000]  val_loss=-0.628578
Fine-tune [650/100000]  val_loss=-0.571872
Fine-tune [651/100000]  val_loss=-0.606597
Fine-tune [652/100000]  val_loss=-0.636532
Fine-tune [653/100000]  val_loss=-0.538102
Fine-tune [654/100000]  val_loss=-0.626896
Fine-tune [655/100000]  val_loss=-0.602360
Fine-tune [656/100000]  val_loss=-0.600401
Fine-tune [657/100000]  val_loss=-0.614764
Fine-tune [658/100000]  val_loss=-0.619618
Fine-tune [659/100000]  val_loss=-0.598465
Fine-tune [660/100000]  val_loss=-0.660338
Fine-tune [661/100000]  val_loss=-0.635356
Fine-tune [662/100000]  val_loss=-0.612318
Fine-tune [663/100000]  val_loss=-0.592190
Fine-tune [664/100000]  val_loss=-0.566390
Fine-tune [665/100000]  val_loss=-0.568711
Fine-tune [666/100000]  val_loss=-0.567915
Fine-tune [667/100000]  val_loss=-0.620920
Fine-tune [668/100000]  val_loss=-0.637921
Fine-tune [669/100000]  val_loss=-0.577206
Fine-tune [670/100000]  val_loss=-0.593571
Fine-tune [671/100000]  val_loss=-0.589254
Fine-tune [672/100000]  val_loss=-0.527709
Fine-tune [673/100000]  val_loss=-0.577811
Fine-tune [674/100000]  val_loss=-0.642593
Fine-tune [675/100000]  val_loss=-0.588738
Fine-tune [676/100000]  val_loss=-0.646125
Fine-tune [677/100000]  val_loss=-0.600524
Fine-tune [678/100000]  val_loss=-0.618922
Fine-tune [679/100000]  val_loss=-0.628333
Fine-tune [680/100000]  val_loss=-0.583326
Fine-tune [681/100000]  val_loss=-0.572090
Fine-tune [682/100000]  val_loss=-0.583387
Fine-tune [683/100000]  val_loss=-0.630961
Fine-tune [684/100000]  val_loss=-0.583281
Fine-tune [685/100000]  val_loss=-0.552924
Fine-tune [686/100000]  val_loss=-0.616800
Fine-tune [687/100000]  val_loss=-0.574000
Fine-tune [688/100000]  val_loss=-0.587667
Fine-tune [689/100000]  val_loss=-0.553560
Fine-tune [690/100000]  val_loss=-0.582484
Fine-tune [691/100000]  val_loss=-0.584664
Fine-tune [692/100000]  val_loss=-0.543339
Fine-tune [693/100000]  val_loss=-0.635408
Fine-tune [694/100000]  val_loss=-0.608975
Fine-tune [695/100000]  val_loss=-0.545464
Fine-tune [696/100000]  val_loss=-0.567482
Fine-tune [697/100000]  val_loss=-0.588995
Fine-tune [698/100000]  val_loss=-0.649887
Fine-tune [699/100000]  val_loss=-0.601666
Fine-tune [700/100000]  val_loss=-0.564892
Fine-tune [701/100000]  val_loss=-0.565098
Fine-tune [702/100000]  val_loss=-0.613770
Fine-tune [703/100000]  val_loss=-0.594358
Fine-tune [704/100000]  val_loss=-0.527608
Fine-tune [705/100000]  val_loss=-0.544523
Fine-tune [706/100000]  val_loss=-0.560673
Fine-tune [707/100000]  val_loss=-0.579078
Fine-tune [708/100000]  val_loss=-0.510842
Fine-tune [709/100000]  val_loss=-0.579997
Fine-tune [710/100000]  val_loss=-0.564323
Fine-tune [711/100000]  val_loss=-0.537795
Fine-tune [712/100000]  val_loss=-0.567430
Fine-tune [713/100000]  val_loss=-0.589143
Fine-tune [714/100000]  val_loss=-0.535080
Fine-tune [715/100000]  val_loss=-0.543700
Fine-tune [716/100000]  val_loss=-0.576727
Fine-tune [717/100000]  val_loss=-0.544741
Fine-tune [718/100000]  val_loss=-0.567882
Fine-tune [719/100000]  val_loss=-0.564241
Fine-tune [720/100000]  val_loss=-0.502806
Fine-tune [721/100000]  val_loss=-0.483898
Fine-tune [722/100000]  val_loss=-0.544188
Fine-tune [723/100000]  val_loss=-0.589927
Fine-tune [724/100000]  val_loss=-0.587999
Fine-tune [725/100000]  val_loss=-0.617901
Fine-tune [726/100000]  val_loss=-0.586682
Fine-tune [727/100000]  val_loss=-0.584107
Fine-tune [728/100000]  val_loss=-0.565683
Fine-tune [729/100000]  val_loss=-0.589015
Fine-tune [730/100000]  val_loss=-0.610911
Fine-tune [731/100000]  val_loss=-0.616002
Fine-tune [732/100000]  val_loss=-0.568940
Fine-tune [733/100000]  val_loss=-0.499552
Fine-tune [734/100000]  val_loss=-0.555020
Fine-tune [735/100000]  val_loss=-0.477478
Fine-tune [736/100000]  val_loss=-0.522632
Fine-tune [737/100000]  val_loss=-0.542584
Fine-tune [738/100000]  val_loss=-0.562310
Fine-tune [739/100000]  val_loss=-0.553942
Fine-tune [740/100000]  val_loss=-0.559893
Fine-tune [741/100000]  val_loss=-0.553856
Fine-tune [742/100000]  val_loss=-0.554437
Fine-tune [743/100000]  val_loss=-0.609671
Fine-tune [744/100000]  val_loss=-0.653715
Fine-tune [745/100000]  val_loss=-0.643025
Fine-tune [746/100000]  val_loss=-0.573593
Fine-tune [747/100000]  val_loss=-0.560838
Fine-tune [748/100000]  val_loss=-0.539696
Fine-tune [749/100000]  val_loss=-0.532969
Fine-tune [750/100000]  val_loss=-0.511892
Fine-tune [751/100000]  val_loss=-0.502340
Fine-tune [752/100000]  val_loss=-0.565958
Fine-tune [753/100000]  val_loss=-0.606539
Fine-tune [754/100000]  val_loss=-0.525920
Fine-tune [755/100000]  val_loss=-0.498162
Fine-tune [756/100000]  val_loss=-0.566577
Fine-tune [757/100000]  val_loss=-0.568113
Fine-tune [758/100000]  val_loss=-0.523545
Fine-tune [759/100000]  val_loss=-0.563159
Fine-tune [760/100000]  val_loss=-0.522676
Fine-tune [761/100000]  val_loss=-0.529001
Fine-tune [762/100000]  val_loss=-0.513161
Fine-tune [763/100000]  val_loss=-0.560213
Fine-tune [764/100000]  val_loss=-0.482646
Fine-tune [765/100000]  val_loss=-0.506682
Fine-tune [766/100000]  val_loss=-0.508804
Fine-tune [767/100000]  val_loss=-0.513519
Fine-tune [768/100000]  val_loss=-0.507428
Fine-tune [769/100000]  val_loss=-0.490901
Fine-tune [770/100000]  val_loss=-0.552345
Fine-tune [771/100000]  val_loss=-0.572723
Fine-tune [772/100000]  val_loss=-0.561281
Fine-tune [773/100000]  val_loss=-0.563245
Fine-tune [774/100000]  val_loss=-0.541939
Fine-tune [775/100000]  val_loss=-0.517122
Fine-tune [776/100000]  val_loss=-0.527383
Fine-tune [777/100000]  val_loss=-0.511386
Fine-tune [778/100000]  val_loss=-0.553204
Fine-tune [779/100000]  val_loss=-0.523257
Fine-tune [780/100000]  val_loss=-0.560317
Fine-tune [781/100000]  val_loss=-0.486441
Fine-tune [782/100000]  val_loss=-0.521557
Fine-tune [783/100000]  val_loss=-0.544569
Fine-tune [784/100000]  val_loss=-0.494485
Fine-tune [785/100000]  val_loss=-0.528536
Fine-tune [786/100000]  val_loss=-0.533767
Fine-tune [787/100000]  val_loss=-0.482999
Fine-tune [788/100000]  val_loss=-0.544210
Fine-tune [789/100000]  val_loss=-0.501490
Fine-tune [790/100000]  val_loss=-0.503162
Fine-tune [791/100000]  val_loss=-0.469309
Fine-tune [792/100000]  val_loss=-0.487111
Fine-tune [793/100000]  val_loss=-0.408807
Fine-tune [794/100000]  val_loss=-0.414186
Fine-tune [795/100000]  val_loss=-0.464777
Fine-tune [796/100000]  val_loss=-0.499656
Fine-tune [797/100000]  val_loss=-0.442795
Fine-tune [798/100000]  val_loss=-0.465119
Fine-tune [799/100000]  val_loss=-0.425453
Fine-tune [800/100000]  val_loss=-0.422523
Fine-tune [801/100000]  val_loss=-0.494774
Fine-tune [802/100000]  val_loss=-0.487424
Fine-tune [803/100000]  val_loss=-0.444633
Fine-tune [804/100000]  val_loss=-0.561430
Fine-tune [805/100000]  val_loss=-0.547442
Fine-tune [806/100000]  val_loss=-0.499344
Fine-tune [807/100000]  val_loss=-0.530295
Fine-tune [808/100000]  val_loss=-0.489738
Fine-tune [809/100000]  val_loss=-0.504253
Fine-tune [810/100000]  val_loss=-0.511446
Fine-tune [811/100000]  val_loss=-0.509726
Fine-tune [812/100000]  val_loss=-0.498887
Fine-tune [813/100000]  val_loss=-0.476691
Fine-tune [814/100000]  val_loss=-0.473698
Fine-tune [815/100000]  val_loss=-0.462543
Fine-tune [816/100000]  val_loss=-0.470628
Fine-tune [817/100000]  val_loss=-0.519980
Fine-tune [818/100000]  val_loss=-0.461612
Fine-tune [819/100000]  val_loss=-0.516599
Fine-tune [820/100000]  val_loss=-0.529150
Fine-tune [821/100000]  val_loss=-0.439883
Fine-tune [822/100000]  val_loss=-0.416487
Fine-tune [823/100000]  val_loss=-0.437726
Fine-tune [824/100000]  val_loss=-0.483730
Fine-tune [825/100000]  val_loss=-0.447792
Fine-tune [826/100000]  val_loss=-0.449655
Fine-tune [827/100000]  val_loss=-0.443602
Fine-tune [828/100000]  val_loss=-0.488029
Fine-tune [829/100000]  val_loss=-0.449578
Fine-tune [830/100000]  val_loss=-0.453022
Fine-tune [831/100000]  val_loss=-0.494055
Fine-tune [832/100000]  val_loss=-0.499634
Fine-tune [833/100000]  val_loss=-0.484944
Fine-tune [834/100000]  val_loss=-0.443119
Fine-tune [835/100000]  val_loss=-0.494114
Fine-tune [836/100000]  val_loss=-0.502201
Fine-tune [837/100000]  val_loss=-0.446542
Fine-tune [838/100000]  val_loss=-0.453391
Fine-tune [839/100000]  val_loss=-0.451353
Fine-tune [840/100000]  val_loss=-0.479030
Fine-tune [841/100000]  val_loss=-0.443707
Fine-tune [842/100000]  val_loss=-0.475078
Fine-tune [843/100000]  val_loss=-0.447137
Fine-tune [844/100000]  val_loss=-0.402610
Fine-tune [845/100000]  val_loss=-0.434009
Fine-tune [846/100000]  val_loss=-0.488203
Fine-tune [847/100000]  val_loss=-0.437964
Fine-tune [848/100000]  val_loss=-0.461513
Fine-tune [849/100000]  val_loss=-0.472583
Fine-tune [850/100000]  val_loss=-0.385422
Fine-tune [851/100000]  val_loss=-0.485914
Fine-tune [852/100000]  val_loss=-0.449080
Fine-tune [853/100000]  val_loss=-0.455534
Fine-tune [854/100000]  val_loss=-0.499736
Fine-tune [855/100000]  val_loss=-0.417211
Fine-tune [856/100000]  val_loss=-0.428812
Fine-tune [857/100000]  val_loss=-0.493230
Fine-tune [858/100000]  val_loss=-0.453480
Fine-tune [859/100000]  val_loss=-0.433779
Fine-tune [860/100000]  val_loss=-0.442021
Fine-tune [861/100000]  val_loss=-0.424342
Fine-tune [862/100000]  val_loss=-0.409656
Fine-tune [863/100000]  val_loss=-0.424381
Fine-tune [864/100000]  val_loss=-0.527796
Fine-tune [865/100000]  val_loss=-0.501718
Fine-tune [866/100000]  val_loss=-0.392525
Fine-tune [867/100000]  val_loss=-0.524803
Fine-tune [868/100000]  val_loss=-0.442918
Fine-tune [869/100000]  val_loss=-0.478625
Fine-tune [870/100000]  val_loss=-0.443522
Fine-tune [871/100000]  val_loss=-0.453554
Fine-tune [872/100000]  val_loss=-0.540146
Fine-tune [873/100000]  val_loss=-0.507366
Fine-tune [874/100000]  val_loss=-0.520282
Fine-tune [875/100000]  val_loss=-0.447452
Fine-tune [876/100000]  val_loss=-0.478158
Fine-tune [877/100000]  val_loss=-0.442559
Fine-tune [878/100000]  val_loss=-0.469883
Fine-tune [879/100000]  val_loss=-0.515558
Fine-tune [880/100000]  val_loss=-0.456017
Fine-tune [881/100000]  val_loss=-0.468976
Fine-tune [882/100000]  val_loss=-0.508338
Fine-tune [883/100000]  val_loss=-0.472193
Fine-tune [884/100000]  val_loss=-0.446186
Fine-tune [885/100000]  val_loss=-0.463917
Fine-tune [886/100000]  val_loss=-0.516438
Fine-tune [887/100000]  val_loss=-0.461891
Fine-tune [888/100000]  val_loss=-0.477299
Fine-tune [889/100000]  val_loss=-0.499514
Fine-tune [890/100000]  val_loss=-0.476624
Fine-tune [891/100000]  val_loss=-0.487388
Fine-tune [892/100000]  val_loss=-0.475866
Fine-tune [893/100000]  val_loss=-0.465361
Fine-tune [894/100000]  val_loss=-0.432140
Fine-tune [895/100000]  val_loss=-0.414704
Fine-tune [896/100000]  val_loss=-0.425103
Fine-tune [897/100000]  val_loss=-0.426745
Fine-tune [898/100000]  val_loss=-0.373285
Fine-tune [899/100000]  val_loss=-0.448711
Fine-tune [900/100000]  val_loss=-0.452330
Fine-tune [901/100000]  val_loss=-0.472925
Fine-tune [902/100000]  val_loss=-0.410767
Fine-tune [903/100000]  val_loss=-0.342700
Fine-tune [904/100000]  val_loss=-0.371650
Fine-tune [905/100000]  val_loss=-0.355558
Fine-tune [906/100000]  val_loss=-0.387386
Fine-tune [907/100000]  val_loss=-0.408984
Fine-tune [908/100000]  val_loss=-0.405635
Fine-tune [909/100000]  val_loss=-0.412836
Fine-tune [910/100000]  val_loss=-0.463143
Fine-tune [911/100000]  val_loss=-0.436610
Fine-tune [912/100000]  val_loss=-0.397982
Fine-tune [913/100000]  val_loss=-0.407066
Fine-tune [914/100000]  val_loss=-0.364226
Fine-tune [915/100000]  val_loss=-0.326330
Fine-tune [916/100000]  val_loss=-0.374982
Fine-tune [917/100000]  val_loss=-0.358321
Fine-tune [918/100000]  val_loss=-0.364881
Fine-tune [919/100000]  val_loss=-0.394183
Fine-tune [920/100000]  val_loss=-0.342533
Fine-tune [921/100000]  val_loss=-0.392419
Fine-tune [922/100000]  val_loss=-0.341569
Fine-tune [923/100000]  val_loss=-0.337525
Fine-tune [924/100000]  val_loss=-0.352627
Fine-tune [925/100000]  val_loss=-0.307872
Fine-tune [926/100000]  val_loss=-0.405862
Fine-tune [927/100000]  val_loss=-0.426975
Fine-tune [928/100000]  val_loss=-0.318641
Fine-tune [929/100000]  val_loss=-0.374298
Fine-tune [930/100000]  val_loss=-0.354220
Fine-tune [931/100000]  val_loss=-0.348059
Fine-tune [932/100000]  val_loss=-0.314480
Fine-tune [933/100000]  val_loss=-0.302410
Fine-tune [934/100000]  val_loss=-0.344933
Fine-tune [935/100000]  val_loss=-0.361441
Fine-tune [936/100000]  val_loss=-0.420426
Fine-tune [937/100000]  val_loss=-0.486608
Fine-tune [938/100000]  val_loss=-0.424861
Fine-tune [939/100000]  val_loss=-0.436411
Fine-tune [940/100000]  val_loss=-0.419070
Fine-tune [941/100000]  val_loss=-0.376713
Fine-tune [942/100000]  val_loss=-0.441294
Fine-tune [943/100000]  val_loss=-0.370716
Fine-tune [944/100000]  val_loss=-0.337289
Fine-tune [945/100000]  val_loss=-0.354068
Fine-tune [946/100000]  val_loss=-0.348943
Fine-tune [947/100000]  val_loss=-0.408042
Fine-tune [948/100000]  val_loss=-0.390257
Fine-tune [949/100000]  val_loss=-0.380536
Fine-tune [950/100000]  val_loss=-0.372332
Fine-tune [951/100000]  val_loss=-0.380002
Fine-tune [952/100000]  val_loss=-0.390563
Fine-tune [953/100000]  val_loss=-0.406866
Fine-tune [954/100000]  val_loss=-0.355306
Fine-tune [955/100000]  val_loss=-0.351635
Fine-tune [956/100000]  val_loss=-0.374262
Fine-tune [957/100000]  val_loss=-0.345404
Fine-tune [958/100000]  val_loss=-0.355801
Fine-tune [959/100000]  val_loss=-0.296576
Fine-tune [960/100000]  val_loss=-0.319705
Fine-tune [961/100000]  val_loss=-0.287107
Fine-tune [962/100000]  val_loss=-0.284256
Fine-tune [963/100000]  val_loss=-0.376749
Fine-tune [964/100000]  val_loss=-0.373100
Fine-tune [965/100000]  val_loss=-0.391869
Fine-tune [966/100000]  val_loss=-0.286709
Fine-tune [967/100000]  val_loss=-0.344041
Fine-tune [968/100000]  val_loss=-0.362175
Fine-tune [969/100000]  val_loss=-0.344167
Fine-tune [970/100000]  val_loss=-0.351329
Fine-tune [971/100000]  val_loss=-0.410450
Fine-tune [972/100000]  val_loss=-0.380672
Fine-tune [973/100000]  val_loss=-0.391238
Fine-tune [974/100000]  val_loss=-0.435389
Fine-tune [975/100000]  val_loss=-0.411212
Fine-tune [976/100000]  val_loss=-0.442757
Fine-tune [977/100000]  val_loss=-0.468434
Fine-tune [978/100000]  val_loss=-0.404944
Fine-tune [979/100000]  val_loss=-0.353461
Fine-tune [980/100000]  val_loss=-0.314175
Fine-tune [981/100000]  val_loss=-0.355334
Fine-tune [982/100000]  val_loss=-0.333257
Fine-tune [983/100000]  val_loss=-0.382915
Fine-tune [984/100000]  val_loss=-0.288420
Fine-tune [985/100000]  val_loss=-0.353536
Fine-tune [986/100000]  val_loss=-0.335979
Fine-tune [987/100000]  val_loss=-0.348925
Fine-tune [988/100000]  val_loss=-0.352422
Fine-tune [989/100000]  val_loss=-0.351476
Fine-tune [990/100000]  val_loss=-0.343002
Fine-tune [991/100000]  val_loss=-0.334362
Fine-tune [992/100000]  val_loss=-0.370856
Fine-tune [993/100000]  val_loss=-0.349362
Fine-tune [994/100000]  val_loss=-0.389461
Fine-tune [995/100000]  val_loss=-0.379295
Fine-tune [996/100000]  val_loss=-0.352148
Fine-tune [997/100000]  val_loss=-0.389982
Fine-tune [998/100000]  val_loss=-0.419755
Fine-tune [999/100000]  val_loss=-0.359957
Fine-tune [1000/100000]  val_loss=-0.383402
Fine-tune [1001/100000]  val_loss=-0.426439
Fine-tune [1002/100000]  val_loss=-0.414229
Fine-tune [1003/100000]  val_loss=-0.351718
Fine-tune [1004/100000]  val_loss=-0.436792
Fine-tune [1005/100000]  val_loss=-0.426321
Fine-tune [1006/100000]  val_loss=-0.431384
Fine-tune [1007/100000]  val_loss=-0.447543
Fine-tune [1008/100000]  val_loss=-0.448312
Fine-tune [1009/100000]  val_loss=-0.366409
Fine-tune [1010/100000]  val_loss=-0.464455
Fine-tune [1011/100000]  val_loss=-0.454241
Fine-tune [1012/100000]  val_loss=-0.434616
Fine-tune [1013/100000]  val_loss=-0.405817
Fine-tune [1014/100000]  val_loss=-0.392423
Fine-tune [1015/100000]  val_loss=-0.400985
Fine-tune [1016/100000]  val_loss=-0.390293
Fine-tune [1017/100000]  val_loss=-0.353229
Fine-tune [1018/100000]  val_loss=-0.344303
Fine-tune [1019/100000]  val_loss=-0.315403
Fine-tune [1020/100000]  val_loss=-0.284401
Fine-tune [1021/100000]  val_loss=-0.332077
Fine-tune [1022/100000]  val_loss=-0.346117
Fine-tune [1023/100000]  val_loss=-0.353029
Fine-tune [1024/100000]  val_loss=-0.461520
Fine-tune [1025/100000]  val_loss=-0.382071
Fine-tune [1026/100000]  val_loss=-0.371965
Fine-tune [1027/100000]  val_loss=-0.375708
Fine-tune [1028/100000]  val_loss=-0.346181
Fine-tune [1029/100000]  val_loss=-0.346925
Fine-tune [1030/100000]  val_loss=-0.335176
Fine-tune [1031/100000]  val_loss=-0.352140
Fine-tune [1032/100000]  val_loss=-0.341304
Fine-tune [1033/100000]  val_loss=-0.354072
Fine-tune [1034/100000]  val_loss=-0.405469
Fine-tune [1035/100000]  val_loss=-0.366871
Fine-tune [1036/100000]  val_loss=-0.391969
Fine-tune [1037/100000]  val_loss=-0.339087
Fine-tune [1038/100000]  val_loss=-0.316466
Fine-tune [1039/100000]  val_loss=-0.321852
Fine-tune [1040/100000]  val_loss=-0.252003
Fine-tune [1041/100000]  val_loss=-0.229302
Fine-tune [1042/100000]  val_loss=-0.289389
Fine-tune [1043/100000]  val_loss=-0.275263
Fine-tune [1044/100000]  val_loss=-0.272887
Fine-tune [1045/100000]  val_loss=-0.341060
Fine-tune [1046/100000]  val_loss=-0.312045
Fine-tune [1047/100000]  val_loss=-0.353015
Fine-tune [1048/100000]  val_loss=-0.293515
Fine-tune [1049/100000]  val_loss=-0.364833
Fine-tune [1050/100000]  val_loss=-0.358377
Fine-tune [1051/100000]  val_loss=-0.410247
Fine-tune [1052/100000]  val_loss=-0.316712
Fine-tune [1053/100000]  val_loss=-0.332719
Fine-tune [1054/100000]  val_loss=-0.284389
Fine-tune [1055/100000]  val_loss=-0.296938
Fine-tune [1056/100000]  val_loss=-0.331782
Fine-tune [1057/100000]  val_loss=-0.324006
Fine-tune [1058/100000]  val_loss=-0.401043
Fine-tune [1059/100000]  val_loss=-0.324633
Fine-tune [1060/100000]  val_loss=-0.293859
Fine-tune [1061/100000]  val_loss=-0.313405
Fine-tune [1062/100000]  val_loss=-0.322171
Fine-tune [1063/100000]  val_loss=-0.341666
Fine-tune [1064/100000]  val_loss=-0.300854
Fine-tune [1065/100000]  val_loss=-0.285719
Fine-tune [1066/100000]  val_loss=-0.327963
Fine-tune [1067/100000]  val_loss=-0.292489
Fine-tune [1068/100000]  val_loss=-0.329510
Fine-tune [1069/100000]  val_loss=-0.332783
Fine-tune [1070/100000]  val_loss=-0.295255
Fine-tune [1071/100000]  val_loss=-0.337241
Fine-tune [1072/100000]  val_loss=-0.357683
Fine-tune [1073/100000]  val_loss=-0.294179
Fine-tune [1074/100000]  val_loss=-0.297819
Fine-tune [1075/100000]  val_loss=-0.309402
Fine-tune [1076/100000]  val_loss=-0.288617
Fine-tune [1077/100000]  val_loss=-0.265051
Fine-tune [1078/100000]  val_loss=-0.317042
Fine-tune [1079/100000]  val_loss=-0.269730
Fine-tune [1080/100000]  val_loss=-0.344232
Fine-tune [1081/100000]  val_loss=-0.327731
Fine-tune [1082/100000]  val_loss=-0.359639
Fine-tune [1083/100000]  val_loss=-0.337206
Fine-tune [1084/100000]  val_loss=-0.311141
Fine-tune [1085/100000]  val_loss=-0.347552
Fine-tune [1086/100000]  val_loss=-0.305143
Fine-tune [1087/100000]  val_loss=-0.346131
Fine-tune [1088/100000]  val_loss=-0.314924
Fine-tune [1089/100000]  val_loss=-0.271349
Fine-tune [1090/100000]  val_loss=-0.348880
Fine-tune [1091/100000]  val_loss=-0.289306
Fine-tune [1092/100000]  val_loss=-0.266305
Fine-tune [1093/100000]  val_loss=-0.290106
Fine-tune [1094/100000]  val_loss=-0.266448
Fine-tune [1095/100000]  val_loss=-0.228286
Fine-tune [1096/100000]  val_loss=-0.181376
Fine-tune [1097/100000]  val_loss=-0.253896
Fine-tune [1098/100000]  val_loss=-0.204141
Fine-tune [1099/100000]  val_loss=-0.280621
Fine-tune [1100/100000]  val_loss=-0.313019
Fine-tune [1101/100000]  val_loss=-0.309011
Fine-tune [1102/100000]  val_loss=-0.307251
Fine-tune [1103/100000]  val_loss=-0.343400
Fine-tune [1104/100000]  val_loss=-0.291012
Fine-tune [1105/100000]  val_loss=-0.237948
Fine-tune [1106/100000]  val_loss=-0.164725
Fine-tune [1107/100000]  val_loss=-0.229507
Fine-tune [1108/100000]  val_loss=-0.303990
Fine-tune [1109/100000]  val_loss=-0.240239
Fine-tune [1110/100000]  val_loss=-0.287001
Fine-tune [1111/100000]  val_loss=-0.288966
Fine-tune [1112/100000]  val_loss=-0.260162
Fine-tune [1113/100000]  val_loss=-0.245002
Fine-tune [1114/100000]  val_loss=-0.316572
Fine-tune [1115/100000]  val_loss=-0.352194
Fine-tune [1116/100000]  val_loss=-0.304141
Fine-tune [1117/100000]  val_loss=-0.283996
Fine-tune [1118/100000]  val_loss=-0.254836
Fine-tune [1119/100000]  val_loss=-0.297227
Fine-tune [1120/100000]  val_loss=-0.218782
Fine-tune [1121/100000]  val_loss=-0.247899
Fine-tune [1122/100000]  val_loss=-0.299871
Fine-tune [1123/100000]  val_loss=-0.256405
Fine-tune [1124/100000]  val_loss=-0.297975
Fine-tune [1125/100000]  val_loss=-0.281815
Fine-tune [1126/100000]  val_loss=-0.259733
Fine-tune [1127/100000]  val_loss=-0.275371
Fine-tune [1128/100000]  val_loss=-0.263039
Fine-tune [1129/100000]  val_loss=-0.291486
Fine-tune [1130/100000]  val_loss=-0.294764
Fine-tune [1131/100000]  val_loss=-0.265753
Fine-tune [1132/100000]  val_loss=-0.209938
Fine-tune [1133/100000]  val_loss=-0.174251
Fine-tune [1134/100000]  val_loss=-0.260103
Fine-tune [1135/100000]  val_loss=-0.253439
Fine-tune [1136/100000]  val_loss=-0.207715
Fine-tune [1137/100000]  val_loss=-0.279786
Fine-tune [1138/100000]  val_loss=-0.291908
Fine-tune [1139/100000]  val_loss=-0.281612
Fine-tune [1140/100000]  val_loss=-0.304644
Fine-tune [1141/100000]  val_loss=-0.279722
Fine-tune [1142/100000]  val_loss=-0.335344
Fine-tune [1143/100000]  val_loss=-0.349022
Fine-tune [1144/100000]  val_loss=-0.361804
Fine-tune [1145/100000]  val_loss=-0.306085
Fine-tune [1146/100000]  val_loss=-0.243277
Fine-tune [1147/100000]  val_loss=-0.255168
Fine-tune [1148/100000]  val_loss=-0.152119
Fine-tune [1149/100000]  val_loss=-0.189466
Fine-tune [1150/100000]  val_loss=-0.265365
Fine-tune [1151/100000]  val_loss=-0.282077
Fine-tune [1152/100000]  val_loss=-0.209715
Fine-tune [1153/100000]  val_loss=-0.268452
Fine-tune [1154/100000]  val_loss=-0.210985
Fine-tune [1155/100000]  val_loss=-0.214684
Fine-tune [1156/100000]  val_loss=-0.215226
Fine-tune [1157/100000]  val_loss=-0.208786
Fine-tune [1158/100000]  val_loss=-0.259176
Fine-tune [1159/100000]  val_loss=-0.242176
Fine-tune [1160/100000]  val_loss=-0.194566
Fine-tune [1161/100000]  val_loss=-0.188138
  -> 验证未改进 1000 次，早停。
[FINETUNE] 最佳验证损失=-0.987371 已保存。

--- 评估 [HD512_L4] ---

=== 本次试验参数 (Run Config) ===
opamp             : two_stage_opamp
hidden_dim        : 512
num_layers        : 4
lr_pretrain       : 0.003
epochs_pretrain   : 1000
patience_pretrain : 200
lr_finetune       : 0.0038
epochs_finetune   : 100000
patience_finetune : 1000
batch_a           : 128
batch_b           : 64
dropout_rate      : 0.2
alpha_r2          : 0.0
lambda_coral      : 0.1
seed              : 42
device            : cpu

--- [评估阶段] 开始计算指标 ---

=== 目标域验证集指标（物理单位）===
slewrate_pos    MSE=1.261e+14  MAE=8.431e+06  R2=0.7060
dc_gain         MSE=2.32e+07  MAE=1458  R2=0.4043
ugf             MSE=1.032e+14  MAE=6.392e+06  R2=0.7666
phase_margin    MSE=153.6  MAE=9.32  R2=0.8662
cmrr            MSE=8.372e+11  MAE=8.955e+04  R2=0.0335

Avg  (all dims)   MSE=4.603e+13  MAE=2.983e+06  R2=0.5553
[OK] HD512_L4 -> r2_avg=0.5553, mae_avg=2.983e+06, mse_avg=4.603e+13
===== [HD512_L4] 训练完成 =====

[SUMMARY] 共 9 次试验，已写入: /home/mario1578347613/eda-for-transfer-learning-1/src/results/sweeps_B/two_stage_opamp/sweep_summary.csv

=== Top-3 by MAE_avg (lower is better) ===
 run_tag  hidden_dim  num_layers      mae_avg   r2_avg
HD512_L3         512           3 2.658034e+06 0.590376
HD256_L2         256           2 2.777744e+06 0.536180
HD128_L3         128           3 2.851741e+06 0.558771

=== Top-3 by R2_avg (higher is better) ===
 run_tag  hidden_dim  num_layers   r2_avg      mae_avg
HD512_L3         512           3 0.590376 2.658034e+06
HD128_L3         128           3 0.558771 2.851741e+06
HD512_L4         512           4 0.555315 2.982782e+06
